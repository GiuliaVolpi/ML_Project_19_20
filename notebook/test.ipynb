{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0, \"./\")\n",
    "\n",
    "from isanet.neural_network import MLPRegressor\n",
    "from isanet.model import Mlp\n",
    "from isanet.optimizer import SGD\n",
    "from isanet.utils.model_utils import printMSE, printAcc, plotMse, save_data, load_data\n",
    "from isanet.optimizer import EarlyStopping\n",
    "from isanet.model_selection import Kfold, GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test high level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'n_layer_units': [38], 'activation': 'sigmoid', 'kernel_regularizer': 0.0001, 'batch_size': None, 'max_epoch': 100, 'learning_rate': 0.014, 'momentum': 0.8, 'nesterov': True, 'early_stop': eps: 9e-05, patience: 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.170633367760731"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "dataset = np.genfromtxt('../CUP/ML-CUP19-TR_tr_vl.csv',delimiter=',')\n",
    "X_train = dataset[:1000,:-2]\n",
    "Y_train = dataset[:1000,-2:]\n",
    "    \n",
    "X_val = dataset[1000:,:-2]\n",
    "Y_val = dataset[1000:,-2:]\n",
    "\n",
    "param = {\n",
    "            \"n_layer_units\": [38], # con questo si specifica la topologia da provare\n",
    "            \"learning_rate\": 0.014,\n",
    "            \"momentum\": 0.8,\n",
    "            \"nesterov\": True,\n",
    "            \"kernel_regularizer\": 0.0001,\n",
    "            \"activation\": \"sigmoid\",\n",
    "            \"early_stop\": EarlyStopping(0.00009, 20),\n",
    "            \"max_epoch\": 100\n",
    "}\n",
    "model = MLPRegressor(X_train.shape[1], Y_train.shape[1], random_state = 42, verbose = 0, **param)\n",
    "print(model.get_params())\n",
    "model.fit(X_train, Y_train, X_val, Y_val)\n",
    "model.get_history()[\"val_loss_mse\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Kfold class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - generate k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1352, 20)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dataset = np.genfromtxt('../CUP/ML-CUP19-TR_tr_vl.csv',delimiter=',')\n",
    "X = dataset[:,:-2]\n",
    "Y = dataset[:,-2:]\n",
    "print(X.shape)\n",
    "kf = Kfold(n_splits=5, shuffle=True, random_state=1)\n",
    "print(kf.get_n_splits())\n",
    "split = kf.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "print(len(split[\"train\"][0]))\n",
    "print(len(split[\"val\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save and load k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = load_data(\"../CUP/4folds.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-f0a97ec20df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mdefault_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def test(grid):\n",
    "    for p in grid:\n",
    "        # Always sort the keys of a dictionary, for reproducibility\n",
    "        items = sorted(p.items())\n",
    "        if not items:\n",
    "           yield {}\n",
    "        else:\n",
    "            keys, values = zip(*items)\n",
    "            for v in product(*values):\n",
    "                params = dict(zip(keys, v))\n",
    "                yield params\n",
    "\n",
    "def product_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    for instance in itertools.product(*vals):\n",
    "        yield dict(zip(keys, instance))\n",
    "\n",
    "grid = {\n",
    "            \"n_units\": [(10, 20), (101, 201), (1,)], # con questo si specifica la topologia da provare\n",
    "            \"learning_rate\": [0.014, 0.017, 0.020],\n",
    "            \"momentum\": [0.8],\n",
    "            \"nesterov\": [False, True],\n",
    "            \"kernel_regularizer\": [0.0001, 0.0002, 0.0003],\n",
    "            \"activation\": [\"sigmoid\", \"relu\"],\n",
    "            \"early_stop\": [es]\n",
    "}\n",
    "\n",
    "default_grid = {\n",
    "            \"n_units\": [100], # con questo si specifica la topologia da provare\n",
    "            \"activation\": [\"relu\"],\n",
    "            \"kernel_regularizer\": [0.0001],\n",
    "\n",
    "            \"batch_size\": [None],\n",
    "            \"max_epoch\": [1000],\n",
    "            \"learning_rate\": [0.014, 0.017, 0.020],\n",
    "            \"momentum\": [0.8],\n",
    "            \"nesterov\": [False, True],\n",
    "            \"early_stop\": [es]\n",
    "}\n",
    "\n",
    "print(len(list(product_dict(**grid))))\n",
    "default_grid.update(grid)\n",
    "print(default_grid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Total Grid Search Iteration: 1, Total train: 4\n",
      "Start Grid Combination n. 1:\n",
      "fold: 1/4 - TR MSE: 1.7742 - VL MSE: 1.8391 - Time: 0:01:07.621529\n",
      "fold: 2/4 - TR MSE: 1.7601 - VL MSE: 2.0898 - Time: 0:01:02.396495\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-168899e0002c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m }\n\u001b[1;32m     46\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dev/repos/IsaNetNN/isanet/model_selection/model_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mfold_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0mfold_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfold_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/repos/IsaNetNN/isanet/neural_network.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, X_val, Y_val)\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"early_stop\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         verbose = self.verbose)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/repos/IsaNetNN/isanet/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, epochs, batch_size, validation_data, es, verbose)\u001b[0m\n\u001b[1;32m    155\u001b[0m                                 \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                                 es=es)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/repos/IsaNetNN/isanet/optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, model, epochs, X_train, Y_train, validation_data, batch_size, es, verbose)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# Update history with MSE, MEE, Accuracy, Time after each Epoach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_epoch_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_validation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/repos/IsaNetNN/isanet/optimizer.py\u001b[0m in \u001b[0;36m__get_epoch_history\u001b[0;34m(self, model, X_train, Y_train, validation_data, time)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mmse_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mmee_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         return {\"mse_train\": mse_train,\n",
      "\u001b[0;32m~/Dev/repos/IsaNetNN/isanet/metrics.py\u001b[0m in \u001b[0;36maccuracy_binary\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnegative\u001b[0m \u001b[0mfloating\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3257\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "dataset = np.genfromtxt('../CUP/ML-CUP19-TR_tr_vl.csv',delimiter=',')\n",
    "split = load_data(\"../CUP/4folds.index\")\n",
    "X_train = dataset[:,:-2]\n",
    "Y_train = dataset[:,-2:]\n",
    "\n",
    "es = EarlyStopping(0.00009, 20)\n",
    "\n",
    "\n",
    "mlp_r = MLPRegressor(X_train.shape[1], Y_train.shape[1])\n",
    "\n",
    "grid0 = {\n",
    "            \"n_layer_units\": [[120], [230]], # con questo si specifica la topologia da provare\n",
    "            \"learning_rate\": [0.026, 0.029],\n",
    "            \"max_epoch\": [13000],\n",
    "            \"momentum\": [0.7,  0.8],\n",
    "            \"nesterov\": [True],\n",
    "            \"kernel_regularizer\": [0.0001, 0.0004],\n",
    "            \"activation\": [\"sigmoid\"],\n",
    "            \"early_stop\": [es],\n",
    "}\n",
    "\n",
    "grid1 = {\n",
    "            \"n_layer_units\": [[120]], # con questo si specifica la topologia da provare\n",
    "            \"learning_rate\": [0.00026],\n",
    "            \"max_epoch\": [13000],\n",
    "            \"momentum\": [0.7],\n",
    "            \"nesterov\": [True],\n",
    "            \"kernel_regularizer\": [0.0001],\n",
    "            \"activation\": [\"relu\"],\n",
    "            \"early_stop\": [es],\n",
    "}\n",
    "\n",
    "grid2 = {\n",
    "            \"n_layer_units\": [[38]], # con questo si specifica la topologia da provare\n",
    "            \"learning_rate\": [0.014, 0.017],\n",
    "            \"max_epoch\": [13000],\n",
    "            \"momentum\": [0.8],\n",
    "            \"nesterov\": [True],\n",
    "            \"kernel_regularizer\": [0.0001],\n",
    "            \"activation\": [\"sigmoid\"],\n",
    "            \"early_stop\": [es],\n",
    "}\n",
    "gs = GridSearchCV(estimator=mlp_r, param_grid = grid1, cv = split, verbose=2)\n",
    "result = gs.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyper_param</th>\n",
       "      <th>fold_results</th>\n",
       "      <th>mean_train_mse</th>\n",
       "      <th>std_train_mse</th>\n",
       "      <th>mean_train_mee</th>\n",
       "      <th>std_train_mee</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>std_train_acc</th>\n",
       "      <th>mean_val_mse</th>\n",
       "      <th>std_val_mse</th>\n",
       "      <th>mean_val_mee</th>\n",
       "      <th>std_val_mee</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>std_val_acc</th>\n",
       "      <th>time_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n_layer_units': [120], 'learning_rate': 0.02...</td>\n",
       "      <td>{'train_mse': [0.5613512871135166, 0.703505986...</td>\n",
       "      <td>0.591431</td>\n",
       "      <td>0.066309</td>\n",
       "      <td>0.853634</td>\n",
       "      <td>0.04083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.021394</td>\n",
       "      <td>0.087621</td>\n",
       "      <td>1.112092</td>\n",
       "      <td>0.042161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>363.121159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         hyper_param  \\\n",
       "0  {'n_layer_units': [120], 'learning_rate': 0.02...   \n",
       "\n",
       "                                        fold_results  mean_train_mse  \\\n",
       "0  {'train_mse': [0.5613512871135166, 0.703505986...        0.591431   \n",
       "\n",
       "   std_train_mse  mean_train_mee  std_train_mee  mean_train_acc  \\\n",
       "0       0.066309        0.853634        0.04083             0.0   \n",
       "\n",
       "   std_train_acc  mean_val_mse  std_val_mse  mean_val_mee  std_val_mee  \\\n",
       "0            0.0      1.021394     0.087621      1.112092     0.042161   \n",
       "\n",
       "   mean_val_acc  std_val_acc  time_train  \n",
       "0           0.0          0.0  363.121159  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_mee</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_mee</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>init_weigth</th>\n",
       "      <th>final_weigth</th>\n",
       "      <th>fold_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.561351</td>\n",
       "      <td>0.829191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029656</td>\n",
       "      <td>1.106946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[-0.031221833168017993, -0.10759847373236685...</td>\n",
       "      <td>[[[1.622004934017362, -0.6911691621642565, -0....</td>\n",
       "      <td>124.927676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703506</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.140926</td>\n",
       "      <td>1.177466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[0.18678834030076547, -0.18352462390604052, ...</td>\n",
       "      <td>[[[-0.3911264134386995, -0.9064238538968712, 0...</td>\n",
       "      <td>51.745208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.569934</td>\n",
       "      <td>0.839759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893512</td>\n",
       "      <td>1.059661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[0.011053931864456579, -0.04102103884800304,...</td>\n",
       "      <td>[[[-0.7443862280740351, -1.1273987081367312, 4...</td>\n",
       "      <td>80.156019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.530933</td>\n",
       "      <td>0.822077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.021481</td>\n",
       "      <td>1.104296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[0.18628015854293406, -0.11387125121236806, ...</td>\n",
       "      <td>[[[-0.3497201536446918, 0.35647190238197224, 0...</td>\n",
       "      <td>106.241446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_mse  train_mee  train_acc   val_mse   val_mee  val_acc  \\\n",
       "0   0.561351   0.829191        0.0  1.029656  1.106946      0.0   \n",
       "1   0.703506   0.923510        0.0  1.140926  1.177466      0.0   \n",
       "2   0.569934   0.839759        0.0  0.893512  1.059661      0.0   \n",
       "3   0.530933   0.822077        0.0  1.021481  1.104296      0.0   \n",
       "\n",
       "                                         init_weigth  \\\n",
       "0  [[[-0.031221833168017993, -0.10759847373236685...   \n",
       "1  [[[0.18678834030076547, -0.18352462390604052, ...   \n",
       "2  [[[0.011053931864456579, -0.04102103884800304,...   \n",
       "3  [[[0.18628015854293406, -0.11387125121236806, ...   \n",
       "\n",
       "                                        final_weigth   fold_time  \n",
       "0  [[[1.622004934017362, -0.6911691621642565, -0....  124.927676  \n",
       "1  [[[-0.3911264134386995, -0.9064238538968712, 0...   51.745208  \n",
       "2  [[[-0.7443862280740351, -1.1273987081367312, 4...   80.156019  \n",
       "3  [[[-0.3497201536446918, 0.35647190238197224, 0...  106.241446  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df[\"fold_results\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1.7558383237405353+/-1.1612630049796557\n",
      "validation: 1.969284101474181+/-1.0290576778489717\n"
     ]
    }
   ],
   "source": [
    "kfold = load_data(\"../CUP/4folds.index\")\n",
    "n_unit = df[\"hyper_param\"][0][\"n_layer_units\"][0]\n",
    "lr = df[\"hyper_param\"][0][\"learning_rate\"]\n",
    "momentum = df[\"hyper_param\"][0][\"momentum\"]/2\n",
    "reg = df[\"hyper_param\"][0][\"kernel_regularizer\"]\n",
    "for train_index_fold, val_index_fold, w in zip(kfold[\"train\"], kfold[\"val\"], df[\"fold_results\"][0][\"init_weigth\"]):\n",
    "                    \n",
    "    X_train = dataset[train_index_fold,:-2]\n",
    "    Y_train = dataset[train_index_fold,-2:]\n",
    "\n",
    "    X_val = dataset[val_index_fold,:-2]\n",
    "    Y_val = dataset[val_index_fold,-2:]\n",
    "    \n",
    "    num_unit = n_unit\n",
    "    kernel_regularizer = reg\n",
    "    model = Mlp()\n",
    "    model.add(num_unit, activation=\"sigmoid\", input= 20, kernel_initializer = np.sqrt(6)/np.sqrt(num_unit + 20), kernel_regularizer = kernel_regularizer)\n",
    "    model.add(2, activation=\"linear\", kernel_initializer = np.sqrt(6)/np.sqrt(2 + num_unit), kernel_regularizer = kernel_regularizer)\n",
    "\n",
    "\n",
    "    model.set_optimizer(\n",
    "        SGD(\n",
    "            lr = lr,\n",
    "            momentum = momentum,\n",
    "            nesterov = False\n",
    "        )\n",
    "    )\n",
    "    model.weights = w\n",
    "    es = EarlyStopping(0.00009, 20)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train,\n",
    "                Y_train, \n",
    "                epochs=13000, \n",
    "                validation_data = [X_val, Y_val],\n",
    "                es = es,\n",
    "                verbose=0) \n",
    "\n",
    "    out = model.predict(X_train)\n",
    "    delta = Y_train - out\n",
    "    mean_tr_mse.append(np.mean(np.square(delta)))\n",
    "\n",
    "    outputNet = model.predict(X_val)\n",
    "    delta = Y_val - outputNet\n",
    "    mean_vl_mse.append(np.mean(np.square(delta)))\n",
    "\n",
    "    outputNet = model.predict(X_val)\n",
    "\n",
    "    out = model.predict(X_train)\n",
    "    delta = Y_train - out\n",
    "    mean_tr_mse.append(np.mean(np.square(delta)))\n",
    "\n",
    "    outputNet = model.predict(X_val)\n",
    "    delta = Y_val - outputNet\n",
    "    mean_vl_mse.append(np.mean(np.square(delta)))\n",
    "\n",
    "print(\"training: {}+/-{}\".format(np.mean(mean_tr_mse), np.std(mean_tr_mse)))\n",
    "print(\"validation: {}+/-{}\".format(np.mean(mean_vl_mse), np.std(mean_vl_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_mee</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_mee</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>init_weigth</th>\n",
       "      <th>final_weigth</th>\n",
       "      <th>fold_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.730083</td>\n",
       "      <td>0.947299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038045</td>\n",
       "      <td>1.106975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[-0.10998516269158107, -0.03474271985218419,...</td>\n",
       "      <td>[[[-0.01643337689075059, -1.2148934603607338, ...</td>\n",
       "      <td>17.389263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638482</td>\n",
       "      <td>0.889918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.205173</td>\n",
       "      <td>1.177304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[-0.20230808635709352, 0.16757201479997574, ...</td>\n",
       "      <td>[[[1.3820625334936396, -0.4969471144614831, 1....</td>\n",
       "      <td>27.567935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668010</td>\n",
       "      <td>0.911347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005068</td>\n",
       "      <td>1.141300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[0.31195745997992474, 0.07908460639642173, 0...</td>\n",
       "      <td>[[[-1.126429472053428, 1.3162840171884789, -0....</td>\n",
       "      <td>52.022505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707622</td>\n",
       "      <td>0.935678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911923</td>\n",
       "      <td>1.037854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[-0.14037858468976755, -0.09049152675502253,...</td>\n",
       "      <td>[[[-0.11832453694566324, 2.4419481243146293, -...</td>\n",
       "      <td>26.730980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.896949</td>\n",
       "      <td>1.052838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.093168</td>\n",
       "      <td>1.149470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[-0.3027322108995666, 0.16416642582688795, 0...</td>\n",
       "      <td>[[[-1.7961261592281033, -0.6740503420552622, -...</td>\n",
       "      <td>5.333829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_mse  train_mee  train_acc   val_mse   val_mee  val_acc  \\\n",
       "0   0.730083   0.947299        0.0  1.038045  1.106975      0.0   \n",
       "1   0.638482   0.889918        0.0  1.205173  1.177304      0.0   \n",
       "2   0.668010   0.911347        0.0  1.005068  1.141300      0.0   \n",
       "3   0.707622   0.935678        0.0  0.911923  1.037854      0.0   \n",
       "4   0.896949   1.052838        0.0  1.093168  1.149470      0.0   \n",
       "\n",
       "                                         init_weigth  \\\n",
       "0  [[[-0.10998516269158107, -0.03474271985218419,...   \n",
       "1  [[[-0.20230808635709352, 0.16757201479997574, ...   \n",
       "2  [[[0.31195745997992474, 0.07908460639642173, 0...   \n",
       "3  [[[-0.14037858468976755, -0.09049152675502253,...   \n",
       "4  [[[-0.3027322108995666, 0.16416642582688795, 0...   \n",
       "\n",
       "                                        final_weigth  fold_time  \n",
       "0  [[[-0.01643337689075059, -1.2148934603607338, ...  17.389263  \n",
       "1  [[[1.3820625334936396, -0.4969471144614831, 1....  27.567935  \n",
       "2  [[[-1.126429472053428, 1.3162840171884789, -0....  52.022505  \n",
       "3  [[[-0.11832453694566324, 2.4419481243146293, -...  26.730980  \n",
       "4  [[[-1.7961261592281033, -0.6740503420552622, -...   5.333829  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df[\"fold_results\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some test on k-folds cup datatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = np.genfromtxt('../CUP/ML-CUP19-TR_tr_vl.csv',delimiter=',')\n",
    "kfold = load_kfold(\"../CUP/4folds.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index_fold, val_index_fold in zip(kfold[\"train\"], kfold[\"val\"]):\n",
    "    X_train = TS[train_index_fold,:-2]\n",
    "    Y_train = TS[train_index_fold,-2:]\n",
    "    \n",
    "    X_val = TS[val_index_fold,:-2]\n",
    "    Y_val = TS[val_index_fold,-2:]\n",
    "\n",
    "    model = Mlp()\n",
    "    model.add(43, activation=\"sigmoid\", input= 20, kernel_initializer = 0.001, kernel_regularizer = 0.001)\n",
    "    model.add(2, activation=\"linear\", kernel_initializer = 0.001, kernel_regularizer = 0.0001)\n",
    "\n",
    "    model.set_optimizer(\n",
    "        SGD(\n",
    "            lr = 0.019,\n",
    "            momentum = 0.8,\n",
    "            nesterov = True\n",
    "        ))\n",
    "    # Batch\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train,\n",
    "                Y_train, \n",
    "                epochs=10000, \n",
    "                #batch_size=31,\n",
    "                validation_data = [X_val, Y_val],\n",
    "                verbose=0) \n",
    "\n",
    "    outputNet = model.predict(X_val)\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(model.history[\"loss_mse\"][-1])\n",
    "    print(model.history[\"val_loss_mse\"][-1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = list(range(35, 45+1)) \n",
    "lrs = list(np.arange(0.017, 0.021, 0.0004))\n",
    "momentus = list(np.arange(0.6, 0.9, 0.04))\n",
    "parameters = []\n",
    "means = []\n",
    "devs = []\n",
    "\n",
    "time_means = []\n",
    "total_grid_search_iteration = len(n_units)*len(lrs)*len(momentus)\n",
    "print(\"Total Grid Search Iteration: {}\".format(total_grid_search_iteration))\n",
    "estimated_time = (total_grid_search_iteration*4*45)/(60*60)\n",
    "print(\"Estimated time {}h\".format(estimated_time))\n",
    "i = 0\n",
    "for units in n_units:\n",
    "    for lr in lrs:\n",
    "        for momentum in momentus:\n",
    "            parameters.append([units, lr, momentum])\n",
    "            mean = []\n",
    "            start_time = time.time()\n",
    "            for train_index_fold, val_index_fold in zip(kfold[\"train\"], kfold[\"val\"]):\n",
    "                X_train = TS[train_index_fold,:-2]\n",
    "                Y_train = TS[train_index_fold,-2:]\n",
    "\n",
    "                X_val = TS[val_index_fold,:-2]\n",
    "                Y_val = TS[val_index_fold,-2:]\n",
    "\n",
    "                model = Mlp()\n",
    "                model.add(units, activation=\"sigmoid\", input= 20, kernel_initializer = 1/np.sqrt(20), kernel_regularizer = 0.001)\n",
    "                model.add(2, activation=\"linear\", kernel_initializer = 1/np.sqrt(20), kernel_regularizer = 0.0001)\n",
    "\n",
    "                model.set_optimizer(\n",
    "                    SGD(\n",
    "                        lr = lr,\n",
    "                        momentum = momentum,\n",
    "                        nesterov = True\n",
    "                    ))\n",
    "                # Batch\n",
    "                start_time = time.time()\n",
    "                model.fit(X_train,\n",
    "                            Y_train, \n",
    "                            epochs=10, \n",
    "                            #batch_size=31,\n",
    "                            validation_data = [X_val, Y_val],\n",
    "                            verbose=0) \n",
    "\n",
    "                mean.append(model.history[\"val_loss_mse\"][-1])\n",
    "            means.append(np.mean(mean))\n",
    "            devs.append(np.std(mean))\n",
    "            i+=1\n",
    "            time_means.append((time.time() - start_time))\n",
    "            remaining_time = (np.mean(time_means)*(total_grid_search_iteration-i))\n",
    "            print(\"It: {}/{} - mean: {} - std:{} | Remaining time: {}\".format(i,total_grid_search_iteration,means[-1],devs[-1],datetime.timedelta(seconds=remaining_time)))\n",
    "\n",
    "save_data(parameters, 'parameters.data')\n",
    "save_data(means, 'means.data')\n",
    "save_data(devs, 'devs.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - time: 0.0030 - loss_train: 155.4272188781142 - loss_val: 169.02272613503783\n",
      "Epoch: 2 - time: 0.0029 - loss_train: 58.059295461282666 - loss_val: 62.95695722104831\n",
      "Epoch: 3 - time: 0.0028 - loss_train: 23.103755227179455 - loss_val: 21.632791794947117\n",
      "Epoch: 4 - time: 0.0026 - loss_train: 76.93822825675481 - loss_val: 83.65676528526961\n",
      "Epoch: 5 - time: 0.0027 - loss_train: 78.53423232672654 - loss_val: 85.26045723506255\n",
      "Epoch: 6 - time: 0.0026 - loss_train: 25.974274657915313 - loss_val: 24.813131633462596\n",
      "Epoch: 7 - time: 0.0028 - loss_train: 17.629982625369564 - loss_val: 16.580521039930304\n",
      "Epoch: 8 - time: 0.0027 - loss_train: 21.514947793649494 - loss_val: 22.740603379402085\n",
      "Epoch: 9 - time: 0.0027 - loss_train: 25.526903358379997 - loss_val: 27.6447311228572\n",
      "Epoch: 10 - time: 0.0027 - loss_train: 24.885959713907003 - loss_val: 26.618985379486787\n",
      "Epoch: 11 - time: 0.0028 - loss_train: 20.16708639399942 - loss_val: 21.255373158574038\n",
      "Epoch: 12 - time: 0.0028 - loss_train: 15.490777038346055 - loss_val: 16.393203575442946\n",
      "Epoch: 13 - time: 0.0028 - loss_train: 14.007805043896246 - loss_val: 15.260657296777337\n",
      "Epoch: 14 - time: 0.0028 - loss_train: 15.287378517292979 - loss_val: 16.96138463778511\n",
      "Epoch: 15 - time: 0.0027 - loss_train: 16.30116389653768 - loss_val: 17.9492220189461\n",
      "Epoch: 16 - time: 0.0027 - loss_train: 14.803353470997154 - loss_val: 15.912205776245171\n",
      "Epoch: 17 - time: 0.0028 - loss_train: 11.513870811294511 - loss_val: 11.974287631154304\n",
      "Epoch: 18 - time: 0.0028 - loss_train: 8.98809386726365 - loss_val: 9.152442184587555\n",
      "Epoch: 19 - time: 0.0027 - loss_train: 8.802109032534023 - loss_val: 9.153794511626053\n",
      "Epoch: 20 - time: 0.0027 - loss_train: 10.168304025655932 - loss_val: 10.951026253622993\n",
      "Epoch: 21 - time: 0.0028 - loss_train: 11.046217900431229 - loss_val: 12.150122475126757\n",
      "Epoch: 22 - time: 0.0028 - loss_train: 10.207893640521345 - loss_val: 11.340211720908908\n",
      "Epoch: 23 - time: 0.0027 - loss_train: 8.18393362614595 - loss_val: 9.126796338617995\n",
      "Epoch: 24 - time: 0.0027 - loss_train: 6.4792419599465445 - loss_val: 7.217812543950762\n",
      "Epoch: 25 - time: 0.0027 - loss_train: 6.097081116401824 - loss_val: 6.757990663888293\n",
      "Epoch: 26 - time: 0.0028 - loss_train: 6.76979402048908 - loss_val: 7.471407982339376\n",
      "Epoch: 27 - time: 0.0028 - loss_train: 7.411116449274199 - loss_val: 8.165691533647333\n",
      "Epoch: 28 - time: 0.0028 - loss_train: 7.179502370314385 - loss_val: 7.909435208795014\n",
      "Epoch: 29 - time: 0.0028 - loss_train: 6.136416809204978 - loss_val: 6.761211924145121\n",
      "Epoch: 30 - time: 0.0028 - loss_train: 5.025980541385767 - loss_val: 5.531326335036205\n",
      "Epoch: 31 - time: 0.0028 - loss_train: 4.534627315873841 - loss_val: 4.970927443033217\n",
      "Epoch: 32 - time: 0.0028 - loss_train: 4.71768195581526 - loss_val: 5.141541743282936\n",
      "Epoch: 33 - time: 0.0028 - loss_train: 5.035598096651081 - loss_val: 5.450226668431189\n",
      "Epoch: 34 - time: 0.0028 - loss_train: 4.943038377532897 - loss_val: 5.299194047545065\n",
      "Epoch: 35 - time: 0.0027 - loss_train: 4.413914808627511 - loss_val: 4.671136168741299\n",
      "Epoch: 36 - time: 0.0028 - loss_train: 3.8516732096663113 - loss_val: 4.0263760724767605\n",
      "Epoch: 37 - time: 0.0027 - loss_train: 3.5913107765164485 - loss_val: 3.740655546025468\n",
      "Epoch: 38 - time: 0.0027 - loss_train: 3.6018975192307687 - loss_val: 3.7716938125209207\n",
      "Epoch: 39 - time: 0.0027 - loss_train: 3.6280438114943143 - loss_val: 3.8227071028756505\n",
      "Epoch: 40 - time: 0.0028 - loss_train: 3.497747555931333 - loss_val: 3.6924750665900565\n",
      "Epoch: 41 - time: 0.0027 - loss_train: 3.258927939395414 - loss_val: 3.433039681952895\n",
      "Epoch: 42 - time: 0.0027 - loss_train: 3.0664735954542053 - loss_val: 3.2239545777028136\n",
      "Epoch: 43 - time: 0.0030 - loss_train: 2.9901144254418344 - loss_val: 3.1479351523172974\n",
      "Epoch: 44 - time: 0.0029 - loss_train: 2.9623826661086823 - loss_val: 3.1250314967882193\n",
      "Epoch: 45 - time: 0.0028 - loss_train: 2.8939669550282123 - loss_val: 3.047926884380984\n",
      "Epoch: 46 - time: 0.0028 - loss_train: 2.7812634915593484 - loss_val: 2.9100278248314453\n",
      "Epoch: 47 - time: 0.0027 - loss_train: 2.683846887017217 - loss_val: 2.7812609346411277\n",
      "Epoch: 48 - time: 0.0027 - loss_train: 2.634333399024366 - loss_val: 2.7048501652379637\n",
      "Epoch: 49 - time: 0.0028 - loss_train: 2.604543924044645 - loss_val: 2.6563367383117713\n",
      "Epoch: 50 - time: 0.0028 - loss_train: 2.5538947371788674 - loss_val: 2.5952067525640765\n",
      "Epoch: 51 - time: 0.0028 - loss_train: 2.481817637692793 - loss_val: 2.522165724387685\n",
      "Epoch: 52 - time: 0.0028 - loss_train: 2.4203170571667236 - loss_val: 2.470433994070673\n",
      "Epoch: 53 - time: 0.0028 - loss_train: 2.389016959063591 - loss_val: 2.4564283596300887\n",
      "Epoch: 54 - time: 0.0028 - loss_train: 2.373977620396134 - loss_val: 2.458458379198683\n",
      "Epoch: 55 - time: 0.0028 - loss_train: 2.350040572858241 - loss_val: 2.4441416008785586\n",
      "Epoch: 56 - time: 0.0028 - loss_train: 2.311558200242385 - loss_val: 2.405538211340881\n",
      "Epoch: 57 - time: 0.0027 - loss_train: 2.2743475007697143 - loss_val: 2.360504299174886\n",
      "Epoch: 58 - time: 0.0027 - loss_train: 2.2527366353858156 - loss_val: 2.3261292747596736\n",
      "Epoch: 59 - time: 0.0028 - loss_train: 2.2432225044685907 - loss_val: 2.300600765098224\n",
      "Epoch: 60 - time: 0.0027 - loss_train: 2.2318674459519854 - loss_val: 2.2720916935941213\n",
      "Epoch: 61 - time: 0.0027 - loss_train: 2.2116410096857897 - loss_val: 2.23768688538015\n",
      "Epoch: 62 - time: 0.0027 - loss_train: 2.1878707669584756 - loss_val: 2.2074279189328787\n",
      "Epoch: 63 - time: 0.0027 - loss_train: 2.1687834533519097 - loss_val: 2.191579707173775\n",
      "Epoch: 64 - time: 0.0028 - loss_train: 2.1555831859418126 - loss_val: 2.1891504730042226\n",
      "Epoch: 65 - time: 0.0028 - loss_train: 2.1431293824774382 - loss_val: 2.190263042024383\n",
      "Epoch: 66 - time: 0.0028 - loss_train: 2.1274416093387774 - loss_val: 2.186670299136329\n",
      "Epoch: 67 - time: 0.0028 - loss_train: 2.109731204411777 - loss_val: 2.1773719064443404\n",
      "Epoch: 68 - time: 0.0028 - loss_train: 2.093415753218913 - loss_val: 2.1651628479919762\n",
      "Epoch: 69 - time: 0.0027 - loss_train: 2.079481847508389 - loss_val: 2.1509921658207207\n",
      "Epoch: 70 - time: 0.0028 - loss_train: 2.066051291723788 - loss_val: 2.133419250267554\n",
      "Epoch: 71 - time: 0.0027 - loss_train: 2.051576618870654 - loss_val: 2.112377662143828\n",
      "Epoch: 72 - time: 0.0028 - loss_train: 2.0368507844019574 - loss_val: 2.091229771566017\n",
      "Epoch: 73 - time: 0.0027 - loss_train: 2.0235402717849666 - loss_val: 2.0743026828484448\n",
      "Epoch: 74 - time: 0.0028 - loss_train: 2.0117785241932378 - loss_val: 2.0631891797872512\n",
      "Epoch: 75 - time: 0.0028 - loss_train: 2.0000944889960484 - loss_val: 2.0561546984927492\n",
      "Epoch: 76 - time: 0.0028 - loss_train: 1.9874489109105384 - loss_val: 2.050673494592367\n",
      "Epoch: 77 - time: 0.0028 - loss_train: 1.9745312614052386 - loss_val: 2.045615916615464\n",
      "Epoch: 78 - time: 0.0028 - loss_train: 1.96279296413384 - loss_val: 2.040867972417471\n",
      "Epoch: 79 - time: 0.0028 - loss_train: 1.9526468690931353 - loss_val: 2.035690428351462\n",
      "Epoch: 80 - time: 0.0028 - loss_train: 1.9430615607425736 - loss_val: 2.0283591986528724\n",
      "Epoch: 81 - time: 0.0028 - loss_train: 1.9328610677599587 - loss_val: 2.017610549469051\n",
      "Epoch: 82 - time: 0.0028 - loss_train: 1.9220406334161402 - loss_val: 2.0040708455428944\n",
      "Epoch: 83 - time: 0.0028 - loss_train: 1.9116090834951238 - loss_val: 1.9899467451224886\n",
      "Epoch: 84 - time: 0.0028 - loss_train: 1.9023237449822523 - loss_val: 1.9773335456840426\n",
      "Epoch: 85 - time: 0.0031 - loss_train: 1.8938738624003013 - loss_val: 1.966938633025845\n",
      "Epoch: 86 - time: 0.0029 - loss_train: 1.8853491325877585 - loss_val: 1.958298913511381\n",
      "Epoch: 87 - time: 0.0028 - loss_train: 1.876284683499941 - loss_val: 1.9508290889361464\n",
      "Epoch: 88 - time: 0.0028 - loss_train: 1.867057239993147 - loss_val: 1.944363152925068\n",
      "Epoch: 89 - time: 0.0028 - loss_train: 1.8583242500583428 - loss_val: 1.938773896457555\n",
      "Epoch: 90 - time: 0.0028 - loss_train: 1.8502829717541185 - loss_val: 1.9334250917149487\n",
      "Epoch: 91 - time: 0.0028 - loss_train: 1.8425642358051915 - loss_val: 1.9272760876219286\n",
      "Epoch: 92 - time: 0.0028 - loss_train: 1.8347365997552396 - loss_val: 1.9195700716840005\n",
      "Epoch: 93 - time: 0.0028 - loss_train: 1.8267617476767641 - loss_val: 1.9103656092437942\n",
      "Epoch: 94 - time: 0.0028 - loss_train: 1.8189389130692453 - loss_val: 1.9004088961371213\n",
      "Epoch: 95 - time: 0.0028 - loss_train: 1.8115129712038747 - loss_val: 1.8905637232336494\n",
      "Epoch: 96 - time: 0.0028 - loss_train: 1.8044310166850588 - loss_val: 1.8813712795380002\n",
      "Epoch: 97 - time: 0.0028 - loss_train: 1.7974646831385566 - loss_val: 1.8730237935527265\n",
      "Epoch: 98 - time: 0.0028 - loss_train: 1.7904827976595563 - loss_val: 1.865557683555469\n",
      "Epoch: 99 - time: 0.0028 - loss_train: 1.783554385290146 - loss_val: 1.858943502115948\n",
      "Epoch: 100 - time: 0.0028 - loss_train: 1.776818705715304 - loss_val: 1.8530068966043032\n",
      "Epoch: 101 - time: 0.0028 - loss_train: 1.7703186880466633 - loss_val: 1.8473702210598968\n",
      "Epoch: 102 - time: 0.0028 - loss_train: 1.7639809428888351 - loss_val: 1.8415694292918763\n",
      "Epoch: 103 - time: 0.0030 - loss_train: 1.7577224992688028 - loss_val: 1.835277851478348\n",
      "Epoch: 104 - time: 0.0034 - loss_train: 1.7515363741687835 - loss_val: 1.8284467978480456\n",
      "Epoch: 105 - time: 0.0031 - loss_train: 1.7454713808791817 - loss_val: 1.821267653488437\n",
      "Epoch: 106 - time: 0.0028 - loss_train: 1.7395576278817872 - loss_val: 1.8140279054135373\n",
      "Epoch: 107 - time: 0.0028 - loss_train: 1.7337731361755269 - loss_val: 1.8069892922233166\n",
      "Epoch: 108 - time: 0.0028 - loss_train: 1.7280765682703745 - loss_val: 1.800339471089321\n",
      "Epoch: 109 - time: 0.0024 - loss_train: 1.7224526037555505 - loss_val: 1.7941802183999425\n",
      "Epoch: 110 - time: 0.0024 - loss_train: 1.7169169671029954 - loss_val: 1.7885100979498447\n",
      "Epoch: 111 - time: 0.0024 - loss_train: 1.7114862782796711 - loss_val: 1.7832122406362014\n",
      "Epoch: 112 - time: 0.0024 - loss_train: 1.7061552233291915 - loss_val: 1.778084159890358\n",
      "Epoch: 113 - time: 0.0024 - loss_train: 1.7009044326237381 - loss_val: 1.7729140246021307\n",
      "Epoch: 114 - time: 0.0024 - loss_train: 1.6957223881177648 - loss_val: 1.7675615171908297\n",
      "Epoch: 115 - time: 0.0024 - loss_train: 1.6906132666621019 - loss_val: 1.7619960536478787\n",
      "Epoch: 116 - time: 0.0024 - loss_train: 1.6855853081721788 - loss_val: 1.7562816688760219\n",
      "Epoch: 117 - time: 0.0024 - loss_train: 1.6806374183504842 - loss_val: 1.750533599865652\n",
      "Epoch: 118 - time: 0.0024 - loss_train: 1.6757595024310732 - loss_val: 1.744875462341095\n",
      "Epoch: 119 - time: 0.0024 - loss_train: 1.6709430835265802 - loss_val: 1.7394073578509839\n",
      "Epoch: 120 - time: 0.0024 - loss_train: 1.666188068781094 - loss_val: 1.7341822727080207\n",
      "Epoch: 121 - time: 0.0024 - loss_train: 1.6614989440997683 - loss_val: 1.7291917412995108\n",
      "Epoch: 122 - time: 0.0024 - loss_train: 1.656876805565918 - loss_val: 1.7243690849847304\n",
      "Epoch: 123 - time: 0.0024 - loss_train: 1.65231676988864 - loss_val: 1.7196146086644486\n",
      "Epoch: 124 - time: 0.0024 - loss_train: 1.6478123616689753 - loss_val: 1.7148336705721754\n",
      "Epoch: 125 - time: 0.0024 - loss_train: 1.6433606449124487 - loss_val: 1.7099695414365625\n",
      "Epoch: 126 - time: 0.0024 - loss_train: 1.6389625416734803 - loss_val: 1.7050171591899432\n",
      "Epoch: 127 - time: 0.0024 - loss_train: 1.634619194920908 - loss_val: 1.7000162494550157\n",
      "Epoch: 128 - time: 0.0024 - loss_train: 1.6303291716985018 - loss_val: 1.6950317799055958\n",
      "Epoch: 129 - time: 0.0030 - loss_train: 1.6260892178745898 - loss_val: 1.69013116278081\n",
      "Epoch: 130 - time: 0.0025 - loss_train: 1.6218968692855047 - loss_val: 1.6853643884223102\n",
      "Epoch: 131 - time: 0.0024 - loss_train: 1.6177516968235508 - loss_val: 1.6807507266068828\n",
      "Epoch: 132 - time: 0.0024 - loss_train: 1.6136541754392761 - loss_val: 1.676274911219031\n",
      "Epoch: 133 - time: 0.0024 - loss_train: 1.6096038704088351 - loss_val: 1.6718943168261016\n",
      "Epoch: 134 - time: 0.0024 - loss_train: 1.6055989197892422 - loss_val: 1.667555033198432\n",
      "Epoch: 135 - time: 0.0024 - loss_train: 1.6016370013307497 - loss_val: 1.6632107890341021\n",
      "Epoch: 136 - time: 0.0024 - loss_train: 1.597716471127118 - loss_val: 1.6588374443988674\n",
      "Epoch: 137 - time: 0.0024 - loss_train: 1.593836572816569 - loss_val: 1.654438240919503\n",
      "Epoch: 138 - time: 0.0024 - loss_train: 1.5899968410779364 - loss_val: 1.6500393184640176\n",
      "Epoch: 139 - time: 0.0024 - loss_train: 1.5861965512992777 - loss_val: 1.645678538747337\n",
      "Epoch: 140 - time: 0.0024 - loss_train: 1.5824347302754458 - loss_val: 1.6413921207280169\n",
      "Epoch: 141 - time: 0.0024 - loss_train: 1.578710504048871 - loss_val: 1.637203329053865\n",
      "Epoch: 142 - time: 0.0024 - loss_train: 1.5750232806250697 - loss_val: 1.6331162831407877\n",
      "Epoch: 143 - time: 0.0024 - loss_train: 1.5713725861106604 - loss_val: 1.6291162930245373\n",
      "Epoch: 144 - time: 0.0025 - loss_train: 1.567757788658315 - loss_val: 1.6251761436026972\n",
      "Epoch: 145 - time: 0.0024 - loss_train: 1.5641780072443685 - loss_val: 1.6212658675087201\n",
      "Epoch: 146 - time: 0.0024 - loss_train: 1.5606322510107549 - loss_val: 1.6173624896768068\n",
      "Epoch: 147 - time: 0.0024 - loss_train: 1.5571196102876206 - loss_val: 1.6134564986401676\n",
      "Epoch: 148 - time: 0.0025 - loss_train: 1.5536393337416958 - loss_val: 1.6095532507266417\n",
      "Epoch: 149 - time: 0.0024 - loss_train: 1.5501907884218271 - loss_val: 1.6056694322048946\n",
      "Epoch: 150 - time: 0.0024 - loss_train: 1.5467734027232412 - loss_val: 1.601826297429471\n",
      "Epoch: 151 - time: 0.0024 - loss_train: 1.543386654796021 - loss_val: 1.5980421949496553\n",
      "Epoch: 152 - time: 0.0024 - loss_train: 1.5400300794845077 - loss_val: 1.5943268098082968\n",
      "Epoch: 153 - time: 0.0024 - loss_train: 1.5367032418783206 - loss_val: 1.5906787622487337\n",
      "Epoch: 154 - time: 0.0024 - loss_train: 1.533405677720793 - loss_val: 1.5870870033635387\n",
      "Epoch: 155 - time: 0.0024 - loss_train: 1.5301368519835306 - loss_val: 1.583535200803994\n",
      "Epoch: 156 - time: 0.0024 - loss_train: 1.5268961745884253 - loss_val: 1.5800074009236642\n",
      "Epoch: 157 - time: 0.0024 - loss_train: 1.5236830565468276 - loss_val: 1.5764929828907208\n",
      "Epoch: 158 - time: 0.0024 - loss_train: 1.5204969565166835 - loss_val: 1.5729893496377594\n",
      "Epoch: 159 - time: 0.0024 - loss_train: 1.517337388717417 - loss_val: 1.569501720335534\n",
      "Epoch: 160 - time: 0.0024 - loss_train: 1.5142039068415183 - loss_val: 1.5660404181424956\n",
      "Epoch: 161 - time: 0.0025 - loss_train: 1.511096094828527 - loss_val: 1.5626168146320074\n",
      "Epoch: 162 - time: 0.0024 - loss_train: 1.5080135728436694 - loss_val: 1.5592393836965275\n",
      "Epoch: 163 - time: 0.0024 - loss_train: 1.5049559992325654 - loss_val: 1.55591111460354\n",
      "Epoch: 164 - time: 0.0024 - loss_train: 1.5019230507372519 - loss_val: 1.5526289686367696\n",
      "Epoch: 165 - time: 0.0024 - loss_train: 1.4989143896799404 - loss_val: 1.5493853467277827\n",
      "Epoch: 166 - time: 0.0024 - loss_train: 1.4959296450150918 - loss_val: 1.5461708938553589\n",
      "Epoch: 167 - time: 0.0024 - loss_train: 1.4929684229030467 - loss_val: 1.5429775926577758\n",
      "Epoch: 168 - time: 0.0024 - loss_train: 1.4900303352839077 - loss_val: 1.5398010995941003\n",
      "Epoch: 169 - time: 0.0024 - loss_train: 1.4871150215128723 - loss_val: 1.5366416296915395\n",
      "Epoch: 170 - time: 0.0024 - loss_train: 1.4842221500926494 - loss_val: 1.5335032517606557\n",
      "Epoch: 171 - time: 0.0024 - loss_train: 1.4813514084471338 - loss_val: 1.530392000398469\n",
      "Epoch: 172 - time: 0.0024 - loss_train: 1.4785024958359962 - loss_val: 1.5273135554667578\n",
      "Epoch: 173 - time: 0.0024 - loss_train: 1.4756751241633956 - loss_val: 1.5242712929994813\n",
      "Epoch: 174 - time: 0.0024 - loss_train: 1.4728690192106275 - loss_val: 1.521265297266521\n",
      "Epoch: 175 - time: 0.0024 - loss_train: 1.470083914993345 - loss_val: 1.5182925478071334\n",
      "Epoch: 176 - time: 0.0024 - loss_train: 1.4673195439278237 - loss_val: 1.515348094909551\n",
      "Epoch: 177 - time: 0.0026 - loss_train: 1.4645756318448215 - loss_val: 1.5124267377282992\n",
      "Epoch: 178 - time: 0.0024 - loss_train: 1.4618519023968102 - loss_val: 1.5095246047354178\n",
      "Epoch: 179 - time: 0.0024 - loss_train: 1.4591480862245678 - loss_val: 1.5066401284919475\n",
      "Epoch: 180 - time: 0.0024 - loss_train: 1.456463926845658 - loss_val: 1.5037741592940543\n",
      "Epoch: 181 - time: 0.0024 - loss_train: 1.4537991800786683 - loss_val: 1.500929275693043\n",
      "Epoch: 182 - time: 0.0024 - loss_train: 1.4511536102134115 - loss_val: 1.4981086102768417\n",
      "Epoch: 183 - time: 0.0024 - loss_train: 1.4485269873217186 - loss_val: 1.4953146327666573\n",
      "Epoch: 184 - time: 0.0024 - loss_train: 1.4459190865643667 - loss_val: 1.4925482943998831\n",
      "Epoch: 185 - time: 0.0024 - loss_train: 1.4433296875150567 - loss_val: 1.4898087715075012\n",
      "Epoch: 186 - time: 0.0024 - loss_train: 1.4407585724645502 - loss_val: 1.4870938227668657\n",
      "Epoch: 187 - time: 0.0024 - loss_train: 1.438205525147115 - loss_val: 1.4844005723959595\n",
      "Epoch: 188 - time: 0.0024 - loss_train: 1.435670331650453 - loss_val: 1.481726412747024\n",
      "Epoch: 189 - time: 0.0024 - loss_train: 1.4331527830619362 - loss_val: 1.4790697142220315\n",
      "Epoch: 190 - time: 0.0024 - loss_train: 1.4306526775425683 - loss_val: 1.4764301291292428\n",
      "Epoch: 191 - time: 0.0024 - loss_train: 1.428169820168485 - loss_val: 1.4738084358536658\n",
      "Epoch: 192 - time: 0.0024 - loss_train: 1.4257040210365497 - loss_val: 1.4712060298625156\n",
      "Epoch: 193 - time: 0.0024 - loss_train: 1.4232550932979606 - loss_val: 1.4686242736950703\n",
      "Epoch: 194 - time: 0.0024 - loss_train: 1.4208228520680273 - loss_val: 1.4660639396456663\n",
      "Epoch: 195 - time: 0.0024 - loss_train: 1.4184071139283227 - loss_val: 1.4635249195986302\n",
      "Epoch: 196 - time: 0.0024 - loss_train: 1.4160076965351698 - loss_val: 1.4610062664326675\n",
      "Epoch: 197 - time: 0.0024 - loss_train: 1.413624418550818 - loss_val: 1.4585065131703898\n",
      "Epoch: 198 - time: 0.0024 - loss_train: 1.4112571004446564 - loss_val: 1.4560241294157346\n",
      "Epoch: 199 - time: 0.0024 - loss_train: 1.4089055660685323 - loss_val: 1.4535579447092064\n",
      "Epoch: 200 - time: 0.0024 - loss_train: 1.4065696440605133 - loss_val: 1.4511073992827674\n",
      "Epoch: 201 - time: 0.0024 - loss_train: 1.4042491681211862 - loss_val: 1.4486725575919719\n",
      "Epoch: 202 - time: 0.0024 - loss_train: 1.401943976063335 - loss_val: 1.4462539085980284\n",
      "Epoch: 203 - time: 0.0024 - loss_train: 1.3996539083433666 - loss_val: 1.4438520469154945\n",
      "Epoch: 204 - time: 0.0024 - loss_train: 1.397378806829262 - loss_val: 1.4414673584847546\n",
      "Epoch: 205 - time: 0.0024 - loss_train: 1.395118514057048 - loss_val: 1.439099818086208\n",
      "Epoch: 206 - time: 0.0024 - loss_train: 1.392872872862626 - loss_val: 1.4367489550063157\n",
      "Epoch: 207 - time: 0.0024 - loss_train: 1.3906417263365516 - loss_val: 1.4344139790185741\n",
      "Epoch: 208 - time: 0.0024 - loss_train: 1.3884249182134876 - loss_val: 1.4320940047659123\n",
      "Epoch: 209 - time: 0.0024 - loss_train: 1.3862222936953508 - loss_val: 1.4297882857598294\n",
      "Epoch: 210 - time: 0.0024 - loss_train: 1.3840337003862864 - loss_val: 1.4274963757461845\n",
      "Epoch: 211 - time: 0.0024 - loss_train: 1.3818589888707347 - loss_val: 1.4252181693958015\n",
      "Epoch: 212 - time: 0.0024 - loss_train: 1.3796980126844347 - loss_val: 1.422953821451931\n",
      "Epoch: 213 - time: 0.0024 - loss_train: 1.3775506278021166 - loss_val: 1.4207035858107766\n",
      "Epoch: 214 - time: 0.0024 - loss_train: 1.3754166919631559 - loss_val: 1.4184676392648192\n",
      "Epoch: 215 - time: 0.0024 - loss_train: 1.3732960640881362 - loss_val: 1.4162459528230198\n",
      "Epoch: 216 - time: 0.0024 - loss_train: 1.3711886038812846 - loss_val: 1.4140382501150703\n",
      "Epoch: 217 - time: 0.0024 - loss_train: 1.3690941716419402 - loss_val: 1.4118440579305294\n",
      "Epoch: 218 - time: 0.0024 - loss_train: 1.3670126283121422 - loss_val: 1.4096628215260039\n",
      "Epoch: 219 - time: 0.0024 - loss_train: 1.3649438357543553 - loss_val: 1.407494037853573\n",
      "Epoch: 220 - time: 0.0024 - loss_train: 1.3628876571548982 - loss_val: 1.4053373586297884\n",
      "Epoch: 221 - time: 0.0024 - loss_train: 1.360843957377698 - loss_val: 1.4031926306924005\n",
      "Epoch: 222 - time: 0.0024 - loss_train: 1.3588126031341776 - loss_val: 1.40105986626628\n",
      "Epoch: 223 - time: 0.0024 - loss_train: 1.356793462956435 - loss_val: 1.398939160826706\n",
      "Epoch: 224 - time: 0.0038 - loss_train: 1.3547864070565885 - loss_val: 1.3968305924931081\n",
      "Epoch: 225 - time: 0.0034 - loss_train: 1.3527913071655344 - loss_val: 1.3947341396119053\n",
      "Epoch: 226 - time: 0.0034 - loss_train: 1.350808036401803 - loss_val: 1.3926496429344544\n",
      "Epoch: 227 - time: 0.0035 - loss_train: 1.3488364691880474 - loss_val: 1.3905768205535487\n",
      "Epoch: 228 - time: 0.0035 - loss_train: 1.3468764812260743 - loss_val: 1.3885153247086748\n",
      "Epoch: 229 - time: 0.0034 - loss_train: 1.3449279495340616 - loss_val: 1.386464816354563\n",
      "Epoch: 230 - time: 0.0034 - loss_train: 1.3429907525243436 - loss_val: 1.3844250299187835\n",
      "Epoch: 231 - time: 0.0024 - loss_train: 1.341064770077197 - loss_val: 1.3823958070882563\n",
      "Epoch: 232 - time: 0.0024 - loss_train: 1.339149883573924 - loss_val: 1.3803770914720803\n",
      "Epoch: 233 - time: 0.0024 - loss_train: 1.3372459758884745 - loss_val: 1.3783688903642504\n",
      "Epoch: 234 - time: 0.0024 - loss_train: 1.3353529313687293 - loss_val: 1.3763712204375043\n",
      "Epoch: 235 - time: 0.0024 - loss_train: 1.333470635840957 - loss_val: 1.3743840577835125\n",
      "Epoch: 236 - time: 0.0024 - loss_train: 1.3315989766490637 - loss_val: 1.3724073088365765\n",
      "Epoch: 237 - time: 0.0024 - loss_train: 1.329737842717448 - loss_val: 1.3704408095867657\n",
      "Epoch: 238 - time: 0.0024 - loss_train: 1.327887124617197 - loss_val: 1.368484349877473\n",
      "Epoch: 239 - time: 0.0024 - loss_train: 1.3260467146169104 - loss_val: 1.3665377113350015\n",
      "Epoch: 240 - time: 0.0024 - loss_train: 1.3242165067035327 - loss_val: 1.3646007041704549\n",
      "Epoch: 241 - time: 0.0024 - loss_train: 1.3223963965646717 - loss_val: 1.3626731902921674\n",
      "Epoch: 242 - time: 0.0024 - loss_train: 1.3205862815358287 - loss_val: 1.360755086457211\n",
      "Epoch: 243 - time: 0.0024 - loss_train: 1.318786060531837 - loss_val: 1.358846348896327\n",
      "Epoch: 244 - time: 0.0024 - loss_train: 1.3169956339918005 - loss_val: 1.3569469471077513\n",
      "Epoch: 245 - time: 0.0033 - loss_train: 1.3152149038629473 - loss_val: 1.3550568373156824\n",
      "Epoch: 246 - time: 0.0034 - loss_train: 1.3134437736325937 - loss_val: 1.3531759448697145\n",
      "Epoch: 247 - time: 0.0033 - loss_train: 1.3116821483983763 - loss_val: 1.3513041605448544\n",
      "Epoch: 248 - time: 0.0034 - loss_train: 1.3099299349539657 - loss_val: 1.3494413501872733\n",
      "Epoch: 249 - time: 0.0032 - loss_train: 1.308187041863775 - loss_val: 1.3475873725276593\n",
      "Epoch: 250 - time: 0.0028 - loss_train: 1.3064533795046163 - loss_val: 1.3457420977714059\n",
      "Epoch: 251 - time: 0.0028 - loss_train: 1.3047288600627354 - loss_val: 1.3439054202562541\n",
      "Epoch: 252 - time: 0.0028 - loss_train: 1.3030133974887617 - loss_val: 1.3420772614431684\n",
      "Epoch: 253 - time: 0.0028 - loss_train: 1.3013069074265997 - loss_val: 1.340257563433116\n",
      "Epoch: 254 - time: 0.0027 - loss_train: 1.2996093071399977 - loss_val: 1.3384462765627425\n",
      "Epoch: 255 - time: 0.0027 - loss_train: 1.2979205154590028 - loss_val: 1.3366433462951954\n",
      "Epoch: 256 - time: 0.0027 - loss_train: 1.2962404527589229 - loss_val: 1.3348487042039912\n",
      "Epoch: 257 - time: 0.0027 - loss_train: 1.2945690409714101 - loss_val: 1.33306226575743\n",
      "Epoch: 258 - time: 0.0027 - loss_train: 1.2929062036161172 - loss_val: 1.331283934808685\n",
      "Epoch: 259 - time: 0.0027 - loss_train: 1.2912518658354346 - loss_val: 1.3295136122806614\n",
      "Epoch: 260 - time: 0.0028 - loss_train: 1.2896059544150873 - loss_val: 1.327751205330082\n",
      "Epoch: 261 - time: 0.0028 - loss_train: 1.2879683977790155 - loss_val: 1.3259966335690916\n",
      "Epoch: 262 - time: 0.0028 - loss_train: 1.2863391259559411 - loss_val: 1.3242498304251236\n",
      "Epoch: 263 - time: 0.0028 - loss_train: 1.2847180705241044 - loss_val: 1.322510739737014\n",
      "Epoch: 264 - time: 0.0035 - loss_train: 1.2831051645465414 - loss_val: 1.3207793094199698\n",
      "Epoch: 265 - time: 0.0029 - loss_train: 1.2815003425100833 - loss_val: 1.3190554848850102\n",
      "Epoch: 266 - time: 0.0028 - loss_train: 1.2799035402772416 - loss_val: 1.317339204664272\n",
      "Epoch: 267 - time: 0.0028 - loss_train: 1.2783146950534483 - loss_val: 1.3156303995885001\n",
      "Epoch: 268 - time: 0.0031 - loss_train: 1.276733745365649 - loss_val: 1.3139289953960402\n",
      "Epoch: 269 - time: 0.0035 - loss_train: 1.2751606310440693 - loss_val: 1.3122349174046217\n",
      "Epoch: 270 - time: 0.0034 - loss_train: 1.2735952931982728 - loss_val: 1.3105480952801136\n",
      "Epoch: 271 - time: 0.0033 - loss_train: 1.2720376741811958 - loss_val: 1.3088684661324541\n",
      "Epoch: 272 - time: 0.0028 - loss_train: 1.2704877175393845 - loss_val: 1.3071959749923043\n",
      "Epoch: 273 - time: 0.0028 - loss_train: 1.2689453679524063 - loss_val: 1.3055305727959847\n",
      "Epoch: 274 - time: 0.0028 - loss_train: 1.2674105711674466 - loss_val: 1.3038722129061484\n",
      "Epoch: 275 - time: 0.0027 - loss_train: 1.265883273935539 - loss_val: 1.3022208476108612\n",
      "Epoch: 276 - time: 0.0027 - loss_train: 1.2643634239538304 - loss_val: 1.300576425878915\n",
      "Epoch: 277 - time: 0.0027 - loss_train: 1.262850969814895 - loss_val: 1.2989388930339731\n",
      "Epoch: 278 - time: 0.0027 - loss_train: 1.2613458609608534 - loss_val: 1.2973081922250285\n",
      "Epoch: 279 - time: 0.0028 - loss_train: 1.2598480476380745 - loss_val: 1.2956842669255468\n",
      "Epoch: 280 - time: 0.0028 - loss_train: 1.2583574808482034 - loss_val: 1.2940670634098335\n",
      "Epoch: 281 - time: 0.0028 - loss_train: 1.256874112292938 - loss_val: 1.2924565322939967\n",
      "Epoch: 282 - time: 0.0028 - loss_train: 1.2553978943126423 - loss_val: 1.2908526286877045\n",
      "Epoch: 283 - time: 0.0028 - loss_train: 1.2539287798214354 - loss_val: 1.289255311072977\n",
      "Epoch: 284 - time: 0.0028 - loss_train: 1.2524667222427972 - loss_val: 1.287664539482234\n",
      "Epoch: 285 - time: 0.0028 - loss_train: 1.2510116754495835 - loss_val: 1.2860802737344883\n",
      "Epoch: 286 - time: 0.0028 - loss_train: 1.24956359371079 - loss_val: 1.2845024723694867\n",
      "Epoch: 287 - time: 0.0028 - loss_train: 1.2481224316451978 - loss_val: 1.2829310925771684\n",
      "Epoch: 288 - time: 0.0028 - loss_train: 1.246688144180015 - loss_val: 1.2813660910096958\n",
      "Epoch: 289 - time: 0.0029 - loss_train: 1.2452606865115572 - loss_val: 1.2798074250475884\n",
      "Epoch: 290 - time: 0.0029 - loss_train: 1.2438400140651598 - loss_val: 1.278255053976914\n",
      "Epoch: 291 - time: 0.0029 - loss_train: 1.2424260824527842 - loss_val: 1.2767089396390592\n",
      "Epoch: 292 - time: 0.0030 - loss_train: 1.2410188474285597 - loss_val: 1.2751690463713885\n",
      "Epoch: 293 - time: 0.0030 - loss_train: 1.2396182648441598 - loss_val: 1.2736353403498435\n",
      "Epoch: 294 - time: 0.0030 - loss_train: 1.2382242906068084 - loss_val: 1.2721077886575545\n",
      "Epoch: 295 - time: 0.0029 - loss_train: 1.2368368806425962 - loss_val: 1.2705863584655923\n",
      "Epoch: 296 - time: 0.0029 - loss_train: 1.2354559908667315 - loss_val: 1.2690710166182075\n",
      "Epoch: 297 - time: 0.0029 - loss_train: 1.2340815771609162 - loss_val: 1.2675617297205226\n",
      "Epoch: 298 - time: 0.0029 - loss_train: 1.2327135953566417 - loss_val: 1.2660584646188595\n",
      "Epoch: 299 - time: 0.0029 - loss_train: 1.2313520012223897 - loss_val: 1.2645611890244886\n",
      "Epoch: 300 - time: 0.0029 - loss_train: 1.2299967504526994 - loss_val: 1.2630698720064188\n",
      "Epoch: 301 - time: 0.0029 - loss_train: 1.2286477986577145 - loss_val: 1.2615844841638193\n",
      "Epoch: 302 - time: 0.0029 - loss_train: 1.227305101352892 - loss_val: 1.260104997437855\n",
      "Epoch: 303 - time: 0.0029 - loss_train: 1.2259686139495642 - loss_val: 1.258631384670225\n",
      "Epoch: 304 - time: 0.0029 - loss_train: 1.2246382917476841 - loss_val: 1.257163619104039\n",
      "Epoch: 305 - time: 0.0033 - loss_train: 1.2233140899321324 - loss_val: 1.2557016740239335\n",
      "Epoch: 306 - time: 0.0030 - loss_train: 1.221995963573485 - loss_val: 1.2542455226556772\n",
      "Epoch: 307 - time: 0.0026 - loss_train: 1.2206838676333782 - loss_val: 1.2527951383297096\n",
      "Epoch: 308 - time: 0.0025 - loss_train: 1.2193777569738187 - loss_val: 1.2513504948078658\n",
      "Epoch: 309 - time: 0.0024 - loss_train: 1.2180775863692974 - loss_val: 1.249911566618206\n",
      "Epoch: 310 - time: 0.0024 - loss_train: 1.216783310520456 - loss_val: 1.2484783292554054\n",
      "Epoch: 311 - time: 0.0024 - loss_train: 1.2154948840683195 - loss_val: 1.2470507591716578\n",
      "Epoch: 312 - time: 0.0024 - loss_train: 1.2142122616086322 - loss_val: 1.2456288335732133\n",
      "Epoch: 313 - time: 0.0024 - loss_train: 1.212935397706318 - loss_val: 1.2442125301128772\n",
      "Epoch: 314 - time: 0.0024 - loss_train: 1.211664246910463 - loss_val: 1.2428018266008913\n",
      "Epoch: 315 - time: 0.0024 - loss_train: 1.2103987637702711 - loss_val: 1.2413967008375542\n",
      "Epoch: 316 - time: 0.0024 - loss_train: 1.2091389028522967 - loss_val: 1.239997130613205\n",
      "Epoch: 317 - time: 0.0025 - loss_train: 1.2078846187589198 - loss_val: 1.238603093851483\n",
      "Epoch: 318 - time: 0.0024 - loss_train: 1.2066358661477392 - loss_val: 1.2372145688183132\n",
      "Epoch: 319 - time: 0.0024 - loss_train: 1.2053925997513333 - loss_val: 1.2358315343013095\n",
      "Epoch: 320 - time: 0.0025 - loss_train: 1.204154774396824 - loss_val: 1.2344539696853865\n",
      "Epoch: 321 - time: 0.0024 - loss_train: 1.2029223450248197 - loss_val: 1.233081854898243\n",
      "Epoch: 322 - time: 0.0024 - loss_train: 1.201695266707517 - loss_val: 1.2317151702526021\n",
      "Epoch: 323 - time: 0.0025 - loss_train: 1.2004734946659714 - loss_val: 1.2303538962494822\n",
      "Epoch: 324 - time: 0.0024 - loss_train: 1.1992569842866696 - loss_val: 1.2289980134153675\n",
      "Epoch: 325 - time: 0.0024 - loss_train: 1.1980456911375568 - loss_val: 1.227647502225648\n",
      "Epoch: 326 - time: 0.0024 - loss_train: 1.1968395709835873 - loss_val: 1.226302343128075\n",
      "Epoch: 327 - time: 0.0024 - loss_train: 1.1956385798017466 - loss_val: 1.2249625166401323\n",
      "Epoch: 328 - time: 0.0024 - loss_train: 1.194442673795394 - loss_val: 1.2236280034687643\n",
      "Epoch: 329 - time: 0.0024 - loss_train: 1.193251809407714 - loss_val: 1.2222987845981041\n",
      "Epoch: 330 - time: 0.0024 - loss_train: 1.1920659433341196 - loss_val: 1.22097484130945\n",
      "Epoch: 331 - time: 0.0024 - loss_train: 1.1908850325335303 - loss_val: 1.2196561551280862\n",
      "Epoch: 332 - time: 0.0024 - loss_train: 1.189709034238547 - loss_val: 1.2183427077206883\n",
      "Epoch: 333 - time: 0.0024 - loss_train: 1.1885379059646457 - loss_val: 1.217034480783689\n",
      "Epoch: 334 - time: 0.0024 - loss_train: 1.187371605518526 - loss_val: 1.2157314559621095\n",
      "Epoch: 335 - time: 0.0024 - loss_train: 1.1862100910057247 - loss_val: 1.2144336148221917\n",
      "Epoch: 336 - time: 0.0025 - loss_train: 1.185053320837562 - loss_val: 1.2131409388777867\n",
      "Epoch: 337 - time: 0.0025 - loss_train: 1.1839012537374065 - loss_val: 1.21185340964969\n",
      "Epoch: 338 - time: 0.0025 - loss_train: 1.182753848746214 - loss_val: 1.210571008726871\n",
      "Epoch: 339 - time: 0.0024 - loss_train: 1.1816110652272973 - loss_val: 1.20929371780159\n",
      "Epoch: 340 - time: 0.0024 - loss_train: 1.180472862870309 - loss_val: 1.2080215186640653\n",
      "Epoch: 341 - time: 0.0024 - loss_train: 1.1793392016944804 - loss_val: 1.2067543931600733\n",
      "Epoch: 342 - time: 0.0024 - loss_train: 1.178210042051208 - loss_val: 1.2054923231293029\n",
      "Epoch: 343 - time: 0.0034 - loss_train: 1.1770853446260894 - loss_val: 1.2042352903480338\n",
      "Epoch: 344 - time: 0.0034 - loss_train: 1.175965070440529 - loss_val: 1.202983276495614\n",
      "Epoch: 345 - time: 0.0033 - loss_train: 1.1748491808529964 - loss_val: 1.201736263152901\n",
      "Epoch: 346 - time: 0.0034 - loss_train: 1.1737376375599728 - loss_val: 1.2004942318276108\n",
      "Epoch: 347 - time: 0.0034 - loss_train: 1.172630402596608 - loss_val: 1.1992571639917515\n",
      "Epoch: 348 - time: 0.0034 - loss_train: 1.171527438337086 - loss_val: 1.1980250411135187\n",
      "Epoch: 349 - time: 0.0025 - loss_train: 1.1704287074947013 - loss_val: 1.1967978446704182\n",
      "Epoch: 350 - time: 0.0030 - loss_train: 1.169334173121671 - loss_val: 1.1955755561394785\n",
      "Epoch: 351 - time: 0.0025 - loss_train: 1.1682437986087275 - loss_val: 1.1943581569701036\n",
      "Epoch: 352 - time: 0.0024 - loss_train: 1.1671575476845477 - loss_val: 1.1931456285514563\n",
      "Epoch: 353 - time: 0.0025 - loss_train: 1.1660753844150835 - loss_val: 1.1919379521872577\n",
      "Epoch: 354 - time: 0.0025 - loss_train: 1.16499727320283 - loss_val: 1.190735109086657\n",
      "Epoch: 355 - time: 0.0024 - loss_train: 1.1639231787860675 - loss_val: 1.1895370803727339\n",
      "Epoch: 356 - time: 0.0024 - loss_train: 1.1628530662380832 - loss_val: 1.1883438471033112\n",
      "Epoch: 357 - time: 0.0024 - loss_train: 1.1617869009663768 - loss_val: 1.1871553902947627\n",
      "Epoch: 358 - time: 0.0025 - loss_train: 1.1607246487118554 - loss_val: 1.1859716909396825\n",
      "Epoch: 359 - time: 0.0024 - loss_train: 1.1596662755480225 - loss_val: 1.184792730012955\n",
      "Epoch: 360 - time: 0.0024 - loss_train: 1.1586117478801998 - loss_val: 1.1836184884662053\n",
      "Epoch: 361 - time: 0.0024 - loss_train: 1.1575610324447976 - loss_val: 1.1824489472152884\n",
      "Epoch: 362 - time: 0.0024 - loss_train: 1.1565140963086742 - loss_val: 1.1812840871278196\n",
      "Epoch: 363 - time: 0.0024 - loss_train: 1.155470906868592 - loss_val: 1.180123889016989\n",
      "Epoch: 364 - time: 0.0024 - loss_train: 1.1544314318507882 - loss_val: 1.1789683336447683\n",
      "Epoch: 365 - time: 0.0024 - loss_train: 1.153395639310639 - loss_val: 1.177817401733726\n",
      "Epoch: 366 - time: 0.0024 - loss_train: 1.1523634976324169 - loss_val: 1.176671073983489\n",
      "Epoch: 367 - time: 0.0024 - loss_train: 1.151334975529116 - loss_val: 1.175529331086787\n",
      "Epoch: 368 - time: 0.0025 - loss_train: 1.1503100420423464 - loss_val: 1.1743921537409865\n",
      "Epoch: 369 - time: 0.0025 - loss_train: 1.1492886665423103 - loss_val: 1.173259522653524\n",
      "Epoch: 370 - time: 0.0024 - loss_train: 1.1482708187278599 - loss_val: 1.1721314185424334\n",
      "Epoch: 371 - time: 0.0024 - loss_train: 1.1472564686266669 - loss_val: 1.1710078221350573\n",
      "Epoch: 372 - time: 0.0024 - loss_train: 1.1462455865955101 - loss_val: 1.1698887141684464\n",
      "Epoch: 373 - time: 0.0024 - loss_train: 1.1452381433206864 - loss_val: 1.1687740753938678\n",
      "Epoch: 374 - time: 0.0024 - loss_train: 1.1442341098185356 - loss_val: 1.1676638865859095\n",
      "Epoch: 375 - time: 0.0025 - loss_train: 1.1432334574360659 - loss_val: 1.1665581285547975\n",
      "Epoch: 376 - time: 0.0024 - loss_train: 1.1422361578516562 - loss_val: 1.1654567821594806\n",
      "Epoch: 377 - time: 0.0024 - loss_train: 1.1412421830758221 - loss_val: 1.1643598283190808\n",
      "Epoch: 378 - time: 0.0025 - loss_train: 1.140251505452043 - loss_val: 1.1632672480213724\n",
      "Epoch: 379 - time: 0.0024 - loss_train: 1.1392640976576296 - loss_val: 1.1621790223283635\n",
      "Epoch: 380 - time: 0.0024 - loss_train: 1.138279932704662 - loss_val: 1.1610951323803074\n",
      "Epoch: 381 - time: 0.0024 - loss_train: 1.1372989839409833 - loss_val: 1.160015559399921\n",
      "Epoch: 382 - time: 0.0024 - loss_train: 1.1363212250512638 - loss_val: 1.1589402846983168\n",
      "Epoch: 383 - time: 0.0024 - loss_train: 1.1353466300581254 - loss_val: 1.1578692896832008\n",
      "Epoch: 384 - time: 0.0025 - loss_train: 1.1343751733233276 - loss_val: 1.1568025558688506\n",
      "Epoch: 385 - time: 0.0024 - loss_train: 1.133406829548987 - loss_val: 1.1557400648866494\n",
      "Epoch: 386 - time: 0.0024 - loss_train: 1.1324415737788336 - loss_val: 1.154681798494818\n",
      "Epoch: 387 - time: 0.0024 - loss_train: 1.1314793813994743 - loss_val: 1.1536277385863813\n",
      "Epoch: 388 - time: 0.0024 - loss_train: 1.1305202281416704 - loss_val: 1.1525778671952223\n",
      "Epoch: 389 - time: 0.0024 - loss_train: 1.1295640900816137 - loss_val: 1.151532166500777\n",
      "Epoch: 390 - time: 0.0025 - loss_train: 1.1286109436422063 - loss_val: 1.1504906188323614\n",
      "Epoch: 391 - time: 0.0024 - loss_train: 1.1276607655943436 - loss_val: 1.1494532066740437\n",
      "Epoch: 392 - time: 0.0024 - loss_train: 1.1267135330581919 - loss_val: 1.1484199126705408\n",
      "Epoch: 393 - time: 0.0024 - loss_train: 1.125769223504464 - loss_val: 1.1473907196340305\n",
      "Epoch: 394 - time: 0.0024 - loss_train: 1.1248278147556765 - loss_val: 1.1463656105512323\n",
      "Epoch: 395 - time: 0.0024 - loss_train: 1.1238892849873863 - loss_val: 1.1453445685899737\n",
      "Epoch: 396 - time: 0.0024 - loss_train: 1.1229536127293942 - loss_val: 1.1443275771045804\n",
      "Epoch: 397 - time: 0.0024 - loss_train: 1.1220207768669066 - loss_val: 1.1433146196398525\n",
      "Epoch: 398 - time: 0.0027 - loss_train: 1.1210907566416546 - loss_val: 1.142305679933841\n",
      "Epoch: 399 - time: 0.0024 - loss_train: 1.1201635316529606 - loss_val: 1.1413007419199706\n",
      "Epoch: 400 - time: 0.0025 - loss_train: 1.119239081858755 - loss_val: 1.1402997897290745\n",
      "Epoch: 401 - time: 0.0025 - loss_train: 1.118317387576536 - loss_val: 1.1393028076917464\n",
      "Epoch: 402 - time: 0.0024 - loss_train: 1.1173984294842694 - loss_val: 1.1383097803410593\n",
      "Epoch: 403 - time: 0.0024 - loss_train: 1.116482188621224 - loss_val: 1.1373206924153827\n",
      "Epoch: 404 - time: 0.0024 - loss_train: 1.1155686463887342 - loss_val: 1.1363355288608379\n",
      "Epoch: 405 - time: 0.0024 - loss_train: 1.114657784550884 - loss_val: 1.1353542748330032\n",
      "Epoch: 406 - time: 0.0024 - loss_train: 1.1137495852351103 - loss_val: 1.1343769156976096\n",
      "Epoch: 407 - time: 0.0024 - loss_train: 1.112844030932712 - loss_val: 1.1334034370303108\n",
      "Epoch: 408 - time: 0.0024 - loss_train: 1.1119411044992733 - loss_val: 1.1324338246157823\n",
      "Epoch: 409 - time: 0.0024 - loss_train: 1.1110407891549865 - loss_val: 1.1314680644465012\n",
      "Epoch: 410 - time: 0.0024 - loss_train: 1.1101430684848779 - loss_val: 1.1305061427215106\n",
      "Epoch: 411 - time: 0.0024 - loss_train: 1.1092479264389352 - loss_val: 1.129548045845271\n",
      "Epoch: 412 - time: 0.0024 - loss_train: 1.108355347332125 - loss_val: 1.1285937604265108\n",
      "Epoch: 413 - time: 0.0025 - loss_train: 1.107465315844302 - loss_val: 1.1276432732768626\n",
      "Epoch: 414 - time: 0.0025 - loss_train: 1.1065778170200076 - loss_val: 1.1266965714090311\n",
      "Epoch: 415 - time: 0.0025 - loss_train: 1.1056928362681464 - loss_val: 1.1257536420343366\n",
      "Epoch: 416 - time: 0.0025 - loss_train: 1.1048103593615441 - loss_val: 1.1248144725596168\n",
      "Epoch: 417 - time: 0.0024 - loss_train: 1.1039303724363814 - loss_val: 1.1238790505836271\n",
      "Epoch: 418 - time: 0.0025 - loss_train: 1.1030528619914954 - loss_val: 1.12294736389314\n",
      "Epoch: 419 - time: 0.0024 - loss_train: 1.102177814887565 - loss_val: 1.122019400458961\n",
      "Epoch: 420 - time: 0.0024 - loss_train: 1.101305218346151 - loss_val: 1.1210951484319611\n",
      "Epoch: 421 - time: 0.0024 - loss_train: 1.1004350599486115 - loss_val: 1.120174596139146\n",
      "Epoch: 422 - time: 0.0024 - loss_train: 1.0995673276348816 - loss_val: 1.1192577320796593\n",
      "Epoch: 423 - time: 0.0024 - loss_train: 1.098702009702111 - loss_val: 1.1183445449205862\n",
      "Epoch: 424 - time: 0.0024 - loss_train: 1.0978390948031655 - loss_val: 1.1174350234924635\n",
      "Epoch: 425 - time: 0.0024 - loss_train: 1.096978571944986 - loss_val: 1.1165291567844462\n",
      "Epoch: 426 - time: 0.0025 - loss_train: 1.0961204304868037 - loss_val: 1.1156269339392033\n",
      "Epoch: 427 - time: 0.0025 - loss_train: 1.0952646601382128 - loss_val: 1.114728344247644\n",
      "Epoch: 428 - time: 0.0025 - loss_train: 1.0944112509570953 - loss_val: 1.1138333771436095\n",
      "Epoch: 429 - time: 0.0025 - loss_train: 1.093560193347404 - loss_val: 1.1129420221986188\n",
      "Epoch: 430 - time: 0.0024 - loss_train: 1.0927114780567968 - loss_val: 1.112054269116712\n",
      "Epoch: 431 - time: 0.0024 - loss_train: 1.0918650961741214 - loss_val: 1.1111701077293583\n",
      "Epoch: 432 - time: 0.0024 - loss_train: 1.0910210391267579 - loss_val: 1.1102895279903628\n",
      "Epoch: 433 - time: 0.0024 - loss_train: 1.0901792986778074 - loss_val: 1.1094125199707288\n",
      "Epoch: 434 - time: 0.0024 - loss_train: 1.0893398669231364 - loss_val: 1.1085390738534249\n",
      "Epoch: 435 - time: 0.0024 - loss_train: 1.0885027362882715 - loss_val: 1.1076691799281002\n",
      "Epoch: 436 - time: 0.0024 - loss_train: 1.0876678995251456 - loss_val: 1.1068028285857694\n",
      "Epoch: 437 - time: 0.0024 - loss_train: 1.0868353497087047 - loss_val: 1.105940010313565\n",
      "Epoch: 438 - time: 0.0024 - loss_train: 1.0860050802333565 - loss_val: 1.1050807156896008\n",
      "Epoch: 439 - time: 0.0025 - loss_train: 1.0851770848092892 - loss_val: 1.1042249353779794\n",
      "Epoch: 440 - time: 0.0025 - loss_train: 1.084351357458635 - loss_val: 1.1033726601239442\n",
      "Epoch: 441 - time: 0.0025 - loss_train: 1.0835278925114975 - loss_val: 1.1025238807491433\n",
      "Epoch: 442 - time: 0.0025 - loss_train: 1.0827066846018347 - loss_val: 1.1016785881469868\n",
      "Epoch: 443 - time: 0.0024 - loss_train: 1.0818877286632052 - loss_val: 1.1008367732780562\n",
      "Epoch: 444 - time: 0.0027 - loss_train: 1.081071019924375 - loss_val: 1.099998427165591\n",
      "Epoch: 445 - time: 0.0025 - loss_train: 1.0802565539047893 - loss_val: 1.099163540891061\n",
      "Epoch: 446 - time: 0.0024 - loss_train: 1.0794443264099105 - loss_val: 1.0983321055898576\n",
      "Epoch: 447 - time: 0.0024 - loss_train: 1.078634333526429 - loss_val: 1.0975041124471439\n",
      "Epoch: 448 - time: 0.0024 - loss_train: 1.07782657161734 - loss_val: 1.0966795526938622\n",
      "Epoch: 449 - time: 0.0024 - loss_train: 1.077021037316903 - loss_val: 1.0958584176029176\n",
      "Epoch: 450 - time: 0.0024 - loss_train: 1.0762177275254725 - loss_val: 1.0950406984855077\n",
      "Epoch: 451 - time: 0.0024 - loss_train: 1.0754166394042113 - loss_val: 1.0942263866875788\n",
      "Epoch: 452 - time: 0.0024 - loss_train: 1.074617770369688 - loss_val: 1.0934154735864052\n",
      "Epoch: 453 - time: 0.0024 - loss_train: 1.073821118088364 - loss_val: 1.092607950587271\n",
      "Epoch: 454 - time: 0.0025 - loss_train: 1.0730266804709638 - loss_val: 1.091803809120277\n",
      "Epoch: 455 - time: 0.0024 - loss_train: 1.0722344556667485 - loss_val: 1.091003040637274\n",
      "Epoch: 456 - time: 0.0024 - loss_train: 1.0714444420576796 - loss_val: 1.090205636608945\n",
      "Epoch: 457 - time: 0.0024 - loss_train: 1.0706566382524918 - loss_val: 1.0894115885220363\n",
      "Epoch: 458 - time: 0.0024 - loss_train: 1.069871043080666 - loss_val: 1.0886208878767354\n",
      "Epoch: 459 - time: 0.0024 - loss_train: 1.0690876555863171 - loss_val: 1.0878335261841858\n",
      "Epoch: 460 - time: 0.0024 - loss_train: 1.0683064750219944 - loss_val: 1.0870494949641174\n",
      "Epoch: 461 - time: 0.0024 - loss_train: 1.0675275008424014 - loss_val: 1.0862687857425908\n",
      "Epoch: 462 - time: 0.0024 - loss_train: 1.0667507326980403 - loss_val: 1.0854913900498266\n",
      "Epoch: 463 - time: 0.0024 - loss_train: 1.0659761704287816 - loss_val: 1.084717299418147\n",
      "Epoch: 464 - time: 0.0024 - loss_train: 1.06520381405737 - loss_val: 1.083946505380014\n",
      "Epoch: 465 - time: 0.0024 - loss_train: 1.0644336637828669 - loss_val: 1.0831789994661671\n",
      "Epoch: 466 - time: 0.0024 - loss_train: 1.0636657199740345 - loss_val: 1.082414773203884\n",
      "Epoch: 467 - time: 0.0024 - loss_train: 1.0628999831626702 - loss_val: 1.0816538181153306\n",
      "Epoch: 468 - time: 0.0024 - loss_train: 1.06213645403689 - loss_val: 1.0808961257160103\n",
      "Epoch: 469 - time: 0.0024 - loss_train: 1.0613751334343753 - loss_val: 1.0801416875132983\n",
      "Epoch: 470 - time: 0.0024 - loss_train: 1.060616022335577 - loss_val: 1.0793904950050432\n",
      "Epoch: 471 - time: 0.0024 - loss_train: 1.0598591218568907 - loss_val: 1.0786425396782338\n",
      "Epoch: 472 - time: 0.0024 - loss_train: 1.059104433243809 - loss_val: 1.0778978130077275\n",
      "Epoch: 473 - time: 0.0024 - loss_train: 1.058351957864045 - loss_val: 1.0771563064550391\n",
      "Epoch: 474 - time: 0.0024 - loss_train: 1.0576016972006483 - loss_val: 1.0764180114671937\n",
      "Epoch: 475 - time: 0.0024 - loss_train: 1.0568536528451054 - loss_val: 1.0756829194756365\n",
      "Epoch: 476 - time: 0.0024 - loss_train: 1.056107826490439 - loss_val: 1.0749510218952076\n",
      "Epoch: 477 - time: 0.0024 - loss_train: 1.0553642199243058 - loss_val: 1.0742223101231652\n",
      "Epoch: 478 - time: 0.0024 - loss_train: 1.0546228350221023 - loss_val: 1.0734967755382554\n",
      "Epoch: 479 - time: 0.0024 - loss_train: 1.0538836737400816 - loss_val: 1.0727744094998188\n",
      "Epoch: 480 - time: 0.0024 - loss_train: 1.0531467381084882 - loss_val: 1.0720552033469295\n",
      "Epoch: 481 - time: 0.0024 - loss_train: 1.0524120302247157 - loss_val: 1.0713391483975703\n",
      "Epoch: 482 - time: 0.0024 - loss_train: 1.05167955224649 - loss_val: 1.0706262359478245\n",
      "Epoch: 483 - time: 0.0024 - loss_train: 1.0509493063850919 - loss_val: 1.0699164572711126\n",
      "Epoch: 484 - time: 0.0024 - loss_train: 1.0502212948986134 - loss_val: 1.0692098036174476\n",
      "Epoch: 485 - time: 0.0024 - loss_train: 1.0494955200852618 - loss_val: 1.0685062662127274\n",
      "Epoch: 486 - time: 0.0024 - loss_train: 1.0487719842767123 - loss_val: 1.0678058362580487\n",
      "Epoch: 487 - time: 0.0024 - loss_train: 1.0480506898315138 - loss_val: 1.067108504929051\n",
      "Epoch: 488 - time: 0.0024 - loss_train: 1.0473316391285625 - loss_val: 1.0664142633752722\n",
      "Epoch: 489 - time: 0.0025 - loss_train: 1.0466148345606296 - loss_val: 1.0657231027195306\n",
      "Epoch: 490 - time: 0.0024 - loss_train: 1.0459002785279699 - loss_val: 1.0650350140573144\n",
      "Epoch: 491 - time: 0.0024 - loss_train: 1.0451879734320002 - loss_val: 1.0643499884561956\n",
      "Epoch: 492 - time: 0.0027 - loss_train: 1.0444779216690592 - loss_val: 1.0636680169552588\n",
      "Epoch: 493 - time: 0.0024 - loss_train: 1.0437701256242538 - loss_val: 1.0629890905645498\n",
      "Epoch: 494 - time: 0.0024 - loss_train: 1.0430645876653926 - loss_val: 1.0623132002645475\n",
      "Epoch: 495 - time: 0.0024 - loss_train: 1.04236131013702 - loss_val: 1.061640337005649\n",
      "Epoch: 496 - time: 0.0024 - loss_train: 1.0416602953545386 - loss_val: 1.0609704917076914\n",
      "Epoch: 497 - time: 0.0025 - loss_train: 1.0409615455984467 - loss_val: 1.0603036552594718\n",
      "Epoch: 498 - time: 0.0024 - loss_train: 1.0402650631086747 - loss_val: 1.0596398185183082\n",
      "Epoch: 499 - time: 0.0024 - loss_train: 1.0395708500790364 - loss_val: 1.0589789723096086\n",
      "Epoch: 500 - time: 0.0024 - loss_train: 1.0388789086517958 - loss_val: 1.058321107426464\n",
      "Epoch: 501 - time: 0.0024 - loss_train: 1.0381892409123517 - loss_val: 1.0576662146292728\n",
      "Epoch: 502 - time: 0.0024 - loss_train: 1.037501848884045 - loss_val: 1.0570142846453843\n",
      "Epoch: 503 - time: 0.0024 - loss_train: 1.036816734523095 - loss_val: 1.0563653081687694\n",
      "Epoch: 504 - time: 0.0024 - loss_train: 1.0361338997136598 - loss_val: 1.0557192758597322\n",
      "Epoch: 505 - time: 0.0024 - loss_train: 1.0354533462630344 - loss_val: 1.055076178344642\n",
      "Epoch: 506 - time: 0.0024 - loss_train: 1.0347750758969803 - loss_val: 1.054436006215699\n",
      "Epoch: 507 - time: 0.0025 - loss_train: 1.034099090255195 - loss_val: 1.05379875003074\n",
      "Epoch: 508 - time: 0.0024 - loss_train: 1.0334253908869218 - loss_val: 1.0531644003130742\n",
      "Epoch: 509 - time: 0.0024 - loss_train: 1.0327539792467024 - loss_val: 1.0525329475513527\n",
      "Epoch: 510 - time: 0.0024 - loss_train: 1.0320848566902718 - loss_val: 1.0519043821994838\n",
      "Epoch: 511 - time: 0.0024 - loss_train: 1.0314180244706053 - loss_val: 1.0512786946765815\n",
      "Epoch: 512 - time: 0.0025 - loss_train: 1.0307534837341088 - loss_val: 1.0506558753669655\n",
      "Epoch: 513 - time: 0.0024 - loss_train: 1.0300912355169618 - loss_val: 1.0500359146201936\n",
      "Epoch: 514 - time: 0.0024 - loss_train: 1.0294312807416113 - loss_val: 1.04941880275115\n",
      "Epoch: 515 - time: 0.0024 - loss_train: 1.0287736202134172 - loss_val: 1.048804530040172\n",
      "Epoch: 516 - time: 0.0024 - loss_train: 1.0281182546174512 - loss_val: 1.0481930867332299\n",
      "Epoch: 517 - time: 0.0024 - loss_train: 1.027465184515451 - loss_val: 1.0475844630421463\n",
      "Epoch: 518 - time: 0.0024 - loss_train: 1.026814410342925 - loss_val: 1.046978649144875\n",
      "Epoch: 519 - time: 0.0024 - loss_train: 1.0261659324064176 - loss_val: 1.0463756351858213\n",
      "Epoch: 520 - time: 0.0024 - loss_train: 1.0255197508809208 - loss_val: 1.0457754112762143\n",
      "Epoch: 521 - time: 0.0024 - loss_train: 1.0248758658074473 - loss_val: 1.045177967494536\n",
      "Epoch: 522 - time: 0.0024 - loss_train: 1.0242342770907542 - loss_val: 1.0445832938869977\n",
      "Epoch: 523 - time: 0.0024 - loss_train: 1.0235949844972185 - loss_val: 1.0439913804680674\n",
      "Epoch: 524 - time: 0.0024 - loss_train: 1.0229579876528716 - loss_val: 1.0434022172210489\n",
      "Epoch: 525 - time: 0.0025 - loss_train: 1.0223232860415736 - loss_val: 1.0428157940987204\n",
      "Epoch: 526 - time: 0.0024 - loss_train: 1.0216908790033516 - loss_val: 1.0422321010240105\n",
      "Epoch: 527 - time: 0.0024 - loss_train: 1.021060765732875 - loss_val: 1.0416511278907383\n",
      "Epoch: 528 - time: 0.0024 - loss_train: 1.0204329452780863 - loss_val: 1.041072864564389\n",
      "Epoch: 529 - time: 0.0024 - loss_train: 1.0198074165389728 - loss_val: 1.0404973008829546\n",
      "Epoch: 530 - time: 0.0024 - loss_train: 1.0191841782664839 - loss_val: 1.0399244266578107\n",
      "Epoch: 531 - time: 0.0024 - loss_train: 1.0185632290615898 - loss_val: 1.0393542316746442\n",
      "Epoch: 532 - time: 0.0025 - loss_train: 1.0179445673744798 - loss_val: 1.038786705694432\n",
      "Epoch: 533 - time: 0.0024 - loss_train: 1.017328191503897 - loss_val: 1.0382218384544522\n",
      "Epoch: 534 - time: 0.0024 - loss_train: 1.0167140995966069 - loss_val: 1.03765961966935\n",
      "Epoch: 535 - time: 0.0024 - loss_train: 1.0161022896470016 - loss_val: 1.037100039032238\n",
      "Epoch: 536 - time: 0.0024 - loss_train: 1.015492759496827 - loss_val: 1.0365430862158342\n",
      "Epoch: 537 - time: 0.0024 - loss_train: 1.0148855068350433 - loss_val: 1.0359887508736394\n",
      "Epoch: 538 - time: 0.0024 - loss_train: 1.0142805291978023 - loss_val: 1.0354370226411478\n",
      "Epoch: 539 - time: 0.0026 - loss_train: 1.0136778239685496 - loss_val: 1.0348878911370918\n",
      "Epoch: 540 - time: 0.0024 - loss_train: 1.0130773883782431 - loss_val: 1.0343413459647124\n",
      "Epoch: 541 - time: 0.0024 - loss_train: 1.0124792195056822 - loss_val: 1.0337973767130608\n",
      "Epoch: 542 - time: 0.0024 - loss_train: 1.0118833142779518 - loss_val: 1.0332559729583246\n",
      "Epoch: 543 - time: 0.0024 - loss_train: 1.0112896694709705 - loss_val: 1.0327171242651738\n",
      "Epoch: 544 - time: 0.0024 - loss_train: 1.010698281710146 - loss_val: 1.0321808201881286\n",
      "Epoch: 545 - time: 0.0024 - loss_train: 1.0101091474711241 - loss_val: 1.031647050272941\n",
      "Epoch: 546 - time: 0.0024 - loss_train: 1.0095222630806424 - loss_val: 1.031115804057991\n",
      "Epoch: 547 - time: 0.0024 - loss_train: 1.0089376247174737 - loss_val: 1.0305870710756961\n",
      "Epoch: 548 - time: 0.0024 - loss_train: 1.0083552284134578 - loss_val: 1.0300608408539285\n",
      "Epoch: 549 - time: 0.0024 - loss_train: 1.00777507005462 - loss_val: 1.029537102917432\n",
      "Epoch: 550 - time: 0.0024 - loss_train: 1.0071971453823756 - loss_val: 1.0290158467892494\n",
      "Epoch: 551 - time: 0.0024 - loss_train: 1.0066214499948092 - loss_val: 1.0284970619921439\n",
      "Epoch: 552 - time: 0.0024 - loss_train: 1.0060479793480313 - loss_val: 1.0279807380500199\n",
      "Epoch: 553 - time: 0.0024 - loss_train: 1.0054767287576083 - loss_val: 1.027466864489337\n",
      "Epoch: 554 - time: 0.0025 - loss_train: 1.0049076934000563 - loss_val: 1.0269554308405169\n",
      "Epoch: 555 - time: 0.0024 - loss_train: 1.0043408683144062 - loss_val: 1.0264464266393332\n",
      "Epoch: 556 - time: 0.0024 - loss_train: 1.0037762484038264 - loss_val: 1.0259398414282965\n",
      "Epoch: 557 - time: 0.0024 - loss_train: 1.003213828437305 - loss_val: 1.0254356647580138\n",
      "Epoch: 558 - time: 0.0024 - loss_train: 1.0026536030513866 - loss_val: 1.0249338861885373\n",
      "Epoch: 559 - time: 0.0024 - loss_train: 1.0020955667519598 - loss_val: 1.024434495290684\n",
      "Epoch: 560 - time: 0.0024 - loss_train: 1.001539713916095 - loss_val: 1.023937481647337\n",
      "Epoch: 561 - time: 0.0025 - loss_train: 1.0009860387939287 - loss_val: 1.0234428348547218\n",
      "Epoch: 562 - time: 0.0024 - loss_train: 1.0004345355105837 - loss_val: 1.0229505445236486\n",
      "Epoch: 563 - time: 0.0025 - loss_train: 0.9998851980681379 - loss_val: 1.0224606002807326\n",
      "Epoch: 564 - time: 0.0024 - loss_train: 0.9993380203476209 - loss_val: 1.021972991769578\n",
      "Epoch: 565 - time: 0.0024 - loss_train: 0.9987929961110493 - loss_val: 1.0214877086519296\n",
      "Epoch: 566 - time: 0.0024 - loss_train: 0.9982501190034911 - loss_val: 1.0210047406087919\n",
      "Epoch: 567 - time: 0.0024 - loss_train: 0.9977093825551575 - loss_val: 1.0205240773415063\n",
      "Epoch: 568 - time: 0.0024 - loss_train: 0.9971707801835215 - loss_val: 1.020045708572799\n",
      "Epoch: 569 - time: 0.0024 - loss_train: 0.9966343051954568 - loss_val: 1.0195696240477818\n",
      "Epoch: 570 - time: 0.0024 - loss_train: 0.9960999507894026 - loss_val: 1.0190958135349206\n",
      "Epoch: 571 - time: 0.0024 - loss_train: 0.9955677100575394 - loss_val: 1.018624266826955\n",
      "Epoch: 572 - time: 0.0024 - loss_train: 0.9950375759879873 - loss_val: 1.0181549737417843\n",
      "Epoch: 573 - time: 0.0024 - loss_train: 0.9945095414670116 - loss_val: 1.0176879241233054\n",
      "Epoch: 574 - time: 0.0025 - loss_train: 0.9939835992812472 - loss_val: 1.0172231078422127\n",
      "Epoch: 575 - time: 0.0024 - loss_train: 0.9934597421199257 - loss_val: 1.0167605147967482\n",
      "Epoch: 576 - time: 0.0024 - loss_train: 0.9929379625771153 - loss_val: 1.0163001349134162\n",
      "Epoch: 577 - time: 0.0025 - loss_train: 0.9924182531539636 - loss_val: 1.0158419581476468\n",
      "Epoch: 578 - time: 0.0024 - loss_train: 0.991900606260946 - loss_val: 1.0153859744844194\n",
      "Epoch: 579 - time: 0.0024 - loss_train: 0.9913850142201163 - loss_val: 1.0149321739388428\n",
      "Epoch: 580 - time: 0.0024 - loss_train: 0.9908714692673568 - loss_val: 1.0144805465566913\n",
      "Epoch: 581 - time: 0.0024 - loss_train: 0.99035996355463 - loss_val: 1.0140310824148953\n",
      "Epoch: 582 - time: 0.0024 - loss_train: 0.9898504891522268 - loss_val: 1.0135837716219909\n",
      "Epoch: 583 - time: 0.0024 - loss_train: 0.9893430380510116 - loss_val: 1.0131386043185302\n",
      "Epoch: 584 - time: 0.0024 - loss_train: 0.9888376021646609 - loss_val: 1.0126955706774403\n",
      "Epoch: 585 - time: 0.0024 - loss_train: 0.9883341733319008 - loss_val: 1.012254660904351\n",
      "Epoch: 586 - time: 0.0027 - loss_train: 0.987832743318731 - loss_val: 1.0118158652378793\n",
      "Epoch: 587 - time: 0.0024 - loss_train: 0.9873333038206442 - loss_val: 1.0113791739498672\n",
      "Epoch: 588 - time: 0.0024 - loss_train: 0.9868358464648372 - loss_val: 1.010944577345595\n",
      "Epoch: 589 - time: 0.0024 - loss_train: 0.9863403628124079 - loss_val: 1.0105120657639395\n",
      "Epoch: 590 - time: 0.0024 - loss_train: 0.9858468443605442 - loss_val: 1.010081629577511\n",
      "Epoch: 591 - time: 0.0025 - loss_train: 0.9853552825447 - loss_val: 1.009653259192742\n",
      "Epoch: 592 - time: 0.0024 - loss_train: 0.9848656687407576 - loss_val: 1.0092269450499545\n",
      "Epoch: 593 - time: 0.0024 - loss_train: 0.984377994267177 - loss_val: 1.008802677623378\n",
      "Epoch: 594 - time: 0.0024 - loss_train: 0.9838922503871315 - loss_val: 1.0083804474211502\n",
      "Epoch: 595 - time: 0.0024 - loss_train: 0.9834084283106257 - loss_val: 1.0079602449852756\n",
      "Epoch: 596 - time: 0.0024 - loss_train: 0.9829265191966002 - loss_val: 1.0075420608915653\n",
      "Epoch: 597 - time: 0.0024 - loss_train: 0.9824465141550205 - loss_val: 1.0071258857495329\n",
      "Epoch: 598 - time: 0.0024 - loss_train: 0.9819684042489446 - loss_val: 1.0067117102022844\n",
      "Epoch: 599 - time: 0.0025 - loss_train: 0.9814921804965794 - loss_val: 1.0062995249263615\n",
      "Epoch: 600 - time: 0.0024 - loss_train: 0.9810178338733127 - loss_val: 1.0058893206315749\n",
      "Epoch: 601 - time: 0.0024 - loss_train: 0.9805453553137333 - loss_val: 1.0054810880608094\n",
      "Epoch: 602 - time: 0.0024 - loss_train: 0.9800747357136252 - loss_val: 1.005074817989805\n",
      "Epoch: 603 - time: 0.0024 - loss_train: 0.9796059659319494 - loss_val: 1.0046705012269255\n",
      "Epoch: 604 - time: 0.0024 - loss_train: 0.9791390367927999 - loss_val: 1.004268128612901\n",
      "Epoch: 605 - time: 0.0025 - loss_train: 0.9786739390873445 - loss_val: 1.0038676910205548\n",
      "Epoch: 606 - time: 0.0024 - loss_train: 0.9782106635757426 - loss_val: 1.0034691793545194\n",
      "Epoch: 607 - time: 0.0024 - loss_train: 0.9777492009890429 - loss_val: 1.0030725845509283\n",
      "Epoch: 608 - time: 0.0024 - loss_train: 0.977289542031059 - loss_val: 1.0026778975771045\n",
      "Epoch: 609 - time: 0.0024 - loss_train: 0.976831677380226 - loss_val: 1.0022851094312284\n",
      "Epoch: 610 - time: 0.0025 - loss_train: 0.9763755976914333 - loss_val: 1.0018942111420022\n",
      "Epoch: 611 - time: 0.0027 - loss_train: 0.9759212935978374 - loss_val: 1.0015051937683015\n",
      "Epoch: 612 - time: 0.0027 - loss_train: 0.9754687557126505 - loss_val: 1.0011180483988136\n",
      "Epoch: 613 - time: 0.0025 - loss_train: 0.9750179746309089 - loss_val: 1.000732766151681\n",
      "Epoch: 614 - time: 0.0024 - loss_train: 0.974568940931217 - loss_val: 1.0003493381741262\n",
      "Epoch: 615 - time: 0.0025 - loss_train: 0.9741216451774701 - loss_val: 0.9999677556420804\n",
      "Epoch: 616 - time: 0.0024 - loss_train: 0.9736760779205546 - loss_val: 0.9995880097598056\n",
      "Epoch: 617 - time: 0.0024 - loss_train: 0.9732322297000223 - loss_val: 0.9992100917595121\n",
      "Epoch: 618 - time: 0.0024 - loss_train: 0.9727900910457442 - loss_val: 0.9988339929009792\n",
      "Epoch: 619 - time: 0.0024 - loss_train: 0.9723496524795409 - loss_val: 0.9984597044711688\n",
      "Epoch: 620 - time: 0.0024 - loss_train: 0.9719109045167875 - loss_val: 0.9980872177838506\n",
      "Epoch: 621 - time: 0.0024 - loss_train: 0.9714738376679958 - loss_val: 0.9977165241792142\n",
      "Epoch: 622 - time: 0.0024 - loss_train: 0.9710384424403742 - loss_val: 0.9973476150234939\n",
      "Epoch: 623 - time: 0.0024 - loss_train: 0.9706047093393612 - loss_val: 0.9969804817085958\n",
      "Epoch: 624 - time: 0.0024 - loss_train: 0.9701726288701361 - loss_val: 0.996615115651723\n",
      "Epoch: 625 - time: 0.0024 - loss_train: 0.9697421915391059 - loss_val: 0.9962515082950106\n",
      "Epoch: 626 - time: 0.0025 - loss_train: 0.9693133878553669 - loss_val: 0.9958896511051648\n",
      "Epoch: 627 - time: 0.0024 - loss_train: 0.968886208332144 - loss_val: 0.9955295355731116\n",
      "Epoch: 628 - time: 0.0024 - loss_train: 0.9684606434882009 - loss_val: 0.9951711532136409\n",
      "Epoch: 629 - time: 0.0024 - loss_train: 0.9680366838492348 - loss_val: 0.9948144955650721\n",
      "Epoch: 630 - time: 0.0024 - loss_train: 0.9676143199492351 - loss_val: 0.9944595541889225\n",
      "Epoch: 631 - time: 0.0024 - loss_train: 0.9671935423318277 - loss_val: 0.994106320669576\n",
      "Epoch: 632 - time: 0.0027 - loss_train: 0.9667743415515893 - loss_val: 0.9937547866139776\n",
      "Epoch: 633 - time: 0.0025 - loss_train: 0.9663567081753369 - loss_val: 0.9934049436513199\n",
      "Epoch: 634 - time: 0.0024 - loss_train: 0.9659406327833967 - loss_val: 0.9930567834327528\n",
      "Epoch: 635 - time: 0.0024 - loss_train: 0.9655261059708431 - loss_val: 0.992710297631095\n",
      "Epoch: 636 - time: 0.0024 - loss_train: 0.9651131183487177 - loss_val: 0.9923654779405607\n",
      "Epoch: 637 - time: 0.0024 - loss_train: 0.9647016605452217 - loss_val: 0.9920223160764968\n",
      "Epoch: 638 - time: 0.0024 - loss_train: 0.9642917232068815 - loss_val: 0.9916808037751282\n",
      "Epoch: 639 - time: 0.0024 - loss_train: 0.9638832969996943 - loss_val: 0.9913409327933211\n",
      "Epoch: 640 - time: 0.0024 - loss_train: 0.9634763726102462 - loss_val: 0.9910026949083515\n",
      "Epoch: 641 - time: 0.0024 - loss_train: 0.9630709407468041 - loss_val: 0.9906660819176877\n",
      "Epoch: 642 - time: 0.0024 - loss_train: 0.9626669921403881 - loss_val: 0.9903310856387875\n",
      "Epoch: 643 - time: 0.0024 - loss_train: 0.9622645175458153 - loss_val: 0.989997697908905\n",
      "Epoch: 644 - time: 0.0024 - loss_train: 0.9618635077427203 - loss_val: 0.9896659105849116\n",
      "Epoch: 645 - time: 0.0024 - loss_train: 0.9614639535365522 - loss_val: 0.9893357155431282\n",
      "Epoch: 646 - time: 0.0025 - loss_train: 0.9610658457595478 - loss_val: 0.9890071046791699\n",
      "Epoch: 647 - time: 0.0024 - loss_train: 0.9606691752716764 - loss_val: 0.9886800699078039\n",
      "Epoch: 648 - time: 0.0025 - loss_train: 0.9602739329615679 - loss_val: 0.9883546031628223\n",
      "Epoch: 649 - time: 0.0024 - loss_train: 0.9598801097474116 - loss_val: 0.9880306963969226\n",
      "Epoch: 650 - time: 0.0024 - loss_train: 0.9594876965778303 - loss_val: 0.9877083415816071\n",
      "Epoch: 651 - time: 0.0024 - loss_train: 0.9590966844327374 - loss_val: 0.9873875307070882\n",
      "Epoch: 652 - time: 0.0024 - loss_train: 0.9587070643241621 - loss_val: 0.9870682557822112\n",
      "Epoch: 653 - time: 0.0024 - loss_train: 0.9583188272970585 - loss_val: 0.9867505088343895\n",
      "Epoch: 654 - time: 0.0024 - loss_train: 0.957931964430085 - loss_val: 0.9864342819095469\n",
      "Epoch: 655 - time: 0.0024 - loss_train: 0.9575464668363673 - loss_val: 0.9861195670720804\n",
      "Epoch: 656 - time: 0.0024 - loss_train: 0.9571623256642313 - loss_val: 0.9858063564048262\n",
      "Epoch: 657 - time: 0.0024 - loss_train: 0.9567795320979201 - loss_val: 0.9854946420090485\n",
      "Epoch: 658 - time: 0.0024 - loss_train: 0.9563980773582842 - loss_val: 0.985184416004427\n",
      "Epoch: 659 - time: 0.0024 - loss_train: 0.9560179527034492 - loss_val: 0.9848756705290684\n",
      "Epoch: 660 - time: 0.0024 - loss_train: 0.9556391494294657 - loss_val: 0.9845683977395199\n",
      "Epoch: 661 - time: 0.0024 - loss_train: 0.9552616588709293 - loss_val: 0.9842625898108033\n",
      "Epoch: 662 - time: 0.0024 - loss_train: 0.9548854724015887 - loss_val: 0.9839582389364473\n",
      "Epoch: 663 - time: 0.0024 - loss_train: 0.9545105814349233 - loss_val: 0.9836553373285476\n",
      "Epoch: 664 - time: 0.0024 - loss_train: 0.954136977424706 - loss_val: 0.9833538772178222\n",
      "Epoch: 665 - time: 0.0025 - loss_train: 0.9537646518655409 - loss_val: 0.9830538508536846\n",
      "Epoch: 666 - time: 0.0024 - loss_train: 0.9533935962933816 - loss_val: 0.9827552505043285\n",
      "Epoch: 667 - time: 0.0024 - loss_train: 0.9530238022860289 - loss_val: 0.9824580684568167\n",
      "Epoch: 668 - time: 0.0024 - loss_train: 0.9526552614636076 - loss_val: 0.9821622970171852\n",
      "Epoch: 669 - time: 0.0024 - loss_train: 0.9522879654890245 - loss_val: 0.9818679285105544\n",
      "Epoch: 670 - time: 0.0024 - loss_train: 0.9519219060684054 - loss_val: 0.9815749552812482\n",
      "Epoch: 671 - time: 0.0024 - loss_train: 0.9515570749515109 - loss_val: 0.981283369692925\n",
      "Epoch: 672 - time: 0.0024 - loss_train: 0.9511934639321379 - loss_val: 0.9809931641287142\n",
      "Epoch: 673 - time: 0.0024 - loss_train: 0.9508310648484949 - loss_val: 0.9807043309913647\n",
      "Epoch: 674 - time: 0.0024 - loss_train: 0.9504698695835655 - loss_val: 0.9804168627033971\n",
      "Epoch: 675 - time: 0.0025 - loss_train: 0.9501098700654488 - loss_val: 0.9801307517072664\n",
      "Epoch: 676 - time: 0.0025 - loss_train: 0.9497510582676828 - loss_val: 0.9798459904655326\n",
      "Epoch: 677 - time: 0.0024 - loss_train: 0.9493934262095496 - loss_val: 0.9795625714610369\n",
      "Epoch: 678 - time: 0.0024 - loss_train: 0.9490369659563656 - loss_val: 0.9792804871970839\n",
      "Epoch: 679 - time: 0.0024 - loss_train: 0.9486816696197478 - loss_val: 0.9789997301976368\n",
      "Epoch: 680 - time: 0.0027 - loss_train: 0.9483275293578717 - loss_val: 0.9787202930075055\n",
      "Epoch: 681 - time: 0.0024 - loss_train: 0.9479745373757039 - loss_val: 0.9784421681925578\n",
      "Epoch: 682 - time: 0.0024 - loss_train: 0.9476226859252256 - loss_val: 0.9781653483399232\n",
      "Epoch: 683 - time: 0.0024 - loss_train: 0.9472719673056326 - loss_val: 0.9778898260582058\n",
      "Epoch: 684 - time: 0.0024 - loss_train: 0.9469223738635264 - loss_val: 0.9776155939777075\n",
      "Epoch: 685 - time: 0.0024 - loss_train: 0.9465738979930846 - loss_val: 0.9773426447506451\n",
      "Epoch: 686 - time: 0.0024 - loss_train: 0.9462265321362178 - loss_val: 0.9770709710513841\n",
      "Epoch: 687 - time: 0.0024 - loss_train: 0.9458802687827117 - loss_val: 0.9768005655766692\n",
      "Epoch: 688 - time: 0.0024 - loss_train: 0.9455351004703545 - loss_val: 0.976531421045857\n",
      "Epoch: 689 - time: 0.0024 - loss_train: 0.9451910197850479 - loss_val: 0.9762635302011613\n",
      "Epoch: 690 - time: 0.0024 - loss_train: 0.9448480193609078 - loss_val: 0.975996885807893\n",
      "Epoch: 691 - time: 0.0024 - loss_train: 0.944506091880347 - loss_val: 0.9757314806547066\n",
      "Epoch: 692 - time: 0.0024 - loss_train: 0.9441652300741462 - loss_val: 0.9754673075538495\n",
      "Epoch: 693 - time: 0.0024 - loss_train: 0.9438254267215136 - loss_val: 0.9752043593414136\n",
      "Epoch: 694 - time: 0.0024 - loss_train: 0.943486674650127 - loss_val: 0.9749426288775871\n",
      "Epoch: 695 - time: 0.0024 - loss_train: 0.9431489667361687 - loss_val: 0.9746821090469151\n",
      "Epoch: 696 - time: 0.0024 - loss_train: 0.9428122959043419 - loss_val: 0.9744227927585489\n",
      "Epoch: 697 - time: 0.0024 - loss_train: 0.9424766551278824 - loss_val: 0.9741646729465114\n",
      "Epoch: 698 - time: 0.0024 - loss_train: 0.94214203742855 - loss_val: 0.9739077425699543\n",
      "Epoch: 699 - time: 0.0025 - loss_train: 0.9418084358766169 - loss_val: 0.9736519946134169\n",
      "Epoch: 700 - time: 0.0025 - loss_train: 0.9414758435908384 - loss_val: 0.97339742208709\n",
      "Epoch: 701 - time: 0.0025 - loss_train: 0.941144253738415 - loss_val: 0.9731440180270758\n",
      "Epoch: 702 - time: 0.0024 - loss_train: 0.9408136595349467 - loss_val: 0.9728917754956503\n",
      "Epoch: 703 - time: 0.0024 - loss_train: 0.9404840542443702 - loss_val: 0.9726406875815233\n",
      "Epoch: 704 - time: 0.0025 - loss_train: 0.9401554311788924 - loss_val: 0.9723907474001\n",
      "Epoch: 705 - time: 0.0024 - loss_train: 0.9398277836989125 - loss_val: 0.9721419480937438\n",
      "Epoch: 706 - time: 0.0024 - loss_train: 0.9395011052129318 - loss_val: 0.9718942828320302\n",
      "Epoch: 707 - time: 0.0024 - loss_train: 0.9391753891774576 - loss_val: 0.9716477448120113\n",
      "Epoch: 708 - time: 0.0024 - loss_train: 0.9388506290968955 - loss_val: 0.9714023272584693\n",
      "Epoch: 709 - time: 0.0024 - loss_train: 0.9385268185234359 - loss_val: 0.9711580234241725\n",
      "Epoch: 710 - time: 0.0024 - loss_train: 0.9382039510569286 - loss_val: 0.9709148265901288\n",
      "Epoch: 711 - time: 0.0024 - loss_train: 0.9378820203447525 - loss_val: 0.9706727300658406\n",
      "Epoch: 712 - time: 0.0025 - loss_train: 0.9375610200816743 - loss_val: 0.9704317271895497\n",
      "Epoch: 713 - time: 0.0024 - loss_train: 0.9372409440097023 - loss_val: 0.9701918113284883\n",
      "Epoch: 714 - time: 0.0025 - loss_train: 0.9369217859179307 - loss_val: 0.9699529758791232\n",
      "Epoch: 715 - time: 0.0025 - loss_train: 0.9366035396423772 - loss_val: 0.9697152142673956\n",
      "Epoch: 716 - time: 0.0025 - loss_train: 0.9362861990658159 - loss_val: 0.969478519948963\n",
      "Epoch: 717 - time: 0.0024 - loss_train: 0.9359697581175979 - loss_val: 0.9692428864094347\n",
      "Epoch: 718 - time: 0.0024 - loss_train: 0.9356542107734721 - loss_val: 0.9690083071646043\n",
      "Epoch: 719 - time: 0.0024 - loss_train: 0.9353395510553958 - loss_val: 0.9687747757606778\n",
      "Epoch: 720 - time: 0.0024 - loss_train: 0.9350257730313392 - loss_val: 0.9685422857745037\n",
      "Epoch: 721 - time: 0.0024 - loss_train: 0.9347128708150862 - loss_val: 0.9683108308137889\n",
      "Epoch: 722 - time: 0.0024 - loss_train: 0.9344008385660271 - loss_val: 0.9680804045173231\n",
      "Epoch: 723 - time: 0.0024 - loss_train: 0.9340896704889496 - loss_val: 0.9678510005551896\n",
      "Epoch: 724 - time: 0.0024 - loss_train: 0.9337793608338194 - loss_val: 0.9676226126289755\n",
      "Epoch: 725 - time: 0.0025 - loss_train: 0.9334699038955614 - loss_val: 0.9673952344719798\n",
      "Epoch: 726 - time: 0.0028 - loss_train: 0.9331612940138312 - loss_val: 0.9671688598494114\n",
      "Epoch: 727 - time: 0.0025 - loss_train: 0.9328535255727862 - loss_val: 0.9669434825585902\n",
      "Epoch: 728 - time: 0.0024 - loss_train: 0.9325465930008513 - loss_val: 0.9667190964291371\n",
      "Epoch: 729 - time: 0.0024 - loss_train: 0.9322404907704763 - loss_val: 0.9664956953231585\n",
      "Epoch: 730 - time: 0.0024 - loss_train: 0.9319352133978971 - loss_val: 0.9662732731354362\n",
      "Epoch: 731 - time: 0.0024 - loss_train: 0.9316307554428854 - loss_val: 0.966051823793598\n",
      "Epoch: 732 - time: 0.0025 - loss_train: 0.9313271115085012 - loss_val: 0.9658313412582947\n",
      "Epoch: 733 - time: 0.0024 - loss_train: 0.9310242762408366 - loss_val: 0.9656118195233657\n",
      "Epoch: 734 - time: 0.0024 - loss_train: 0.9307222443287598 - loss_val: 0.9653932526160033\n",
      "Epoch: 735 - time: 0.0024 - loss_train: 0.930421010503655 - loss_val: 0.9651756345969051\n",
      "Epoch: 736 - time: 0.0024 - loss_train: 0.9301205695391607 - loss_val: 0.9649589595604324\n",
      "Epoch: 737 - time: 0.0025 - loss_train: 0.9298209162509018 - loss_val: 0.9647432216347511\n",
      "Epoch: 738 - time: 0.0024 - loss_train: 0.9295220454962222 - loss_val: 0.9645284149819746\n",
      "Epoch: 739 - time: 0.0024 - loss_train: 0.929223952173916 - loss_val: 0.9643145337982967\n",
      "Epoch: 740 - time: 0.0024 - loss_train: 0.9289266312239512 - loss_val: 0.9641015723141257\n",
      "Epoch: 741 - time: 0.0024 - loss_train: 0.9286300776271995 - loss_val: 0.9638895247942035\n",
      "Epoch: 742 - time: 0.0024 - loss_train: 0.9283342864051545 - loss_val: 0.9636783855377257\n",
      "Epoch: 743 - time: 0.0024 - loss_train: 0.9280392526196558 - loss_val: 0.9634681488784549\n",
      "Epoch: 744 - time: 0.0024 - loss_train: 0.9277449713726091 - loss_val: 0.9632588091848242\n",
      "Epoch: 745 - time: 0.0024 - loss_train: 0.9274514378057026 - loss_val: 0.9630503608600427\n",
      "Epoch: 746 - time: 0.0024 - loss_train: 0.9271586471001263 - loss_val: 0.962842798342185\n",
      "Epoch: 747 - time: 0.0024 - loss_train: 0.9268665944762834 - loss_val: 0.962636116104285\n",
      "Epoch: 748 - time: 0.0024 - loss_train: 0.9265752751935095 - loss_val: 0.9624303086544175\n",
      "Epoch: 749 - time: 0.0024 - loss_train: 0.926284684549783 - loss_val: 0.9622253705357725\n",
      "Epoch: 750 - time: 0.0024 - loss_train: 0.925994817881438 - loss_val: 0.9620212963267323\n",
      "Epoch: 751 - time: 0.0024 - loss_train: 0.9257056705628772 - loss_val: 0.9618180806409312\n",
      "Epoch: 752 - time: 0.0024 - loss_train: 0.9254172380062816 - loss_val: 0.9616157181273199\n",
      "Epoch: 753 - time: 0.0024 - loss_train: 0.9251295156613214 - loss_val: 0.9614142034702143\n",
      "Epoch: 754 - time: 0.0035 - loss_train: 0.9248424990148668 - loss_val: 0.9612135313893495\n",
      "Epoch: 755 - time: 0.0035 - loss_train: 0.9245561835906968 - loss_val: 0.9610136966399152\n",
      "Epoch: 756 - time: 0.0035 - loss_train: 0.9242705649492091 - loss_val: 0.960814694012595\n",
      "Epoch: 757 - time: 0.0035 - loss_train: 0.9239856386871296 - loss_val: 0.9606165183335968\n",
      "Epoch: 758 - time: 0.0035 - loss_train: 0.9237014004372215 - loss_val: 0.9604191644646757\n",
      "Epoch: 759 - time: 0.0034 - loss_train: 0.9234178458679947 - loss_val: 0.9602226273031526\n",
      "Epoch: 760 - time: 0.0027 - loss_train: 0.9231349706834158 - loss_val: 0.9600269017819278\n",
      "Epoch: 761 - time: 0.0027 - loss_train: 0.9228527706226155 - loss_val: 0.9598319828694863\n",
      "Epoch: 762 - time: 0.0027 - loss_train: 0.922571241459603 - loss_val: 0.9596378655699009\n",
      "Epoch: 763 - time: 0.0027 - loss_train: 0.9222903790029716 - loss_val: 0.9594445449228249\n",
      "Epoch: 764 - time: 0.0027 - loss_train: 0.9220101790956137 - loss_val: 0.959252016003485\n",
      "Epoch: 765 - time: 0.0027 - loss_train: 0.9217306376144289 - loss_val: 0.9590602739226622\n",
      "Epoch: 766 - time: 0.0027 - loss_train: 0.9214517504700378 - loss_val: 0.9588693138266722\n",
      "Epoch: 767 - time: 0.0027 - loss_train: 0.9211735136064952 - loss_val: 0.9586791308973388\n",
      "Epoch: 768 - time: 0.0027 - loss_train: 0.9208959230010021 - loss_val: 0.9584897203519598\n",
      "Epoch: 769 - time: 0.0027 - loss_train: 0.9206189746636203 - loss_val: 0.9583010774432699\n",
      "Epoch: 770 - time: 0.0033 - loss_train: 0.9203426646369889 - loss_val: 0.9581131974593957\n",
      "Epoch: 771 - time: 0.0029 - loss_train: 0.9200669889960391 - loss_val: 0.957926075723812\n",
      "Epoch: 772 - time: 0.0030 - loss_train: 0.9197919438477116 - loss_val: 0.9577397075952794\n",
      "Epoch: 773 - time: 0.0029 - loss_train: 0.9195175253306752 - loss_val: 0.9575540884677937\n",
      "Epoch: 774 - time: 0.0029 - loss_train: 0.919243729615046 - loss_val: 0.957369213770515\n",
      "Epoch: 775 - time: 0.0029 - loss_train: 0.9189705529021068 - loss_val: 0.9571850789677023\n",
      "Epoch: 776 - time: 0.0029 - loss_train: 0.9186979914240319 - loss_val: 0.9570016795586376\n",
      "Epoch: 777 - time: 0.0027 - loss_train: 0.9184260414436057 - loss_val: 0.9568190110775455\n",
      "Epoch: 778 - time: 0.0028 - loss_train: 0.9181546992539507 - loss_val: 0.9566370690935081\n",
      "Epoch: 779 - time: 0.0027 - loss_train: 0.9178839611782514 - loss_val: 0.9564558492103802\n",
      "Epoch: 780 - time: 0.0027 - loss_train: 0.9176138235694818 - loss_val: 0.9562753470666888\n",
      "Epoch: 781 - time: 0.0028 - loss_train: 0.9173442828101336 - loss_val: 0.9560955583355395\n",
      "Epoch: 782 - time: 0.0028 - loss_train: 0.9170753353119466 - loss_val: 0.9559164787245108\n",
      "Epoch: 783 - time: 0.0028 - loss_train: 0.9168069775156409 - loss_val: 0.9557381039755463\n",
      "Epoch: 784 - time: 0.0028 - loss_train: 0.9165392058906484 - loss_val: 0.9555604298648425\n",
      "Epoch: 785 - time: 0.0028 - loss_train: 0.9162720169348484 - loss_val: 0.9553834522027314\n",
      "Epoch: 786 - time: 0.0028 - loss_train: 0.9160054071743035 - loss_val: 0.9552071668335601\n",
      "Epoch: 787 - time: 0.0027 - loss_train: 0.9157393731629992 - loss_val: 0.9550315696355649\n",
      "Epoch: 788 - time: 0.0028 - loss_train: 0.9154739114825808 - loss_val: 0.9548566565207423\n",
      "Epoch: 789 - time: 0.0027 - loss_train: 0.9152090187420971 - loss_val: 0.9546824234347129\n",
      "Epoch: 790 - time: 0.0028 - loss_train: 0.9149446915777426 - loss_val: 0.9545088663565868\n",
      "Epoch: 791 - time: 0.0027 - loss_train: 0.9146809266526018 - loss_val: 0.9543359812988205\n",
      "Epoch: 792 - time: 0.0027 - loss_train: 0.9144177206563968 - loss_val: 0.9541637643070692\n",
      "Epoch: 793 - time: 0.0028 - loss_train: 0.9141550703052365 - loss_val: 0.953992211460041\n",
      "Epoch: 794 - time: 0.0027 - loss_train: 0.9138929723413642 - loss_val: 0.9538213188693428\n",
      "Epoch: 795 - time: 0.0027 - loss_train: 0.9136314235329126 - loss_val: 0.9536510826793216\n",
      "Epoch: 796 - time: 0.0028 - loss_train: 0.9133704206736566 - loss_val: 0.9534814990669046\n",
      "Epoch: 797 - time: 0.0027 - loss_train: 0.9131099605827685 - loss_val: 0.9533125642414386\n",
      "Epoch: 798 - time: 0.0030 - loss_train: 0.9128500401045776 - loss_val: 0.9531442744445184\n",
      "Epoch: 799 - time: 0.0030 - loss_train: 0.9125906561083287 - loss_val: 0.9529766259498206\n",
      "Epoch: 800 - time: 0.0029 - loss_train: 0.9123318054879441 - loss_val: 0.9528096150629268\n",
      "Epoch: 801 - time: 0.0029 - loss_train: 0.912073485161787 - loss_val: 0.952643238121147\n",
      "Epoch: 802 - time: 0.0029 - loss_train: 0.9118156920724275 - loss_val: 0.9524774914933424\n",
      "Epoch: 803 - time: 0.0029 - loss_train: 0.9115584231864096 - loss_val: 0.9523123715797392\n",
      "Epoch: 804 - time: 0.0024 - loss_train: 0.9113016754940213 - loss_val: 0.9521478748117456\n",
      "Epoch: 805 - time: 0.0024 - loss_train: 0.9110454460090662 - loss_val: 0.9519839976517612\n",
      "Epoch: 806 - time: 0.0024 - loss_train: 0.9107897317686363 - loss_val: 0.9518207365929873\n",
      "Epoch: 807 - time: 0.0024 - loss_train: 0.9105345298328877 - loss_val: 0.9516580881592301\n",
      "Epoch: 808 - time: 0.0024 - loss_train: 0.9102798372848184 - loss_val: 0.9514960489047096\n",
      "Epoch: 809 - time: 0.0024 - loss_train: 0.9100256512300475 - loss_val: 0.9513346154138557\n",
      "Epoch: 810 - time: 0.0024 - loss_train: 0.9097719687965979 - loss_val: 0.9511737843011075\n",
      "Epoch: 811 - time: 0.0024 - loss_train: 0.9095187871346774 - loss_val: 0.9510135522107114\n",
      "Epoch: 812 - time: 0.0026 - loss_train: 0.909266103416467 - loss_val: 0.9508539158165139\n",
      "Epoch: 813 - time: 0.0024 - loss_train: 0.9090139148359061 - loss_val: 0.9506948718217536\n",
      "Epoch: 814 - time: 0.0024 - loss_train: 0.9087622186084839 - loss_val: 0.9505364169588509\n",
      "Epoch: 815 - time: 0.0024 - loss_train: 0.9085110119710312 - loss_val: 0.9503785479891957\n",
      "Epoch: 816 - time: 0.0025 - loss_train: 0.9082602921815114 - loss_val: 0.950221261702934\n",
      "Epoch: 817 - time: 0.0024 - loss_train: 0.9080100565188195 - loss_val: 0.9500645549187479\n",
      "Epoch: 818 - time: 0.0024 - loss_train: 0.9077603022825779 - loss_val: 0.9499084244836442\n",
      "Epoch: 819 - time: 0.0024 - loss_train: 0.9075110267929363 - loss_val: 0.9497528672727299\n",
      "Epoch: 820 - time: 0.0024 - loss_train: 0.907262227390374 - loss_val: 0.9495978801889933\n",
      "Epoch: 821 - time: 0.0024 - loss_train: 0.9070139014355039 - loss_val: 0.9494434601630777\n",
      "Epoch: 822 - time: 0.0024 - loss_train: 0.906766046308877 - loss_val: 0.9492896041530619\n",
      "Epoch: 823 - time: 0.0025 - loss_train: 0.9065186594107911 - loss_val: 0.9491363091442317\n",
      "Epoch: 824 - time: 0.0024 - loss_train: 0.9062717381611016 - loss_val: 0.9489835721488528\n",
      "Epoch: 825 - time: 0.0024 - loss_train: 0.9060252799990305 - loss_val: 0.948831390205942\n",
      "Epoch: 826 - time: 0.0024 - loss_train: 0.9057792823829834 - loss_val: 0.9486797603810396\n",
      "Epoch: 827 - time: 0.0024 - loss_train: 0.9055337427903618 - loss_val: 0.9485286797659789\n",
      "Epoch: 828 - time: 0.0024 - loss_train: 0.9052886587173847 - loss_val: 0.9483781454786476\n",
      "Epoch: 829 - time: 0.0024 - loss_train: 0.9050440276789059 - loss_val: 0.9482281546627684\n",
      "Epoch: 830 - time: 0.0024 - loss_train: 0.9047998472082351 - loss_val: 0.9480787044876506\n",
      "Epoch: 831 - time: 0.0024 - loss_train: 0.9045561148569641 - loss_val: 0.9479297921479647\n",
      "Epoch: 832 - time: 0.0024 - loss_train: 0.9043128281947898 - loss_val: 0.9477814148635055\n",
      "Epoch: 833 - time: 0.0024 - loss_train: 0.904069984809344 - loss_val: 0.9476335698789529\n",
      "Epoch: 834 - time: 0.0024 - loss_train: 0.90382758230602 - loss_val: 0.9474862544636378\n",
      "Epoch: 835 - time: 0.0024 - loss_train: 0.9035856183078074 - loss_val: 0.947339465911306\n",
      "Epoch: 836 - time: 0.0024 - loss_train: 0.9033440904551227 - loss_val: 0.947193201539875\n",
      "Epoch: 837 - time: 0.0024 - loss_train: 0.9031029964056467 - loss_val: 0.9470474586912012\n",
      "Epoch: 838 - time: 0.0025 - loss_train: 0.9028623338341597 - loss_val: 0.9469022347308366\n",
      "Epoch: 839 - time: 0.0024 - loss_train: 0.9026221004323809 - loss_val: 0.9467575270477939\n",
      "Epoch: 840 - time: 0.0025 - loss_train: 0.9023822939088109 - loss_val: 0.9466133330543051\n",
      "Epoch: 841 - time: 0.0025 - loss_train: 0.9021429119885729 - loss_val: 0.9464696501855776\n",
      "Epoch: 842 - time: 0.0024 - loss_train: 0.9019039524132573 - loss_val: 0.9463264758995615\n",
      "Epoch: 843 - time: 0.0024 - loss_train: 0.9016654129407682 - loss_val: 0.9461838076767046\n",
      "Epoch: 844 - time: 0.0024 - loss_train: 0.901427291345173 - loss_val: 0.9460416430197134\n",
      "Epoch: 845 - time: 0.0024 - loss_train: 0.9011895854165515 - loss_val: 0.9458999794533137\n",
      "Epoch: 846 - time: 0.0024 - loss_train: 0.9009522929608472 - loss_val: 0.9457588145240098\n",
      "Epoch: 847 - time: 0.0024 - loss_train: 0.9007154117997225 - loss_val: 0.9456181457998434\n",
      "Epoch: 848 - time: 0.0024 - loss_train: 0.9004789397704128 - loss_val: 0.9454779708701565\n",
      "Epoch: 849 - time: 0.0024 - loss_train: 0.9002428747255857 - loss_val: 0.9453382873453492\n",
      "Epoch: 850 - time: 0.0024 - loss_train: 0.9000072145331972 - loss_val: 0.9451990928566388\n",
      "Epoch: 851 - time: 0.0024 - loss_train: 0.8997719570763554 - loss_val: 0.9450603850558267\n",
      "Epoch: 852 - time: 0.0024 - loss_train: 0.899537100253182 - loss_val: 0.9449221616150518\n",
      "Epoch: 853 - time: 0.0024 - loss_train: 0.8993026419766752 - loss_val: 0.9447844202265591\n",
      "Epoch: 854 - time: 0.0024 - loss_train: 0.899068580174579 - loss_val: 0.9446471586024549\n",
      "Epoch: 855 - time: 0.0024 - loss_train: 0.8988349127892468 - loss_val: 0.9445103744744756\n",
      "Epoch: 856 - time: 0.0024 - loss_train: 0.8986016377775145 - loss_val: 0.9443740655937456\n",
      "Epoch: 857 - time: 0.0024 - loss_train: 0.8983687531105697 - loss_val: 0.9442382297305454\n",
      "Epoch: 858 - time: 0.0024 - loss_train: 0.898136256773825 - loss_val: 0.944102864674071\n",
      "Epoch: 859 - time: 0.0026 - loss_train: 0.8979041467667913 - loss_val: 0.9439679682322029\n",
      "Epoch: 860 - time: 0.0024 - loss_train: 0.8976724211029564 - loss_val: 0.9438335382312685\n",
      "Epoch: 861 - time: 0.0025 - loss_train: 0.8974410778096599 - loss_val: 0.9436995725158117\n",
      "Epoch: 862 - time: 0.0024 - loss_train: 0.8972101149279749 - loss_val: 0.9435660689483558\n",
      "Epoch: 863 - time: 0.0024 - loss_train: 0.8969795305125869 - loss_val: 0.9434330254091751\n",
      "Epoch: 864 - time: 0.0024 - loss_train: 0.8967493226316777 - loss_val: 0.9433004397960629\n",
      "Epoch: 865 - time: 0.0024 - loss_train: 0.8965194893668093 - loss_val: 0.9431683100240986\n",
      "Epoch: 866 - time: 0.0024 - loss_train: 0.8962900288128085 - loss_val: 0.9430366340254231\n",
      "Epoch: 867 - time: 0.0024 - loss_train: 0.8960609390776563 - loss_val: 0.9429054097490043\n",
      "Epoch: 868 - time: 0.0024 - loss_train: 0.8958322182823745 - loss_val: 0.9427746351604159\n",
      "Epoch: 869 - time: 0.0024 - loss_train: 0.8956038645609167 - loss_val: 0.9426443082416079\n",
      "Epoch: 870 - time: 0.0024 - loss_train: 0.8953758760600599 - loss_val: 0.9425144269906799\n",
      "Epoch: 871 - time: 0.0024 - loss_train: 0.8951482509393001 - loss_val: 0.9423849894216612\n",
      "Epoch: 872 - time: 0.0024 - loss_train: 0.8949209873707423 - loss_val: 0.9422559935642844\n",
      "Epoch: 873 - time: 0.0024 - loss_train: 0.8946940835390021 - loss_val: 0.9421274374637655\n",
      "Epoch: 874 - time: 0.0024 - loss_train: 0.8944675376411001 - loss_val: 0.9419993191805818\n",
      "Epoch: 875 - time: 0.0024 - loss_train: 0.8942413478863611 - loss_val: 0.9418716367902554\n",
      "Epoch: 876 - time: 0.0024 - loss_train: 0.8940155124963173 - loss_val: 0.9417443883831318\n",
      "Epoch: 877 - time: 0.0024 - loss_train: 0.8937900297046064 - loss_val: 0.9416175720641669\n",
      "Epoch: 878 - time: 0.0024 - loss_train: 0.8935648977568803 - loss_val: 0.9414911859527076\n",
      "Epoch: 879 - time: 0.0024 - loss_train: 0.8933401149107042 - loss_val: 0.9413652281822822\n",
      "Epoch: 880 - time: 0.0024 - loss_train: 0.8931156794354665 - loss_val: 0.9412396969003837\n",
      "Epoch: 881 - time: 0.0024 - loss_train: 0.8928915896122861 - loss_val: 0.9411145902682635\n",
      "Epoch: 882 - time: 0.0024 - loss_train: 0.8926678437339205 - loss_val: 0.940989906460716\n",
      "Epoch: 883 - time: 0.0024 - loss_train: 0.8924444401046762 - loss_val: 0.9408656436658778\n",
      "Epoch: 884 - time: 0.0024 - loss_train: 0.8922213770403202 - loss_val: 0.9407418000850127\n",
      "Epoch: 885 - time: 0.0024 - loss_train: 0.8919986528679941 - loss_val: 0.9406183739323142\n",
      "Epoch: 886 - time: 0.0024 - loss_train: 0.8917762659261275 - loss_val: 0.9404953634346973\n",
      "Epoch: 887 - time: 0.0024 - loss_train: 0.8915542145643532 - loss_val: 0.9403727668315984\n",
      "Epoch: 888 - time: 0.0024 - loss_train: 0.8913324971434252 - loss_val: 0.9402505823747759\n",
      "Epoch: 889 - time: 0.0024 - loss_train: 0.8911111120351354 - loss_val: 0.9401288083281072\n",
      "Epoch: 890 - time: 0.0024 - loss_train: 0.8908900576222345 - loss_val: 0.9400074429673989\n",
      "Epoch: 891 - time: 0.0024 - loss_train: 0.8906693322983513 - loss_val: 0.9398864845801854\n",
      "Epoch: 892 - time: 0.0024 - loss_train: 0.8904489344679153 - loss_val: 0.939765931465538\n",
      "Epoch: 893 - time: 0.0024 - loss_train: 0.8902288625460795 - loss_val: 0.9396457819338723\n",
      "Epoch: 894 - time: 0.0024 - loss_train: 0.8900091149586453 - loss_val: 0.9395260343067586\n",
      "Epoch: 895 - time: 0.0025 - loss_train: 0.8897896901419858 - loss_val: 0.9394066869167328\n",
      "Epoch: 896 - time: 0.0024 - loss_train: 0.8895705865429768 - loss_val: 0.9392877381071121\n",
      "Epoch: 897 - time: 0.0024 - loss_train: 0.8893518026189186 - loss_val: 0.9391691862318058\n",
      "Epoch: 898 - time: 0.0024 - loss_train: 0.8891333368374705 - loss_val: 0.9390510296551376\n",
      "Epoch: 899 - time: 0.0024 - loss_train: 0.888915187676578 - loss_val: 0.9389332667516601\n",
      "Epoch: 900 - time: 0.0024 - loss_train: 0.8886973536244038 - loss_val: 0.9388158959059792\n",
      "Epoch: 901 - time: 0.0024 - loss_train: 0.8884798331792619 - loss_val: 0.9386989155125737\n",
      "Epoch: 902 - time: 0.0024 - loss_train: 0.8882626248495498 - loss_val: 0.9385823239756216\n",
      "Epoch: 903 - time: 0.0024 - loss_train: 0.8880457271536831 - loss_val: 0.9384661197088262\n",
      "Epoch: 904 - time: 0.0024 - loss_train: 0.8878291386200312 - loss_val: 0.9383503011352445\n",
      "Epoch: 905 - time: 0.0025 - loss_train: 0.8876128577868544 - loss_val: 0.938234866687118\n",
      "Epoch: 906 - time: 0.0026 - loss_train: 0.887396883202241 - loss_val: 0.9381198148057036\n",
      "Epoch: 907 - time: 0.0024 - loss_train: 0.8871812134240459 - loss_val: 0.9380051439411087\n",
      "Epoch: 908 - time: 0.0024 - loss_train: 0.8869658470198315 - loss_val: 0.9378908525521276\n",
      "Epoch: 909 - time: 0.0024 - loss_train: 0.886750782566807 - loss_val: 0.9377769391060808\n",
      "Epoch: 910 - time: 0.0024 - loss_train: 0.8865360186517716 - loss_val: 0.9376634020786507\n",
      "Epoch: 911 - time: 0.0024 - loss_train: 0.8863215538710554 - loss_val: 0.9375502399537322\n",
      "Epoch: 912 - time: 0.0025 - loss_train: 0.8861073868304657 - loss_val: 0.9374374512232662\n",
      "Epoch: 913 - time: 0.0024 - loss_train: 0.8858935161452296 - loss_val: 0.9373250343870968\n",
      "Epoch: 914 - time: 0.0024 - loss_train: 0.8856799404399394 - loss_val: 0.9372129879528114\n",
      "Epoch: 915 - time: 0.0024 - loss_train: 0.885466658348502 - loss_val: 0.9371013104355959\n",
      "Epoch: 916 - time: 0.0024 - loss_train: 0.8852536685140827 - loss_val: 0.9369900003580841\n",
      "Epoch: 917 - time: 0.0024 - loss_train: 0.8850409695890562 - loss_val: 0.9368790562502168\n",
      "Epoch: 918 - time: 0.0024 - loss_train: 0.8848285602349545 - loss_val: 0.9367684766490912\n",
      "Epoch: 919 - time: 0.0024 - loss_train: 0.884616439122418 - loss_val: 0.9366582600988292\n",
      "Epoch: 920 - time: 0.0024 - loss_train: 0.8844046049311458 - loss_val: 0.9365484051504298\n",
      "Epoch: 921 - time: 0.0024 - loss_train: 0.8841930563498488 - loss_val: 0.9364389103616365\n",
      "Epoch: 922 - time: 0.0024 - loss_train: 0.8839817920762001 - loss_val: 0.9363297742968028\n",
      "Epoch: 923 - time: 0.0024 - loss_train: 0.8837708108167912 - loss_val: 0.9362209955267576\n",
      "Epoch: 924 - time: 0.0024 - loss_train: 0.8835601112870844 - loss_val: 0.936112572628675\n",
      "Epoch: 925 - time: 0.0024 - loss_train: 0.8833496922113689 - loss_val: 0.9360045041859488\n",
      "Epoch: 926 - time: 0.0024 - loss_train: 0.8831395523227175 - loss_val: 0.9358967887880605\n",
      "Epoch: 927 - time: 0.0024 - loss_train: 0.8829296903629409 - loss_val: 0.9357894250304607\n",
      "Epoch: 928 - time: 0.0024 - loss_train: 0.8827201050825474 - loss_val: 0.9356824115144458\n",
      "Epoch: 929 - time: 0.0024 - loss_train: 0.8825107952407013 - loss_val: 0.9355757468470368\n",
      "Epoch: 930 - time: 0.0024 - loss_train: 0.8823017596051801 - loss_val: 0.9354694296408619\n",
      "Epoch: 931 - time: 0.0024 - loss_train: 0.882092996952335 - loss_val: 0.9353634585140443\n",
      "Epoch: 932 - time: 0.0024 - loss_train: 0.8818845060670524 - loss_val: 0.9352578320900843\n",
      "Epoch: 933 - time: 0.0024 - loss_train: 0.8816762857427134 - loss_val: 0.9351525489977527\n",
      "Epoch: 934 - time: 0.0024 - loss_train: 0.8814683347811563 - loss_val: 0.9350476078709784\n",
      "Epoch: 935 - time: 0.0024 - loss_train: 0.8812606519926389 - loss_val: 0.9349430073487444\n",
      "Epoch: 936 - time: 0.0024 - loss_train: 0.8810532361958028 - loss_val: 0.934838746074983\n",
      "Epoch: 937 - time: 0.0024 - loss_train: 0.8808460862176342 - loss_val: 0.9347348226984714\n",
      "Epoch: 938 - time: 0.0024 - loss_train: 0.8806392008934317 - loss_val: 0.9346312358727351\n",
      "Epoch: 939 - time: 0.0024 - loss_train: 0.8804325790667685 - loss_val: 0.9345279842559473\n",
      "Epoch: 940 - time: 0.0024 - loss_train: 0.88022621958946 - loss_val: 0.9344250665108351\n",
      "Epoch: 941 - time: 0.0024 - loss_train: 0.8800201213215294 - loss_val: 0.9343224813045856\n",
      "Epoch: 942 - time: 0.0024 - loss_train: 0.8798142831311729 - loss_val: 0.9342202273087536\n",
      "Epoch: 943 - time: 0.0024 - loss_train: 0.8796087038947293 - loss_val: 0.9341183031991739\n",
      "Epoch: 944 - time: 0.0024 - loss_train: 0.879403382496646 - loss_val: 0.9340167076558739\n",
      "Epoch: 945 - time: 0.0024 - loss_train: 0.8791983178294488 - loss_val: 0.9339154393629897\n",
      "Epoch: 946 - time: 0.0024 - loss_train: 0.8789935087937094 - loss_val: 0.9338144970086824\n",
      "Epoch: 947 - time: 0.0024 - loss_train: 0.8787889542980162 - loss_val: 0.9337138792850591\n",
      "Epoch: 948 - time: 0.0024 - loss_train: 0.8785846532589429 - loss_val: 0.9336135848880939\n",
      "Epoch: 949 - time: 0.0024 - loss_train: 0.8783806046010189 - loss_val: 0.9335136125175536\n",
      "Epoch: 950 - time: 0.0024 - loss_train: 0.8781768072567013 - loss_val: 0.9334139608769203\n",
      "Epoch: 951 - time: 0.0024 - loss_train: 0.8779732601663445 - loss_val: 0.9333146286733255\n",
      "Epoch: 952 - time: 0.0024 - loss_train: 0.8777699622781729 - loss_val: 0.9332156146174749\n",
      "Epoch: 953 - time: 0.0034 - loss_train: 0.8775669125482531 - loss_val: 0.9331169174235847\n",
      "Epoch: 954 - time: 0.0033 - loss_train: 0.8773641099404653 - loss_val: 0.933018535809317\n",
      "Epoch: 955 - time: 0.0025 - loss_train: 0.8771615534264774 - loss_val: 0.932920468495714\n",
      "Epoch: 956 - time: 0.0024 - loss_train: 0.8769592419857164 - loss_val: 0.9328227142071394\n",
      "Epoch: 957 - time: 0.0025 - loss_train: 0.8767571746053444 - loss_val: 0.9327252716712188\n",
      "Epoch: 958 - time: 0.0024 - loss_train: 0.8765553502802306 - loss_val: 0.9326281396187842\n",
      "Epoch: 959 - time: 0.0024 - loss_train: 0.8763537680129254 - loss_val: 0.9325313167838187\n",
      "Epoch: 960 - time: 0.0024 - loss_train: 0.8761524268136374 - loss_val: 0.9324348019034031\n",
      "Epoch: 961 - time: 0.0024 - loss_train: 0.8759513257002047 - loss_val: 0.9323385937176683\n",
      "Epoch: 962 - time: 0.0024 - loss_train: 0.8757504636980732 - loss_val: 0.9322426909697465\n",
      "Epoch: 963 - time: 0.0024 - loss_train: 0.8755498398402694 - loss_val: 0.9321470924057226\n",
      "Epoch: 964 - time: 0.0024 - loss_train: 0.8753494531673779 - loss_val: 0.9320517967745936\n",
      "Epoch: 965 - time: 0.0024 - loss_train: 0.8751493027275165 - loss_val: 0.9319568028282234\n",
      "Epoch: 966 - time: 0.0024 - loss_train: 0.8749493875763119 - loss_val: 0.9318621093213071\n",
      "Epoch: 967 - time: 0.0024 - loss_train: 0.8747497067768772 - loss_val: 0.9317677150113282\n",
      "Epoch: 968 - time: 0.0024 - loss_train: 0.8745502593997867 - loss_val: 0.9316736186585249\n",
      "Epoch: 969 - time: 0.0024 - loss_train: 0.8743510445230539 - loss_val: 0.931579819025859\n",
      "Epoch: 970 - time: 0.0024 - loss_train: 0.8741520612321092 - loss_val: 0.93148631487898\n",
      "Epoch: 971 - time: 0.0024 - loss_train: 0.873953308619773 - loss_val: 0.931393104986196\n",
      "Epoch: 972 - time: 0.0024 - loss_train: 0.8737547857862373 - loss_val: 0.9313001881184468\n",
      "Epoch: 973 - time: 0.0024 - loss_train: 0.8735564918390409 - loss_val: 0.9312075630492782\n",
      "Epoch: 974 - time: 0.0024 - loss_train: 0.8733584258930461 - loss_val: 0.9311152285548141\n",
      "Epoch: 975 - time: 0.0024 - loss_train: 0.8731605870704187 - loss_val: 0.9310231834137415\n",
      "Epoch: 976 - time: 0.0024 - loss_train: 0.8729629745006013 - loss_val: 0.9309314264072821\n",
      "Epoch: 977 - time: 0.0024 - loss_train: 0.8727655873202953 - loss_val: 0.9308399563191806\n",
      "Epoch: 978 - time: 0.0024 - loss_train: 0.8725684246734355 - loss_val: 0.9307487719356824\n",
      "Epoch: 979 - time: 0.0024 - loss_train: 0.8723714857111697 - loss_val: 0.9306578720455236\n",
      "Epoch: 980 - time: 0.0024 - loss_train: 0.8721747695918353 - loss_val: 0.9305672554399139\n",
      "Epoch: 981 - time: 0.0024 - loss_train: 0.8719782754809363 - loss_val: 0.9304769209125286\n",
      "Epoch: 982 - time: 0.0024 - loss_train: 0.8717820025511233 - loss_val: 0.930386867259499\n",
      "Epoch: 983 - time: 0.0024 - loss_train: 0.8715859499821693 - loss_val: 0.9302970932793999\n",
      "Epoch: 984 - time: 0.0024 - loss_train: 0.8713901169609474 - loss_val: 0.930207597773251\n",
      "Epoch: 985 - time: 0.0024 - loss_train: 0.8711945026814094 - loss_val: 0.9301183795445074\n",
      "Epoch: 986 - time: 0.0024 - loss_train: 0.8709991063445626 - loss_val: 0.9300294373990596\n",
      "Epoch: 987 - time: 0.0024 - loss_train: 0.8708039271584478 - loss_val: 0.9299407701452297\n",
      "Epoch: 988 - time: 0.0024 - loss_train: 0.8706089643381156 - loss_val: 0.9298523765937753\n",
      "Epoch: 989 - time: 0.0024 - loss_train: 0.8704142171056047 - loss_val: 0.92976425555789\n",
      "Epoch: 990 - time: 0.0024 - loss_train: 0.8702196846899192 - loss_val: 0.9296764058532078\n",
      "Epoch: 991 - time: 0.0024 - loss_train: 0.8700253663270048 - loss_val: 0.9295888262978097\n",
      "Epoch: 992 - time: 0.0024 - loss_train: 0.8698312612597259 - loss_val: 0.9295015157122256\n",
      "Epoch: 993 - time: 0.0024 - loss_train: 0.8696373687378431 - loss_val: 0.9294144729194513\n",
      "Epoch: 994 - time: 0.0024 - loss_train: 0.8694436880179894 - loss_val: 0.9293276967449504\n",
      "Epoch: 995 - time: 0.0024 - loss_train: 0.8692502183636459 - loss_val: 0.9292411860166697\n",
      "Epoch: 996 - time: 0.0024 - loss_train: 0.8690569590451188 - loss_val: 0.929154939565052\n",
      "Epoch: 997 - time: 0.0024 - loss_train: 0.8688639093395158 - loss_val: 0.929068956223049\n",
      "Epoch: 998 - time: 0.0024 - loss_train: 0.8686710685307214 - loss_val: 0.9289832348261367\n",
      "Epoch: 999 - time: 0.0029 - loss_train: 0.8684784359093719 - loss_val: 0.9288977742123341\n",
      "Epoch: 1000 - time: 0.0025 - loss_train: 0.8682860107728323 - loss_val: 0.9288125732222192\n",
      "Epoch: 1001 - time: 0.0024 - loss_train: 0.8680937924251704 - loss_val: 0.9287276306989503\n",
      "Epoch: 1002 - time: 0.0024 - loss_train: 0.8679017801771322 - loss_val: 0.9286429454882851\n",
      "Epoch: 1003 - time: 0.0024 - loss_train: 0.8677099733461157 - loss_val: 0.9285585164386041\n",
      "Epoch: 1004 - time: 0.0024 - loss_train: 0.8675183712561468 - loss_val: 0.9284743424009319\n",
      "Epoch: 1005 - time: 0.0024 - loss_train: 0.867326973237852 - loss_val: 0.9283904222289634\n",
      "Epoch: 1006 - time: 0.0024 - loss_train: 0.8671357786284336 - loss_val: 0.9283067547790879\n",
      "Epoch: 1007 - time: 0.0024 - loss_train: 0.8669447867716412 - loss_val: 0.9282233389104142\n",
      "Epoch: 1008 - time: 0.0024 - loss_train: 0.8667539970177474 - loss_val: 0.9281401734848024\n",
      "Epoch: 1009 - time: 0.0024 - loss_train: 0.8665634087235184 - loss_val: 0.9280572573668865\n",
      "Epoch: 1010 - time: 0.0024 - loss_train: 0.8663730212521894 - loss_val: 0.9279745894241092\n",
      "Epoch: 1011 - time: 0.0024 - loss_train: 0.8661828339734337 - loss_val: 0.9278921685267487\n",
      "Epoch: 1012 - time: 0.0024 - loss_train: 0.8659928462633361 - loss_val: 0.9278099935479512\n",
      "Epoch: 1013 - time: 0.0024 - loss_train: 0.8658030575043657 - loss_val: 0.9277280633637622\n",
      "Epoch: 1014 - time: 0.0024 - loss_train: 0.8656134670853459 - loss_val: 0.9276463768531634\n",
      "Epoch: 1015 - time: 0.0024 - loss_train: 0.8654240744014243 - loss_val: 0.9275649328981008\n",
      "Epoch: 1016 - time: 0.0024 - loss_train: 0.8652348788540457 - loss_val: 0.9274837303835212\n",
      "Epoch: 1017 - time: 0.0024 - loss_train: 0.8650458798509203 - loss_val: 0.9274027681974094\n",
      "Epoch: 1018 - time: 0.0024 - loss_train: 0.8648570768059941 - loss_val: 0.9273220452308253\n",
      "Epoch: 1019 - time: 0.0024 - loss_train: 0.8646684691394193 - loss_val: 0.9272415603779324\n",
      "Epoch: 1020 - time: 0.0024 - loss_train: 0.8644800562775214 - loss_val: 0.9271613125360456\n",
      "Epoch: 1021 - time: 0.0024 - loss_train: 0.86429183765277 - loss_val: 0.9270813006056627\n",
      "Epoch: 1022 - time: 0.0024 - loss_train: 0.8641038127037451 - loss_val: 0.9270015234905045\n",
      "Epoch: 1023 - time: 0.0024 - loss_train: 0.8639159808751067 - loss_val: 0.9269219800975531\n",
      "Epoch: 1024 - time: 0.0024 - loss_train: 0.8637283416175622 - loss_val: 0.926842669337091\n",
      "Epoch: 1025 - time: 0.0024 - loss_train: 0.8635408943878312 - loss_val: 0.9267635901227428\n",
      "Epoch: 1026 - time: 0.0024 - loss_train: 0.8633536386486157 - loss_val: 0.9266847413715148\n",
      "Epoch: 1027 - time: 0.0024 - loss_train: 0.8631665738685633 - loss_val: 0.926606122003833\n",
      "Epoch: 1028 - time: 0.0024 - loss_train: 0.8629796995222362 - loss_val: 0.9265277309435866\n",
      "Epoch: 1029 - time: 0.0024 - loss_train: 0.8627930150900729 - loss_val: 0.9264495671181683\n",
      "Epoch: 1030 - time: 0.0024 - loss_train: 0.8626065200583564 - loss_val: 0.9263716294585163\n",
      "Epoch: 1031 - time: 0.0024 - loss_train: 0.8624202139191796 - loss_val: 0.9262939168991557\n",
      "Epoch: 1032 - time: 0.0024 - loss_train: 0.8622340961704048 - loss_val: 0.9262164283782385\n",
      "Epoch: 1033 - time: 0.0024 - loss_train: 0.8620481663156331 - loss_val: 0.9261391628375877\n",
      "Epoch: 1034 - time: 0.0024 - loss_train: 0.861862423864165 - loss_val: 0.9260621192227404\n",
      "Epoch: 1035 - time: 0.0024 - loss_train: 0.861676868330964 - loss_val: 0.9259852964829856\n",
      "Epoch: 1036 - time: 0.0024 - loss_train: 0.8614914992366192 - loss_val: 0.9259086935714101\n",
      "Epoch: 1037 - time: 0.0024 - loss_train: 0.8613063161073082 - loss_val: 0.925832309444939\n",
      "Epoch: 1038 - time: 0.0024 - loss_train: 0.8611213184747591 - loss_val: 0.9257561430643777\n",
      "Epoch: 1039 - time: 0.0024 - loss_train: 0.8609365058762105 - loss_val: 0.9256801933944547\n",
      "Epoch: 1040 - time: 0.0024 - loss_train: 0.8607518778543747 - loss_val: 0.9256044594038628\n",
      "Epoch: 1041 - time: 0.0024 - loss_train: 0.8605674339573975 - loss_val: 0.9255289400653005\n",
      "Epoch: 1042 - time: 0.0024 - loss_train: 0.8603831737388171 - loss_val: 0.9254536343555146\n",
      "Epoch: 1043 - time: 0.0024 - loss_train: 0.860199096757529 - loss_val: 0.9253785412553384\n",
      "Epoch: 1044 - time: 0.0024 - loss_train: 0.8600152025777388 - loss_val: 0.9253036597497382\n",
      "Epoch: 1045 - time: 0.0024 - loss_train: 0.8598314907689272 - loss_val: 0.9252289888278472\n",
      "Epoch: 1046 - time: 0.0024 - loss_train: 0.8596479609058058 - loss_val: 0.9251545274830124\n",
      "Epoch: 1047 - time: 0.0030 - loss_train: 0.8594646125682769 - loss_val: 0.9250802747128292\n",
      "Epoch: 1048 - time: 0.0025 - loss_train: 0.8592814453413916 - loss_val: 0.9250062295191844\n",
      "Epoch: 1049 - time: 0.0024 - loss_train: 0.8590984588153076 - loss_val: 0.9249323909082953\n",
      "Epoch: 1050 - time: 0.0024 - loss_train: 0.8589156525852464 - loss_val: 0.9248587578907425\n",
      "Epoch: 1051 - time: 0.0024 - loss_train: 0.8587330262514514 - loss_val: 0.9247853294815181\n",
      "Epoch: 1052 - time: 0.0024 - loss_train: 0.8585505794191438 - loss_val: 0.9247121047000557\n",
      "Epoch: 1053 - time: 0.0024 - loss_train: 0.8583683116984798 - loss_val: 0.9246390825702681\n",
      "Epoch: 1054 - time: 0.0024 - loss_train: 0.8581862227045075 - loss_val: 0.9245662621205892\n",
      "Epoch: 1055 - time: 0.0024 - loss_train: 0.8580043120571217 - loss_val: 0.9244936423840034\n",
      "Epoch: 1056 - time: 0.0024 - loss_train: 0.8578225793810204 - loss_val: 0.9244212223980829\n",
      "Epoch: 1057 - time: 0.0024 - loss_train: 0.8576410243056602 - loss_val: 0.9243490012050243\n",
      "Epoch: 1058 - time: 0.0024 - loss_train: 0.8574596464652117 - loss_val: 0.9242769778516798\n",
      "Epoch: 1059 - time: 0.0024 - loss_train: 0.8572784454985136 - loss_val: 0.9242051513895931\n",
      "Epoch: 1060 - time: 0.0024 - loss_train: 0.8570974210490286 - loss_val: 0.9241335208750263\n",
      "Epoch: 1061 - time: 0.0024 - loss_train: 0.8569165727647974 - loss_val: 0.9240620853689993\n",
      "Epoch: 1062 - time: 0.0024 - loss_train: 0.8567359002983923 - loss_val: 0.9239908439373129\n",
      "Epoch: 1063 - time: 0.0024 - loss_train: 0.8565554033068729 - loss_val: 0.9239197956505818\n",
      "Epoch: 1064 - time: 0.0024 - loss_train: 0.8563750814517379 - loss_val: 0.9238489395842673\n",
      "Epoch: 1065 - time: 0.0024 - loss_train: 0.8561949343988802 - loss_val: 0.923778274818697\n",
      "Epoch: 1066 - time: 0.0024 - loss_train: 0.8560149618185404 - loss_val: 0.9237078004390998\n",
      "Epoch: 1067 - time: 0.0024 - loss_train: 0.8558351633852597 - loss_val: 0.9236375155356277\n",
      "Epoch: 1068 - time: 0.0024 - loss_train: 0.8556555387778324 - loss_val: 0.9235674192033838\n",
      "Epoch: 1069 - time: 0.0024 - loss_train: 0.8554760876792604 - loss_val: 0.9234975105424427\n",
      "Epoch: 1070 - time: 0.0024 - loss_train: 0.8552968097767052 - loss_val: 0.9234277886578798\n",
      "Epoch: 1071 - time: 0.0024 - loss_train: 0.8551177047614412 - loss_val: 0.9233582526597873\n",
      "Epoch: 1072 - time: 0.0024 - loss_train: 0.8549387723288076 - loss_val: 0.9232889016632986\n",
      "Epoch: 1073 - time: 0.0024 - loss_train: 0.854760012178162 - loss_val: 0.9232197347886096\n",
      "Epoch: 1074 - time: 0.0024 - loss_train: 0.8545814240128319 - loss_val: 0.9231507511609948\n",
      "Epoch: 1075 - time: 0.0024 - loss_train: 0.8544030075400687 - loss_val: 0.9230819499108286\n",
      "Epoch: 1076 - time: 0.0024 - loss_train: 0.8542247624709978 - loss_val: 0.9230133301736002\n",
      "Epoch: 1077 - time: 0.0024 - loss_train: 0.854046688520573 - loss_val: 0.9229448910899292\n",
      "Epoch: 1078 - time: 0.0024 - loss_train: 0.8538687854075286 - loss_val: 0.9228766318055818\n",
      "Epoch: 1079 - time: 0.0024 - loss_train: 0.8536910528543309 - loss_val: 0.9228085514714828\n",
      "Epoch: 1080 - time: 0.0024 - loss_train: 0.8535134905871304 - loss_val: 0.9227406492437302\n",
      "Epoch: 1081 - time: 0.0024 - loss_train: 0.8533360983357159 - loss_val: 0.9226729242836047\n",
      "Epoch: 1082 - time: 0.0024 - loss_train: 0.8531588758334653 - loss_val: 0.9226053757575801\n",
      "Epoch: 1083 - time: 0.0024 - loss_train: 0.8529818228172974 - loss_val: 0.9225380028373331\n",
      "Epoch: 1084 - time: 0.0024 - loss_train: 0.8528049390276267 - loss_val: 0.9224708046997507\n",
      "Epoch: 1085 - time: 0.0024 - loss_train: 0.8526282242083141 - loss_val: 0.9224037805269348\n",
      "Epoch: 1086 - time: 0.0024 - loss_train: 0.8524516781066201 - loss_val: 0.9223369295062118\n",
      "Epoch: 1087 - time: 0.0024 - loss_train: 0.8522753004731579 - loss_val: 0.9222702508301343\n",
      "Epoch: 1088 - time: 0.0024 - loss_train: 0.8520990910618456 - loss_val: 0.922203743696482\n",
      "Epoch: 1089 - time: 0.0024 - loss_train: 0.8519230496298594 - loss_val: 0.9221374073082698\n",
      "Epoch: 1090 - time: 0.0024 - loss_train: 0.851747175937587 - loss_val: 0.922071240873739\n",
      "Epoch: 1091 - time: 0.0024 - loss_train: 0.8515714697485798 - loss_val: 0.9220052436063677\n",
      "Epoch: 1092 - time: 0.0024 - loss_train: 0.8513959308295077 - loss_val: 0.921939414724859\n",
      "Epoch: 1093 - time: 0.0024 - loss_train: 0.8512205589501125 - loss_val: 0.9218737534531458\n",
      "Epoch: 1094 - time: 0.0024 - loss_train: 0.8510453538831596 - loss_val: 0.9218082590203812\n",
      "Epoch: 1095 - time: 0.0026 - loss_train: 0.850870315404395 - loss_val: 0.9217429306609344\n",
      "Epoch: 1096 - time: 0.0024 - loss_train: 0.8506954432924977 - loss_val: 0.9216777676143857\n",
      "Epoch: 1097 - time: 0.0024 - loss_train: 0.8505207373290333 - loss_val: 0.9216127691255187\n",
      "Epoch: 1098 - time: 0.0024 - loss_train: 0.850346197298411 - loss_val: 0.9215479344443092\n",
      "Epoch: 1099 - time: 0.0024 - loss_train: 0.8501718229878366 - loss_val: 0.9214832628259151\n",
      "Epoch: 1100 - time: 0.0024 - loss_train: 0.8499976141872678 - loss_val: 0.9214187535306669\n",
      "Epoch: 1101 - time: 0.0025 - loss_train: 0.8498235706893702 - loss_val: 0.9213544058240555\n",
      "Epoch: 1102 - time: 0.0024 - loss_train: 0.8496496922894736 - loss_val: 0.9212902189767147\n",
      "Epoch: 1103 - time: 0.0024 - loss_train: 0.8494759787855249 - loss_val: 0.9212261922644102\n",
      "Epoch: 1104 - time: 0.0024 - loss_train: 0.8493024299780486 - loss_val: 0.9211623249680222\n",
      "Epoch: 1105 - time: 0.0024 - loss_train: 0.8491290456700995 - loss_val: 0.9210986163735272\n",
      "Epoch: 1106 - time: 0.0024 - loss_train: 0.8489558256672228 - loss_val: 0.9210350657719826\n",
      "Epoch: 1107 - time: 0.0024 - loss_train: 0.8487827697774094 - loss_val: 0.9209716724595031\n",
      "Epoch: 1108 - time: 0.0024 - loss_train: 0.8486098778110531 - loss_val: 0.9209084357372442\n",
      "Epoch: 1109 - time: 0.0024 - loss_train: 0.8484371495809104 - loss_val: 0.920845354911379\n",
      "Epoch: 1110 - time: 0.0024 - loss_train: 0.8482645849020564 - loss_val: 0.9207824292930742\n",
      "Epoch: 1111 - time: 0.0024 - loss_train: 0.8480921835918465 - loss_val: 0.9207196581984671\n",
      "Epoch: 1112 - time: 0.0024 - loss_train: 0.8479199454698714 - loss_val: 0.9206570409486431\n",
      "Epoch: 1113 - time: 0.0024 - loss_train: 0.8477478703579205 - loss_val: 0.9205945768696077\n",
      "Epoch: 1114 - time: 0.0024 - loss_train: 0.8475759580799395 - loss_val: 0.9205322652922583\n",
      "Epoch: 1115 - time: 0.0024 - loss_train: 0.84740420846199 - loss_val: 0.9204701055523599\n",
      "Epoch: 1116 - time: 0.0024 - loss_train: 0.8472326213322122 - loss_val: 0.920408096990514\n",
      "Epoch: 1117 - time: 0.0024 - loss_train: 0.8470611965207845 - loss_val: 0.9203462389521299\n",
      "Epoch: 1118 - time: 0.0024 - loss_train: 0.8468899338598846 - loss_val: 0.9202845307873906\n",
      "Epoch: 1119 - time: 0.0024 - loss_train: 0.846718833183653 - loss_val: 0.9202229718512267\n",
      "Epoch: 1120 - time: 0.0024 - loss_train: 0.8465478943281539 - loss_val: 0.9201615615032792\n",
      "Epoch: 1121 - time: 0.0024 - loss_train: 0.8463771171313381 - loss_val: 0.9201002991078714\n",
      "Epoch: 1122 - time: 0.0024 - loss_train: 0.8462065014330065 - loss_val: 0.9200391840339652\n",
      "Epoch: 1123 - time: 0.0024 - loss_train: 0.8460360470747744 - loss_val: 0.9199782156551362\n",
      "Epoch: 1124 - time: 0.0024 - loss_train: 0.8458657539000335 - loss_val: 0.9199173933495305\n",
      "Epoch: 1125 - time: 0.0024 - loss_train: 0.8456956217539195 - loss_val: 0.919856716499832\n",
      "Epoch: 1126 - time: 0.0024 - loss_train: 0.8455256504832743 - loss_val: 0.9197961844932226\n",
      "Epoch: 1127 - time: 0.0024 - loss_train: 0.8453558399366143 - loss_val: 0.9197357967213451\n",
      "Epoch: 1128 - time: 0.0024 - loss_train: 0.8451861899640919 - loss_val: 0.919675552580262\n",
      "Epoch: 1129 - time: 0.0024 - loss_train: 0.845016700417468 - loss_val: 0.9196154514704186\n",
      "Epoch: 1130 - time: 0.0024 - loss_train: 0.844847371150074 - loss_val: 0.9195554927966002\n",
      "Epoch: 1131 - time: 0.0024 - loss_train: 0.8446782020167817 - loss_val: 0.9194956759678911\n",
      "Epoch: 1132 - time: 0.0024 - loss_train: 0.8445091928739706 - loss_val: 0.9194360003976343\n",
      "Epoch: 1133 - time: 0.0024 - loss_train: 0.8443403435794952 - loss_val: 0.9193764655033861\n",
      "Epoch: 1134 - time: 0.0024 - loss_train: 0.8441716539926563 - loss_val: 0.9193170707068752\n",
      "Epoch: 1135 - time: 0.0024 - loss_train: 0.8440031239741684 - loss_val: 0.9192578154339596\n",
      "Epoch: 1136 - time: 0.0024 - loss_train: 0.8438347533861303 - loss_val: 0.9191986991145786\n",
      "Epoch: 1137 - time: 0.0024 - loss_train: 0.8436665420919954 - loss_val: 0.9191397211827126\n",
      "Epoch: 1138 - time: 0.0024 - loss_train: 0.8434984899565423 - loss_val: 0.919080881076334\n",
      "Epoch: 1139 - time: 0.0024 - loss_train: 0.8433305968458472 - loss_val: 0.9190221782373631\n",
      "Epoch: 1140 - time: 0.0024 - loss_train: 0.8431628626272537 - loss_val: 0.9189636121116223\n",
      "Epoch: 1141 - time: 0.0024 - loss_train: 0.8429952871693481 - loss_val: 0.918905182148786\n",
      "Epoch: 1142 - time: 0.0026 - loss_train: 0.8428278703419287 - loss_val: 0.918846887802339\n",
      "Epoch: 1143 - time: 0.0024 - loss_train: 0.8426606120159824 - loss_val: 0.9187887285295229\n",
      "Epoch: 1144 - time: 0.0024 - loss_train: 0.8424935120636569 - loss_val: 0.9187307037912924\n",
      "Epoch: 1145 - time: 0.0024 - loss_train: 0.8423265703582353 - loss_val: 0.9186728130522651\n",
      "Epoch: 1146 - time: 0.0024 - loss_train: 0.8421597867741106 - loss_val: 0.9186150557806713\n",
      "Epoch: 1147 - time: 0.0024 - loss_train: 0.8419931611867617 - loss_val: 0.918557431448309\n",
      "Epoch: 1148 - time: 0.0024 - loss_train: 0.8418266934727285 - loss_val: 0.9184999395304911\n",
      "Epoch: 1149 - time: 0.0024 - loss_train: 0.8416603835095886 - loss_val: 0.9184425795059962\n",
      "Epoch: 1150 - time: 0.0024 - loss_train: 0.8414942311759345 - loss_val: 0.9183853508570204\n",
      "Epoch: 1151 - time: 0.0024 - loss_train: 0.84132823635135 - loss_val: 0.9183282530691264\n",
      "Epoch: 1152 - time: 0.0024 - loss_train: 0.8411623989163878 - loss_val: 0.9182712856311933\n",
      "Epoch: 1153 - time: 0.0024 - loss_train: 0.8409967187525489 - loss_val: 0.9182144480353647\n",
      "Epoch: 1154 - time: 0.0024 - loss_train: 0.8408311957422597 - loss_val: 0.9181577397770003\n",
      "Epoch: 1155 - time: 0.0024 - loss_train: 0.8406658297688523 - loss_val: 0.918101160354624\n",
      "Epoch: 1156 - time: 0.0024 - loss_train: 0.8405006207165442 - loss_val: 0.9180447092698746\n",
      "Epoch: 1157 - time: 0.0024 - loss_train: 0.8403355684704169 - loss_val: 0.9179883860274513\n",
      "Epoch: 1158 - time: 0.0024 - loss_train: 0.8401706729163977 - loss_val: 0.9179321901350659\n",
      "Epoch: 1159 - time: 0.0024 - loss_train: 0.8400059339412411 - loss_val: 0.9178761211033913\n",
      "Epoch: 1160 - time: 0.0024 - loss_train: 0.8398413514325079 - loss_val: 0.9178201784460098\n",
      "Epoch: 1161 - time: 0.0024 - loss_train: 0.8396769252785492 - loss_val: 0.9177643616793603\n",
      "Epoch: 1162 - time: 0.0024 - loss_train: 0.8395126553684882 - loss_val: 0.9177086703226902\n",
      "Epoch: 1163 - time: 0.0024 - loss_train: 0.8393485415922023 - loss_val: 0.9176531038980029\n",
      "Epoch: 1164 - time: 0.0024 - loss_train: 0.8391845838403069 - loss_val: 0.9175976619300068\n",
      "Epoch: 1165 - time: 0.0024 - loss_train: 0.8390207820041378 - loss_val: 0.9175423439460633\n",
      "Epoch: 1166 - time: 0.0024 - loss_train: 0.8388571359757366 - loss_val: 0.9174871494761387\n",
      "Epoch: 1167 - time: 0.0024 - loss_train: 0.8386936456478344 - loss_val: 0.9174320780527491\n",
      "Epoch: 1168 - time: 0.0024 - loss_train: 0.8385303109138362 - loss_val: 0.9173771292109136\n",
      "Epoch: 1169 - time: 0.0024 - loss_train: 0.838367131667806 - loss_val: 0.917322302488102\n",
      "Epoch: 1170 - time: 0.0024 - loss_train: 0.8382041078044538 - loss_val: 0.9172675974241848\n",
      "Epoch: 1171 - time: 0.0024 - loss_train: 0.838041239219119 - loss_val: 0.917213013561382\n",
      "Epoch: 1172 - time: 0.0024 - loss_train: 0.8378785258077589 - loss_val: 0.9171585504442132\n",
      "Epoch: 1173 - time: 0.0024 - loss_train: 0.8377159674669349 - loss_val: 0.9171042076194499\n",
      "Epoch: 1174 - time: 0.0024 - loss_train: 0.8375535640937981 - loss_val: 0.9170499846360636\n",
      "Epoch: 1175 - time: 0.0024 - loss_train: 0.8373913155860785 - loss_val: 0.9169958810451748\n",
      "Epoch: 1176 - time: 0.0024 - loss_train: 0.8372292218420713 - loss_val: 0.9169418964000069\n",
      "Epoch: 1177 - time: 0.0024 - loss_train: 0.8370672827606267 - loss_val: 0.9168880302558374\n",
      "Epoch: 1178 - time: 0.0024 - loss_train: 0.836905498241136 - loss_val: 0.9168342821699486\n",
      "Epoch: 1179 - time: 0.0024 - loss_train: 0.8367438681835231 - loss_val: 0.9167806517015727\n",
      "Epoch: 1180 - time: 0.0024 - loss_train: 0.83658239248823 - loss_val: 0.9167271384118565\n",
      "Epoch: 1181 - time: 0.0024 - loss_train: 0.8364210710562097 - loss_val: 0.916673741863802\n",
      "Epoch: 1182 - time: 0.0024 - loss_train: 0.8362599037889143 - loss_val: 0.9166204616222239\n",
      "Epoch: 1183 - time: 0.0024 - loss_train: 0.8360988905882843 - loss_val: 0.9165672972537032\n",
      "Epoch: 1184 - time: 0.0024 - loss_train: 0.8359380313567402 - loss_val: 0.9165142483265377\n",
      "Epoch: 1185 - time: 0.0024 - loss_train: 0.8357773259971725 - loss_val: 0.9164613144106977\n",
      "Epoch: 1186 - time: 0.0024 - loss_train: 0.8356167744129325 - loss_val: 0.9164084950777771\n",
      "Epoch: 1187 - time: 0.0024 - loss_train: 0.8354563765078236 - loss_val: 0.9163557899009502\n",
      "Epoch: 1188 - time: 0.0024 - loss_train: 0.8352961321860917 - loss_val: 0.9163031984549261\n",
      "Epoch: 1189 - time: 0.0030 - loss_train: 0.8351360413524191 - loss_val: 0.9162507203159032\n",
      "Epoch: 1190 - time: 0.0025 - loss_train: 0.8349761039119141 - loss_val: 0.9161983550615208\n",
      "Epoch: 1191 - time: 0.0024 - loss_train: 0.8348163197701048 - loss_val: 0.9161461022708238\n",
      "Epoch: 1192 - time: 0.0024 - loss_train: 0.8346566888329303 - loss_val: 0.9160939615242093\n",
      "Epoch: 1193 - time: 0.0024 - loss_train: 0.8344972110067331 - loss_val: 0.9160419324033889\n",
      "Epoch: 1194 - time: 0.0024 - loss_train: 0.834337886198254 - loss_val: 0.9159900144913442\n",
      "Epoch: 1195 - time: 0.0024 - loss_train: 0.8341787143146231 - loss_val: 0.9159382073722843\n",
      "Epoch: 1196 - time: 0.0024 - loss_train: 0.8340196952633533 - loss_val: 0.9158865106316023\n",
      "Epoch: 1197 - time: 0.0024 - loss_train: 0.8338608289523354 - loss_val: 0.9158349238558369\n",
      "Epoch: 1198 - time: 0.0024 - loss_train: 0.8337021152898295 - loss_val: 0.9157834466326273\n",
      "Epoch: 1199 - time: 0.0024 - loss_train: 0.8335435541844602 - loss_val: 0.9157320785506776\n",
      "Epoch: 1200 - time: 0.0024 - loss_train: 0.8333851455452111 - loss_val: 0.9156808191997083\n",
      "Epoch: 1201 - time: 0.0024 - loss_train: 0.833226889281418 - loss_val: 0.9156296681704266\n",
      "Epoch: 1202 - time: 0.0024 - loss_train: 0.833068785302763 - loss_val: 0.9155786250544786\n",
      "Epoch: 1203 - time: 0.0024 - loss_train: 0.8329108335192704 - loss_val: 0.9155276894444142\n",
      "Epoch: 1204 - time: 0.0024 - loss_train: 0.8327530338413007 - loss_val: 0.9154768609336493\n",
      "Epoch: 1205 - time: 0.0024 - loss_train: 0.8325953861795458 - loss_val: 0.9154261391164268\n",
      "Epoch: 1206 - time: 0.0024 - loss_train: 0.8324378904450229 - loss_val: 0.9153755235877777\n",
      "Epoch: 1207 - time: 0.0024 - loss_train: 0.8322805465490709 - loss_val: 0.9153250139434868\n",
      "Epoch: 1208 - time: 0.0024 - loss_train: 0.8321233544033453 - loss_val: 0.9152746097800557\n",
      "Epoch: 1209 - time: 0.0024 - loss_train: 0.8319663139198139 - loss_val: 0.9152243106946647\n",
      "Epoch: 1210 - time: 0.0024 - loss_train: 0.8318094250107517 - loss_val: 0.9151741162851401\n",
      "Epoch: 1211 - time: 0.0024 - loss_train: 0.8316526875887361 - loss_val: 0.915124026149917\n",
      "Epoch: 1212 - time: 0.0024 - loss_train: 0.8314961015666453 - loss_val: 0.9150740398880064\n",
      "Epoch: 1213 - time: 0.0024 - loss_train: 0.8313396668576509 - loss_val: 0.9150241570989617\n",
      "Epoch: 1214 - time: 0.0024 - loss_train: 0.8311833833752156 - loss_val: 0.9149743773828412\n",
      "Epoch: 1215 - time: 0.0024 - loss_train: 0.8310272510330892 - loss_val: 0.9149247003401817\n",
      "Epoch: 1216 - time: 0.0024 - loss_train: 0.8308712697453038 - loss_val: 0.9148751255719613\n",
      "Epoch: 1217 - time: 0.0024 - loss_train: 0.830715439426172 - loss_val: 0.9148256526795673\n",
      "Epoch: 1218 - time: 0.0024 - loss_train: 0.8305597599902801 - loss_val: 0.9147762812647673\n",
      "Epoch: 1219 - time: 0.0024 - loss_train: 0.8304042313524881 - loss_val: 0.9147270109296772\n",
      "Epoch: 1220 - time: 0.0024 - loss_train: 0.830248853427923 - loss_val: 0.9146778412767308\n",
      "Epoch: 1221 - time: 0.0024 - loss_train: 0.8300936261319771 - loss_val: 0.9146287719086486\n",
      "Epoch: 1222 - time: 0.0024 - loss_train: 0.8299385493803043 - loss_val: 0.9145798024284102\n",
      "Epoch: 1223 - time: 0.0024 - loss_train: 0.8297836230888163 - loss_val: 0.9145309324392247\n",
      "Epoch: 1224 - time: 0.0024 - loss_train: 0.829628847173679 - loss_val: 0.9144821615445027\n",
      "Epoch: 1225 - time: 0.0024 - loss_train: 0.8294742215513103 - loss_val: 0.9144334893478265\n",
      "Epoch: 1226 - time: 0.0024 - loss_train: 0.8293197461383758 - loss_val: 0.9143849154529257\n",
      "Epoch: 1227 - time: 0.0024 - loss_train: 0.8291654208517857 - loss_val: 0.9143364394636474\n",
      "Epoch: 1228 - time: 0.0024 - loss_train: 0.8290112456086925 - loss_val: 0.9142880609839324\n",
      "Epoch: 1229 - time: 0.0024 - loss_train: 0.8288572203264867 - loss_val: 0.9142397796177855\n",
      "Epoch: 1230 - time: 0.0024 - loss_train: 0.8287033449227937 - loss_val: 0.9141915949692552\n",
      "Epoch: 1231 - time: 0.0024 - loss_train: 0.8285496193154714 - loss_val: 0.9141435066424047\n",
      "Epoch: 1232 - time: 0.0024 - loss_train: 0.8283960434226073 - loss_val: 0.9140955142412894\n",
      "Epoch: 1233 - time: 0.0024 - loss_train: 0.8282426171625141 - loss_val: 0.9140476173699302\n",
      "Epoch: 1234 - time: 0.0024 - loss_train: 0.8280893404537268 - loss_val: 0.9139998156322955\n",
      "Epoch: 1235 - time: 0.0024 - loss_train: 0.8279362132150015 - loss_val: 0.9139521086322714\n",
      "Epoch: 1236 - time: 0.0024 - loss_train: 0.827783235365309 - loss_val: 0.9139044959736454\n",
      "Epoch: 1237 - time: 0.0030 - loss_train: 0.8276304068238352 - loss_val: 0.9138569772600804\n",
      "Epoch: 1238 - time: 0.0025 - loss_train: 0.8274777275099754 - loss_val: 0.9138095520950926\n",
      "Epoch: 1239 - time: 0.0024 - loss_train: 0.8273251973433321 - loss_val: 0.913762220082036\n",
      "Epoch: 1240 - time: 0.0024 - loss_train: 0.8271728162437118 - loss_val: 0.9137149808240744\n",
      "Epoch: 1241 - time: 0.0024 - loss_train: 0.8270205841311222 - loss_val: 0.9136678339241662\n",
      "Epoch: 1242 - time: 0.0024 - loss_train: 0.8268685009257684 - loss_val: 0.9136207789850432\n",
      "Epoch: 1243 - time: 0.0024 - loss_train: 0.8267165665480494 - loss_val: 0.9135738156091914\n",
      "Epoch: 1244 - time: 0.0024 - loss_train: 0.8265647809185561 - loss_val: 0.9135269433988321\n",
      "Epoch: 1245 - time: 0.0024 - loss_train: 0.8264131439580674 - loss_val: 0.9134801619559043\n",
      "Epoch: 1246 - time: 0.0024 - loss_train: 0.8262616555875455 - loss_val: 0.9134334708820454\n",
      "Epoch: 1247 - time: 0.0024 - loss_train: 0.8261103157281359 - loss_val: 0.9133868697785753\n",
      "Epoch: 1248 - time: 0.0024 - loss_train: 0.8259591243011598 - loss_val: 0.9133403582464795\n",
      "Epoch: 1249 - time: 0.0024 - loss_train: 0.8258080812281148 - loss_val: 0.9132939358863911\n",
      "Epoch: 1250 - time: 0.0024 - loss_train: 0.8256571864306687 - loss_val: 0.913247602298576\n",
      "Epoch: 1251 - time: 0.0024 - loss_train: 0.8255064398306564 - loss_val: 0.9132013570829164\n",
      "Epoch: 1252 - time: 0.0024 - loss_train: 0.8253558413500778 - loss_val: 0.9131551998388968\n",
      "Epoch: 1253 - time: 0.0024 - loss_train: 0.8252053909110928 - loss_val: 0.9131091301655891\n",
      "Epoch: 1254 - time: 0.0024 - loss_train: 0.8250550884360177 - loss_val: 0.9130631476616368\n",
      "Epoch: 1255 - time: 0.0024 - loss_train: 0.8249049338473231 - loss_val: 0.9130172519252423\n",
      "Epoch: 1256 - time: 0.0024 - loss_train: 0.824754927067628 - loss_val: 0.9129714425541517\n",
      "Epoch: 1257 - time: 0.0024 - loss_train: 0.8246050680196975 - loss_val: 0.9129257191456477\n",
      "Epoch: 1258 - time: 0.0024 - loss_train: 0.8244553566264381 - loss_val: 0.9128800812965278\n",
      "Epoch: 1259 - time: 0.0024 - loss_train: 0.8243057928108959 - loss_val: 0.9128345286030988\n",
      "Epoch: 1260 - time: 0.0024 - loss_train: 0.8241563764962486 - loss_val: 0.9127890606611629\n",
      "Epoch: 1261 - time: 0.0024 - loss_train: 0.8240071076058056 - loss_val: 0.9127436770660082\n",
      "Epoch: 1262 - time: 0.0024 - loss_train: 0.8238579860630014 - loss_val: 0.9126983774123906\n",
      "Epoch: 1263 - time: 0.0026 - loss_train: 0.8237090117913942 - loss_val: 0.9126531612945349\n",
      "Epoch: 1264 - time: 0.0029 - loss_train: 0.8235601847146574 - loss_val: 0.9126080283061146\n",
      "Epoch: 1265 - time: 0.0028 - loss_train: 0.8234115047565795 - loss_val: 0.9125629780402462\n",
      "Epoch: 1266 - time: 0.0028 - loss_train: 0.823262971841058 - loss_val: 0.9125180100894803\n",
      "Epoch: 1267 - time: 0.0028 - loss_train: 0.8231145858920945 - loss_val: 0.9124731240457902\n",
      "Epoch: 1268 - time: 0.0028 - loss_train: 0.822966346833792 - loss_val: 0.9124283195005669\n",
      "Epoch: 1269 - time: 0.0028 - loss_train: 0.8228182545903496 - loss_val: 0.9123835960446063\n",
      "Epoch: 1270 - time: 0.0027 - loss_train: 0.8226703090860564 - loss_val: 0.9123389532681047\n",
      "Epoch: 1271 - time: 0.0027 - loss_train: 0.82252251024529 - loss_val: 0.9122943907606506\n",
      "Epoch: 1272 - time: 0.0027 - loss_train: 0.8223748579925091 - loss_val: 0.9122499081112168\n",
      "Epoch: 1273 - time: 0.0027 - loss_train: 0.8222273522522504 - loss_val: 0.912205504908155\n",
      "Epoch: 1274 - time: 0.0027 - loss_train: 0.8220799929491229 - loss_val: 0.9121611807391881\n",
      "Epoch: 1275 - time: 0.0027 - loss_train: 0.8219327800078037 - loss_val: 0.9121169351914048\n",
      "Epoch: 1276 - time: 0.0029 - loss_train: 0.8217857133530322 - loss_val: 0.9120727678512535\n",
      "Epoch: 1277 - time: 0.0029 - loss_train: 0.8216387929096063 - loss_val: 0.9120286783045382\n",
      "Epoch: 1278 - time: 0.0029 - loss_train: 0.8214920186023762 - loss_val: 0.9119846661364116\n",
      "Epoch: 1279 - time: 0.0029 - loss_train: 0.82134539035624 - loss_val: 0.9119407309313735\n",
      "Epoch: 1280 - time: 0.0029 - loss_train: 0.8211989080961392 - loss_val: 0.9118968722732641\n",
      "Epoch: 1281 - time: 0.0029 - loss_train: 0.8210525717470503 - loss_val: 0.9118530897452587\n",
      "Epoch: 1282 - time: 0.0044 - loss_train: 0.8209063812339837 - loss_val: 0.9118093829298707\n",
      "Epoch: 1283 - time: 0.0032 - loss_train: 0.8207603364819765 - loss_val: 0.9117657514089412\n",
      "Epoch: 1284 - time: 0.0035 - loss_train: 0.8206144374160849 - loss_val: 0.911722194763639\n",
      "Epoch: 1285 - time: 0.0034 - loss_train: 0.8204686839613833 - loss_val: 0.9116787125744592\n",
      "Epoch: 1286 - time: 0.0034 - loss_train: 0.8203230760429535 - loss_val: 0.9116353044212203\n",
      "Epoch: 1287 - time: 0.0034 - loss_train: 0.8201776135858837 - loss_val: 0.9115919698830603\n",
      "Epoch: 1288 - time: 0.0034 - loss_train: 0.8200322965152601 - loss_val: 0.9115487085384407\n",
      "Epoch: 1289 - time: 0.0034 - loss_train: 0.8198871247561623 - loss_val: 0.911505519965137\n",
      "Epoch: 1290 - time: 0.0034 - loss_train: 0.819742098233656 - loss_val: 0.9114624037402469\n",
      "Epoch: 1291 - time: 0.0034 - loss_train: 0.8195972168727892 - loss_val: 0.9114193594401823\n",
      "Epoch: 1292 - time: 0.0034 - loss_train: 0.819452480598585 - loss_val: 0.9113763866406741\n",
      "Epoch: 1293 - time: 0.0034 - loss_train: 0.8193078893360355 - loss_val: 0.9113334849167705\n",
      "Epoch: 1294 - time: 0.0034 - loss_train: 0.8191634430100965 - loss_val: 0.9112906538428376\n",
      "Epoch: 1295 - time: 0.0034 - loss_train: 0.8190191415456802 - loss_val: 0.9112478929925589\n",
      "Epoch: 1296 - time: 0.0035 - loss_train: 0.8188749848676515 - loss_val: 0.9112052019389397\n",
      "Epoch: 1297 - time: 0.0035 - loss_train: 0.8187309729008182 - loss_val: 0.9111625802543036\n",
      "Epoch: 1298 - time: 0.0034 - loss_train: 0.818587105569928 - loss_val: 0.9111200275102997\n",
      "Epoch: 1299 - time: 0.0035 - loss_train: 0.81844338279966 - loss_val: 0.9110775432779008\n",
      "Epoch: 1300 - time: 0.0034 - loss_train: 0.8182998045146189 - loss_val: 0.9110351271274064\n",
      "Epoch: 1301 - time: 0.0034 - loss_train: 0.8181563706393303 - loss_val: 0.9109927786284466\n",
      "Epoch: 1302 - time: 0.0034 - loss_train: 0.8180130810982311 - loss_val: 0.9109504973499836\n",
      "Epoch: 1303 - time: 0.0034 - loss_train: 0.8178699358156651 - loss_val: 0.9109082828603159\n",
      "Epoch: 1304 - time: 0.0024 - loss_train: 0.8177269347158759 - loss_val: 0.9108661347270822\n",
      "Epoch: 1305 - time: 0.0024 - loss_train: 0.8175840777230003 - loss_val: 0.9108240525172615\n",
      "Epoch: 1306 - time: 0.0025 - loss_train: 0.817441364761062 - loss_val: 0.910782035797183\n",
      "Epoch: 1307 - time: 0.0024 - loss_train: 0.8172987957539638 - loss_val: 0.9107400841325279\n",
      "Epoch: 1308 - time: 0.0024 - loss_train: 0.8171563706254815 - loss_val: 0.9106981970883307\n",
      "Epoch: 1309 - time: 0.0024 - loss_train: 0.8170140892992572 - loss_val: 0.91065637422899\n",
      "Epoch: 1310 - time: 0.0024 - loss_train: 0.8168719516987932 - loss_val: 0.9106146151182695\n",
      "Epoch: 1311 - time: 0.0024 - loss_train: 0.8167299577474432 - loss_val: 0.9105729193193061\n",
      "Epoch: 1312 - time: 0.0024 - loss_train: 0.8165881073684073 - loss_val: 0.9105312863946126\n",
      "Epoch: 1313 - time: 0.0024 - loss_train: 0.816446400484723 - loss_val: 0.9104897159060877\n",
      "Epoch: 1314 - time: 0.0024 - loss_train: 0.8163048370192598 - loss_val: 0.9104482074150188\n",
      "Epoch: 1315 - time: 0.0024 - loss_train: 0.8161634168947131 - loss_val: 0.910406760482091\n",
      "Epoch: 1316 - time: 0.0024 - loss_train: 0.8160221400335939 - loss_val: 0.9103653746673925\n",
      "Epoch: 1317 - time: 0.0024 - loss_train: 0.8158810063582239 - loss_val: 0.9103240495304232\n",
      "Epoch: 1318 - time: 0.0024 - loss_train: 0.8157400157907293 - loss_val: 0.910282784630099\n",
      "Epoch: 1319 - time: 0.0024 - loss_train: 0.8155991682530311 - loss_val: 0.9102415795247657\n",
      "Epoch: 1320 - time: 0.0024 - loss_train: 0.8154584636668398 - loss_val: 0.9102004337721984\n",
      "Epoch: 1321 - time: 0.0029 - loss_train: 0.8153179019536467 - loss_val: 0.9101593469296161\n",
      "Epoch: 1322 - time: 0.0025 - loss_train: 0.8151774830347185 - loss_val: 0.9101183185536889\n",
      "Epoch: 1323 - time: 0.0024 - loss_train: 0.8150372068310893 - loss_val: 0.9100773482005441\n",
      "Epoch: 1324 - time: 0.0024 - loss_train: 0.814897073263551 - loss_val: 0.9100364354257788\n",
      "Epoch: 1325 - time: 0.0024 - loss_train: 0.8147570822526504 - loss_val: 0.9099955797844665\n",
      "Epoch: 1326 - time: 0.0024 - loss_train: 0.8146172337186781 - loss_val: 0.9099547808311663\n",
      "Epoch: 1327 - time: 0.0024 - loss_train: 0.8144775275816633 - loss_val: 0.9099140381199354\n",
      "Epoch: 1328 - time: 0.0024 - loss_train: 0.814337963761365 - loss_val: 0.909873351204335\n",
      "Epoch: 1329 - time: 0.0024 - loss_train: 0.8141985421772656 - loss_val: 0.9098327196374438\n",
      "Epoch: 1330 - time: 0.0024 - loss_train: 0.8140592627485634 - loss_val: 0.9097921429718678\n",
      "Epoch: 1331 - time: 0.0024 - loss_train: 0.8139201253941643 - loss_val: 0.9097516207597481\n",
      "Epoch: 1332 - time: 0.0024 - loss_train: 0.8137811300326758 - loss_val: 0.9097111525527763\n",
      "Epoch: 1333 - time: 0.0024 - loss_train: 0.8136422765823991 - loss_val: 0.9096707379022003\n",
      "Epoch: 1334 - time: 0.0024 - loss_train: 0.8135035649613195 - loss_val: 0.9096303763588423\n",
      "Epoch: 1335 - time: 0.0024 - loss_train: 0.8133649950871029 - loss_val: 0.909590067473102\n",
      "Epoch: 1336 - time: 0.0024 - loss_train: 0.8132265668770852 - loss_val: 0.9095498107949755\n",
      "Epoch: 1337 - time: 0.0024 - loss_train: 0.8130882802482663 - loss_val: 0.9095096058740639\n",
      "Epoch: 1338 - time: 0.0024 - loss_train: 0.8129501351173019 - loss_val: 0.909469452259586\n",
      "Epoch: 1339 - time: 0.0024 - loss_train: 0.8128121314004962 - loss_val: 0.9094293495003903\n",
      "Epoch: 1340 - time: 0.0024 - loss_train: 0.8126742690137956 - loss_val: 0.9093892971449693\n",
      "Epoch: 1341 - time: 0.0024 - loss_train: 0.8125365478727793 - loss_val: 0.9093492947414701\n",
      "Epoch: 1342 - time: 0.0024 - loss_train: 0.8123989678926526 - loss_val: 0.9093093418377073\n",
      "Epoch: 1343 - time: 0.0024 - loss_train: 0.8122615289882404 - loss_val: 0.9092694379811799\n",
      "Epoch: 1344 - time: 0.0024 - loss_train: 0.8121242310739788 - loss_val: 0.9092295827190796\n",
      "Epoch: 1345 - time: 0.0024 - loss_train: 0.8119870740639074 - loss_val: 0.9091897755983073\n",
      "Epoch: 1346 - time: 0.0024 - loss_train: 0.8118500578716629 - loss_val: 0.9091500161654874\n",
      "Epoch: 1347 - time: 0.0024 - loss_train: 0.8117131824104699 - loss_val: 0.9091103039669801\n",
      "Epoch: 1348 - time: 0.0024 - loss_train: 0.8115764475931362 - loss_val: 0.9090706385488957\n",
      "Epoch: 1349 - time: 0.0024 - loss_train: 0.8114398533320428 - loss_val: 0.909031019457111\n",
      "Epoch: 1350 - time: 0.0024 - loss_train: 0.8113033995391375 - loss_val: 0.9089914462372799\n",
      "Epoch: 1351 - time: 0.0024 - loss_train: 0.8111670861259284 - loss_val: 0.9089519184348532\n",
      "Epoch: 1352 - time: 0.0024 - loss_train: 0.8110309130034754 - loss_val: 0.90891243559509\n",
      "Epoch: 1353 - time: 0.0024 - loss_train: 0.8108948800823824 - loss_val: 0.9088729972630717\n",
      "Epoch: 1354 - time: 0.0024 - loss_train: 0.8107589872727919 - loss_val: 0.9088336029837233\n",
      "Epoch: 1355 - time: 0.0024 - loss_train: 0.8106232344843758 - loss_val: 0.9087942523018189\n",
      "Epoch: 1356 - time: 0.0024 - loss_train: 0.8104876216263294 - loss_val: 0.908754944762008\n",
      "Epoch: 1357 - time: 0.0024 - loss_train: 0.8103521486073635 - loss_val: 0.9087156799088245\n",
      "Epoch: 1358 - time: 0.0024 - loss_train: 0.8102168153356966 - loss_val: 0.9086764572867027\n",
      "Epoch: 1359 - time: 0.0024 - loss_train: 0.8100816217190497 - loss_val: 0.9086372764399974\n",
      "Epoch: 1360 - time: 0.0024 - loss_train: 0.8099465676646375 - loss_val: 0.9085981369129964\n",
      "Epoch: 1361 - time: 0.0024 - loss_train: 0.8098116530791601 - loss_val: 0.9085590382499382\n",
      "Epoch: 1362 - time: 0.0024 - loss_train: 0.8096768778687999 - loss_val: 0.9085199799950281\n",
      "Epoch: 1363 - time: 0.0024 - loss_train: 0.8095422419392095 - loss_val: 0.9084809616924552\n",
      "Epoch: 1364 - time: 0.0024 - loss_train: 0.8094077451955093 - loss_val: 0.9084419828864102\n",
      "Epoch: 1365 - time: 0.0024 - loss_train: 0.8092733875422768 - loss_val: 0.9084030431210987\n",
      "Epoch: 1366 - time: 0.0024 - loss_train: 0.809139168883542 - loss_val: 0.908364141940762\n",
      "Epoch: 1367 - time: 0.0024 - loss_train: 0.809005089122779 - loss_val: 0.9083252788896929\n",
      "Epoch: 1368 - time: 0.0024 - loss_train: 0.8088711481628996 - loss_val: 0.9082864535122536\n",
      "Epoch: 1369 - time: 0.0033 - loss_train: 0.8087373459062471 - loss_val: 0.9082476653528917\n",
      "Epoch: 1370 - time: 0.0025 - loss_train: 0.8086036822545893 - loss_val: 0.908208913956157\n",
      "Epoch: 1371 - time: 0.0027 - loss_train: 0.8084701571091093 - loss_val: 0.9081701988667233\n",
      "Epoch: 1372 - time: 0.0024 - loss_train: 0.8083367703704025 - loss_val: 0.9081315196294033\n",
      "Epoch: 1373 - time: 0.0024 - loss_train: 0.8082035219384679 - loss_val: 0.9080928757891634\n",
      "Epoch: 1374 - time: 0.0024 - loss_train: 0.8080704117127004 - loss_val: 0.9080542668911484\n",
      "Epoch: 1375 - time: 0.0024 - loss_train: 0.8079374395918869 - loss_val: 0.908015692480695\n",
      "Epoch: 1376 - time: 0.0024 - loss_train: 0.8078046054741976 - loss_val: 0.90797715210335\n",
      "Epoch: 1377 - time: 0.0024 - loss_train: 0.8076719092571792 - loss_val: 0.9079386453048912\n",
      "Epoch: 1378 - time: 0.0024 - loss_train: 0.8075393508377513 - loss_val: 0.9079001716313421\n",
      "Epoch: 1379 - time: 0.0024 - loss_train: 0.8074069301121966 - loss_val: 0.9078617306289932\n",
      "Epoch: 1380 - time: 0.0024 - loss_train: 0.8072746469761548 - loss_val: 0.9078233218444208\n",
      "Epoch: 1381 - time: 0.0024 - loss_train: 0.8071425013246205 - loss_val: 0.907784944824502\n",
      "Epoch: 1382 - time: 0.0024 - loss_train: 0.80701049305193 - loss_val: 0.9077465991164382\n",
      "Epoch: 1383 - time: 0.0024 - loss_train: 0.8068786220517624 - loss_val: 0.9077082842677685\n",
      "Epoch: 1384 - time: 0.0024 - loss_train: 0.8067468882171267 - loss_val: 0.907669999826395\n",
      "Epoch: 1385 - time: 0.0029 - loss_train: 0.8066152914403613 - loss_val: 0.9076317453405954\n",
      "Epoch: 1386 - time: 0.0024 - loss_train: 0.8064838316131236 - loss_val: 0.9075935203590448\n",
      "Epoch: 1387 - time: 0.0024 - loss_train: 0.8063525086263862 - loss_val: 0.9075553244308353\n",
      "Epoch: 1388 - time: 0.0024 - loss_train: 0.8062213223704318 - loss_val: 0.9075171571054935\n",
      "Epoch: 1389 - time: 0.0024 - loss_train: 0.8060902727348445 - loss_val: 0.9074790179330009\n",
      "Epoch: 1390 - time: 0.0024 - loss_train: 0.8059593596085064 - loss_val: 0.9074409064638121\n",
      "Epoch: 1391 - time: 0.0024 - loss_train: 0.8058285828795901 - loss_val: 0.9074028222488736\n",
      "Epoch: 1392 - time: 0.0034 - loss_train: 0.8056979424355543 - loss_val: 0.9073647648396456\n",
      "Epoch: 1393 - time: 0.0034 - loss_train: 0.8055674381631375 - loss_val: 0.9073267337881157\n",
      "Epoch: 1394 - time: 0.0034 - loss_train: 0.805437069948353 - loss_val: 0.9072887286468255\n",
      "Epoch: 1395 - time: 0.0034 - loss_train: 0.805306837676482 - loss_val: 0.9072507489688857\n",
      "Epoch: 1396 - time: 0.0034 - loss_train: 0.805176741232069 - loss_val: 0.907212794307994\n",
      "Epoch: 1397 - time: 0.0034 - loss_train: 0.805046780498917 - loss_val: 0.9071748642184566\n",
      "Epoch: 1398 - time: 0.0034 - loss_train: 0.8049169553600806 - loss_val: 0.9071369582552099\n",
      "Epoch: 1399 - time: 0.0030 - loss_train: 0.804787265697862 - loss_val: 0.9070990759738338\n",
      "Epoch: 1400 - time: 0.0024 - loss_train: 0.8046577113938058 - loss_val: 0.907061216930578\n",
      "Epoch: 1401 - time: 0.0024 - loss_train: 0.804528292328692 - loss_val: 0.9070233806823756\n",
      "Epoch: 1402 - time: 0.0024 - loss_train: 0.8043990083825335 - loss_val: 0.9069855667868649\n",
      "Epoch: 1403 - time: 0.0024 - loss_train: 0.8042698594345697 - loss_val: 0.9069477748024097\n",
      "Epoch: 1404 - time: 0.0024 - loss_train: 0.8041408453632605 - loss_val: 0.9069100042881184\n",
      "Epoch: 1405 - time: 0.0024 - loss_train: 0.804011966046284 - loss_val: 0.9068722548038614\n",
      "Epoch: 1406 - time: 0.0024 - loss_train: 0.8038832213605285 - loss_val: 0.9068345259102919\n",
      "Epoch: 1407 - time: 0.0024 - loss_train: 0.8037546111820913 - loss_val: 0.906796817168865\n",
      "Epoch: 1408 - time: 0.0024 - loss_train: 0.8036261353862706 - loss_val: 0.906759128141859\n",
      "Epoch: 1409 - time: 0.0024 - loss_train: 0.8034977938475627 - loss_val: 0.9067214583923903\n",
      "Epoch: 1410 - time: 0.0024 - loss_train: 0.8033695864396575 - loss_val: 0.9066838074844357\n",
      "Epoch: 1411 - time: 0.0024 - loss_train: 0.8032415130354337 - loss_val: 0.9066461749828525\n",
      "Epoch: 1412 - time: 0.0024 - loss_train: 0.8031135735069527 - loss_val: 0.9066085604533951\n",
      "Epoch: 1413 - time: 0.0028 - loss_train: 0.8029857677254584 - loss_val: 0.9065709634627366\n",
      "Epoch: 1414 - time: 0.0025 - loss_train: 0.8028580955613672 - loss_val: 0.9065333835784852\n",
      "Epoch: 1415 - time: 0.0024 - loss_train: 0.8027305568842699 - loss_val: 0.9064958203692052\n",
      "Epoch: 1416 - time: 0.0024 - loss_train: 0.8026031515629217 - loss_val: 0.9064582734044356\n",
      "Epoch: 1417 - time: 0.0024 - loss_train: 0.8024758794652435 - loss_val: 0.9064207422547115\n",
      "Epoch: 1418 - time: 0.0024 - loss_train: 0.8023487404583136 - loss_val: 0.9063832264915759\n",
      "Epoch: 1419 - time: 0.0024 - loss_train: 0.8022217344083651 - loss_val: 0.906345725687608\n",
      "Epoch: 1420 - time: 0.0024 - loss_train: 0.8020948611807851 - loss_val: 0.9063082394164332\n",
      "Epoch: 1421 - time: 0.0024 - loss_train: 0.8019681206401047 - loss_val: 0.9062707672527496\n",
      "Epoch: 1422 - time: 0.0024 - loss_train: 0.8018415126500005 - loss_val: 0.9062333087723402\n",
      "Epoch: 1423 - time: 0.0024 - loss_train: 0.8017150370732902 - loss_val: 0.906195863552095\n",
      "Epoch: 1424 - time: 0.0024 - loss_train: 0.8015886937719255 - loss_val: 0.9061584311700301\n",
      "Epoch: 1425 - time: 0.0024 - loss_train: 0.8014624826069933 - loss_val: 0.9061210112053018\n",
      "Epoch: 1426 - time: 0.0024 - loss_train: 0.8013364034387094 - loss_val: 0.9060836032382319\n",
      "Epoch: 1427 - time: 0.0024 - loss_train: 0.8012104561264151 - loss_val: 0.9060462068503189\n",
      "Epoch: 1428 - time: 0.0024 - loss_train: 0.8010846405285751 - loss_val: 0.9060088216242598\n",
      "Epoch: 1429 - time: 0.0024 - loss_train: 0.8009589565027739 - loss_val: 0.9059714471439695\n",
      "Epoch: 1430 - time: 0.0024 - loss_train: 0.8008334039057124 - loss_val: 0.9059340829945947\n",
      "Epoch: 1431 - time: 0.0024 - loss_train: 0.8007079825932042 - loss_val: 0.905896728762536\n",
      "Epoch: 1432 - time: 0.0024 - loss_train: 0.8005826924201745 - loss_val: 0.9058593840354618\n",
      "Epoch: 1433 - time: 0.0024 - loss_train: 0.8004575332406552 - loss_val: 0.90582204840233\n",
      "Epoch: 1434 - time: 0.0024 - loss_train: 0.8003325049077826 - loss_val: 0.9057847214534015\n",
      "Epoch: 1435 - time: 0.0024 - loss_train: 0.8002076072737953 - loss_val: 0.9057474027802614\n",
      "Epoch: 1436 - time: 0.0024 - loss_train: 0.8000828401900302 - loss_val: 0.9057100919758347\n",
      "Epoch: 1437 - time: 0.0024 - loss_train: 0.7999582035069212 - loss_val: 0.9056727886344013\n",
      "Epoch: 1438 - time: 0.0024 - loss_train: 0.7998336970739959 - loss_val: 0.9056354923516184\n",
      "Epoch: 1439 - time: 0.0024 - loss_train: 0.7997093207398726 - loss_val: 0.9055982027245335\n",
      "Epoch: 1440 - time: 0.0024 - loss_train: 0.7995850743522591 - loss_val: 0.905560919351601\n",
      "Epoch: 1441 - time: 0.0024 - loss_train: 0.7994609577579488 - loss_val: 0.9055236418327021\n",
      "Epoch: 1442 - time: 0.0025 - loss_train: 0.7993369708028201 - loss_val: 0.9054863697691583\n",
      "Epoch: 1443 - time: 0.0024 - loss_train: 0.7992131133318326 - loss_val: 0.9054491027637502\n",
      "Epoch: 1444 - time: 0.0024 - loss_train: 0.7990893851890263 - loss_val: 0.9054118404207321\n",
      "Epoch: 1445 - time: 0.0024 - loss_train: 0.7989657862175179 - loss_val: 0.9053745823458503\n",
      "Epoch: 1446 - time: 0.0024 - loss_train: 0.7988423162594995 - loss_val: 0.9053373281463561\n",
      "Epoch: 1447 - time: 0.0024 - loss_train: 0.7987189751562382 - loss_val: 0.9053000774310256\n",
      "Epoch: 1448 - time: 0.0024 - loss_train: 0.7985957627480714 - loss_val: 0.9052628298101727\n",
      "Epoch: 1449 - time: 0.0024 - loss_train: 0.7984726788744074 - loss_val: 0.9052255848956656\n",
      "Epoch: 1450 - time: 0.0024 - loss_train: 0.7983497233737215 - loss_val: 0.9051883423009426\n",
      "Epoch: 1451 - time: 0.0024 - loss_train: 0.7982268960835563 - loss_val: 0.9051511016410286\n",
      "Epoch: 1452 - time: 0.0024 - loss_train: 0.7981041968405188 - loss_val: 0.9051138625325467\n",
      "Epoch: 1453 - time: 0.0024 - loss_train: 0.7979816254802793 - loss_val: 0.9050766245937372\n",
      "Epoch: 1454 - time: 0.0024 - loss_train: 0.7978591818375697 - loss_val: 0.905039387444472\n",
      "Epoch: 1455 - time: 0.0024 - loss_train: 0.7977368657461823 - loss_val: 0.905002150706267\n",
      "Epoch: 1456 - time: 0.0024 - loss_train: 0.7976146770389686 - loss_val: 0.9049649140022966\n",
      "Epoch: 1457 - time: 0.0024 - loss_train: 0.7974926155478371 - loss_val: 0.904927676957414\n",
      "Epoch: 1458 - time: 0.0024 - loss_train: 0.7973706811037534 - loss_val: 0.9048904391981579\n",
      "Epoch: 1459 - time: 0.0024 - loss_train: 0.7972488735367383 - loss_val: 0.9048532003527712\n",
      "Epoch: 1460 - time: 0.0024 - loss_train: 0.7971271926758658 - loss_val: 0.9048159600512151\n",
      "Epoch: 1461 - time: 0.0027 - loss_train: 0.7970056383492646 - loss_val: 0.9047787179251788\n",
      "Epoch: 1462 - time: 0.0025 - loss_train: 0.7968842103841138 - loss_val: 0.9047414736080991\n",
      "Epoch: 1463 - time: 0.0024 - loss_train: 0.7967629086066454 - loss_val: 0.9047042267351685\n",
      "Epoch: 1464 - time: 0.0024 - loss_train: 0.7966417328421402 - loss_val: 0.9046669769433527\n",
      "Epoch: 1465 - time: 0.0024 - loss_train: 0.7965206829149296 - loss_val: 0.9046297238714001\n",
      "Epoch: 1466 - time: 0.0024 - loss_train: 0.7963997586483941 - loss_val: 0.9045924671598591\n",
      "Epoch: 1467 - time: 0.0024 - loss_train: 0.7962789598649613 - loss_val: 0.9045552064510869\n",
      "Epoch: 1468 - time: 0.0024 - loss_train: 0.796158286386107 - loss_val: 0.9045179413892631\n",
      "Epoch: 1469 - time: 0.0024 - loss_train: 0.7960377380323543 - loss_val: 0.9044806716204041\n",
      "Epoch: 1470 - time: 0.0024 - loss_train: 0.7959173146232726 - loss_val: 0.9044433967923742\n",
      "Epoch: 1471 - time: 0.0024 - loss_train: 0.7957970159774779 - loss_val: 0.9044061165548962\n",
      "Epoch: 1472 - time: 0.0024 - loss_train: 0.7956768419126303 - loss_val: 0.904368830559567\n",
      "Epoch: 1473 - time: 0.0024 - loss_train: 0.7955567922454377 - loss_val: 0.9043315384598654\n",
      "Epoch: 1474 - time: 0.0024 - loss_train: 0.7954368667916519 - loss_val: 0.9042942399111655\n",
      "Epoch: 1475 - time: 0.0024 - loss_train: 0.7953170653660698 - loss_val: 0.9042569345707486\n",
      "Epoch: 1476 - time: 0.0024 - loss_train: 0.795197387782533 - loss_val: 0.9042196220978156\n",
      "Epoch: 1477 - time: 0.0024 - loss_train: 0.7950778338539287 - loss_val: 0.904182302153492\n",
      "Epoch: 1478 - time: 0.0024 - loss_train: 0.7949584033921888 - loss_val: 0.9041449744008475\n",
      "Epoch: 1479 - time: 0.0024 - loss_train: 0.794839096208289 - loss_val: 0.9041076385049001\n",
      "Epoch: 1480 - time: 0.0024 - loss_train: 0.7947199121122509 - loss_val: 0.9040702941326294\n",
      "Epoch: 1481 - time: 0.0024 - loss_train: 0.7946008509131404 - loss_val: 0.9040329409529869\n",
      "Epoch: 1482 - time: 0.0024 - loss_train: 0.7944819124190694 - loss_val: 0.9039955786369047\n",
      "Epoch: 1483 - time: 0.0024 - loss_train: 0.7943630964371948 - loss_val: 0.9039582068573074\n",
      "Epoch: 1484 - time: 0.0024 - loss_train: 0.7942444027737194 - loss_val: 0.9039208252891197\n",
      "Epoch: 1485 - time: 0.0024 - loss_train: 0.7941258312338922 - loss_val: 0.9038834336092789\n",
      "Epoch: 1486 - time: 0.0024 - loss_train: 0.794007381622009 - loss_val: 0.9038460314967401\n",
      "Epoch: 1487 - time: 0.0024 - loss_train: 0.793889053741412 - loss_val: 0.9038086186324911\n",
      "Epoch: 1488 - time: 0.0024 - loss_train: 0.7937708473944901 - loss_val: 0.903771194699555\n",
      "Epoch: 1489 - time: 0.0024 - loss_train: 0.7936527623826832 - loss_val: 0.9037337593830057\n",
      "Epoch: 1490 - time: 0.0024 - loss_train: 0.7935347985064767 - loss_val: 0.903696312369972\n",
      "Epoch: 1491 - time: 0.0024 - loss_train: 0.7934169555654068 - loss_val: 0.9036588533496465\n",
      "Epoch: 1492 - time: 0.0024 - loss_train: 0.7932992333580594 - loss_val: 0.9036213820132948\n",
      "Epoch: 1493 - time: 0.0024 - loss_train: 0.7931816316820711 - loss_val: 0.9035838980542662\n",
      "Epoch: 1494 - time: 0.0024 - loss_train: 0.7930641503341308 - loss_val: 0.9035464011679966\n",
      "Epoch: 1495 - time: 0.0024 - loss_train: 0.7929467891099787 - loss_val: 0.903508891052019\n",
      "Epoch: 1496 - time: 0.0024 - loss_train: 0.7928295478044085 - loss_val: 0.9034713674059733\n",
      "Epoch: 1497 - time: 0.0024 - loss_train: 0.7927124262112683 - loss_val: 0.9034338299316083\n",
      "Epoch: 1498 - time: 0.0025 - loss_train: 0.7925954241234622 - loss_val: 0.9033962783327942\n",
      "Epoch: 1499 - time: 0.0024 - loss_train: 0.7924785413329485 - loss_val: 0.9033587123155268\n",
      "Epoch: 1500 - time: 0.0024 - loss_train: 0.7923617776307442 - loss_val: 0.9033211315879349\n",
      "Epoch: 1501 - time: 0.0024 - loss_train: 0.7922451328069253 - loss_val: 0.9032835358602881\n",
      "Epoch: 1502 - time: 0.0024 - loss_train: 0.7921286066506252 - loss_val: 0.9032459248450013\n",
      "Epoch: 1503 - time: 0.0024 - loss_train: 0.7920121989500407 - loss_val: 0.9032082982566437\n",
      "Epoch: 1504 - time: 0.0024 - loss_train: 0.7918959094924284 - loss_val: 0.9031706558119408\n",
      "Epoch: 1505 - time: 0.0024 - loss_train: 0.7917797380641084 - loss_val: 0.9031329972297867\n",
      "Epoch: 1506 - time: 0.0024 - loss_train: 0.7916636844504669 - loss_val: 0.9030953222312447\n",
      "Epoch: 1507 - time: 0.0024 - loss_train: 0.7915477484359542 - loss_val: 0.9030576305395538\n",
      "Epoch: 1508 - time: 0.0027 - loss_train: 0.7914319298040892 - loss_val: 0.9030199218801354\n",
      "Epoch: 1509 - time: 0.0024 - loss_train: 0.791316228337459 - loss_val: 0.9029821959806006\n",
      "Epoch: 1510 - time: 0.0024 - loss_train: 0.7912006438177207 - loss_val: 0.9029444525707496\n",
      "Epoch: 1511 - time: 0.0024 - loss_train: 0.7910851760256035 - loss_val: 0.9029066913825818\n",
      "Epoch: 1512 - time: 0.0024 - loss_train: 0.79096982474091 - loss_val: 0.9028689121503\n",
      "Epoch: 1513 - time: 0.0024 - loss_train: 0.7908545897425177 - loss_val: 0.9028311146103111\n",
      "Epoch: 1514 - time: 0.0024 - loss_train: 0.7907394708083803 - loss_val: 0.9027932985012365\n",
      "Epoch: 1515 - time: 0.0024 - loss_train: 0.7906244677155297 - loss_val: 0.9027554635639116\n",
      "Epoch: 1516 - time: 0.0024 - loss_train: 0.7905095802400781 - loss_val: 0.9027176095413936\n",
      "Epoch: 1517 - time: 0.0024 - loss_train: 0.7903948081572192 - loss_val: 0.9026797361789618\n",
      "Epoch: 1518 - time: 0.0024 - loss_train: 0.7902801512412292 - loss_val: 0.9026418432241234\n",
      "Epoch: 1519 - time: 0.0024 - loss_train: 0.7901656092654711 - loss_val: 0.9026039304266185\n",
      "Epoch: 1520 - time: 0.0024 - loss_train: 0.7900511820023938 - loss_val: 0.9025659975384224\n",
      "Epoch: 1521 - time: 0.0024 - loss_train: 0.789936869223535 - loss_val: 0.9025280443137469\n",
      "Epoch: 1522 - time: 0.0024 - loss_train: 0.7898226706995244 - loss_val: 0.9024900705090466\n",
      "Epoch: 1523 - time: 0.0024 - loss_train: 0.7897085862000831 - loss_val: 0.902452075883023\n",
      "Epoch: 1524 - time: 0.0024 - loss_train: 0.7895946154940278 - loss_val: 0.9024140601966205\n",
      "Epoch: 1525 - time: 0.0024 - loss_train: 0.7894807583492711 - loss_val: 0.9023760232130392\n",
      "Epoch: 1526 - time: 0.0024 - loss_train: 0.7893670145328253 - loss_val: 0.9023379646977284\n",
      "Epoch: 1527 - time: 0.0024 - loss_train: 0.7892533838108033 - loss_val: 0.9022998844183953\n",
      "Epoch: 1528 - time: 0.0024 - loss_train: 0.7891398659484201 - loss_val: 0.9022617821450034\n",
      "Epoch: 1529 - time: 0.0024 - loss_train: 0.7890264607099969 - loss_val: 0.9022236576497773\n",
      "Epoch: 1530 - time: 0.0024 - loss_train: 0.7889131678589616 - loss_val: 0.9021855107072049\n",
      "Epoch: 1531 - time: 0.0024 - loss_train: 0.788799987157851 - loss_val: 0.9021473410940346\n",
      "Epoch: 1532 - time: 0.0024 - loss_train: 0.788686918368315 - loss_val: 0.9021091485892846\n",
      "Epoch: 1533 - time: 0.0024 - loss_train: 0.7885739612511151 - loss_val: 0.9020709329742381\n",
      "Epoch: 1534 - time: 0.0024 - loss_train: 0.7884611155661314 - loss_val: 0.9020326940324493\n",
      "Epoch: 1535 - time: 0.0024 - loss_train: 0.7883483810723603 - loss_val: 0.9019944315497408\n",
      "Epoch: 1536 - time: 0.0024 - loss_train: 0.7882357575279203 - loss_val: 0.901956145314208\n",
      "Epoch: 1537 - time: 0.0024 - loss_train: 0.788123244690053 - loss_val: 0.9019178351162195\n",
      "Epoch: 1538 - time: 0.0024 - loss_train: 0.7880108423151246 - loss_val: 0.9018795007484159\n",
      "Epoch: 1539 - time: 0.0024 - loss_train: 0.7878985501586303 - loss_val: 0.9018411420057139\n",
      "Epoch: 1540 - time: 0.0024 - loss_train: 0.7877863679751953 - loss_val: 0.9018027586853059\n",
      "Epoch: 1541 - time: 0.0024 - loss_train: 0.7876742955185767 - loss_val: 0.9017643505866599\n",
      "Epoch: 1542 - time: 0.0024 - loss_train: 0.7875623325416682 - loss_val: 0.9017259175115189\n",
      "Epoch: 1543 - time: 0.0024 - loss_train: 0.7874504787965013 - loss_val: 0.9016874592639057\n",
      "Epoch: 1544 - time: 0.0024 - loss_train: 0.7873387340342468 - loss_val: 0.901648975650118\n",
      "Epoch: 1545 - time: 0.0024 - loss_train: 0.7872270980052201 - loss_val: 0.9016104664787326\n",
      "Epoch: 1546 - time: 0.0024 - loss_train: 0.78711557045888 - loss_val: 0.9015719315606019\n",
      "Epoch: 1547 - time: 0.0024 - loss_train: 0.7870041511438363 - loss_val: 0.901533370708857\n",
      "Epoch: 1548 - time: 0.0024 - loss_train: 0.786892839807847 - loss_val: 0.9014947837389063\n",
      "Epoch: 1549 - time: 0.0024 - loss_train: 0.7867816361978253 - loss_val: 0.9014561704684347\n",
      "Epoch: 1550 - time: 0.0024 - loss_train: 0.7866705400598393 - loss_val: 0.9014175307174037\n",
      "Epoch: 1551 - time: 0.0024 - loss_train: 0.7865595511391171 - loss_val: 0.9013788643080511\n",
      "Epoch: 1552 - time: 0.0024 - loss_train: 0.7864486691800484 - loss_val: 0.90134017106489\n",
      "Epoch: 1553 - time: 0.0024 - loss_train: 0.7863378939261877 - loss_val: 0.9013014508147082\n",
      "Epoch: 1554 - time: 0.0024 - loss_train: 0.7862272251202548 - loss_val: 0.9012627033865699\n",
      "Epoch: 1555 - time: 0.0027 - loss_train: 0.7861166625041415 - loss_val: 0.9012239286118094\n",
      "Epoch: 1556 - time: 0.0024 - loss_train: 0.7860062058189125 - loss_val: 0.9011851263240356\n",
      "Epoch: 1557 - time: 0.0024 - loss_train: 0.785895854804807 - loss_val: 0.9011462963591275\n",
      "Epoch: 1558 - time: 0.0024 - loss_train: 0.7857856092012442 - loss_val: 0.9011074385552346\n",
      "Epoch: 1559 - time: 0.0024 - loss_train: 0.7856754687468237 - loss_val: 0.9010685527527771\n",
      "Epoch: 1560 - time: 0.0024 - loss_train: 0.7855654331793311 - loss_val: 0.9010296387944415\n",
      "Epoch: 1561 - time: 0.0024 - loss_train: 0.7854555022357383 - loss_val: 0.9009906965251796\n",
      "Epoch: 1562 - time: 0.0024 - loss_train: 0.785345675652208 - loss_val: 0.9009517257922111\n",
      "Epoch: 1563 - time: 0.0024 - loss_train: 0.7852359531640963 - loss_val: 0.9009127264450156\n",
      "Epoch: 1564 - time: 0.0024 - loss_train: 0.7851263345059565 - loss_val: 0.9008736983353393\n",
      "Epoch: 1565 - time: 0.0024 - loss_train: 0.7850168194115402 - loss_val: 0.9008346413171845\n",
      "Epoch: 1566 - time: 0.0024 - loss_train: 0.7849074076138041 - loss_val: 0.9007955552468127\n",
      "Epoch: 1567 - time: 0.0024 - loss_train: 0.7847980988449071 - loss_val: 0.9007564399827465\n",
      "Epoch: 1568 - time: 0.0024 - loss_train: 0.7846888928362205 - loss_val: 0.9007172953857561\n",
      "Epoch: 1569 - time: 0.0024 - loss_train: 0.7845797893183253 - loss_val: 0.9006781213188709\n",
      "Epoch: 1570 - time: 0.0024 - loss_train: 0.7844707880210194 - loss_val: 0.9006389176473685\n",
      "Epoch: 1571 - time: 0.0024 - loss_train: 0.7843618886733184 - loss_val: 0.9005996842387758\n",
      "Epoch: 1572 - time: 0.0024 - loss_train: 0.7842530910034591 - loss_val: 0.9005604209628668\n",
      "Epoch: 1573 - time: 0.0024 - loss_train: 0.7841443947389041 - loss_val: 0.9005211276916605\n",
      "Epoch: 1574 - time: 0.0024 - loss_train: 0.7840357996063444 - loss_val: 0.9004818042994188\n",
      "Epoch: 1575 - time: 0.0024 - loss_train: 0.7839273053317017 - loss_val: 0.9004424506626422\n",
      "Epoch: 1576 - time: 0.0024 - loss_train: 0.7838189116401327 - loss_val: 0.9004030666600706\n",
      "Epoch: 1577 - time: 0.0024 - loss_train: 0.783710618256033 - loss_val: 0.9003636521726787\n",
      "Epoch: 1578 - time: 0.0024 - loss_train: 0.7836024249030396 - loss_val: 0.900324207083677\n",
      "Epoch: 1579 - time: 0.0024 - loss_train: 0.7834943313040342 - loss_val: 0.900284731278503\n",
      "Epoch: 1580 - time: 0.0024 - loss_train: 0.7833863371811471 - loss_val: 0.9002452246448253\n",
      "Epoch: 1581 - time: 0.0024 - loss_train: 0.7832784422557604 - loss_val: 0.9002056870725365\n",
      "Epoch: 1582 - time: 0.0024 - loss_train: 0.7831706462485121 - loss_val: 0.900166118453755\n",
      "Epoch: 1583 - time: 0.0024 - loss_train: 0.7830629488792986 - loss_val: 0.9001265186828158\n",
      "Epoch: 1584 - time: 0.0024 - loss_train: 0.782955349867279 - loss_val: 0.9000868876562769\n",
      "Epoch: 1585 - time: 0.0024 - loss_train: 0.782847848930878 - loss_val: 0.9000472252729089\n",
      "Epoch: 1586 - time: 0.0024 - loss_train: 0.7827404457877908 - loss_val: 0.9000075314336944\n",
      "Epoch: 1587 - time: 0.0024 - loss_train: 0.7826331401549851 - loss_val: 0.8999678060418287\n",
      "Epoch: 1588 - time: 0.0024 - loss_train: 0.7825259317487062 - loss_val: 0.899928049002712\n",
      "Epoch: 1589 - time: 0.0024 - loss_train: 0.7824188202844794 - loss_val: 0.8998882602239502\n",
      "Epoch: 1590 - time: 0.0024 - loss_train: 0.7823118054771147 - loss_val: 0.8998484396153504\n",
      "Epoch: 1591 - time: 0.0024 - loss_train: 0.7822048870407096 - loss_val: 0.8998085870889202\n",
      "Epoch: 1592 - time: 0.0024 - loss_train: 0.7820980646886546 - loss_val: 0.8997687025588609\n",
      "Epoch: 1593 - time: 0.0024 - loss_train: 0.7819913381336349 - loss_val: 0.8997287859415696\n",
      "Epoch: 1594 - time: 0.0024 - loss_train: 0.781884707087635 - loss_val: 0.8996888371556316\n",
      "Epoch: 1595 - time: 0.0033 - loss_train: 0.7817781712619439 - loss_val: 0.8996488561218211\n",
      "Epoch: 1596 - time: 0.0034 - loss_train: 0.7816717303671571 - loss_val: 0.8996088427630984\n",
      "Epoch: 1597 - time: 0.0026 - loss_train: 0.7815653841131817 - loss_val: 0.8995687970046017\n",
      "Epoch: 1598 - time: 0.0024 - loss_train: 0.7814591322092399 - loss_val: 0.8995287187736521\n",
      "Epoch: 1599 - time: 0.0024 - loss_train: 0.7813529743638722 - loss_val: 0.899488607999744\n",
      "Epoch: 1600 - time: 0.0024 - loss_train: 0.7812469102849438 - loss_val: 0.899448464614547\n",
      "Epoch: 1601 - time: 0.0037 - loss_train: 0.7811409396796468 - loss_val: 0.8994082885519004\n",
      "Epoch: 1602 - time: 0.0035 - loss_train: 0.7810350622545046 - loss_val: 0.8993680797478091\n",
      "Epoch: 1603 - time: 0.0025 - loss_train: 0.7809292777153761 - loss_val: 0.899327838140445\n",
      "Epoch: 1604 - time: 0.0024 - loss_train: 0.7808235857674605 - loss_val: 0.8992875636701392\n",
      "Epoch: 1605 - time: 0.0024 - loss_train: 0.7807179861153006 - loss_val: 0.8992472562793841\n",
      "Epoch: 1606 - time: 0.0024 - loss_train: 0.7806124784627879 - loss_val: 0.8992069159128235\n",
      "Epoch: 1607 - time: 0.0024 - loss_train: 0.7805070625131658 - loss_val: 0.8991665425172586\n",
      "Epoch: 1608 - time: 0.0024 - loss_train: 0.780401737969036 - loss_val: 0.8991261360416376\n",
      "Epoch: 1609 - time: 0.0025 - loss_train: 0.7802965045323608 - loss_val: 0.8990856964370569\n",
      "Epoch: 1610 - time: 0.0024 - loss_train: 0.7801913619044686 - loss_val: 0.8990452236567572\n",
      "Epoch: 1611 - time: 0.0024 - loss_train: 0.7800863097860572 - loss_val: 0.8990047176561183\n",
      "Epoch: 1612 - time: 0.0024 - loss_train: 0.7799813478772014 - loss_val: 0.8989641783926613\n",
      "Epoch: 1613 - time: 0.0024 - loss_train: 0.7798764758773534 - loss_val: 0.8989236058260407\n",
      "Epoch: 1614 - time: 0.0025 - loss_train: 0.7797716934853506 - loss_val: 0.8988829999180447\n",
      "Epoch: 1615 - time: 0.0025 - loss_train: 0.779667000399419 - loss_val: 0.8988423606325912\n",
      "Epoch: 1616 - time: 0.0024 - loss_train: 0.7795623963171778 - loss_val: 0.898801687935725\n",
      "Epoch: 1617 - time: 0.0024 - loss_train: 0.7794578809356446 - loss_val: 0.8987609817956154\n",
      "Epoch: 1618 - time: 0.0024 - loss_train: 0.7793534539512403 - loss_val: 0.8987202421825536\n",
      "Epoch: 1619 - time: 0.0024 - loss_train: 0.7792491150597936 - loss_val: 0.8986794690689491\n",
      "Epoch: 1620 - time: 0.0024 - loss_train: 0.7791448639565458 - loss_val: 0.8986386624293276\n",
      "Epoch: 1621 - time: 0.0024 - loss_train: 0.7790407003361569 - loss_val: 0.8985978222403271\n",
      "Epoch: 1622 - time: 0.0024 - loss_train: 0.7789366238927096 - loss_val: 0.8985569484806988\n",
      "Epoch: 1623 - time: 0.0024 - loss_train: 0.7788326343197136 - loss_val: 0.8985160411312996\n",
      "Epoch: 1624 - time: 0.0024 - loss_train: 0.7787287313101132 - loss_val: 0.8984751001750924\n",
      "Epoch: 1625 - time: 0.0024 - loss_train: 0.7786249145562903 - loss_val: 0.8984341255971438\n",
      "Epoch: 1626 - time: 0.0024 - loss_train: 0.7785211837500711 - loss_val: 0.8983931173846196\n",
      "Epoch: 1627 - time: 0.0024 - loss_train: 0.77841753858273 - loss_val: 0.8983520755267838\n",
      "Epoch: 1628 - time: 0.0024 - loss_train: 0.7783139787449963 - loss_val: 0.898311000014995\n",
      "Epoch: 1629 - time: 0.0025 - loss_train: 0.7782105039270597 - loss_val: 0.8982698908427044\n",
      "Epoch: 1630 - time: 0.0024 - loss_train: 0.7781071138185741 - loss_val: 0.8982287480054547\n",
      "Epoch: 1631 - time: 0.0024 - loss_train: 0.7780038081086653 - loss_val: 0.8981875715008745\n",
      "Epoch: 1632 - time: 0.0024 - loss_train: 0.7779005864859366 - loss_val: 0.898146361328678\n",
      "Epoch: 1633 - time: 0.0024 - loss_train: 0.7777974486384717 - loss_val: 0.8981051174906642\n",
      "Epoch: 1634 - time: 0.0024 - loss_train: 0.7776943942538443 - loss_val: 0.8980638399907086\n",
      "Epoch: 1635 - time: 0.0024 - loss_train: 0.7775914230191213 - loss_val: 0.8980225288347696\n",
      "Epoch: 1636 - time: 0.0024 - loss_train: 0.7774885346208704 - loss_val: 0.8979811840308789\n",
      "Epoch: 1637 - time: 0.0024 - loss_train: 0.7773857287451648 - loss_val: 0.8979398055891418\n",
      "Epoch: 1638 - time: 0.0024 - loss_train: 0.7772830050775902 - loss_val: 0.8978983935217348\n",
      "Epoch: 1639 - time: 0.0025 - loss_train: 0.777180363303251 - loss_val: 0.8978569478429056\n",
      "Epoch: 1640 - time: 0.0028 - loss_train: 0.7770778031067764 - loss_val: 0.8978154685689674\n",
      "Epoch: 1641 - time: 0.0027 - loss_train: 0.7769753241723261 - loss_val: 0.8977739557182977\n",
      "Epoch: 1642 - time: 0.0024 - loss_train: 0.7768729261835982 - loss_val: 0.8977324093113387\n",
      "Epoch: 1643 - time: 0.0024 - loss_train: 0.7767706088238338 - loss_val: 0.8976908293705922\n",
      "Epoch: 1644 - time: 0.0024 - loss_train: 0.7766683717758254 - loss_val: 0.897649215920618\n",
      "Epoch: 1645 - time: 0.0024 - loss_train: 0.776566214721923 - loss_val: 0.8976075689880344\n",
      "Epoch: 1646 - time: 0.0025 - loss_train: 0.7764641373440404 - loss_val: 0.8975658886015121\n",
      "Epoch: 1647 - time: 0.0024 - loss_train: 0.776362139323663 - loss_val: 0.8975241747917783\n",
      "Epoch: 1648 - time: 0.0031 - loss_train: 0.7762602203418542 - loss_val: 0.8974824275916062\n",
      "Epoch: 1649 - time: 0.0024 - loss_train: 0.7761583800792616 - loss_val: 0.8974406470358213\n",
      "Epoch: 1650 - time: 0.0024 - loss_train: 0.7760566182161267 - loss_val: 0.897398833161295\n",
      "Epoch: 1651 - time: 0.0024 - loss_train: 0.77595493443229 - loss_val: 0.8973569860069467\n",
      "Epoch: 1652 - time: 0.0024 - loss_train: 0.7758533284071989 - loss_val: 0.8973151056137356\n",
      "Epoch: 1653 - time: 0.0024 - loss_train: 0.7757517998199152 - loss_val: 0.8972731920246635\n",
      "Epoch: 1654 - time: 0.0024 - loss_train: 0.7756503483491233 - loss_val: 0.8972312452847758\n",
      "Epoch: 1655 - time: 0.0024 - loss_train: 0.7755489736731377 - loss_val: 0.8971892654411507\n",
      "Epoch: 1656 - time: 0.0024 - loss_train: 0.7754476754699099 - loss_val: 0.8971472525429082\n",
      "Epoch: 1657 - time: 0.0024 - loss_train: 0.775346453417038 - loss_val: 0.8971052066412009\n",
      "Epoch: 1658 - time: 0.0024 - loss_train: 0.7752453071917726 - loss_val: 0.8970631277892143\n",
      "Epoch: 1659 - time: 0.0024 - loss_train: 0.7751442364710276 - loss_val: 0.8970210160421676\n",
      "Epoch: 1660 - time: 0.0024 - loss_train: 0.7750432409313864 - loss_val: 0.8969788714573115\n",
      "Epoch: 1661 - time: 0.0024 - loss_train: 0.7749423202491109 - loss_val: 0.8969366940939213\n",
      "Epoch: 1662 - time: 0.0024 - loss_train: 0.7748414741001504 - loss_val: 0.8968944840133046\n",
      "Epoch: 1663 - time: 0.0024 - loss_train: 0.77474070216015 - loss_val: 0.8968522412787907\n",
      "Epoch: 1664 - time: 0.0024 - loss_train: 0.7746400041044594 - loss_val: 0.8968099659557369\n",
      "Epoch: 1665 - time: 0.0024 - loss_train: 0.7745393796081423 - loss_val: 0.896767658111521\n",
      "Epoch: 1666 - time: 0.0024 - loss_train: 0.774438828345985 - loss_val: 0.8967253178155435\n",
      "Epoch: 1667 - time: 0.0024 - loss_train: 0.7743383499925054 - loss_val: 0.8966829451392266\n",
      "Epoch: 1668 - time: 0.0024 - loss_train: 0.7742379442219623 - loss_val: 0.8966405401560089\n",
      "Epoch: 1669 - time: 0.0024 - loss_train: 0.7741376107083663 - loss_val: 0.8965981029413472\n",
      "Epoch: 1670 - time: 0.0024 - loss_train: 0.7740373491254875 - loss_val: 0.8965556335727162\n",
      "Epoch: 1671 - time: 0.0024 - loss_train: 0.7739371591468668 - loss_val: 0.8965131321296048\n",
      "Epoch: 1672 - time: 0.0024 - loss_train: 0.7738370404458245 - loss_val: 0.8964705986935144\n",
      "Epoch: 1673 - time: 0.0024 - loss_train: 0.7737369926954717 - loss_val: 0.8964280333479598\n",
      "Epoch: 1674 - time: 0.0024 - loss_train: 0.7736370155687196 - loss_val: 0.896385436178467\n",
      "Epoch: 1675 - time: 0.0024 - loss_train: 0.7735371087382903 - loss_val: 0.8963428072725717\n",
      "Epoch: 1676 - time: 0.0024 - loss_train: 0.7734372718767275 - loss_val: 0.8963001467198183\n",
      "Epoch: 1677 - time: 0.0024 - loss_train: 0.7733375046564069 - loss_val: 0.896257454611759\n",
      "Epoch: 1678 - time: 0.0024 - loss_train: 0.7732378067495468 - loss_val: 0.8962147310419512\n",
      "Epoch: 1679 - time: 0.0024 - loss_train: 0.7731381778282203 - loss_val: 0.8961719761059582\n",
      "Epoch: 1680 - time: 0.0024 - loss_train: 0.7730386175643653 - loss_val: 0.896129189901346\n",
      "Epoch: 1681 - time: 0.0024 - loss_train: 0.772939125629796 - loss_val: 0.8960863725276847\n",
      "Epoch: 1682 - time: 0.0024 - loss_train: 0.7728397016962164 - loss_val: 0.8960435240865442\n",
      "Epoch: 1683 - time: 0.0024 - loss_train: 0.7727403454352288 - loss_val: 0.8960006446814952\n",
      "Epoch: 1684 - time: 0.0024 - loss_train: 0.7726410565183482 - loss_val: 0.8959577344181064\n",
      "Epoch: 1685 - time: 0.0024 - loss_train: 0.7725418346170138 - loss_val: 0.8959147934039462\n",
      "Epoch: 1686 - time: 0.0024 - loss_train: 0.772442679402601 - loss_val: 0.8958718217485765\n",
      "Epoch: 1687 - time: 0.0024 - loss_train: 0.7723435905464344 - loss_val: 0.8958288195635569\n",
      "Epoch: 1688 - time: 0.0024 - loss_train: 0.7722445677197997 - loss_val: 0.8957857869624375\n",
      "Epoch: 1689 - time: 0.0024 - loss_train: 0.7721456105939575 - loss_val: 0.8957427240607659\n",
      "Epoch: 1690 - time: 0.0024 - loss_train: 0.7720467188401557 - loss_val: 0.8956996309760765\n",
      "Epoch: 1691 - time: 0.0024 - loss_train: 0.7719478921296434 - loss_val: 0.8956565078278951\n",
      "Epoch: 1692 - time: 0.0024 - loss_train: 0.7718491301336842 - loss_val: 0.8956133547377374\n",
      "Epoch: 1693 - time: 0.0024 - loss_train: 0.7717504325235686 - loss_val: 0.8955701718291055\n",
      "Epoch: 1694 - time: 0.0023 - loss_train: 0.7716517989706306 - loss_val: 0.8955269592274858\n",
      "Epoch: 1695 - time: 0.0026 - loss_train: 0.7715532291462596 - loss_val: 0.8954837170603506\n",
      "Epoch: 1696 - time: 0.0024 - loss_train: 0.7714547227219157 - loss_val: 0.8954404454571565\n",
      "Epoch: 1697 - time: 0.0024 - loss_train: 0.7713562793691436 - loss_val: 0.8953971445493394\n",
      "Epoch: 1698 - time: 0.0024 - loss_train: 0.7712578987595882 - loss_val: 0.8953538144703158\n",
      "Epoch: 1699 - time: 0.0024 - loss_train: 0.771159580565009 - loss_val: 0.8953104553554817\n",
      "Epoch: 1700 - time: 0.0024 - loss_train: 0.7710613244572956 - loss_val: 0.8952670673422086\n",
      "Epoch: 1701 - time: 0.0024 - loss_train: 0.7709631301084834 - loss_val: 0.8952236505698447\n",
      "Epoch: 1702 - time: 0.0024 - loss_train: 0.7708649971907683 - loss_val: 0.8951802051797099\n",
      "Epoch: 1703 - time: 0.0024 - loss_train: 0.7707669253765246 - loss_val: 0.895136731315097\n",
      "Epoch: 1704 - time: 0.0024 - loss_train: 0.7706689143383181 - loss_val: 0.8950932291212705\n",
      "Epoch: 1705 - time: 0.0024 - loss_train: 0.7705709637489263 - loss_val: 0.8950496987454595\n",
      "Epoch: 1706 - time: 0.0024 - loss_train: 0.770473073281352 - loss_val: 0.8950061403368629\n",
      "Epoch: 1707 - time: 0.0024 - loss_train: 0.7703752426088406 - loss_val: 0.8949625540466418\n",
      "Epoch: 1708 - time: 0.0024 - loss_train: 0.7702774714048999 - loss_val: 0.8949189400279199\n",
      "Epoch: 1709 - time: 0.0024 - loss_train: 0.7701797593433141 - loss_val: 0.894875298435783\n",
      "Epoch: 1710 - time: 0.0024 - loss_train: 0.7700821060981632 - loss_val: 0.8948316294272729\n",
      "Epoch: 1711 - time: 0.0024 - loss_train: 0.7699845113438403 - loss_val: 0.8947879331613872\n",
      "Epoch: 1712 - time: 0.0024 - loss_train: 0.7698869747550715 - loss_val: 0.8947442097990799\n",
      "Epoch: 1713 - time: 0.0033 - loss_train: 0.769789496006931 - loss_val: 0.8947004595032534\n",
      "Epoch: 1714 - time: 0.0025 - loss_train: 0.7696920747748632 - loss_val: 0.8946566824387598\n",
      "Epoch: 1715 - time: 0.0024 - loss_train: 0.7695947107346996 - loss_val: 0.8946128787723969\n",
      "Epoch: 1716 - time: 0.0024 - loss_train: 0.7694974035626791 - loss_val: 0.8945690486729085\n",
      "Epoch: 1717 - time: 0.0024 - loss_train: 0.7694001529354664 - loss_val: 0.894525192310976\n",
      "Epoch: 1718 - time: 0.0024 - loss_train: 0.7693029585301729 - loss_val: 0.894481309859222\n",
      "Epoch: 1719 - time: 0.0024 - loss_train: 0.7692058200243761 - loss_val: 0.8944374014922012\n",
      "Epoch: 1720 - time: 0.0024 - loss_train: 0.7691087370961407 - loss_val: 0.8943934673864028\n",
      "Epoch: 1721 - time: 0.0024 - loss_train: 0.7690117094240376 - loss_val: 0.8943495077202438\n",
      "Epoch: 1722 - time: 0.0024 - loss_train: 0.7689147366871664 - loss_val: 0.8943055226740684\n",
      "Epoch: 1723 - time: 0.0024 - loss_train: 0.7688178185651766 - loss_val: 0.8942615124301426\n",
      "Epoch: 1724 - time: 0.0024 - loss_train: 0.7687209547382882 - loss_val: 0.8942174771726498\n",
      "Epoch: 1725 - time: 0.0024 - loss_train: 0.7686241448873128 - loss_val: 0.8941734170876918\n",
      "Epoch: 1726 - time: 0.0024 - loss_train: 0.7685273886936778 - loss_val: 0.8941293323632813\n",
      "Epoch: 1727 - time: 0.0024 - loss_train: 0.7684306858394475 - loss_val: 0.894085223189339\n",
      "Epoch: 1728 - time: 0.0024 - loss_train: 0.768334036007345 - loss_val: 0.8940410897576883\n",
      "Epoch: 1729 - time: 0.0024 - loss_train: 0.7682374388807757 - loss_val: 0.8939969322620536\n",
      "Epoch: 1730 - time: 0.0024 - loss_train: 0.7681408941438522 - loss_val: 0.893952750898057\n",
      "Epoch: 1731 - time: 0.0024 - loss_train: 0.7680444014814152 - loss_val: 0.8939085458632104\n",
      "Epoch: 1732 - time: 0.0024 - loss_train: 0.7679479605790582 - loss_val: 0.8938643173569125\n",
      "Epoch: 1733 - time: 0.0024 - loss_train: 0.767851571123152 - loss_val: 0.8938200655804455\n",
      "Epoch: 1734 - time: 0.0024 - loss_train: 0.76775523280087 - loss_val: 0.8937757907369684\n",
      "Epoch: 1735 - time: 0.0024 - loss_train: 0.7676589453002104 - loss_val: 0.8937314930315142\n",
      "Epoch: 1736 - time: 0.0024 - loss_train: 0.7675627083100228 - loss_val: 0.8936871726709835\n",
      "Epoch: 1737 - time: 0.0024 - loss_train: 0.767466521520034 - loss_val: 0.8936428298641383\n",
      "Epoch: 1738 - time: 0.0024 - loss_train: 0.7673703846208725 - loss_val: 0.8935984648215993\n",
      "Epoch: 1739 - time: 0.0025 - loss_train: 0.7672742973040944 - loss_val: 0.8935540777558388\n",
      "Epoch: 1740 - time: 0.0024 - loss_train: 0.767178259262211 - loss_val: 0.8935096688811732\n",
      "Epoch: 1741 - time: 0.0029 - loss_train: 0.7670822701887132 - loss_val: 0.893465238413762\n",
      "Epoch: 1742 - time: 0.0025 - loss_train: 0.7669863297780994 - loss_val: 0.893420786571597\n",
      "Epoch: 1743 - time: 0.0024 - loss_train: 0.7668904377259044 - loss_val: 0.8933763135744981\n",
      "Epoch: 1744 - time: 0.0024 - loss_train: 0.7667945937287218 - loss_val: 0.8933318196441071\n",
      "Epoch: 1745 - time: 0.0024 - loss_train: 0.7666987974842382 - loss_val: 0.8932873050038804\n",
      "Epoch: 1746 - time: 0.0024 - loss_train: 0.7666030486912555 - loss_val: 0.8932427698790836\n",
      "Epoch: 1747 - time: 0.0024 - loss_train: 0.766507347049722 - loss_val: 0.8931982144967827\n",
      "Epoch: 1748 - time: 0.0024 - loss_train: 0.7664116922607611 - loss_val: 0.8931536390858388\n",
      "Epoch: 1749 - time: 0.0024 - loss_train: 0.7663160840266992 - loss_val: 0.8931090438768972\n",
      "Epoch: 1750 - time: 0.0024 - loss_train: 0.7662205220510946 - loss_val: 0.8930644291023875\n",
      "Epoch: 1751 - time: 0.0024 - loss_train: 0.7661250060387687 - loss_val: 0.893019794996506\n",
      "Epoch: 1752 - time: 0.0024 - loss_train: 0.7660295356958329 - loss_val: 0.892975141795217\n",
      "Epoch: 1753 - time: 0.0024 - loss_train: 0.7659341107297221 - loss_val: 0.8929304697362372\n",
      "Epoch: 1754 - time: 0.0024 - loss_train: 0.7658387308492218 - loss_val: 0.8928857790590319\n",
      "Epoch: 1755 - time: 0.0024 - loss_train: 0.7657433957645006 - loss_val: 0.8928410700048065\n",
      "Epoch: 1756 - time: 0.0024 - loss_train: 0.7656481051871399 - loss_val: 0.8927963428164948\n",
      "Epoch: 1757 - time: 0.0024 - loss_train: 0.7655528588301657 - loss_val: 0.8927515977387533\n",
      "Epoch: 1758 - time: 0.0032 - loss_train: 0.7654576564080803 - loss_val: 0.89270683501795\n",
      "Epoch: 1759 - time: 0.0034 - loss_train: 0.7653624976368921 - loss_val: 0.8926620549021548\n",
      "Epoch: 1760 - time: 0.0034 - loss_train: 0.7652673822341507 - loss_val: 0.8926172576411329\n",
      "Epoch: 1761 - time: 0.0035 - loss_train: 0.7651723099189758 - loss_val: 0.8925724434863296\n",
      "Epoch: 1762 - time: 0.0035 - loss_train: 0.7650772804120902 - loss_val: 0.8925276126908678\n",
      "Epoch: 1763 - time: 0.0035 - loss_train: 0.7649822934358549 - loss_val: 0.8924827655095313\n",
      "Epoch: 1764 - time: 0.0034 - loss_train: 0.7648873487142994 - loss_val: 0.8924379021987562\n",
      "Epoch: 1765 - time: 0.0034 - loss_train: 0.7647924459731553 - loss_val: 0.8923930230166208\n",
      "Epoch: 1766 - time: 0.0034 - loss_train: 0.76469758493989 - loss_val: 0.8923481282228358\n",
      "Epoch: 1767 - time: 0.0034 - loss_train: 0.7646027653437402 - loss_val: 0.8923032180787316\n",
      "Epoch: 1768 - time: 0.0034 - loss_train: 0.7645079869157462 - loss_val: 0.8922582928472462\n",
      "Epoch: 1769 - time: 0.0035 - loss_train: 0.7644132493887844 - loss_val: 0.8922133527929172\n",
      "Epoch: 1770 - time: 0.0034 - loss_train: 0.7643185524976027 - loss_val: 0.8921683981818619\n",
      "Epoch: 1771 - time: 0.0034 - loss_train: 0.7642238959788547 - loss_val: 0.892123429281778\n",
      "Epoch: 1772 - time: 0.0034 - loss_train: 0.764129279571133 - loss_val: 0.8920784463619197\n",
      "Epoch: 1773 - time: 0.0034 - loss_train: 0.7640347030150066 - loss_val: 0.8920334496930906\n",
      "Epoch: 1774 - time: 0.0030 - loss_train: 0.7639401660530525 - loss_val: 0.891988439547631\n",
      "Epoch: 1775 - time: 0.0029 - loss_train: 0.763845668429893 - loss_val: 0.8919434161994018\n",
      "Epoch: 1776 - time: 0.0029 - loss_train: 0.7637512098922309 - loss_val: 0.8918983799237765\n",
      "Epoch: 1777 - time: 0.0029 - loss_train: 0.7636567901888823 - loss_val: 0.8918533309976219\n",
      "Epoch: 1778 - time: 0.0030 - loss_train: 0.7635624090708153 - loss_val: 0.8918082696992894\n",
      "Epoch: 1779 - time: 0.0034 - loss_train: 0.7634680662911839 - loss_val: 0.8917631963085976\n",
      "Epoch: 1780 - time: 0.0029 - loss_train: 0.7633737616053643 - loss_val: 0.8917181111068201\n",
      "Epoch: 1781 - time: 0.0030 - loss_train: 0.7632794947709883 - loss_val: 0.8916730143766715\n",
      "Epoch: 1782 - time: 0.0029 - loss_train: 0.7631852655479839 - loss_val: 0.8916279064022904\n",
      "Epoch: 1783 - time: 0.0029 - loss_train: 0.7630910736986068 - loss_val: 0.8915827874692261\n",
      "Epoch: 1784 - time: 0.0029 - loss_train: 0.7629969189874779 - loss_val: 0.8915376578644266\n",
      "Epoch: 1785 - time: 0.0029 - loss_train: 0.762902801181621 - loss_val: 0.8914925178762175\n",
      "Epoch: 1786 - time: 0.0029 - loss_train: 0.762808720050496 - loss_val: 0.891447367794289\n",
      "Epoch: 1787 - time: 0.0029 - loss_train: 0.7627146753660374 - loss_val: 0.8914022079096838\n",
      "Epoch: 1788 - time: 0.0029 - loss_train: 0.762620666902688 - loss_val: 0.8913570385147745\n",
      "Epoch: 1789 - time: 0.0029 - loss_train: 0.7625266944374388 - loss_val: 0.8913118599032547\n",
      "Epoch: 1790 - time: 0.0029 - loss_train: 0.76243275774986 - loss_val: 0.8912666723701149\n",
      "Epoch: 1791 - time: 0.0029 - loss_train: 0.7623388566221424 - loss_val: 0.8912214762116337\n",
      "Epoch: 1792 - time: 0.0030 - loss_train: 0.7622449908391294 - loss_val: 0.8911762717253553\n",
      "Epoch: 1793 - time: 0.0030 - loss_train: 0.7621511601883548 - loss_val: 0.8911310592100761\n",
      "Epoch: 1794 - time: 0.0029 - loss_train: 0.7620573644600779 - loss_val: 0.8910858389658238\n",
      "Epoch: 1795 - time: 0.0029 - loss_train: 0.7619636034473211 - loss_val: 0.8910406112938445\n",
      "Epoch: 1796 - time: 0.0029 - loss_train: 0.7618698769459027 - loss_val: 0.8909953764965823\n",
      "Epoch: 1797 - time: 0.0029 - loss_train: 0.7617761847544746 - loss_val: 0.8909501348776622\n",
      "Epoch: 1798 - time: 0.0029 - loss_train: 0.7616825266745569 - loss_val: 0.8909048867418728\n",
      "Epoch: 1799 - time: 0.0029 - loss_train: 0.7615889025105741 - loss_val: 0.8908596323951465\n",
      "Epoch: 1800 - time: 0.0029 - loss_train: 0.7614953120698886 - loss_val: 0.8908143721445426\n",
      "--- 8.041340589523315 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 0.8908143721445426 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = TS[:1000,:-2]\n",
    "Y_train = TS[:1000,-2:]\n",
    "    \n",
    "X_val = TS[1000:1250,:-2]\n",
    "Y_val = TS[1000:1250,-2:]\n",
    "\n",
    "model = Mlp()\n",
    "model.add(38, activation=\"sigmoid\", input= 20, kernel_initializer = 1/np.sqrt(20), kernel_regularizer = 0.0001)\n",
    "model.add(2, activation=\"linear\", kernel_initializer = 1/np.sqrt(100), kernel_regularizer = 0.0001)\n",
    "\n",
    "model.set_optimizer(\n",
    "    SGD(\n",
    "        lr = 0.018200000000000004,\n",
    "        momentum = 0.8800000000000002,\n",
    "        nesterov = True\n",
    "    ))\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train,\n",
    "            Y_train, \n",
    "            epochs=1800, \n",
    "            validation_data = [X_val, Y_val],\n",
    "            verbose=1) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "outputNet = model.predict(X_val)\n",
    "\n",
    "plt.plot(outputNet[:,-2], outputNet[:,-1], 'ro', markersize=0.3)\n",
    "plt.ylabel('y2')\n",
    "plt.xlabel('y1')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "printMSE(outputNet, Y_val, type = \"test\")\n",
    "plt.plot(model.history[\"loss_mse\"][500:])\n",
    "plt.plot(model.history[\"val_loss_mse\"][500:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - time: 0.0042 - loss_train: 127.08884659634317 - loss_val: 138.04436597344215\n",
      "Epoch: 2 - time: 0.0041 - loss_train: 29.04561518992258 - loss_val: 29.322501535259413\n",
      "Epoch: 3 - time: 0.0046 - loss_train: 53.143890449166456 - loss_val: 52.697868034017546\n",
      "Epoch: 4 - time: 0.0039 - loss_train: 95.33546871630836 - loss_val: 101.80419623993272\n",
      "Epoch: 5 - time: 0.0039 - loss_train: 43.83840259214797 - loss_val: 45.79714318328057\n",
      "Epoch: 6 - time: 0.0039 - loss_train: 10.259225317266738 - loss_val: 9.829743138161987\n",
      "Epoch: 7 - time: 0.0039 - loss_train: 23.165933237519894 - loss_val: 25.177885842383574\n",
      "Epoch: 8 - time: 0.0039 - loss_train: 38.91660456971095 - loss_val: 42.541713090670555\n",
      "Epoch: 9 - time: 0.0039 - loss_train: 35.87347048869118 - loss_val: 38.958342815704356\n",
      "Epoch: 10 - time: 0.0039 - loss_train: 19.87757057840891 - loss_val: 21.426754500328848\n",
      "Epoch: 11 - time: 0.0042 - loss_train: 9.232452620587031 - loss_val: 9.76774690939649\n",
      "Epoch: 12 - time: 0.0039 - loss_train: 12.635562807745599 - loss_val: 13.147547066900733\n",
      "Epoch: 13 - time: 0.0038 - loss_train: 20.863051819257297 - loss_val: 21.74518779431865\n",
      "Epoch: 14 - time: 0.0038 - loss_train: 21.231837411412425 - loss_val: 22.21782332590811\n",
      "Epoch: 15 - time: 0.0038 - loss_train: 13.834393781810347 - loss_val: 14.630842319374596\n",
      "Epoch: 16 - time: 0.0031 - loss_train: 7.885439338046224 - loss_val: 8.571134587161618\n",
      "Epoch: 17 - time: 0.0032 - loss_train: 8.366640478405795 - loss_val: 9.243427582937176\n",
      "Epoch: 18 - time: 0.0031 - loss_train: 11.971466962997345 - loss_val: 13.181752300198072\n",
      "Epoch: 19 - time: 0.0031 - loss_train: 13.208558615670675 - loss_val: 14.536810933308807\n",
      "Epoch: 20 - time: 0.0045 - loss_train: 10.703371271974873 - loss_val: 11.731840793972077\n",
      "Epoch: 21 - time: 0.0073 - loss_train: 7.417578632873758 - loss_val: 7.8702323797044125\n",
      "Epoch: 22 - time: 0.0066 - loss_train: 6.341899669166638 - loss_val: 6.304263717385858\n",
      "Epoch: 23 - time: 0.0046 - loss_train: 7.282951481371692 - loss_val: 7.116968038294707\n",
      "Epoch: 24 - time: 0.0046 - loss_train: 7.938936117378779 - loss_val: 7.984860689623438\n",
      "Epoch: 25 - time: 0.0046 - loss_train: 7.032769404814388 - loss_val: 7.381488607380063\n",
      "Epoch: 26 - time: 0.0045 - loss_train: 5.448124699600959 - loss_val: 5.976765777865171\n",
      "Epoch: 27 - time: 0.0045 - loss_train: 4.644196970997867 - loss_val: 5.21165804811389\n",
      "Epoch: 28 - time: 0.0045 - loss_train: 4.87059263907532 - loss_val: 5.427967682846515\n",
      "Epoch: 29 - time: 0.0045 - loss_train: 5.190716865277273 - loss_val: 5.732437047968824\n",
      "Epoch: 30 - time: 0.0047 - loss_train: 4.818490555964301 - loss_val: 5.296958438247291\n",
      "Epoch: 31 - time: 0.0046 - loss_train: 3.977023526867891 - loss_val: 4.297366583556824\n",
      "Epoch: 32 - time: 0.0045 - loss_train: 3.4338655052656186 - loss_val: 3.5291783331481184\n",
      "Epoch: 33 - time: 0.0045 - loss_train: 3.504848733119728 - loss_val: 3.406349905060401\n",
      "Epoch: 34 - time: 0.0045 - loss_train: 3.758662152552526 - loss_val: 3.5869941686784177\n",
      "Epoch: 35 - time: 0.0045 - loss_train: 3.647079316543533 - loss_val: 3.534640453620288\n",
      "Epoch: 36 - time: 0.0044 - loss_train: 3.164746631248921 - loss_val: 3.1823589174617997\n",
      "Epoch: 37 - time: 0.0045 - loss_train: 2.7574112879234054 - loss_val: 2.900822395128498\n",
      "Epoch: 38 - time: 0.0045 - loss_train: 2.7296110834174785 - loss_val: 2.954680986958925\n",
      "Epoch: 39 - time: 0.0044 - loss_train: 2.9271683519385916 - loss_val: 3.186519137102306\n",
      "Epoch: 40 - time: 0.0045 - loss_train: 2.991414939824668 - loss_val: 3.245998462662853\n",
      "Epoch: 41 - time: 0.0044 - loss_train: 2.789120150092636 - loss_val: 3.0044277107342032\n",
      "Epoch: 42 - time: 0.0045 - loss_train: 2.513078739192556 - loss_val: 2.6601974480071786\n",
      "Epoch: 43 - time: 0.0045 - loss_train: 2.405755702872254 - loss_val: 2.472392635987456\n",
      "Epoch: 44 - time: 0.0045 - loss_train: 2.481060496085417 - loss_val: 2.481855796639117\n",
      "Epoch: 45 - time: 0.0045 - loss_train: 2.555164305421968 - loss_val: 2.52906814289668\n",
      "Epoch: 46 - time: 0.0045 - loss_train: 2.494179192028707 - loss_val: 2.4873440435542107\n",
      "Epoch: 47 - time: 0.0044 - loss_train: 2.3531889464572804 - loss_val: 2.398510324196338\n",
      "Epoch: 48 - time: 0.0045 - loss_train: 2.268895217013305 - loss_val: 2.3756865848554627\n",
      "Epoch: 49 - time: 0.0045 - loss_train: 2.284147386277977 - loss_val: 2.441360094241911\n",
      "Epoch: 50 - time: 0.0045 - loss_train: 2.3213234209906712 - loss_val: 2.5073930583297335\n",
      "Epoch: 51 - time: 0.0045 - loss_train: 2.2989062106447364 - loss_val: 2.490291940304727\n",
      "Epoch: 52 - time: 0.0045 - loss_train: 2.2244281321879136 - loss_val: 2.4003893259782423\n",
      "Epoch: 53 - time: 0.0045 - loss_train: 2.164295229204805 - loss_val: 2.3100671045640677\n",
      "Epoch: 54 - time: 0.0045 - loss_train: 2.153565601649934 - loss_val: 2.2639780888451257\n",
      "Epoch: 55 - time: 0.0045 - loss_train: 2.162677330821579 - loss_val: 2.2446906042697843\n",
      "Epoch: 56 - time: 0.0045 - loss_train: 2.1471963364584066 - loss_val: 2.217769729446093\n",
      "Epoch: 57 - time: 0.0047 - loss_train: 2.1041633066224814 - loss_val: 2.1828384345164626\n",
      "Epoch: 58 - time: 0.0046 - loss_train: 2.066546018054447 - loss_val: 2.1670386583630727\n",
      "Epoch: 59 - time: 0.0046 - loss_train: 2.05559150356145 - loss_val: 2.181574853007249\n",
      "Epoch: 60 - time: 0.0044 - loss_train: 2.0572483251491778 - loss_val: 2.2036380440176053\n",
      "Epoch: 61 - time: 0.0044 - loss_train: 2.04576042967408 - loss_val: 2.202879307349101\n",
      "Epoch: 62 - time: 0.0044 - loss_train: 2.0163646981387897 - loss_val: 2.1739103219528726\n",
      "Epoch: 63 - time: 0.0044 - loss_train: 1.9866373331506015 - loss_val: 2.1363826709710483\n",
      "Epoch: 64 - time: 0.0044 - loss_train: 1.9715997348236056 - loss_val: 2.1092395850123475\n",
      "Epoch: 65 - time: 0.0044 - loss_train: 1.9671258742801156 - loss_val: 2.093384321157512\n",
      "Epoch: 66 - time: 0.0044 - loss_train: 1.9590596135245528 - loss_val: 2.079320882892528\n",
      "Epoch: 67 - time: 0.0044 - loss_train: 1.94181748644531 - loss_val: 2.063811411895434\n",
      "Epoch: 68 - time: 0.0044 - loss_train: 1.9227877462367138 - loss_val: 2.053229419323282\n",
      "Epoch: 69 - time: 0.0044 - loss_train: 1.9106490258190378 - loss_val: 2.0526478942711575\n",
      "Epoch: 70 - time: 0.0044 - loss_train: 1.9048588513362552 - loss_val: 2.057331905523054\n",
      "Epoch: 71 - time: 0.0044 - loss_train: 1.898204852663122 - loss_val: 2.057100256491017\n",
      "Epoch: 72 - time: 0.0044 - loss_train: 1.8864225762512306 - loss_val: 2.0466588714395053\n",
      "Epoch: 73 - time: 0.0044 - loss_train: 1.8722063559730822 - loss_val: 2.0293882013018605\n",
      "Epoch: 74 - time: 0.0044 - loss_train: 1.8604339245360444 - loss_val: 2.0120148577980723\n",
      "Epoch: 75 - time: 0.0044 - loss_train: 1.8522184678959224 - loss_val: 1.9980770205660896\n",
      "Epoch: 76 - time: 0.0044 - loss_train: 1.8448074035151745 - loss_val: 1.9871180189176907\n",
      "Epoch: 77 - time: 0.0044 - loss_train: 1.8358593852715108 - loss_val: 1.9781555540954896\n",
      "Epoch: 78 - time: 0.0044 - loss_train: 1.8259888301193377 - loss_val: 1.9716876761693507\n",
      "Epoch: 79 - time: 0.0045 - loss_train: 1.8170997654957648 - loss_val: 1.9681561077052536\n",
      "Epoch: 80 - time: 0.0044 - loss_train: 1.8096241357323175 - loss_val: 1.965943509345673\n",
      "Epoch: 81 - time: 0.0044 - loss_train: 1.8022647185882505 - loss_val: 1.9620224818072909\n",
      "Epoch: 82 - time: 0.0044 - loss_train: 1.7939327979012234 - loss_val: 1.9544580287750926\n",
      "Epoch: 83 - time: 0.0044 - loss_train: 1.7850104997470944 - loss_val: 1.9437610551805442\n",
      "Epoch: 84 - time: 0.0047 - loss_train: 1.776573305245894 - loss_val: 1.931896865673605\n",
      "Epoch: 85 - time: 0.0045 - loss_train: 1.7689867339508027 - loss_val: 1.9205427440017635\n",
      "Epoch: 86 - time: 0.0044 - loss_train: 1.7617064154058266 - loss_val: 1.9104776305118767\n",
      "Epoch: 87 - time: 0.0044 - loss_train: 1.7542217534689275 - loss_val: 1.9020842515756362\n",
      "Epoch: 88 - time: 0.0044 - loss_train: 1.746707124529116 - loss_val: 1.8956779494966176\n",
      "Epoch: 89 - time: 0.0032 - loss_train: 1.739635085588712 - loss_val: 1.8911013677154551\n",
      "Epoch: 90 - time: 0.0032 - loss_train: 1.7330596830792995 - loss_val: 1.8873251971184135\n",
      "Epoch: 91 - time: 0.0032 - loss_train: 1.7265476434672584 - loss_val: 1.8828535807292532\n",
      "Epoch: 92 - time: 0.0031 - loss_train: 1.7197410626833805 - loss_val: 1.876669119848676\n",
      "Epoch: 93 - time: 0.0031 - loss_train: 1.7127574367746252 - loss_val: 1.868785613303852\n",
      "Epoch: 94 - time: 0.0031 - loss_train: 1.7059758070675202 - loss_val: 1.8599745494251083\n",
      "Epoch: 95 - time: 0.0031 - loss_train: 1.6995768137714955 - loss_val: 1.85111818208224\n",
      "Epoch: 96 - time: 0.0031 - loss_train: 1.6934165274105388 - loss_val: 1.8428380138327471\n",
      "Epoch: 97 - time: 0.0031 - loss_train: 1.6872946156297695 - loss_val: 1.8355118640805985\n",
      "Epoch: 98 - time: 0.0031 - loss_train: 1.6812034019561382 - loss_val: 1.8293368857417023\n",
      "Epoch: 99 - time: 0.0031 - loss_train: 1.675268583886626 - loss_val: 1.8242258288486686\n",
      "Epoch: 100 - time: 0.0031 - loss_train: 1.6695315043886185 - loss_val: 1.8197100369690145\n",
      "Epoch: 101 - time: 0.0031 - loss_train: 1.663880551935085 - loss_val: 1.8150950878926055\n",
      "Epoch: 102 - time: 0.0031 - loss_train: 1.6581901814494382 - loss_val: 1.8098182162677507\n",
      "Epoch: 103 - time: 0.0031 - loss_train: 1.6524611293259157 - loss_val: 1.8037149052678452\n",
      "Epoch: 104 - time: 0.0031 - loss_train: 1.6467962881207008 - loss_val: 1.7970049976467903\n",
      "Epoch: 105 - time: 0.0031 - loss_train: 1.641275342067666 - loss_val: 1.7900863839458565\n",
      "Epoch: 106 - time: 0.0031 - loss_train: 1.6358922335746477 - loss_val: 1.7833422854953886\n",
      "Epoch: 107 - time: 0.0031 - loss_train: 1.630603753993635 - loss_val: 1.7770527840771906\n",
      "Epoch: 108 - time: 0.0031 - loss_train: 1.6253958057360574 - loss_val: 1.7713584455547238\n",
      "Epoch: 109 - time: 0.0031 - loss_train: 1.6202815411270501 - loss_val: 1.7662240520890586\n",
      "Epoch: 110 - time: 0.0031 - loss_train: 1.6152552441856765 - loss_val: 1.7614362426389234\n",
      "Epoch: 111 - time: 0.0031 - loss_train: 1.610277808195177 - loss_val: 1.7566872772465727\n",
      "Epoch: 112 - time: 0.0031 - loss_train: 1.6053130145988148 - loss_val: 1.751718182270563\n",
      "Epoch: 113 - time: 0.0031 - loss_train: 1.6003635738439086 - loss_val: 1.746427209091074\n",
      "Epoch: 114 - time: 0.0031 - loss_train: 1.595463016018783 - loss_val: 1.7408791231958103\n",
      "Epoch: 115 - time: 0.0031 - loss_train: 1.5906396235806235 - loss_val: 1.7352360623041958\n",
      "Epoch: 116 - time: 0.0032 - loss_train: 1.5858971955766128 - loss_val: 1.7296751283643594\n",
      "Epoch: 117 - time: 0.0031 - loss_train: 1.5812268035315298 - loss_val: 1.7243324541946343\n",
      "Epoch: 118 - time: 0.0031 - loss_train: 1.5766243034861696 - loss_val: 1.719271851364839\n",
      "Epoch: 119 - time: 0.0031 - loss_train: 1.5720897543694545 - loss_val: 1.7144693987633801\n",
      "Epoch: 120 - time: 0.0031 - loss_train: 1.567615328068057 - loss_val: 1.709822667060394\n",
      "Epoch: 121 - time: 0.0032 - loss_train: 1.56318301137998 - loss_val: 1.7051939457108747\n",
      "Epoch: 122 - time: 0.0031 - loss_train: 1.558777175568777 - loss_val: 1.7004720754776783\n",
      "Epoch: 123 - time: 0.0031 - loss_train: 1.5543966379212528 - loss_val: 1.6956180185350613\n",
      "Epoch: 124 - time: 0.0031 - loss_train: 1.5500527186380362 - loss_val: 1.6906701067092385\n",
      "Epoch: 125 - time: 0.0031 - loss_train: 1.5457576019867172 - loss_val: 1.6857142425150564\n",
      "Epoch: 126 - time: 0.0032 - loss_train: 1.5415165268107685 - loss_val: 1.6808426291074752\n",
      "Epoch: 127 - time: 0.0031 - loss_train: 1.5373291444882395 - loss_val: 1.676120545263216\n",
      "Epoch: 128 - time: 0.0031 - loss_train: 1.5331937988907511 - loss_val: 1.6715678943131733\n",
      "Epoch: 129 - time: 0.0032 - loss_train: 1.5291080174733638 - loss_val: 1.667156160507829\n",
      "Epoch: 130 - time: 0.0032 - loss_train: 1.5250664436636259 - loss_val: 1.6628213988771485\n",
      "Epoch: 131 - time: 0.0032 - loss_train: 1.521061414496113 - loss_val: 1.6584907315595427\n",
      "Epoch: 132 - time: 0.0031 - loss_train: 1.517087081700755 - loss_val: 1.654112126106797\n",
      "Epoch: 133 - time: 0.0031 - loss_train: 1.513142721410542 - loss_val: 1.6496733874721876\n",
      "Epoch: 134 - time: 0.0031 - loss_train: 1.5092318059828895 - loss_val: 1.6452021900821816\n",
      "Epoch: 135 - time: 0.0031 - loss_train: 1.5053584152434223 - loss_val: 1.6407499959234975\n",
      "Epoch: 136 - time: 0.0031 - loss_train: 1.5015248212677346 - loss_val: 1.636369702437876\n",
      "Epoch: 137 - time: 0.0031 - loss_train: 1.4977315478775617 - loss_val: 1.632096412819562\n",
      "Epoch: 138 - time: 0.0031 - loss_train: 1.4939781208252751 - loss_val: 1.6279366665777082\n",
      "Epoch: 139 - time: 0.0032 - loss_train: 1.4902629369793903 - loss_val: 1.6238681867393647\n",
      "Epoch: 140 - time: 0.0031 - loss_train: 1.4865829374321125 - loss_val: 1.6198498315413818\n",
      "Epoch: 141 - time: 0.0031 - loss_train: 1.4829344722228632 - loss_val: 1.615838257653564\n",
      "Epoch: 142 - time: 0.0032 - loss_train: 1.47931511135091 - loss_val: 1.6118045553420903\n",
      "Epoch: 143 - time: 0.0031 - loss_train: 1.4757247165757033 - loss_val: 1.6077437585329961\n",
      "Epoch: 144 - time: 0.0031 - loss_train: 1.472164798757705 - loss_val: 1.6036738427274795\n",
      "Epoch: 145 - time: 0.0031 - loss_train: 1.4686369784400477 - loss_val: 1.5996261141880768\n",
      "Epoch: 146 - time: 0.0031 - loss_train: 1.4651419858901213 - loss_val: 1.5956321758004817\n",
      "Epoch: 147 - time: 0.0031 - loss_train: 1.4616796364584765 - loss_val: 1.5917126796137173\n",
      "Epoch: 148 - time: 0.0031 - loss_train: 1.4582491448019272 - loss_val: 1.5878712252131395\n",
      "Epoch: 149 - time: 0.0031 - loss_train: 1.4548492275089362 - loss_val: 1.5840946979239714\n",
      "Epoch: 150 - time: 0.0031 - loss_train: 1.4514781837770283 - loss_val: 1.5803594422702727\n",
      "Epoch: 151 - time: 0.0031 - loss_train: 1.44813434573397 - loss_val: 1.5766407769808315\n",
      "Epoch: 152 - time: 0.0031 - loss_train: 1.4448167505390215 - loss_val: 1.5729220357017373\n",
      "Epoch: 153 - time: 0.0031 - loss_train: 1.4415254558906383 - loss_val: 1.569199577170964\n",
      "Epoch: 154 - time: 0.0032 - loss_train: 1.438261203555624 - loss_val: 1.5654822080264816\n",
      "Epoch: 155 - time: 0.0031 - loss_train: 1.4350247463369952 - loss_val: 1.5617860342407204\n",
      "Epoch: 156 - time: 0.0031 - loss_train: 1.431816360294223 - loss_val: 1.5581274208271585\n",
      "Epoch: 157 - time: 0.0031 - loss_train: 1.4286357399931373 - loss_val: 1.5545169104014371\n",
      "Epoch: 158 - time: 0.0036 - loss_train: 1.4254821162770286 - loss_val: 1.5509560632715615\n",
      "Epoch: 159 - time: 0.0032 - loss_train: 1.422354422338685 - loss_val: 1.5474379174693083\n",
      "Epoch: 160 - time: 0.0031 - loss_train: 1.4192515113344526 - loss_val: 1.5439505104936204\n",
      "Epoch: 161 - time: 0.0031 - loss_train: 1.416172458263712 - loss_val: 1.5404818770113566\n",
      "Epoch: 162 - time: 0.0032 - loss_train: 1.4131168292126823 - loss_val: 1.5370244694691495\n",
      "Epoch: 163 - time: 0.0032 - loss_train: 1.410084727199947 - loss_val: 1.5335773292714256\n",
      "Epoch: 164 - time: 0.0032 - loss_train: 1.4070765669140368 - loss_val: 1.5301454333371172\n",
      "Epoch: 165 - time: 0.0032 - loss_train: 1.4040927352241865 - loss_val: 1.5267368721876524\n",
      "Epoch: 166 - time: 0.0032 - loss_train: 1.4011333405189252 - loss_val: 1.5233592678294672\n",
      "Epoch: 167 - time: 0.0032 - loss_train: 1.3981981325328898 - loss_val: 1.5200168826415201\n",
      "Epoch: 168 - time: 0.0031 - loss_train: 1.395286552249338 - loss_val: 1.5167093769091244\n",
      "Epoch: 169 - time: 0.0031 - loss_train: 1.3923978549395928 - loss_val: 1.5134324516058433\n",
      "Epoch: 170 - time: 0.0032 - loss_train: 1.389531282462765 - loss_val: 1.5101799149328208\n",
      "Epoch: 171 - time: 0.0031 - loss_train: 1.3866862514890095 - loss_val: 1.506946228620193\n",
      "Epoch: 172 - time: 0.0031 - loss_train: 1.383862482039216 - loss_val: 1.5037284860854656\n",
      "Epoch: 173 - time: 0.0031 - loss_train: 1.3810599948320297 - loss_val: 1.5005271019974473\n",
      "Epoch: 174 - time: 0.0031 - loss_train: 1.378278979823335 - loss_val: 1.497345100304605\n",
      "Epoch: 175 - time: 0.0032 - loss_train: 1.37551961530181 - loss_val: 1.4941864743673232\n",
      "Epoch: 176 - time: 0.0032 - loss_train: 1.3727819280194793 - loss_val: 1.4910543955104705\n",
      "Epoch: 177 - time: 0.0032 - loss_train: 1.3700657373684275 - loss_val: 1.4879499873390327\n",
      "Epoch: 178 - time: 0.0031 - loss_train: 1.3673706781709831 - loss_val: 1.4848720617751592\n",
      "Epoch: 179 - time: 0.0032 - loss_train: 1.3646962792287822 - loss_val: 1.4818177980996907\n",
      "Epoch: 180 - time: 0.0032 - loss_train: 1.3620420722512836 - loss_val: 1.478783991981214\n",
      "Epoch: 181 - time: 0.0031 - loss_train: 1.359407696806128 - loss_val: 1.47576831955203\n",
      "Epoch: 182 - time: 0.0031 - loss_train: 1.3567929600412176 - loss_val: 1.4727701086750398\n",
      "Epoch: 183 - time: 0.0031 - loss_train: 1.3541978257752936 - loss_val: 1.469790358789113\n",
      "Epoch: 184 - time: 0.0031 - loss_train: 1.3516223433642878 - loss_val: 1.4668310856859839\n",
      "Epoch: 185 - time: 0.0031 - loss_train: 1.3490665554881716 - loss_val: 1.4638943345088828\n",
      "Epoch: 186 - time: 0.0031 - loss_train: 1.3465304256731474 - loss_val: 1.4609812955112096\n",
      "Epoch: 187 - time: 0.0031 - loss_train: 1.344013807423765 - loss_val: 1.4580918606266655\n",
      "Epoch: 188 - time: 0.0032 - loss_train: 1.3415164566336613 - loss_val: 1.4552247438242243\n",
      "Epoch: 189 - time: 0.0031 - loss_train: 1.3390380769572199 - loss_val: 1.4523780546633116\n",
      "Epoch: 190 - time: 0.0032 - loss_train: 1.3365783806781606 - loss_val: 1.4495500502286138\n",
      "Epoch: 191 - time: 0.0032 - loss_train: 1.3341371425479849 - loss_val: 1.4467397485811584\n",
      "Epoch: 192 - time: 0.0031 - loss_train: 1.3317142257133305 - loss_val: 1.4439471734002625\n",
      "Epoch: 193 - time: 0.0032 - loss_train: 1.3293095710778653 - loss_val: 1.441173171327034\n",
      "Epoch: 194 - time: 0.0032 - loss_train: 1.3269231587014496 - loss_val: 1.4384189230274387\n",
      "Epoch: 195 - time: 0.0031 - loss_train: 1.324554961066182 - loss_val: 1.4356853796573887\n",
      "Epoch: 196 - time: 0.0038 - loss_train: 1.3222049075433955 - loss_val: 1.43297285934119\n",
      "Epoch: 197 - time: 0.0032 - loss_train: 1.3198728708085297 - loss_val: 1.430280946100326\n",
      "Epoch: 198 - time: 0.0031 - loss_train: 1.3175586762225144 - loss_val: 1.427608696408814\n",
      "Epoch: 199 - time: 0.0032 - loss_train: 1.3152621279241916 - loss_val: 1.4249550359165941\n",
      "Epoch: 200 - time: 0.0032 - loss_train: 1.3129830407694503 - loss_val: 1.4223191662565673\n",
      "Epoch: 201 - time: 0.0032 - loss_train: 1.3107212657544518 - loss_val: 1.419700816923154\n",
      "Epoch: 202 - time: 0.0031 - loss_train: 1.3084766995690116 - loss_val: 1.4171002567548114\n",
      "Epoch: 203 - time: 0.0031 - loss_train: 1.306249276074411 - loss_val: 1.4145180859503046\n",
      "Epoch: 204 - time: 0.0032 - loss_train: 1.304038945304804 - loss_val: 1.411954916765009\n",
      "Epoch: 205 - time: 0.0032 - loss_train: 1.301845649904021 - loss_val: 1.4094110847754175\n",
      "Epoch: 206 - time: 0.0031 - loss_train: 1.2996693082176032 - loss_val: 1.4068865045731935\n",
      "Epoch: 207 - time: 0.0031 - loss_train: 1.2975098091492483 - loss_val: 1.4043807125386811\n",
      "Epoch: 208 - time: 0.0032 - loss_train: 1.2953670189155237 - loss_val: 1.4018930589571712\n",
      "Epoch: 209 - time: 0.0031 - loss_train: 1.293240795726205 - loss_val: 1.3994229555130362\n",
      "Epoch: 210 - time: 0.0031 - loss_train: 1.291131006072735 - loss_val: 1.3969700718513223\n",
      "Epoch: 211 - time: 0.0031 - loss_train: 1.2890375363145918 - loss_val: 1.3945344067394139\n",
      "Epoch: 212 - time: 0.0032 - loss_train: 1.2869602956725699 - loss_val: 1.392116218158483\n",
      "Epoch: 213 - time: 0.0031 - loss_train: 1.284899210552441 - loss_val: 1.3897158558724956\n",
      "Epoch: 214 - time: 0.0032 - loss_train: 1.2828542135323868 - loss_val: 1.387333575330714\n",
      "Epoch: 215 - time: 0.0031 - loss_train: 1.280825231890765 - loss_val: 1.3849694110230844\n",
      "Epoch: 216 - time: 0.0032 - loss_train: 1.2788121799313463 - loss_val: 1.38262315470288\n",
      "Epoch: 217 - time: 0.0032 - loss_train: 1.276814957297781 - loss_val: 1.3802944360893532\n",
      "Epoch: 218 - time: 0.0032 - loss_train: 1.274833452992897 - loss_val: 1.3779828619527636\n",
      "Epoch: 219 - time: 0.0032 - loss_train: 1.2728675528071962 - loss_val: 1.3756881502096807\n",
      "Epoch: 220 - time: 0.0031 - loss_train: 1.2709171469127607 - loss_val: 1.3734102043047023\n",
      "Epoch: 221 - time: 0.0031 - loss_train: 1.2689821347404118 - loss_val: 1.371149103332601\n",
      "Epoch: 222 - time: 0.0032 - loss_train: 1.2670624256881056 - loss_val: 1.368905020540772\n",
      "Epoch: 223 - time: 0.0031 - loss_train: 1.2651579360169476 - loss_val: 1.3666781110612443\n",
      "Epoch: 224 - time: 0.0032 - loss_train: 1.2632685836818345 - loss_val: 1.3644684182261044\n",
      "Epoch: 225 - time: 0.0032 - loss_train: 1.2613942833273961 - loss_val: 1.3622758351103703\n",
      "Epoch: 226 - time: 0.0031 - loss_train: 1.2595349432425418 - loss_val: 1.360100131447578\n",
      "Epoch: 227 - time: 0.0032 - loss_train: 1.2576904650476817 - loss_val: 1.357941028125595\n",
      "Epoch: 228 - time: 0.0031 - loss_train: 1.2558607457563231 - loss_val: 1.355798283742244\n",
      "Epoch: 229 - time: 0.0031 - loss_train: 1.2540456810304577 - loss_val: 1.3536717564188863\n",
      "Epoch: 230 - time: 0.0032 - loss_train: 1.2522451681963653 - loss_val: 1.351561418070492\n",
      "Epoch: 231 - time: 0.0032 - loss_train: 1.2504591079220873 - loss_val: 1.3494673202779626\n",
      "Epoch: 232 - time: 0.0036 - loss_train: 1.2486874041608502 - loss_val: 1.347389530931089\n",
      "Epoch: 233 - time: 0.0035 - loss_train: 1.2469299626968082 - loss_val: 1.3453280708324924\n",
      "Epoch: 234 - time: 0.0037 - loss_train: 1.2451866890986596 - loss_val: 1.3432828763646567\n",
      "Epoch: 235 - time: 0.0032 - loss_train: 1.2434574869622668 - loss_val: 1.3412538007690142\n",
      "Epoch: 236 - time: 0.0031 - loss_train: 1.2417422570504733 - loss_val: 1.339240649275278\n",
      "Epoch: 237 - time: 0.0032 - loss_train: 1.240040897482093 - loss_val: 1.337243229816094\n",
      "Epoch: 238 - time: 0.0032 - loss_train: 1.238353304688376 - loss_val: 1.3352613965653026\n",
      "Epoch: 239 - time: 0.0031 - loss_train: 1.2366793746109537 - loss_val: 1.3332950689698684\n",
      "Epoch: 240 - time: 0.0032 - loss_train: 1.2350190036259683 - loss_val: 1.3313442210054995\n",
      "Epoch: 241 - time: 0.0031 - loss_train: 1.2333720888936957 - loss_val: 1.3294088483557844\n",
      "Epoch: 242 - time: 0.0031 - loss_train: 1.2317385281243556 - loss_val: 1.3274889295914023\n",
      "Epoch: 243 - time: 0.0032 - loss_train: 1.2301182189866418 - loss_val: 1.325584398201408\n",
      "Epoch: 244 - time: 0.0031 - loss_train: 1.228511058484333 - loss_val: 1.323695135986493\n",
      "Epoch: 245 - time: 0.0031 - loss_train: 1.2269169425762396 - loss_val: 1.3218209882708374\n",
      "Epoch: 246 - time: 0.0031 - loss_train: 1.2253357661625348 - loss_val: 1.3199617922214297\n",
      "Epoch: 247 - time: 0.0032 - loss_train: 1.223767423385218 - loss_val: 1.318117405023056\n",
      "Epoch: 248 - time: 0.0032 - loss_train: 1.2222118080692377 - loss_val: 1.316287720154055\n",
      "Epoch: 249 - time: 0.0032 - loss_train: 1.220668814106125 - loss_val: 1.314472666271836\n",
      "Epoch: 250 - time: 0.0031 - loss_train: 1.2191383356463275 - loss_val: 1.3126721911083166\n",
      "Epoch: 251 - time: 0.0031 - loss_train: 1.2176202670739567 - loss_val: 1.3108862388013147\n",
      "Epoch: 252 - time: 0.0031 - loss_train: 1.2161145028338791 - loss_val: 1.3091147309146232\n",
      "Epoch: 253 - time: 0.0031 - loss_train: 1.2146209372290846 - loss_val: 1.3073575587132127\n",
      "Epoch: 254 - time: 0.0032 - loss_train: 1.213139464296793 - loss_val: 1.3056145886834034\n",
      "Epoch: 255 - time: 0.0032 - loss_train: 1.2116699778194884 - loss_val: 1.303885677486621\n",
      "Epoch: 256 - time: 0.0031 - loss_train: 1.2102123714607997 - loss_val: 1.302170688982152\n",
      "Epoch: 257 - time: 0.0032 - loss_train: 1.2087665389661106 - loss_val: 1.300469505905356\n",
      "Epoch: 258 - time: 0.0032 - loss_train: 1.2073323743529063 - loss_val: 1.298782031881251\n",
      "Epoch: 259 - time: 0.0032 - loss_train: 1.205909772035855 - loss_val: 1.2971081840342171\n",
      "Epoch: 260 - time: 0.0032 - loss_train: 1.204498626869961 - loss_val: 1.295447880415305\n",
      "Epoch: 261 - time: 0.0031 - loss_train: 1.2030988341306526 - loss_val: 1.2938010281951933\n",
      "Epoch: 262 - time: 0.0032 - loss_train: 1.2017102894681393 - loss_val: 1.292167517576472\n",
      "Epoch: 263 - time: 0.0032 - loss_train: 1.2003328888720353 - loss_val: 1.2905472233893966\n",
      "Epoch: 264 - time: 0.0031 - loss_train: 1.1989665286673261 - loss_val: 1.288940012845633\n",
      "Epoch: 265 - time: 0.0032 - loss_train: 1.1976111055442127 - loss_val: 1.287345755477474\n",
      "Epoch: 266 - time: 0.0031 - loss_train: 1.1962665166111597 - loss_val: 1.285764330812498\n",
      "Epoch: 267 - time: 0.0031 - loss_train: 1.1949326594569658 - loss_val: 1.2841956308085818\n",
      "Epoch: 268 - time: 0.0031 - loss_train: 1.1936094322122284 - loss_val: 1.2826395566512239\n",
      "Epoch: 269 - time: 0.0032 - loss_train: 1.1922967336072996 - loss_val: 1.281096011966768\n",
      "Epoch: 270 - time: 0.0031 - loss_train: 1.1909944630270135 - loss_val: 1.2795648957951442\n",
      "Epoch: 271 - time: 0.0034 - loss_train: 1.1897025205603589 - loss_val: 1.2780460983736195\n",
      "Epoch: 272 - time: 0.0031 - loss_train: 1.1884208070386586 - loss_val: 1.2765395012162544\n",
      "Epoch: 273 - time: 0.0031 - loss_train: 1.1871492240535335 - loss_val: 1.2750449809530127\n",
      "Epoch: 274 - time: 0.0031 - loss_train: 1.1858876739492499 - loss_val: 1.273562414840344\n",
      "Epoch: 275 - time: 0.0031 - loss_train: 1.1846360597927565 - loss_val: 1.2720916853860171\n",
      "Epoch: 276 - time: 0.0031 - loss_train: 1.1833942853351218 - loss_val: 1.27063268222133\n",
      "Epoch: 277 - time: 0.0032 - loss_train: 1.1821622549846174 - loss_val: 1.2691853007693075\n",
      "Epoch: 278 - time: 0.0031 - loss_train: 1.1809398738100623 - loss_val: 1.2677494387000776\n",
      "Epoch: 279 - time: 0.0031 - loss_train: 1.1797270475824186 - loss_val: 1.2663249920050348\n",
      "Epoch: 280 - time: 0.0031 - loss_train: 1.178523682846832 - loss_val: 1.2649118524655176\n",
      "Epoch: 281 - time: 0.0031 - loss_train: 1.1773296870032088 - loss_val: 1.263509907469573\n",
      "Epoch: 282 - time: 0.0031 - loss_train: 1.1761449683676797 - loss_val: 1.2621190419909663\n",
      "Epoch: 283 - time: 0.0032 - loss_train: 1.1749694361929894 - loss_val: 1.260739141622686\n",
      "Epoch: 284 - time: 0.0032 - loss_train: 1.1738030006411542 - loss_val: 1.2593700952298459\n",
      "Epoch: 285 - time: 0.0032 - loss_train: 1.1726455727203138 - loss_val: 1.2580117961265826\n",
      "Epoch: 286 - time: 0.0030 - loss_train: 1.171497064211812 - loss_val: 1.2566641414600184\n",
      "Epoch: 287 - time: 0.0031 - loss_train: 1.1703573876170998 - loss_val: 1.2553270303076078\n",
      "Epoch: 288 - time: 0.0031 - loss_train: 1.1692264561455454 - loss_val: 1.2540003614952486\n",
      "Epoch: 289 - time: 0.0031 - loss_train: 1.168104183747232 - loss_val: 1.2526840321407053\n",
      "Epoch: 290 - time: 0.0032 - loss_train: 1.1669904851765296 - loss_val: 1.2513779374822998\n",
      "Epoch: 291 - time: 0.0032 - loss_train: 1.1658852760601799 - loss_val: 1.2500819719160536\n",
      "Epoch: 292 - time: 0.0031 - loss_train: 1.1647884729426055 - loss_val: 1.248796030640255\n",
      "Epoch: 293 - time: 0.0032 - loss_train: 1.1636999932911263 - loss_val: 1.2475200111130371\n",
      "Epoch: 294 - time: 0.0032 - loss_train: 1.1626197554602264 - loss_val: 1.2462538137113623\n",
      "Epoch: 295 - time: 0.0032 - loss_train: 1.1615476786299606 - loss_val: 1.244997341411428\n",
      "Epoch: 296 - time: 0.0032 - loss_train: 1.160483682742606 - loss_val: 1.2437504987683727\n",
      "Epoch: 297 - time: 0.0031 - loss_train: 1.1594276884605386 - loss_val: 1.242513190749805\n",
      "Epoch: 298 - time: 0.0031 - loss_train: 1.1583796171581298 - loss_val: 1.2412853219717748\n",
      "Epoch: 299 - time: 0.0031 - loss_train: 1.1573393909460101 - loss_val: 1.2400667966348624\n",
      "Epoch: 300 - time: 0.0032 - loss_train: 1.1563069327133886 - loss_val: 1.2388575191048863\n",
      "Epoch: 301 - time: 0.0031 - loss_train: 1.1552821661682182 - loss_val: 1.2376573947986953\n",
      "Epoch: 302 - time: 0.0032 - loss_train: 1.1542650158576215 - loss_val: 1.236466330940214\n",
      "Epoch: 303 - time: 0.0032 - loss_train: 1.1532554071602985 - loss_val: 1.2352842368650645\n",
      "Epoch: 304 - time: 0.0032 - loss_train: 1.1522532662543876 - loss_val: 1.2341110237969142\n",
      "Epoch: 305 - time: 0.0031 - loss_train: 1.151258520073376 - loss_val: 1.2329466042679156\n",
      "Epoch: 306 - time: 0.0031 - loss_train: 1.1502710962659355 - loss_val: 1.2317908914953524\n",
      "Epoch: 307 - time: 0.0032 - loss_train: 1.149290923172153 - loss_val: 1.2306437990065442\n",
      "Epoch: 308 - time: 0.0037 - loss_train: 1.148317929820765 - loss_val: 1.229505240652788\n",
      "Epoch: 309 - time: 0.0032 - loss_train: 1.1473520459431912 - loss_val: 1.2283751309558517\n",
      "Epoch: 310 - time: 0.0031 - loss_train: 1.1463932019941263 - loss_val: 1.2272533855833914\n",
      "Epoch: 311 - time: 0.0031 - loss_train: 1.1454413291671892 - loss_val: 1.2261399217143858\n",
      "Epoch: 312 - time: 0.0031 - loss_train: 1.144496359397568 - loss_val: 1.225034658135332\n",
      "Epoch: 313 - time: 0.0031 - loss_train: 1.1435582253497973 - loss_val: 1.2239375150521012\n",
      "Epoch: 314 - time: 0.0032 - loss_train: 1.142626860394886 - loss_val: 1.222848413736794\n",
      "Epoch: 315 - time: 0.0032 - loss_train: 1.141702198584583 - loss_val: 1.221767276192221\n",
      "Epoch: 316 - time: 0.0031 - loss_train: 1.1407841746305767 - loss_val: 1.2206940249875435\n",
      "Epoch: 317 - time: 0.0032 - loss_train: 1.1398727238933084 - loss_val: 1.2196285833208644\n",
      "Epoch: 318 - time: 0.0032 - loss_train: 1.1389677823806268 - loss_val: 1.2185708752515265\n",
      "Epoch: 319 - time: 0.0032 - loss_train: 1.1380692867526023 - loss_val: 1.2175208259707784\n",
      "Epoch: 320 - time: 0.0031 - loss_train: 1.137177174327037 - loss_val: 1.2164783619748105\n",
      "Epoch: 321 - time: 0.0032 - loss_train: 1.136291383080836 - loss_val: 1.215443411063569\n",
      "Epoch: 322 - time: 0.0032 - loss_train: 1.1354118516448761 - loss_val: 1.2144159021778558\n",
      "Epoch: 323 - time: 0.0031 - loss_train: 1.1345385192929907 - loss_val: 1.2133957651612095\n",
      "Epoch: 324 - time: 0.0032 - loss_train: 1.1336713259279159 - loss_val: 1.2123829305591936\n",
      "Epoch: 325 - time: 0.0032 - loss_train: 1.1328102120677344 - loss_val: 1.2113773295397354\n",
      "Epoch: 326 - time: 0.0031 - loss_train: 1.1319551188355224 - loss_val: 1.2103788939533127\n",
      "Epoch: 327 - time: 0.0032 - loss_train: 1.1311059879531562 - loss_val: 1.2093875564849499\n",
      "Epoch: 328 - time: 0.0032 - loss_train: 1.1302627617384189 - loss_val: 1.2084032508123377\n",
      "Epoch: 329 - time: 0.0031 - loss_train: 1.1294253831034697 - loss_val: 1.2074259116903678\n",
      "Epoch: 330 - time: 0.0032 - loss_train: 1.128593795552622 - loss_val: 1.2064554749245877\n",
      "Epoch: 331 - time: 0.0032 - loss_train: 1.1277679431781136 - loss_val: 1.2054918772512249\n",
      "Epoch: 332 - time: 0.0032 - loss_train: 1.1269477706536648 - loss_val: 1.2045350561825976\n",
      "Epoch: 333 - time: 0.0031 - loss_train: 1.1261332232265477 - loss_val: 1.2035849498863622\n",
      "Epoch: 334 - time: 0.0032 - loss_train: 1.1253242467093296 - loss_val: 1.202641497144155\n",
      "Epoch: 335 - time: 0.0032 - loss_train: 1.1245207874722987 - loss_val: 1.201704637393729\n",
      "Epoch: 336 - time: 0.0032 - loss_train: 1.1237227924370805 - loss_val: 1.2007743108198932\n",
      "Epoch: 337 - time: 0.0032 - loss_train: 1.1229302090713789 - loss_val: 1.1998504584410024\n",
      "Epoch: 338 - time: 0.0032 - loss_train: 1.1221429853843499 - loss_val: 1.1989330221457628\n",
      "Epoch: 339 - time: 0.0032 - loss_train: 1.1213610699220828 - loss_val: 1.1980219446630458\n",
      "Epoch: 340 - time: 0.0031 - loss_train: 1.1205844117627803 - loss_val: 1.197117169480181\n",
      "Epoch: 341 - time: 0.0031 - loss_train: 1.1198129605115328 - loss_val: 1.1962186407471418\n",
      "Epoch: 342 - time: 0.0031 - loss_train: 1.1190466662947873 - loss_val: 1.1953263032061974\n",
      "Epoch: 343 - time: 0.0031 - loss_train: 1.1182854797547026 - loss_val: 1.1944401021703677\n",
      "Epoch: 344 - time: 0.0031 - loss_train: 1.1175293520435423 - loss_val: 1.1935599835488415\n",
      "Epoch: 345 - time: 0.0032 - loss_train: 1.1167782348181767 - loss_val: 1.1926858938962133\n",
      "Epoch: 346 - time: 0.0037 - loss_train: 1.1160320802346755 - loss_val: 1.1918177804542565\n",
      "Epoch: 347 - time: 0.0036 - loss_train: 1.1152908409429698 - loss_val: 1.190955591162296\n",
      "Epoch: 348 - time: 0.0032 - loss_train: 1.1145544700816155 - loss_val: 1.1900992746297652\n",
      "Epoch: 349 - time: 0.0032 - loss_train: 1.1138229212726969 - loss_val: 1.1892487800829994\n",
      "Epoch: 350 - time: 0.0032 - loss_train: 1.1130961486169422 - loss_val: 1.1884040573089258\n",
      "Epoch: 351 - time: 0.0040 - loss_train: 1.1123741066890398 - loss_val: 1.187565056617169\n",
      "Epoch: 352 - time: 0.0035 - loss_train: 1.1116567505330712 - loss_val: 1.1867317288310186\n",
      "Epoch: 353 - time: 0.0036 - loss_train: 1.1109440356579214 - loss_val: 1.185904025303132\n",
      "Epoch: 354 - time: 0.0036 - loss_train: 1.110235918032525 - loss_val: 1.1850818979408912\n",
      "Epoch: 355 - time: 0.0044 - loss_train: 1.1095323540808968 - loss_val: 1.1842652992237395\n",
      "Epoch: 356 - time: 0.0044 - loss_train: 1.1088333006770055 - loss_val: 1.1834541822007956\n",
      "Epoch: 357 - time: 0.0044 - loss_train: 1.1081387151396491 - loss_val: 1.1826485004677338\n",
      "Epoch: 358 - time: 0.0039 - loss_train: 1.1074485552275146 - loss_val: 1.1818482081318133\n",
      "Epoch: 359 - time: 0.0036 - loss_train: 1.1067627791345525 - loss_val: 1.1810532597784908\n",
      "Epoch: 360 - time: 0.0037 - loss_train: 1.1060813454856657 - loss_val: 1.1802636104507809\n",
      "Epoch: 361 - time: 0.0036 - loss_train: 1.1054042133326016 - loss_val: 1.1794792156453275\n",
      "Epoch: 362 - time: 0.0036 - loss_train: 1.104731342149855 - loss_val: 1.1787000313209706\n",
      "Epoch: 363 - time: 0.0036 - loss_train: 1.104062691830414 - loss_val: 1.1779260139104408\n",
      "Epoch: 364 - time: 0.0036 - loss_train: 1.1033982226812722 - loss_val: 1.1771571203256257\n",
      "Epoch: 365 - time: 0.0036 - loss_train: 1.1027378954187625 - loss_val: 1.1763933079512077\n",
      "Epoch: 366 - time: 0.0036 - loss_train: 1.1020816711638506 - loss_val: 1.1756345346276784\n",
      "Epoch: 367 - time: 0.0036 - loss_train: 1.1014295114375772 - loss_val: 1.1748807586296663\n",
      "Epoch: 368 - time: 0.0041 - loss_train: 1.1007813781567697 - loss_val: 1.174131938647028\n",
      "Epoch: 369 - time: 0.0044 - loss_train: 1.1001372336300375 - loss_val: 1.173388033773951\n",
      "Epoch: 370 - time: 0.0044 - loss_train: 1.0994970405539612 - loss_val: 1.1726490035069277\n",
      "Epoch: 371 - time: 0.0043 - loss_train: 1.0988607620093298 - loss_val: 1.1719148077482167\n",
      "Epoch: 372 - time: 0.0044 - loss_train: 1.0982283614572743 - loss_val: 1.1711854068093626\n",
      "Epoch: 373 - time: 0.0039 - loss_train: 1.0975998027352207 - loss_val: 1.1704607614101175\n",
      "Epoch: 374 - time: 0.0036 - loss_train: 1.0969750500527102 - loss_val: 1.1697408326710075\n",
      "Epoch: 375 - time: 0.0036 - loss_train: 1.096354067987167 - loss_val: 1.169025582101151\n",
      "Epoch: 376 - time: 0.0036 - loss_train: 1.0957368214797671 - loss_val: 1.1683149715850734\n",
      "Epoch: 377 - time: 0.0036 - loss_train: 1.095123275831496 - loss_val: 1.1676089633723221\n",
      "Epoch: 378 - time: 0.0038 - loss_train: 1.0945133966994323 - loss_val: 1.1669075200718988\n",
      "Epoch: 379 - time: 0.0039 - loss_train: 1.0939071500931978 - loss_val: 1.1662106046509662\n",
      "Epoch: 380 - time: 0.0039 - loss_train: 1.0933045023714727 - loss_val: 1.1655181804353638\n",
      "Epoch: 381 - time: 0.0039 - loss_train: 1.0927054202384725 - loss_val: 1.1648302111089222\n",
      "Epoch: 382 - time: 0.0036 - loss_train: 1.0921098707403283 - loss_val: 1.1641466607096127\n",
      "Epoch: 383 - time: 0.0036 - loss_train: 1.0915178212613705 - loss_val: 1.1634674936224354\n",
      "Epoch: 384 - time: 0.0037 - loss_train: 1.0909292395203782 - loss_val: 1.1627926745706205\n",
      "Epoch: 385 - time: 0.0036 - loss_train: 1.090344093566874 - loss_val: 1.1621221686074474\n",
      "Epoch: 386 - time: 0.0036 - loss_train: 1.0897623517775425 - loss_val: 1.1614559411104648\n",
      "Epoch: 387 - time: 0.0036 - loss_train: 1.0891839828527918 - loss_val: 1.1607939577785729\n",
      "Epoch: 388 - time: 0.0037 - loss_train: 1.0886089558134477 - loss_val: 1.1601361846309928\n",
      "Epoch: 389 - time: 0.0033 - loss_train: 1.0880372399975209 - loss_val: 1.1594825880063795\n",
      "Epoch: 390 - time: 0.0032 - loss_train: 1.0874688050569867 - loss_val: 1.1588331345604623\n",
      "Epoch: 391 - time: 0.0032 - loss_train: 1.086903620954534 - loss_val: 1.1581877912615484\n",
      "Epoch: 392 - time: 0.0031 - loss_train: 1.0863416579602723 - loss_val: 1.157546525384355\n",
      "Epoch: 393 - time: 0.0032 - loss_train: 1.0857828866484212 - loss_val: 1.1569093045034717\n",
      "Epoch: 394 - time: 0.0032 - loss_train: 1.085227277894022 - loss_val: 1.1562760964878256\n",
      "Epoch: 395 - time: 0.0031 - loss_train: 1.0846748028697082 - loss_val: 1.1556468694969435\n",
      "Epoch: 396 - time: 0.0032 - loss_train: 1.0841254330425671 - loss_val: 1.1550215919788906\n",
      "Epoch: 397 - time: 0.0032 - loss_train: 1.0835791401710777 - loss_val: 1.1544002326690146\n",
      "Epoch: 398 - time: 0.0031 - loss_train: 1.0830358963021183 - loss_val: 1.1537827605883453\n",
      "Epoch: 399 - time: 0.0031 - loss_train: 1.0824956737680125 - loss_val: 1.15316914504084\n",
      "Epoch: 400 - time: 0.0031 - loss_train: 1.0819584451835853 - loss_val: 1.1525593556093185\n",
      "Epoch: 401 - time: 0.0031 - loss_train: 1.0814241834432268 - loss_val: 1.1519533621506197\n",
      "Epoch: 402 - time: 0.0032 - loss_train: 1.0808928617179596 - loss_val: 1.1513511347908398\n",
      "Epoch: 403 - time: 0.0031 - loss_train: 1.080364453452523 - loss_val: 1.1507526439214146\n",
      "Epoch: 404 - time: 0.0032 - loss_train: 1.0798389323624893 - loss_val: 1.1501578601963476\n",
      "Epoch: 405 - time: 0.0031 - loss_train: 1.079316272431422 - loss_val: 1.14956675453031\n",
      "Epoch: 406 - time: 0.0032 - loss_train: 1.078796447908082 - loss_val: 1.1489792980970126\n",
      "Epoch: 407 - time: 0.0032 - loss_train: 1.0782794333036745 - loss_val: 1.1483954623271813\n",
      "Epoch: 408 - time: 0.0032 - loss_train: 1.0777652033891407 - loss_val: 1.1478152189057942\n",
      "Epoch: 409 - time: 0.0031 - loss_train: 1.0772537331924774 - loss_val: 1.147238539768614\n",
      "Epoch: 410 - time: 0.0032 - loss_train: 1.0767449979960875 - loss_val: 1.1466653970984593\n",
      "Epoch: 411 - time: 0.0032 - loss_train: 1.0762389733341535 - loss_val: 1.1460957633216953\n",
      "Epoch: 412 - time: 0.0031 - loss_train: 1.0757356349900358 - loss_val: 1.1455296111053226\n",
      "Epoch: 413 - time: 0.0048 - loss_train: 1.0752349589936905 - loss_val: 1.144966913354715\n",
      "Epoch: 414 - time: 0.0046 - loss_train: 1.0747369216191147 - loss_val: 1.1444076432117525\n",
      "Epoch: 415 - time: 0.0045 - loss_train: 1.074241499381814 - loss_val: 1.1438517740529852\n",
      "Epoch: 416 - time: 0.0045 - loss_train: 1.0737486690362976 - loss_val: 1.1432992794874708\n",
      "Epoch: 417 - time: 0.0045 - loss_train: 1.0732584075736067 - loss_val: 1.142750133354194\n",
      "Epoch: 418 - time: 0.0045 - loss_train: 1.0727706922188738 - loss_val: 1.1422043097191823\n",
      "Epoch: 419 - time: 0.0045 - loss_train: 1.0722855004289131 - loss_val: 1.1416617828725821\n",
      "Epoch: 420 - time: 0.0045 - loss_train: 1.0718028098898493 - loss_val: 1.1411225273259797\n",
      "Epoch: 421 - time: 0.0045 - loss_train: 1.0713225985147679 - loss_val: 1.1405865178101016\n",
      "Epoch: 422 - time: 0.0045 - loss_train: 1.0708448444413892 - loss_val: 1.1400537292728554\n",
      "Epoch: 423 - time: 0.0045 - loss_train: 1.0703695260297676 - loss_val: 1.1395241368775113\n",
      "Epoch: 424 - time: 0.0045 - loss_train: 1.0698966218599983 - loss_val: 1.138997716000833\n",
      "Epoch: 425 - time: 0.0045 - loss_train: 1.0694261107299514 - loss_val: 1.138474442230981\n",
      "Epoch: 426 - time: 0.0045 - loss_train: 1.0689579716530229 - loss_val: 1.1379542913652105\n",
      "Epoch: 427 - time: 0.0045 - loss_train: 1.0684921838559165 - loss_val: 1.137437239407454\n",
      "Epoch: 428 - time: 0.0045 - loss_train: 1.0680287267764523 - loss_val: 1.136923262565972\n",
      "Epoch: 429 - time: 0.0045 - loss_train: 1.0675675800614048 - loss_val: 1.1364123372511865\n",
      "Epoch: 430 - time: 0.0045 - loss_train: 1.0671087235643728 - loss_val: 1.1359044400737384\n",
      "Epoch: 431 - time: 0.0045 - loss_train: 1.0666521373436673 - loss_val: 1.1353995478427132\n",
      "Epoch: 432 - time: 0.0045 - loss_train: 1.0661978016602194 - loss_val: 1.134897637563898\n",
      "Epoch: 433 - time: 0.0045 - loss_train: 1.065745696975509 - loss_val: 1.134398686437984\n",
      "Epoch: 434 - time: 0.0046 - loss_train: 1.0652958039495055 - loss_val: 1.133902671858642\n",
      "Epoch: 435 - time: 0.0045 - loss_train: 1.0648481034386268 - loss_val: 1.133409571410514\n",
      "Epoch: 436 - time: 0.0045 - loss_train: 1.0644025764937224 - loss_val: 1.1329193628672019\n",
      "Epoch: 437 - time: 0.0045 - loss_train: 1.0639592043580781 - loss_val: 1.1324320241893224\n",
      "Epoch: 438 - time: 0.0045 - loss_train: 1.0635179684654466 - loss_val: 1.1319475335226998\n",
      "Epoch: 439 - time: 0.0045 - loss_train: 1.0630788504380995 - loss_val: 1.1314658691966657\n",
      "Epoch: 440 - time: 0.0039 - loss_train: 1.0626418320849054 - loss_val: 1.1309870097224266\n",
      "Epoch: 441 - time: 0.0033 - loss_train: 1.0622068953994213 - loss_val: 1.130510933791424\n",
      "Epoch: 442 - time: 0.0032 - loss_train: 1.0617740225580041 - loss_val: 1.1300376202736533\n",
      "Epoch: 443 - time: 0.0032 - loss_train: 1.0613431959179378 - loss_val: 1.1295670482159257\n",
      "Epoch: 444 - time: 0.0031 - loss_train: 1.0609143980155769 - loss_val: 1.1290991968401187\n",
      "Epoch: 445 - time: 0.0031 - loss_train: 1.060487611564506 - loss_val: 1.1286340455414583\n",
      "Epoch: 446 - time: 0.0032 - loss_train: 1.0600628194537258 - loss_val: 1.1281715738868698\n",
      "Epoch: 447 - time: 0.0031 - loss_train: 1.0596400047458474 - loss_val: 1.1277117616134182\n",
      "Epoch: 448 - time: 0.0032 - loss_train: 1.0592191506753204 - loss_val: 1.1272545886267915\n",
      "Epoch: 449 - time: 0.0032 - loss_train: 1.0588002406466648 - loss_val: 1.1268000349998089\n",
      "Epoch: 450 - time: 0.0032 - loss_train: 1.0583832582327342 - loss_val: 1.126348080970913\n",
      "Epoch: 451 - time: 0.0032 - loss_train: 1.0579681871729831 - loss_val: 1.1258987069426338\n",
      "Epoch: 452 - time: 0.0032 - loss_train: 1.0575550113717622 - loss_val: 1.1254518934800364\n",
      "Epoch: 453 - time: 0.0032 - loss_train: 1.0571437148966156 - loss_val: 1.125007621309182\n",
      "Epoch: 454 - time: 0.0032 - loss_train: 1.056734281976609 - loss_val: 1.1245658713156372\n",
      "Epoch: 455 - time: 0.0032 - loss_train: 1.0563266970006606 - loss_val: 1.1241266245430326\n",
      "Epoch: 456 - time: 0.0032 - loss_train: 1.0559209445159008 - loss_val: 1.1236898621916775\n",
      "Epoch: 457 - time: 0.0032 - loss_train: 1.0555170092260409 - loss_val: 1.1232555656171896\n",
      "Epoch: 458 - time: 0.0031 - loss_train: 1.0551148759897582 - loss_val: 1.1228237163291428\n",
      "Epoch: 459 - time: 0.0031 - loss_train: 1.0547145298191025 - loss_val: 1.1223942959896935\n",
      "Epoch: 460 - time: 0.0031 - loss_train: 1.0543159558779114 - loss_val: 1.1219672864121935\n",
      "Epoch: 461 - time: 0.0031 - loss_train: 1.0539191394802434 - loss_val: 1.1215426695598094\n",
      "Epoch: 462 - time: 0.0032 - loss_train: 1.0535240660888257 - loss_val: 1.1211204275441662\n",
      "Epoch: 463 - time: 0.0032 - loss_train: 1.0531307213135184 - loss_val: 1.120700542624016\n",
      "Epoch: 464 - time: 0.0031 - loss_train: 1.0527390909097887 - loss_val: 1.1202829972039607\n",
      "Epoch: 465 - time: 0.0032 - loss_train: 1.0523491607772062 - loss_val: 1.1198677738331944\n",
      "Epoch: 466 - time: 0.0032 - loss_train: 1.0519609169579462 - loss_val: 1.119454855204261\n",
      "Epoch: 467 - time: 0.0032 - loss_train: 1.051574345635313 - loss_val: 1.1190442241518177\n",
      "Epoch: 468 - time: 0.0032 - loss_train: 1.051189433132273 - loss_val: 1.1186358636513942\n",
      "Epoch: 469 - time: 0.0032 - loss_train: 1.0508061659100056 - loss_val: 1.1182297568181436\n",
      "Epoch: 470 - time: 0.0031 - loss_train: 1.0504245305664646 - loss_val: 1.1178258869056166\n",
      "Epoch: 471 - time: 0.0031 - loss_train: 1.0500445138349548 - loss_val: 1.1174242373045422\n",
      "Epoch: 472 - time: 0.0032 - loss_train: 1.0496661025827234 - loss_val: 1.1170247915416467\n",
      "Epoch: 473 - time: 0.0031 - loss_train: 1.0492892838095615 - loss_val: 1.1166275332784894\n",
      "Epoch: 474 - time: 0.0032 - loss_train: 1.0489140446464225 - loss_val: 1.11623244631032\n",
      "Epoch: 475 - time: 0.0032 - loss_train: 1.0485403723540507 - loss_val: 1.1158395145649458\n",
      "Epoch: 476 - time: 0.0032 - loss_train: 1.0481682543216257 - loss_val: 1.1154487221016012\n",
      "Epoch: 477 - time: 0.0032 - loss_train: 1.0477976780654175 - loss_val: 1.1150600531098138\n",
      "Epoch: 478 - time: 0.0038 - loss_train: 1.0474286312274534 - loss_val: 1.1146734919082892\n",
      "Epoch: 479 - time: 0.0033 - loss_train: 1.0470611015742035 - loss_val: 1.1142890229437965\n",
      "Epoch: 480 - time: 0.0032 - loss_train: 1.0466950769952712 - loss_val: 1.1139066307900773\n",
      "Epoch: 481 - time: 0.0031 - loss_train: 1.0463305455021013 - loss_val: 1.1135263001467763\n",
      "Epoch: 482 - time: 0.0031 - loss_train: 1.0459674952266989 - loss_val: 1.1131480158383742\n",
      "Epoch: 483 - time: 0.0031 - loss_train: 1.0456059144203609 - loss_val: 1.1127717628131513\n",
      "Epoch: 484 - time: 0.0031 - loss_train: 1.0452457914524187 - loss_val: 1.1123975261421437\n",
      "Epoch: 485 - time: 0.0032 - loss_train: 1.044887114808993 - loss_val: 1.112025291018108\n",
      "Epoch: 486 - time: 0.0032 - loss_train: 1.0445298730917627 - loss_val: 1.1116550427544944\n",
      "Epoch: 487 - time: 0.0032 - loss_train: 1.0441740550167415 - loss_val: 1.1112867667844266\n",
      "Epoch: 488 - time: 0.0032 - loss_train: 1.0438196494130705 - loss_val: 1.1109204486596986\n",
      "Epoch: 489 - time: 0.0032 - loss_train: 1.0434666452218202 - loss_val: 1.1105560740497717\n",
      "Epoch: 490 - time: 0.0035 - loss_train: 1.0431150314948063 - loss_val: 1.1101936287408039\n",
      "Epoch: 491 - time: 0.0036 - loss_train: 1.0427647973934118 - loss_val: 1.1098330986346765\n",
      "Epoch: 492 - time: 0.0032 - loss_train: 1.0424159321874285 - loss_val: 1.109474469748031\n",
      "Epoch: 493 - time: 0.0032 - loss_train: 1.0420684252539023 - loss_val: 1.1091177282113163\n",
      "Epoch: 494 - time: 0.0032 - loss_train: 1.0417222660759926 - loss_val: 1.1087628602678405\n",
      "Epoch: 495 - time: 0.0032 - loss_train: 1.041377444241845 - loss_val: 1.1084098522728258\n",
      "Epoch: 496 - time: 0.0032 - loss_train: 1.0410339494434706 - loss_val: 1.1080586906924796\n",
      "Epoch: 497 - time: 0.0031 - loss_train: 1.040691771475639 - loss_val: 1.107709362103071\n",
      "Epoch: 498 - time: 0.0032 - loss_train: 1.0403509002347835 - loss_val: 1.1073618531900238\n",
      "Epoch: 499 - time: 0.0032 - loss_train: 1.0400113257179127 - loss_val: 1.1070161507470067\n",
      "Epoch: 500 - time: 0.0032 - loss_train: 1.0396730380215375 - loss_val: 1.1066722416750465\n",
      "Epoch: 501 - time: 0.0031 - loss_train: 1.0393360273406085 - loss_val: 1.1063301129816399\n",
      "Epoch: 502 - time: 0.0031 - loss_train: 1.039000283967457 - loss_val: 1.105989751779872\n",
      "Epoch: 503 - time: 0.0032 - loss_train: 1.0386657982907563 - loss_val: 1.1056511452875413\n",
      "Epoch: 504 - time: 0.0032 - loss_train: 1.0383325607944862 - loss_val: 1.1053142808262961\n",
      "Epoch: 505 - time: 0.0031 - loss_train: 1.038000562056912 - loss_val: 1.1049791458207747\n",
      "Epoch: 506 - time: 0.0032 - loss_train: 1.0376697927495702 - loss_val: 1.1046457277977566\n",
      "Epoch: 507 - time: 0.0032 - loss_train: 1.0373402436362678 - loss_val: 1.1043140143853198\n",
      "Epoch: 508 - time: 0.0032 - loss_train: 1.0370119055720894 - loss_val: 1.1039839933120128\n",
      "Epoch: 509 - time: 0.0032 - loss_train: 1.0366847695024155 - loss_val: 1.1036556524060206\n",
      "Epoch: 510 - time: 0.0032 - loss_train: 1.0363588264619505 - loss_val: 1.1033289795943473\n",
      "Epoch: 511 - time: 0.0032 - loss_train: 1.0360340675737594 - loss_val: 1.103003962902002\n",
      "Epoch: 512 - time: 0.0032 - loss_train: 1.0357104840483167 - loss_val: 1.10268059045119\n",
      "Epoch: 513 - time: 0.0032 - loss_train: 1.0353880671825637 - loss_val: 1.1023588504605082\n",
      "Epoch: 514 - time: 0.0031 - loss_train: 1.0350668083589734 - loss_val: 1.1020387312441533\n",
      "Epoch: 515 - time: 0.0031 - loss_train: 1.0347466990446292 - loss_val: 1.101720221211136\n",
      "Epoch: 516 - time: 0.0034 - loss_train: 1.0344277307903094 - loss_val: 1.1014033088645\n",
      "Epoch: 517 - time: 0.0032 - loss_train: 1.0341098952295846 - loss_val: 1.1010879828005475\n",
      "Epoch: 518 - time: 0.0032 - loss_train: 1.033793184077919 - loss_val: 1.1007742317080729\n",
      "Epoch: 519 - time: 0.0032 - loss_train: 1.0334775891317889 - loss_val: 1.1004620443675976\n",
      "Epoch: 520 - time: 0.0032 - loss_train: 1.0331631022678032 - loss_val: 1.1001514096506173\n",
      "Epoch: 521 - time: 0.0032 - loss_train: 1.0328497154418366 - loss_val: 1.0998423165188473\n",
      "Epoch: 522 - time: 0.0031 - loss_train: 1.0325374206881714 - loss_val: 1.099534754023481\n",
      "Epoch: 523 - time: 0.0032 - loss_train: 1.0322262101186488 - loss_val: 1.099228711304446\n",
      "Epoch: 524 - time: 0.0032 - loss_train: 1.031916075921827 - loss_val: 1.0989241775896819\n",
      "Epoch: 525 - time: 0.0031 - loss_train: 1.031607010362152 - loss_val: 1.0986211421944037\n",
      "Epoch: 526 - time: 0.0031 - loss_train: 1.0312990057791311 - loss_val: 1.0983195945203892\n",
      "Epoch: 527 - time: 0.0032 - loss_train: 1.0309920545865243 - loss_val: 1.0980195240552593\n",
      "Epoch: 528 - time: 0.0031 - loss_train: 1.030686149271534 - loss_val: 1.0977209203717717\n",
      "Epoch: 529 - time: 0.0032 - loss_train: 1.0303812823940113 - loss_val: 1.0974237731271073\n",
      "Epoch: 530 - time: 0.0032 - loss_train: 1.0300774465856672 - loss_val: 1.0971280720621834\n",
      "Epoch: 531 - time: 0.0032 - loss_train: 1.0297746345492929 - loss_val: 1.0968338070009485\n",
      "Epoch: 532 - time: 0.0032 - loss_train: 1.0294728390579881 - loss_val: 1.0965409678496998\n",
      "Epoch: 533 - time: 0.0032 - loss_train: 1.029172052954399 - loss_val: 1.0962495445964018\n",
      "Epoch: 534 - time: 0.0032 - loss_train: 1.0288722691499634 - loss_val: 1.0959595273100036\n",
      "Epoch: 535 - time: 0.0032 - loss_train: 1.028573480624164 - loss_val: 1.0956709061397694\n",
      "Epoch: 536 - time: 0.0032 - loss_train: 1.02827568042379 - loss_val: 1.0953836713146108\n",
      "Epoch: 537 - time: 0.0031 - loss_train: 1.0279788616622063 - loss_val: 1.0950978131424236\n",
      "Epoch: 538 - time: 0.0032 - loss_train: 1.0276830175186338 - loss_val: 1.0948133220094283\n",
      "Epoch: 539 - time: 0.0031 - loss_train: 1.0273881412374313 - loss_val: 1.0945301883795182\n",
      "Epoch: 540 - time: 0.0032 - loss_train: 1.027094226127392 - loss_val: 1.094248402793613\n",
      "Epoch: 541 - time: 0.0032 - loss_train: 1.0268012655610435 - loss_val: 1.0939679558690145\n",
      "Epoch: 542 - time: 0.0032 - loss_train: 1.0265092529739563 - loss_val: 1.0936888382987673\n",
      "Epoch: 543 - time: 0.0032 - loss_train: 1.0262181818640612 - loss_val: 1.0934110408510278\n",
      "Epoch: 544 - time: 0.0032 - loss_train: 1.0259280457909736 - loss_val: 1.093134554368435\n",
      "Epoch: 545 - time: 0.0031 - loss_train: 1.0256388383753248 - loss_val: 1.0928593697674844\n",
      "Epoch: 546 - time: 0.0032 - loss_train: 1.0253505532981002 - loss_val: 1.0925854780379118\n",
      "Epoch: 547 - time: 0.0032 - loss_train: 1.0250631842999887 - loss_val: 1.0923128702420768\n",
      "Epoch: 548 - time: 0.0032 - loss_train: 1.0247767251807323 - loss_val: 1.0920415375143488\n",
      "Epoch: 549 - time: 0.0031 - loss_train: 1.0244911697984909 - loss_val: 1.09177147106051\n",
      "Epoch: 550 - time: 0.0031 - loss_train: 1.0242065120692077 - loss_val: 1.0915026621571458\n",
      "Epoch: 551 - time: 0.0032 - loss_train: 1.023922745965986 - loss_val: 1.0912351021510545\n",
      "Epoch: 552 - time: 0.0032 - loss_train: 1.0236398655184715 - loss_val: 1.0909687824586505\n",
      "Epoch: 553 - time: 0.0038 - loss_train: 1.0233578648122394 - loss_val: 1.0907036945653776\n",
      "Epoch: 554 - time: 0.0033 - loss_train: 1.023076737988194 - loss_val: 1.0904398300251306\n",
      "Epoch: 555 - time: 0.0032 - loss_train: 1.0227964792419686 - loss_val: 1.090177180459667\n",
      "Epoch: 556 - time: 0.0032 - loss_train: 1.0225170828233354 - loss_val: 1.0899157375580393\n",
      "Epoch: 557 - time: 0.0031 - loss_train: 1.0222385430356247 - loss_val: 1.089655493076023\n",
      "Epoch: 558 - time: 0.0032 - loss_train: 1.0219608542351435 - loss_val: 1.0893964388355488\n",
      "Epoch: 559 - time: 0.0032 - loss_train: 1.0216840108306082 - loss_val: 1.0891385667241424\n",
      "Epoch: 560 - time: 0.0032 - loss_train: 1.0214080072825795 - loss_val: 1.088881868694366\n",
      "Epoch: 561 - time: 0.0031 - loss_train: 1.021132838102905 - loss_val: 1.0886263367632634\n",
      "Epoch: 562 - time: 0.0032 - loss_train: 1.0208584978541657 - loss_val: 1.0883719630118158\n",
      "Epoch: 563 - time: 0.0031 - loss_train: 1.020584981149136 - loss_val: 1.0881187395843885\n",
      "Epoch: 564 - time: 0.0031 - loss_train: 1.0203122826502395 - loss_val: 1.0878666586881982\n",
      "Epoch: 565 - time: 0.0032 - loss_train: 1.020040397069018 - loss_val: 1.0876157125927675\n",
      "Epoch: 566 - time: 0.0032 - loss_train: 1.0197693191656076 - loss_val: 1.0873658936294002\n",
      "Epoch: 567 - time: 0.0032 - loss_train: 1.0194990437482137 - loss_val: 1.087117194190646\n",
      "Epoch: 568 - time: 0.0032 - loss_train: 1.019229565672599 - loss_val: 1.0868696067297778\n",
      "Epoch: 569 - time: 0.0032 - loss_train: 1.0189608798415748 - loss_val: 1.0866231237602741\n",
      "Epoch: 570 - time: 0.0032 - loss_train: 1.0186929812044965 - loss_val: 1.0863777378552943\n",
      "Epoch: 571 - time: 0.0032 - loss_train: 1.0184258647567674 - loss_val: 1.0861334416471746\n",
      "Epoch: 572 - time: 0.0032 - loss_train: 1.0181595255393474 - loss_val: 1.0858902278269116\n",
      "Epoch: 573 - time: 0.0031 - loss_train: 1.0178939586382658 - loss_val: 1.0856480891436608\n",
      "Epoch: 574 - time: 0.0032 - loss_train: 1.017629159184142 - loss_val: 1.0854070184042364\n",
      "Epoch: 575 - time: 0.0032 - loss_train: 1.0173651223517102 - loss_val: 1.0851670084726097\n",
      "Epoch: 576 - time: 0.0031 - loss_train: 1.0171018433593504 - loss_val: 1.0849280522694187\n",
      "Epoch: 577 - time: 0.0031 - loss_train: 1.016839317468623 - loss_val: 1.0846901427714781\n",
      "Epoch: 578 - time: 0.0032 - loss_train: 1.0165775399838115 - loss_val: 1.084453273011292\n",
      "Epoch: 579 - time: 0.0032 - loss_train: 1.0163165062514679 - loss_val: 1.0842174360765728\n",
      "Epoch: 580 - time: 0.0032 - loss_train: 1.0160562116599652 - loss_val: 1.0839826251097628\n",
      "Epoch: 581 - time: 0.0032 - loss_train: 1.015796651639054 - loss_val: 1.0837488333075587\n",
      "Epoch: 582 - time: 0.0032 - loss_train: 1.0155378216594229 - loss_val: 1.083516053920442\n",
      "Epoch: 583 - time: 0.0032 - loss_train: 1.0152797172322683 - loss_val: 1.0832842802522087\n",
      "Epoch: 584 - time: 0.0032 - loss_train: 1.015022333908862 - loss_val: 1.0830535056595099\n",
      "Epoch: 585 - time: 0.0032 - loss_train: 1.0147656672801317 - loss_val: 1.0828237235513893\n",
      "Epoch: 586 - time: 0.0032 - loss_train: 1.014509712976241 - loss_val: 1.082594927388827\n",
      "Epoch: 587 - time: 0.0031 - loss_train: 1.0142544666661752 - loss_val: 1.0823671106842867\n",
      "Epoch: 588 - time: 0.0032 - loss_train: 1.0139999240573332 - loss_val: 1.0821402670012685\n",
      "Epoch: 589 - time: 0.0032 - loss_train: 1.0137460808951215 - loss_val: 1.0819143899538624\n",
      "Epoch: 590 - time: 0.0032 - loss_train: 1.0134929329625568 - loss_val: 1.0816894732063038\n",
      "Epoch: 591 - time: 0.0037 - loss_train: 1.0132404760798697 - loss_val: 1.0814655104725395\n",
      "Epoch: 592 - time: 0.0032 - loss_train: 1.012988706104112 - loss_val: 1.081242495515789\n",
      "Epoch: 593 - time: 0.0032 - loss_train: 1.0127376189287738 - loss_val: 1.0810204221481168\n",
      "Epoch: 594 - time: 0.0032 - loss_train: 1.0124872104834 - loss_val: 1.0807992842300005\n",
      "Epoch: 595 - time: 0.0031 - loss_train: 1.0122374767332116 - loss_val: 1.0805790756699094\n",
      "Epoch: 596 - time: 0.0032 - loss_train: 1.0119884136787347 - loss_val: 1.0803597904238822\n",
      "Epoch: 597 - time: 0.0032 - loss_train: 1.0117400173554294 - loss_val: 1.0801414224951096\n",
      "Epoch: 598 - time: 0.0031 - loss_train: 1.011492283833326 - loss_val: 1.0799239659335198\n",
      "Epoch: 599 - time: 0.0031 - loss_train: 1.011245209216664 - loss_val: 1.0797074148353696\n",
      "Epoch: 600 - time: 0.0032 - loss_train: 1.0109987896435348 - loss_val: 1.0794917633428338\n",
      "Epoch: 601 - time: 0.0031 - loss_train: 1.0107530212855302 - loss_val: 1.0792770056436018\n",
      "Epoch: 602 - time: 0.0032 - loss_train: 1.0105079003473927 - loss_val: 1.0790631359704816\n",
      "Epoch: 603 - time: 0.0031 - loss_train: 1.0102634230666703 - loss_val: 1.078850148600994\n",
      "Epoch: 604 - time: 0.0031 - loss_train: 1.0100195857133774 - loss_val: 1.0786380378569866\n",
      "Epoch: 605 - time: 0.0031 - loss_train: 1.009776384589656 - loss_val: 1.0784267981042353\n",
      "Epoch: 606 - time: 0.0031 - loss_train: 1.0095338160294423 - loss_val: 1.078216423752063\n",
      "Epoch: 607 - time: 0.0031 - loss_train: 1.0092918763981389 - loss_val: 1.0780069092529516\n",
      "Epoch: 608 - time: 0.0031 - loss_train: 1.009050562092287 - loss_val: 1.0777982491021616\n",
      "Epoch: 609 - time: 0.0031 - loss_train: 1.0088098695392456 - loss_val: 1.0775904378373533\n",
      "Epoch: 610 - time: 0.0031 - loss_train: 1.0085697951968708 - loss_val: 1.077383470038214\n",
      "Epoch: 611 - time: 0.0031 - loss_train: 1.0083303355532038 - loss_val: 1.0771773403260816\n",
      "Epoch: 612 - time: 0.0031 - loss_train: 1.008091487126157 - loss_val: 1.0769720433635805\n",
      "Epoch: 613 - time: 0.0031 - loss_train: 1.0078532464632055 - loss_val: 1.0767675738542544\n",
      "Epoch: 614 - time: 0.0031 - loss_train: 1.007615610141085 - loss_val: 1.0765639265422038\n",
      "Epoch: 615 - time: 0.0031 - loss_train: 1.0073785747654873 - loss_val: 1.076361096211725\n",
      "Epoch: 616 - time: 0.0032 - loss_train: 1.0071421369707652 - loss_val: 1.0761590776869547\n",
      "Epoch: 617 - time: 0.0031 - loss_train: 1.006906293419636 - loss_val: 1.075957865831518\n",
      "Epoch: 618 - time: 0.0031 - loss_train: 1.0066710408028914 - loss_val: 1.0757574555481744\n",
      "Epoch: 619 - time: 0.0031 - loss_train: 1.006436375839107 - loss_val: 1.0755578417784741\n",
      "Epoch: 620 - time: 0.0031 - loss_train: 1.006202295274361 - loss_val: 1.0753590195024112\n",
      "Epoch: 621 - time: 0.0031 - loss_train: 1.0059687958819483 - loss_val: 1.0751609837380818\n",
      "Epoch: 622 - time: 0.0031 - loss_train: 1.0057358744621059 - loss_val: 1.0749637295413463\n",
      "Epoch: 623 - time: 0.0031 - loss_train: 1.0055035278417332 - loss_val: 1.0747672520054925\n",
      "Epoch: 624 - time: 0.0031 - loss_train: 1.0052717528741224 - loss_val: 1.074571546260904\n",
      "Epoch: 625 - time: 0.0031 - loss_train: 1.0050405464386885 - loss_val: 1.0743766074747296\n",
      "Epoch: 626 - time: 0.0031 - loss_train: 1.0048099054406996 - loss_val: 1.0741824308505534\n",
      "Epoch: 627 - time: 0.0031 - loss_train: 1.0045798268110169 - loss_val: 1.0739890116280735\n",
      "Epoch: 628 - time: 0.0032 - loss_train: 1.004350307505833 - loss_val: 1.0737963450827805\n",
      "Epoch: 629 - time: 0.0038 - loss_train: 1.0041213445064125 - loss_val: 1.0736044265256346\n",
      "Epoch: 630 - time: 0.0033 - loss_train: 1.003892934818838 - loss_val: 1.0734132513027541\n",
      "Epoch: 631 - time: 0.0032 - loss_train: 1.0036650754737566 - loss_val: 1.073222814795098\n",
      "Epoch: 632 - time: 0.0031 - loss_train: 1.0034377635261331 - loss_val: 1.0730331124181558\n",
      "Epoch: 633 - time: 0.0031 - loss_train: 1.0032109960549982 - loss_val: 1.0728441396216422\n",
      "Epoch: 634 - time: 0.0031 - loss_train: 1.0029847701632102 - loss_val: 1.0726558918891878\n",
      "Epoch: 635 - time: 0.0031 - loss_train: 1.0027590829772086 - loss_val: 1.0724683647380415\n",
      "Epoch: 636 - time: 0.0031 - loss_train: 1.002533931646778 - loss_val: 1.0722815537187604\n",
      "Epoch: 637 - time: 0.0031 - loss_train: 1.0023093133448093 - loss_val: 1.0720954544149248\n",
      "Epoch: 638 - time: 0.0031 - loss_train: 1.0020852252670707 - loss_val: 1.0719100624428317\n",
      "Epoch: 639 - time: 0.0031 - loss_train: 1.0018616646319705 - loss_val: 1.0717253734512124\n",
      "Epoch: 640 - time: 0.0032 - loss_train: 1.0016386286803325 - loss_val: 1.0715413831209317\n",
      "Epoch: 641 - time: 0.0031 - loss_train: 1.0014161146751692 - loss_val: 1.0713580871647104\n",
      "Epoch: 642 - time: 0.0031 - loss_train: 1.0011941199014558 - loss_val: 1.0711754813268346\n",
      "Epoch: 643 - time: 0.0031 - loss_train: 1.0009726416659128 - loss_val: 1.0709935613828734\n",
      "Epoch: 644 - time: 0.0031 - loss_train: 1.0007516772967837 - loss_val: 1.0708123231394036\n",
      "Epoch: 645 - time: 0.0031 - loss_train: 1.0005312241436202 - loss_val: 1.070631762433724\n",
      "Epoch: 646 - time: 0.0031 - loss_train: 1.0003112795770674 - loss_val: 1.0704518751335892\n",
      "Epoch: 647 - time: 0.0031 - loss_train: 1.0000918409886517 - loss_val: 1.0702726571369292\n",
      "Epoch: 648 - time: 0.0031 - loss_train: 0.9998729057905736 - loss_val: 1.0700941043715853\n",
      "Epoch: 649 - time: 0.0031 - loss_train: 0.9996544714154956 - loss_val: 1.0699162127950355\n",
      "Epoch: 650 - time: 0.0031 - loss_train: 0.9994365353163427 - loss_val: 1.0697389783941356\n",
      "Epoch: 651 - time: 0.0032 - loss_train: 0.9992190949660951 - loss_val: 1.069562397184852\n",
      "Epoch: 652 - time: 0.0031 - loss_train: 0.9990021478575914 - loss_val: 1.0693864652120015\n",
      "Epoch: 653 - time: 0.0031 - loss_train: 0.9987856915033273 - loss_val: 1.0692111785489908\n",
      "Epoch: 654 - time: 0.0031 - loss_train: 0.9985697234352592 - loss_val: 1.0690365332975647\n",
      "Epoch: 655 - time: 0.0031 - loss_train: 0.9983542412046132 - loss_val: 1.0688625255875466\n",
      "Epoch: 656 - time: 0.0031 - loss_train: 0.9981392423816892 - loss_val: 1.0686891515765908\n",
      "Epoch: 657 - time: 0.0031 - loss_train: 0.9979247245556738 - loss_val: 1.0685164074499294\n",
      "Epoch: 658 - time: 0.0031 - loss_train: 0.9977106853344512 - loss_val: 1.0683442894201274\n",
      "Epoch: 659 - time: 0.0031 - loss_train: 0.9974971223444175 - loss_val: 1.0681727937268366\n",
      "Epoch: 660 - time: 0.0031 - loss_train: 0.9972840332302958 - loss_val: 1.0680019166365518\n",
      "Epoch: 661 - time: 0.0032 - loss_train: 0.9970714156549562 - loss_val: 1.067831654442369\n",
      "Epoch: 662 - time: 0.0032 - loss_train: 0.9968592672992349 - loss_val: 1.067662003463751\n",
      "Epoch: 663 - time: 0.0032 - loss_train: 0.9966475858617565 - loss_val: 1.0674929600462846\n",
      "Epoch: 664 - time: 0.0032 - loss_train: 0.9964363690587572 - loss_val: 1.067324520561451\n",
      "Epoch: 665 - time: 0.0031 - loss_train: 0.9962256146239119 - loss_val: 1.0671566814063895\n",
      "Epoch: 666 - time: 0.0031 - loss_train: 0.9960153203081624 - loss_val: 1.0669894390036703\n",
      "Epoch: 667 - time: 0.0038 - loss_train: 0.9958054838795438 - loss_val: 1.0668227898010632\n",
      "Epoch: 668 - time: 0.0032 - loss_train: 0.9955961031230199 - loss_val: 1.0666567302713148\n",
      "Epoch: 669 - time: 0.0032 - loss_train: 0.9953871758403161 - loss_val: 1.0664912569119196\n",
      "Epoch: 670 - time: 0.0032 - loss_train: 0.9951786998497503 - loss_val: 1.0663263662449014\n",
      "Epoch: 671 - time: 0.0032 - loss_train: 0.9949706729860761 - loss_val: 1.0661620548165944\n",
      "Epoch: 672 - time: 0.0031 - loss_train: 0.9947630931003173 - loss_val: 1.0659983191974178\n",
      "Epoch: 673 - time: 0.0031 - loss_train: 0.9945559580596095 - loss_val: 1.0658351559816672\n",
      "Epoch: 674 - time: 0.0031 - loss_train: 0.9943492657470421 - loss_val: 1.0656725617872969\n",
      "Epoch: 675 - time: 0.0031 - loss_train: 0.994143014061503 - loss_val: 1.0655105332557055\n",
      "Epoch: 676 - time: 0.0032 - loss_train: 0.9939372009175241 - loss_val: 1.06534906705153\n",
      "Epoch: 677 - time: 0.0031 - loss_train: 0.9937318242451277 - loss_val: 1.065188159862434\n",
      "Epoch: 678 - time: 0.0031 - loss_train: 0.9935268819896771 - loss_val: 1.0650278083989022\n",
      "Epoch: 679 - time: 0.0031 - loss_train: 0.9933223721117251 - loss_val: 1.064868009394034\n",
      "Epoch: 680 - time: 0.0031 - loss_train: 0.9931182925868689 - loss_val: 1.0647087596033429\n",
      "Epoch: 681 - time: 0.0031 - loss_train: 0.9929146414056017 - loss_val: 1.0645500558045555\n",
      "Epoch: 682 - time: 0.0032 - loss_train: 0.9927114165731696 - loss_val: 1.0643918947974076\n",
      "Epoch: 683 - time: 0.0031 - loss_train: 0.9925086161094289 - loss_val: 1.0642342734034522\n",
      "Epoch: 684 - time: 0.0031 - loss_train: 0.9923062380487033 - loss_val: 1.0640771884658642\n",
      "Epoch: 685 - time: 0.0031 - loss_train: 0.9921042804396458 - loss_val: 1.0639206368492404\n",
      "Epoch: 686 - time: 0.0031 - loss_train: 0.9919027413450995 - loss_val: 1.0637646154394147\n",
      "Epoch: 687 - time: 0.0031 - loss_train: 0.9917016188419607 - loss_val: 1.0636091211432641\n",
      "Epoch: 688 - time: 0.0031 - loss_train: 0.9915009110210451 - loss_val: 1.0634541508885174\n",
      "Epoch: 689 - time: 0.0031 - loss_train: 0.9913006159869524 - loss_val: 1.063299701623579\n",
      "Epoch: 690 - time: 0.0031 - loss_train: 0.9911007318579355 - loss_val: 1.0631457703173313\n",
      "Epoch: 691 - time: 0.0031 - loss_train: 0.9909012567657687 - loss_val: 1.0629923539589572\n",
      "Epoch: 692 - time: 0.0031 - loss_train: 0.9907021888556182 - loss_val: 1.0628394495577622\n",
      "Epoch: 693 - time: 0.0031 - loss_train: 0.9905035262859155 - loss_val: 1.0626870541429896\n",
      "Epoch: 694 - time: 0.0031 - loss_train: 0.9903052672282318 - loss_val: 1.062535164763642\n",
      "Epoch: 695 - time: 0.0031 - loss_train: 0.990107409867148 - loss_val: 1.0623837784883081\n",
      "Epoch: 696 - time: 0.0031 - loss_train: 0.9899099524001365 - loss_val: 1.062232892404985\n",
      "Epoch: 697 - time: 0.0036 - loss_train: 0.9897128930374361 - loss_val: 1.0620825036209103\n",
      "Epoch: 698 - time: 0.0032 - loss_train: 0.989516230001933 - loss_val: 1.0619326092623829\n",
      "Epoch: 699 - time: 0.0032 - loss_train: 0.989319961529038 - loss_val: 1.061783206474598\n",
      "Epoch: 700 - time: 0.0031 - loss_train: 0.9891240858665722 - loss_val: 1.0616342924214817\n",
      "Epoch: 701 - time: 0.0031 - loss_train: 0.9889286012746462 - loss_val: 1.0614858642855152\n",
      "Epoch: 702 - time: 0.0031 - loss_train: 0.9887335060255478 - loss_val: 1.0613379192675811\n",
      "Epoch: 703 - time: 0.0031 - loss_train: 0.9885387984036247 - loss_val: 1.0611904545867903\n",
      "Epoch: 704 - time: 0.0032 - loss_train: 0.9883444767051751 - loss_val: 1.0610434674803255\n",
      "Epoch: 705 - time: 0.0036 - loss_train: 0.9881505392383315 - loss_val: 1.0608969552032814\n",
      "Epoch: 706 - time: 0.0032 - loss_train: 0.9879569843229533 - loss_val: 1.0607509150285013\n",
      "Epoch: 707 - time: 0.0032 - loss_train: 0.9877638102905166 - loss_val: 1.060605344246427\n",
      "Epoch: 708 - time: 0.0031 - loss_train: 0.987571015484006 - loss_val: 1.0604602401649355\n",
      "Epoch: 709 - time: 0.0032 - loss_train: 0.9873785982578077 - loss_val: 1.0603156001091907\n",
      "Epoch: 710 - time: 0.0031 - loss_train: 0.9871865569776037 - loss_val: 1.0601714214214883\n",
      "Epoch: 711 - time: 0.0031 - loss_train: 0.9869948900202674 - loss_val: 1.0600277014611044\n",
      "Epoch: 712 - time: 0.0032 - loss_train: 0.9868035957737613 - loss_val: 1.05988443760415\n",
      "Epoch: 713 - time: 0.0032 - loss_train: 0.9866126726370329 - loss_val: 1.0597416272434157\n",
      "Epoch: 714 - time: 0.0031 - loss_train: 0.9864221190199153 - loss_val: 1.0595992677882318\n",
      "Epoch: 715 - time: 0.0031 - loss_train: 0.9862319333430262 - loss_val: 1.0594573566643193\n",
      "Epoch: 716 - time: 0.0031 - loss_train: 0.986042114037671 - loss_val: 1.0593158913136471\n",
      "Epoch: 717 - time: 0.0031 - loss_train: 0.9858526595457427 - loss_val: 1.0591748691942926\n",
      "Epoch: 718 - time: 0.0032 - loss_train: 0.985663568319627 - loss_val: 1.0590342877802945\n",
      "Epoch: 719 - time: 0.0032 - loss_train: 0.985474838822106 - loss_val: 1.0588941445615196\n",
      "Epoch: 720 - time: 0.0031 - loss_train: 0.9852864695262654 - loss_val: 1.0587544370435233\n",
      "Epoch: 721 - time: 0.0031 - loss_train: 0.9850984589153993 - loss_val: 1.0586151627474096\n",
      "Epoch: 722 - time: 0.0031 - loss_train: 0.984910805482919 - loss_val: 1.0584763192097006\n",
      "Epoch: 723 - time: 0.0031 - loss_train: 0.9847235077322614 - loss_val: 1.0583379039822007\n",
      "Epoch: 724 - time: 0.0031 - loss_train: 0.9845365641767994 - loss_val: 1.0581999146318626\n",
      "Epoch: 725 - time: 0.0031 - loss_train: 0.9843499733397516 - loss_val: 1.0580623487406597\n",
      "Epoch: 726 - time: 0.0031 - loss_train: 0.9841637337540967 - loss_val: 1.057925203905453\n",
      "Epoch: 727 - time: 0.0031 - loss_train: 0.9839778439624826 - loss_val: 1.0577884777378648\n",
      "Epoch: 728 - time: 0.0031 - loss_train: 0.9837923025171433 - loss_val: 1.057652167864151\n",
      "Epoch: 729 - time: 0.0031 - loss_train: 0.9836071079798125 - loss_val: 1.0575162719250761\n",
      "Epoch: 730 - time: 0.0031 - loss_train: 0.9834222589216401 - loss_val: 1.0573807875757875\n",
      "Epoch: 731 - time: 0.0031 - loss_train: 0.9832377539231076 - loss_val: 1.0572457124856947\n",
      "Epoch: 732 - time: 0.0031 - loss_train: 0.9830535915739482 - loss_val: 1.0571110443383431\n",
      "Epoch: 733 - time: 0.0031 - loss_train: 0.9828697704730616 - loss_val: 1.0569767808312989\n",
      "Epoch: 734 - time: 0.0032 - loss_train: 0.9826862892284374 - loss_val: 1.0568429196760274\n",
      "Epoch: 735 - time: 0.0031 - loss_train: 0.9825031464570736 - loss_val: 1.0567094585977737\n",
      "Epoch: 736 - time: 0.0031 - loss_train: 0.9823203407848986 - loss_val: 1.0565763953354492\n",
      "Epoch: 737 - time: 0.0031 - loss_train: 0.9821378708466934 - loss_val: 1.0564437276415128\n",
      "Epoch: 738 - time: 0.0031 - loss_train: 0.9819557352860131 - loss_val: 1.05631145328186\n",
      "Epoch: 739 - time: 0.0031 - loss_train: 0.9817739327551139 - loss_val: 1.056179570035706\n",
      "Epoch: 740 - time: 0.0031 - loss_train: 0.9815924619148755 - loss_val: 1.056048075695478\n",
      "Epoch: 741 - time: 0.0031 - loss_train: 0.9814113214347285 - loss_val: 1.0559169680667038\n",
      "Epoch: 742 - time: 0.0037 - loss_train: 0.9812305099925792 - loss_val: 1.055786244967898\n",
      "Epoch: 743 - time: 0.0033 - loss_train: 0.9810500262747389 - loss_val: 1.0556559042304625\n",
      "Epoch: 744 - time: 0.0031 - loss_train: 0.98086986897585 - loss_val: 1.0555259436985702\n",
      "Epoch: 745 - time: 0.0032 - loss_train: 0.9806900367988175 - loss_val: 1.0553963612290673\n",
      "Epoch: 746 - time: 0.0033 - loss_train: 0.9805105284547362 - loss_val: 1.0552671546913617\n",
      "Epoch: 747 - time: 0.0044 - loss_train: 0.9803313426628233 - loss_val: 1.0551383219673247\n",
      "Epoch: 748 - time: 0.0044 - loss_train: 0.9801524781503489 - loss_val: 1.0550098609511873\n",
      "Epoch: 749 - time: 0.0036 - loss_train: 0.9799739336525681 - loss_val: 1.0548817695494395\n",
      "Epoch: 750 - time: 0.0036 - loss_train: 0.9797957079126545 - loss_val: 1.0547540456807252\n",
      "Epoch: 751 - time: 0.0036 - loss_train: 0.9796177996816335 - loss_val: 1.0546266872757533\n",
      "Epoch: 752 - time: 0.0036 - loss_train: 0.9794402077183161 - loss_val: 1.0544996922771914\n",
      "Epoch: 753 - time: 0.0036 - loss_train: 0.9792629307892352 - loss_val: 1.054373058639571\n",
      "Epoch: 754 - time: 0.0036 - loss_train: 0.979085967668581 - loss_val: 1.054246784329195\n",
      "Epoch: 755 - time: 0.0036 - loss_train: 0.9789093171381379 - loss_val: 1.0541208673240403\n",
      "Epoch: 756 - time: 0.0036 - loss_train: 0.9787329779872204 - loss_val: 1.053995305613666\n",
      "Epoch: 757 - time: 0.0036 - loss_train: 0.9785569490126135 - loss_val: 1.053870097199119\n",
      "Epoch: 758 - time: 0.0036 - loss_train: 0.978381229018509 - loss_val: 1.0537452400928442\n",
      "Epoch: 759 - time: 0.0039 - loss_train: 0.9782058168164465 - loss_val: 1.0536207323185947\n",
      "Epoch: 760 - time: 0.0044 - loss_train: 0.9780307112252533 - loss_val: 1.053496571911342\n",
      "Epoch: 761 - time: 0.0043 - loss_train: 0.9778559110709844 - loss_val: 1.0533727569171878\n",
      "Epoch: 762 - time: 0.0039 - loss_train: 0.9776814151868635 - loss_val: 1.053249285393276\n",
      "Epoch: 763 - time: 0.0040 - loss_train: 0.977507222413227 - loss_val: 1.0531261554077083\n",
      "Epoch: 764 - time: 0.0039 - loss_train: 0.977333331597465 - loss_val: 1.0530033650394575\n",
      "Epoch: 765 - time: 0.0039 - loss_train: 0.9771597415939653 - loss_val: 1.0528809123782847\n",
      "Epoch: 766 - time: 0.0039 - loss_train: 0.9769864512640568 - loss_val: 1.0527587955246567\n",
      "Epoch: 767 - time: 0.0046 - loss_train: 0.9768134594759539 - loss_val: 1.0526370125896598\n",
      "Epoch: 768 - time: 0.0046 - loss_train: 0.9766407651047035 - loss_val: 1.0525155616949229\n",
      "Epoch: 769 - time: 0.0046 - loss_train: 0.9764683670321276 - loss_val: 1.0523944409725368\n",
      "Epoch: 770 - time: 0.0043 - loss_train: 0.9762962641467725 - loss_val: 1.0522736485649722\n",
      "Epoch: 771 - time: 0.0039 - loss_train: 0.9761244553438551 - loss_val: 1.0521531826250055\n",
      "Epoch: 772 - time: 0.0039 - loss_train: 0.9759529395252082 - loss_val: 1.0520330413156354\n",
      "Epoch: 773 - time: 0.0042 - loss_train: 0.9757817155992329 - loss_val: 1.0519132228100139\n",
      "Epoch: 774 - time: 0.0040 - loss_train: 0.9756107824808421 - loss_val: 1.0517937252913636\n",
      "Epoch: 775 - time: 0.0038 - loss_train: 0.9754401390914134 - loss_val: 1.051674546952909\n",
      "Epoch: 776 - time: 0.0039 - loss_train: 0.9752697843587385 - loss_val: 1.0515556859977981\n",
      "Epoch: 777 - time: 0.0039 - loss_train: 0.9750997172169715 - loss_val: 1.0514371406390324\n",
      "Epoch: 778 - time: 0.0040 - loss_train: 0.9749299366065818 - loss_val: 1.0513189090993933\n",
      "Epoch: 779 - time: 0.0032 - loss_train: 0.9747604414743039 - loss_val: 1.051200989611373\n",
      "Epoch: 780 - time: 0.0032 - loss_train: 0.9745912307730908 - loss_val: 1.0510833804170998\n",
      "Epoch: 781 - time: 0.0031 - loss_train: 0.9744223034620649 - loss_val: 1.0509660797682756\n",
      "Epoch: 782 - time: 0.0032 - loss_train: 0.9742536585064724 - loss_val: 1.050849085926102\n",
      "Epoch: 783 - time: 0.0032 - loss_train: 0.9740852948776343 - loss_val: 1.0507323971612121\n",
      "Epoch: 784 - time: 0.0031 - loss_train: 0.9739172115529035 - loss_val: 1.0506160117536096\n",
      "Epoch: 785 - time: 0.0032 - loss_train: 0.9737494075156162 - loss_val: 1.0504999279925937\n",
      "Epoch: 786 - time: 0.0031 - loss_train: 0.9735818817550493 - loss_val: 1.050384144176704\n",
      "Epoch: 787 - time: 0.0031 - loss_train: 0.9734146332663733 - loss_val: 1.0502686586136478\n",
      "Epoch: 788 - time: 0.0032 - loss_train: 0.97324766105061 - loss_val: 1.0501534696202404\n",
      "Epoch: 789 - time: 0.0031 - loss_train: 0.9730809641145877 - loss_val: 1.0500385755223418\n",
      "Epoch: 790 - time: 0.0031 - loss_train: 0.972914541470898 - loss_val: 1.0499239746547926\n",
      "Epoch: 791 - time: 0.0032 - loss_train: 0.9727483921378538 - loss_val: 1.0498096653613564\n",
      "Epoch: 792 - time: 0.0032 - loss_train: 0.9725825151394454 - loss_val: 1.049695645994655\n",
      "Epoch: 793 - time: 0.0032 - loss_train: 0.9724169095052996 - loss_val: 1.0495819149161139\n",
      "Epoch: 794 - time: 0.0032 - loss_train: 0.9722515742706386 - loss_val: 1.0494684704958954\n",
      "Epoch: 795 - time: 0.0032 - loss_train: 0.972086508476237 - loss_val: 1.049355311112849\n",
      "Epoch: 796 - time: 0.0032 - loss_train: 0.9719217111683836 - loss_val: 1.0492424351544478\n",
      "Epoch: 797 - time: 0.0032 - loss_train: 0.9717571813988384 - loss_val: 1.0491298410167333\n",
      "Epoch: 798 - time: 0.0031 - loss_train: 0.9715929182247944 - loss_val: 1.0490175271042599\n",
      "Epoch: 799 - time: 0.0032 - loss_train: 0.9714289207088392 - loss_val: 1.0489054918300393\n",
      "Epoch: 800 - time: 0.0032 - loss_train: 0.9712651879189131 - loss_val: 1.0487937336154851\n",
      "Epoch: 801 - time: 0.0031 - loss_train: 0.9711017189282717 - loss_val: 1.048682250890359\n",
      "Epoch: 802 - time: 0.0032 - loss_train: 0.9709385128154482 - loss_val: 1.0485710420927161\n",
      "Epoch: 803 - time: 0.0032 - loss_train: 0.9707755686642155 - loss_val: 1.0484601056688556\n",
      "Epoch: 804 - time: 0.0031 - loss_train: 0.9706128855635469 - loss_val: 1.0483494400732662\n",
      "Epoch: 805 - time: 0.0032 - loss_train: 0.9704504626075806 - loss_val: 1.0482390437685731\n",
      "Epoch: 806 - time: 0.0032 - loss_train: 0.9702882988955823 - loss_val: 1.0481289152254913\n",
      "Epoch: 807 - time: 0.0031 - loss_train: 0.9701263935319097 - loss_val: 1.048019052922772\n",
      "Epoch: 808 - time: 0.0032 - loss_train: 0.9699647456259729 - loss_val: 1.0479094553471546\n",
      "Epoch: 809 - time: 0.0032 - loss_train: 0.9698033542922048 - loss_val: 1.0478001209933185\n",
      "Epoch: 810 - time: 0.0038 - loss_train: 0.9696422186500184 - loss_val: 1.0476910483638344\n",
      "Epoch: 811 - time: 0.0032 - loss_train: 0.9694813378237782 - loss_val: 1.047582235969112\n",
      "Epoch: 812 - time: 0.0031 - loss_train: 0.9693207109427602 - loss_val: 1.047473682327364\n",
      "Epoch: 813 - time: 0.0031 - loss_train: 0.9691603371411225 - loss_val: 1.0473653859645464\n",
      "Epoch: 814 - time: 0.0032 - loss_train: 0.9690002155578659 - loss_val: 1.0472573454143232\n",
      "Epoch: 815 - time: 0.0031 - loss_train: 0.9688403453368045 - loss_val: 1.0471495592180153\n",
      "Epoch: 816 - time: 0.0031 - loss_train: 0.9686807256265298 - loss_val: 1.0470420259245565\n",
      "Epoch: 817 - time: 0.0032 - loss_train: 0.9685213555803783 - loss_val: 1.0469347440904526\n",
      "Epoch: 818 - time: 0.0031 - loss_train: 0.9683622343563983 - loss_val: 1.046827712279732\n",
      "Epoch: 819 - time: 0.0032 - loss_train: 0.9682033611173188 - loss_val: 1.0467209290639083\n",
      "Epoch: 820 - time: 0.0032 - loss_train: 0.9680447350305148 - loss_val: 1.046614393021936\n",
      "Epoch: 821 - time: 0.0032 - loss_train: 0.9678863552679766 - loss_val: 1.046508102740166\n",
      "Epoch: 822 - time: 0.0031 - loss_train: 0.9677282210062794 - loss_val: 1.0464020568123074\n",
      "Epoch: 823 - time: 0.0031 - loss_train: 0.9675703314265496 - loss_val: 1.0462962538393843\n",
      "Epoch: 824 - time: 0.0032 - loss_train: 0.9674126857144341 - loss_val: 1.0461906924296969\n",
      "Epoch: 825 - time: 0.0031 - loss_train: 0.9672552830600727 - loss_val: 1.0460853711987812\n",
      "Epoch: 826 - time: 0.0031 - loss_train: 0.9670981226580625 - loss_val: 1.0459802887693685\n",
      "Epoch: 827 - time: 0.0031 - loss_train: 0.966941203707431 - loss_val: 1.0458754437713471\n",
      "Epoch: 828 - time: 0.0031 - loss_train: 0.9667845254116049 - loss_val: 1.0457708348417243\n",
      "Epoch: 829 - time: 0.0032 - loss_train: 0.9666280869783815 - loss_val: 1.0456664606245887\n",
      "Epoch: 830 - time: 0.0031 - loss_train: 0.9664718876198982 - loss_val: 1.045562319771071\n",
      "Epoch: 831 - time: 0.0031 - loss_train: 0.9663159265526025 - loss_val: 1.0454584109393077\n",
      "Epoch: 832 - time: 0.0031 - loss_train: 0.9661602029972253 - loss_val: 1.0453547327944062\n",
      "Epoch: 833 - time: 0.0031 - loss_train: 0.966004716178749 - loss_val: 1.0452512840084056\n",
      "Epoch: 834 - time: 0.0031 - loss_train: 0.9658494653263828 - loss_val: 1.0451480632602423\n",
      "Epoch: 835 - time: 0.0031 - loss_train: 0.9656944496735316 - loss_val: 1.0450450692357174\n",
      "Epoch: 836 - time: 0.0031 - loss_train: 0.9655396684577686 - loss_val: 1.0449423006274565\n",
      "Epoch: 837 - time: 0.0032 - loss_train: 0.9653851209208085 - loss_val: 1.0448397561348797\n",
      "Epoch: 838 - time: 0.0031 - loss_train: 0.965230806308479 - loss_val: 1.044737434464164\n",
      "Epoch: 839 - time: 0.0032 - loss_train: 0.965076723870694 - loss_val: 1.0446353343282158\n",
      "Epoch: 840 - time: 0.0032 - loss_train: 0.9649228728614259 - loss_val: 1.0445334544466294\n",
      "Epoch: 841 - time: 0.0031 - loss_train: 0.9647692525386785 - loss_val: 1.0444317935456604\n",
      "Epoch: 842 - time: 0.0031 - loss_train: 0.9646158621644638 - loss_val: 1.044330350358189\n",
      "Epoch: 843 - time: 0.0032 - loss_train: 0.9644627010047688 - loss_val: 1.0442291236236938\n",
      "Epoch: 844 - time: 0.0031 - loss_train: 0.9643097683295367 - loss_val: 1.044128112088214\n",
      "Epoch: 845 - time: 0.0032 - loss_train: 0.9641570634126352 - loss_val: 1.0440273145043204\n",
      "Epoch: 846 - time: 0.0032 - loss_train: 0.9640045855318342 - loss_val: 1.0439267296310841\n",
      "Epoch: 847 - time: 0.0041 - loss_train: 0.9638523339687782 - loss_val: 1.0438263562340517\n",
      "Epoch: 848 - time: 0.0033 - loss_train: 0.9637003080089628 - loss_val: 1.0437261930852018\n",
      "Epoch: 849 - time: 0.0031 - loss_train: 0.9635485069417077 - loss_val: 1.0436262389629287\n",
      "Epoch: 850 - time: 0.0031 - loss_train: 0.9633969300601319 - loss_val: 1.0435264926520058\n",
      "Epoch: 851 - time: 0.0032 - loss_train: 0.9632455766611306 - loss_val: 1.043426952943557\n",
      "Epoch: 852 - time: 0.0031 - loss_train: 0.9630944460453482 - loss_val: 1.0433276186350315\n",
      "Epoch: 853 - time: 0.0031 - loss_train: 0.9629435375171568 - loss_val: 1.0432284885301693\n",
      "Epoch: 854 - time: 0.0032 - loss_train: 0.9627928503846286 - loss_val: 1.0431295614389775\n",
      "Epoch: 855 - time: 0.0031 - loss_train: 0.9626423839595147 - loss_val: 1.0430308361777016\n",
      "Epoch: 856 - time: 0.0032 - loss_train: 0.9624921375572202 - loss_val: 1.0429323115687983\n",
      "Epoch: 857 - time: 0.0031 - loss_train: 0.9623421104967792 - loss_val: 1.0428339864409042\n",
      "Epoch: 858 - time: 0.0031 - loss_train: 0.9621923021008342 - loss_val: 1.0427358596288145\n",
      "Epoch: 859 - time: 0.0032 - loss_train: 0.9620427116956093 - loss_val: 1.0426379299734536\n",
      "Epoch: 860 - time: 0.0031 - loss_train: 0.9618933386108915 - loss_val: 1.0425401963218468\n",
      "Epoch: 861 - time: 0.0031 - loss_train: 0.9617441821800023 - loss_val: 1.0424426575270964\n",
      "Epoch: 862 - time: 0.0031 - loss_train: 0.9615952417397798 - loss_val: 1.0423453124483593\n",
      "Epoch: 863 - time: 0.0031 - loss_train: 0.9614465166305523 - loss_val: 1.0422481599508129\n",
      "Epoch: 864 - time: 0.0031 - loss_train: 0.9612980061961186 - loss_val: 1.0421511989056367\n",
      "Epoch: 865 - time: 0.0031 - loss_train: 0.9611497097837249 - loss_val: 1.0420544281899844\n",
      "Epoch: 866 - time: 0.0031 - loss_train: 0.961001626744041 - loss_val: 1.0419578466869603\n",
      "Epoch: 867 - time: 0.0031 - loss_train: 0.9608537564311411 - loss_val: 1.0418614532855943\n",
      "Epoch: 868 - time: 0.0032 - loss_train: 0.9607060982024793 - loss_val: 1.0417652468808156\n",
      "Epoch: 869 - time: 0.0031 - loss_train: 0.9605586514188695 - loss_val: 1.0416692263734326\n",
      "Epoch: 870 - time: 0.0032 - loss_train: 0.9604114154444635 - loss_val: 1.0415733906701052\n",
      "Epoch: 871 - time: 0.0032 - loss_train: 0.96026438964673 - loss_val: 1.0414777386833247\n",
      "Epoch: 872 - time: 0.0031 - loss_train: 0.9601175733964324 - loss_val: 1.0413822693313868\n",
      "Epoch: 873 - time: 0.0032 - loss_train: 0.9599709660676087 - loss_val: 1.0412869815383712\n",
      "Epoch: 874 - time: 0.0031 - loss_train: 0.9598245670375494 - loss_val: 1.0411918742341177\n",
      "Epoch: 875 - time: 0.0031 - loss_train: 0.9596783756867789 - loss_val: 1.0410969463542024\n",
      "Epoch: 876 - time: 0.0031 - loss_train: 0.9595323913990317 - loss_val: 1.0410021968399166\n",
      "Epoch: 877 - time: 0.0032 - loss_train: 0.9593866135612352 - loss_val: 1.0409076246382452\n",
      "Epoch: 878 - time: 0.0031 - loss_train: 0.9592410415634862 - loss_val: 1.040813228701842\n",
      "Epoch: 879 - time: 0.0031 - loss_train: 0.9590956747990338 - loss_val: 1.040719007989011\n",
      "Epoch: 880 - time: 0.0031 - loss_train: 0.9589505126642559 - loss_val: 1.0406249614636807\n",
      "Epoch: 881 - time: 0.0031 - loss_train: 0.9588055545586426 - loss_val: 1.040531088095386\n",
      "Epoch: 882 - time: 0.0031 - loss_train: 0.9586607998847742 - loss_val: 1.0404373868592451\n",
      "Epoch: 883 - time: 0.0031 - loss_train: 0.9585162480483024 - loss_val: 1.0403438567359409\n",
      "Epoch: 884 - time: 0.0031 - loss_train: 0.9583718984579296 - loss_val: 1.0402504967116943\n",
      "Epoch: 885 - time: 0.0038 - loss_train: 0.9582277505253912 - loss_val: 1.0401573057782496\n",
      "Epoch: 886 - time: 0.0032 - loss_train: 0.958083803665435 - loss_val: 1.0400642829328506\n",
      "Epoch: 887 - time: 0.0032 - loss_train: 0.9579400572958023 - loss_val: 1.0399714271782203\n",
      "Epoch: 888 - time: 0.0032 - loss_train: 0.9577965108372098 - loss_val: 1.0398787375225425\n",
      "Epoch: 889 - time: 0.0031 - loss_train: 0.9576531637133286 - loss_val: 1.0397862129794375\n",
      "Epoch: 890 - time: 0.0031 - loss_train: 0.9575100153507671 - loss_val: 1.039693852567947\n",
      "Epoch: 891 - time: 0.0031 - loss_train: 0.957367065179052 - loss_val: 1.0396016553125111\n",
      "Epoch: 892 - time: 0.0031 - loss_train: 0.9572243126306094 - loss_val: 1.0395096202429486\n",
      "Epoch: 893 - time: 0.0031 - loss_train: 0.957081757140746 - loss_val: 1.0394177463944403\n",
      "Epoch: 894 - time: 0.0032 - loss_train: 0.9569393981476322 - loss_val: 1.0393260328075047\n",
      "Epoch: 895 - time: 0.0031 - loss_train: 0.9567972350922825 - loss_val: 1.0392344785279843\n",
      "Epoch: 896 - time: 0.0031 - loss_train: 0.9566552674185367 - loss_val: 1.0391430826070205\n",
      "Epoch: 897 - time: 0.0031 - loss_train: 0.9565134945730446 - loss_val: 1.0390518441010406\n",
      "Epoch: 898 - time: 0.0031 - loss_train: 0.9563719160052448 - loss_val: 1.0389607620717347\n",
      "Epoch: 899 - time: 0.0031 - loss_train: 0.9562305311673508 - loss_val: 1.0388698355860364\n",
      "Epoch: 900 - time: 0.0031 - loss_train: 0.9560893395143287 - loss_val: 1.0387790637161087\n",
      "Epoch: 901 - time: 0.0031 - loss_train: 0.9559483405038844 - loss_val: 1.0386884455393204\n",
      "Epoch: 902 - time: 0.0031 - loss_train: 0.9558075335964419 - loss_val: 1.0385979801382315\n",
      "Epoch: 903 - time: 0.0031 - loss_train: 0.9556669182551293 - loss_val: 1.0385076666005701\n",
      "Epoch: 904 - time: 0.0031 - loss_train: 0.955526493945759 - loss_val: 1.0384175040192223\n",
      "Epoch: 905 - time: 0.0031 - loss_train: 0.9553862601368123 - loss_val: 1.0383274914922054\n",
      "Epoch: 906 - time: 0.0031 - loss_train: 0.9552462162994223 - loss_val: 1.038237628122652\n",
      "Epoch: 907 - time: 0.0031 - loss_train: 0.9551063619073554 - loss_val: 1.0381479130187978\n",
      "Epoch: 908 - time: 0.0031 - loss_train: 0.9549666964369967 - loss_val: 1.0380583452939574\n",
      "Epoch: 909 - time: 0.0031 - loss_train: 0.9548272193673313 - loss_val: 1.0379689240665082\n",
      "Epoch: 910 - time: 0.0031 - loss_train: 0.9546879301799285 - loss_val: 1.0378796484598745\n",
      "Epoch: 911 - time: 0.0031 - loss_train: 0.9545488283589256 - loss_val: 1.037790517602508\n",
      "Epoch: 912 - time: 0.0031 - loss_train: 0.9544099133910111 - loss_val: 1.0377015306278723\n",
      "Epoch: 913 - time: 0.0031 - loss_train: 0.9542711847654083 - loss_val: 1.0376126866744224\n",
      "Epoch: 914 - time: 0.0031 - loss_train: 0.9541326419738593 - loss_val: 1.0375239848855902\n",
      "Epoch: 915 - time: 0.0031 - loss_train: 0.9539942845106085 - loss_val: 1.037435424409767\n",
      "Epoch: 916 - time: 0.0031 - loss_train: 0.9538561118723876 - loss_val: 1.0373470044002853\n",
      "Epoch: 917 - time: 0.0032 - loss_train: 0.9537181235583979 - loss_val: 1.037258724015402\n",
      "Epoch: 918 - time: 0.0031 - loss_train: 0.9535803190702958 - loss_val: 1.037170582418282\n",
      "Epoch: 919 - time: 0.0031 - loss_train: 0.9534426979121766 - loss_val: 1.0370825787769813\n",
      "Epoch: 920 - time: 0.0031 - loss_train: 0.9533052595905589 - loss_val: 1.0369947122644299\n",
      "Epoch: 921 - time: 0.0031 - loss_train: 0.9531680036143697 - loss_val: 1.0369069820584114\n",
      "Epoch: 922 - time: 0.0031 - loss_train: 0.9530309294949268 - loss_val: 1.0368193873415554\n",
      "Epoch: 923 - time: 0.0038 - loss_train: 0.9528940367459257 - loss_val: 1.036731927301313\n",
      "Epoch: 924 - time: 0.0032 - loss_train: 0.9527573248834236 - loss_val: 1.0366446011299404\n",
      "Epoch: 925 - time: 0.0031 - loss_train: 0.9526207934258234 - loss_val: 1.0365574080244866\n",
      "Epoch: 926 - time: 0.0031 - loss_train: 0.9524844418938598 - loss_val: 1.0364703471867756\n",
      "Epoch: 927 - time: 0.0031 - loss_train: 0.9523482698105832 - loss_val: 1.0363834178233857\n",
      "Epoch: 928 - time: 0.0032 - loss_train: 0.9522122767013448 - loss_val: 1.0362966191456402\n",
      "Epoch: 929 - time: 0.0031 - loss_train: 0.9520764620937826 - loss_val: 1.0362099503695867\n",
      "Epoch: 930 - time: 0.0032 - loss_train: 0.9519408255178062 - loss_val: 1.036123410715978\n",
      "Epoch: 931 - time: 0.0031 - loss_train: 0.9518053665055817 - loss_val: 1.0360369994102643\n",
      "Epoch: 932 - time: 0.0032 - loss_train: 0.9516700845915171 - loss_val: 1.0359507156825702\n",
      "Epoch: 933 - time: 0.0031 - loss_train: 0.9515349793122487 - loss_val: 1.035864558767681\n",
      "Epoch: 934 - time: 0.0031 - loss_train: 0.9514000502066257 - loss_val: 1.0357785279050256\n",
      "Epoch: 935 - time: 0.0031 - loss_train: 0.9512652968156956 - loss_val: 1.0356926223386602\n",
      "Epoch: 936 - time: 0.0031 - loss_train: 0.9511307186826912 - loss_val: 1.0356068413172566\n",
      "Epoch: 937 - time: 0.0031 - loss_train: 0.9509963153530145 - loss_val: 1.0355211840940792\n",
      "Epoch: 938 - time: 0.0031 - loss_train: 0.9508620863742255 - loss_val: 1.0354356499269743\n",
      "Epoch: 939 - time: 0.0031 - loss_train: 0.9507280312960237 - loss_val: 1.035350238078353\n",
      "Epoch: 940 - time: 0.0031 - loss_train: 0.9505941496702389 - loss_val: 1.0352649478151739\n",
      "Epoch: 941 - time: 0.0031 - loss_train: 0.9504604410508144 - loss_val: 1.0351797784089298\n",
      "Epoch: 942 - time: 0.0031 - loss_train: 0.9503269049937937 - loss_val: 1.0350947291356296\n",
      "Epoch: 943 - time: 0.0031 - loss_train: 0.9501935410573075 - loss_val: 1.0350097992757834\n",
      "Epoch: 944 - time: 0.0031 - loss_train: 0.9500603488015588 - loss_val: 1.034924988114387\n",
      "Epoch: 945 - time: 0.0032 - loss_train: 0.9499273277888108 - loss_val: 1.0348402949409057\n",
      "Epoch: 946 - time: 0.0031 - loss_train: 0.9497944775833723 - loss_val: 1.0347557190492611\n",
      "Epoch: 947 - time: 0.0032 - loss_train: 0.9496617977515841 - loss_val: 1.03467125973781\n",
      "Epoch: 948 - time: 0.0032 - loss_train: 0.949529287861807 - loss_val: 1.0345869163093353\n",
      "Epoch: 949 - time: 0.0031 - loss_train: 0.9493969474844076 - loss_val: 1.0345026880710253\n",
      "Epoch: 950 - time: 0.0032 - loss_train: 0.9492647761917438 - loss_val: 1.0344185743344603\n",
      "Epoch: 951 - time: 0.0031 - loss_train: 0.9491327735581542 - loss_val: 1.034334574415598\n",
      "Epoch: 952 - time: 0.0031 - loss_train: 0.9490009391599442 - loss_val: 1.0342506876347575\n",
      "Epoch: 953 - time: 0.0031 - loss_train: 0.9488692725753721 - loss_val: 1.0341669133166007\n",
      "Epoch: 954 - time: 0.0031 - loss_train: 0.9487377733846363 - loss_val: 1.0340832507901216\n",
      "Epoch: 955 - time: 0.0031 - loss_train: 0.9486064411698633 - loss_val: 1.0339996993886276\n",
      "Epoch: 956 - time: 0.0032 - loss_train: 0.9484752755150948 - loss_val: 1.033916258449725\n",
      "Epoch: 957 - time: 0.0031 - loss_train: 0.9483442760062748 - loss_val: 1.0338329273153044\n",
      "Epoch: 958 - time: 0.0031 - loss_train: 0.9482134422312358 - loss_val: 1.033749705331525\n",
      "Epoch: 959 - time: 0.0031 - loss_train: 0.9480827737796885 - loss_val: 1.0336665918487984\n",
      "Epoch: 960 - time: 0.0032 - loss_train: 0.9479522702432077 - loss_val: 1.0335835862217726\n",
      "Epoch: 961 - time: 0.0038 - loss_train: 0.9478219312152205 - loss_val: 1.0335006878093191\n",
      "Epoch: 962 - time: 0.0033 - loss_train: 0.9476917562909934 - loss_val: 1.0334178959745164\n",
      "Epoch: 963 - time: 0.0031 - loss_train: 0.9475617450676208 - loss_val: 1.0333352100846338\n",
      "Epoch: 964 - time: 0.0032 - loss_train: 0.9474318971440122 - loss_val: 1.0332526295111177\n",
      "Epoch: 965 - time: 0.0031 - loss_train: 0.9473022121208803 - loss_val: 1.0331701536295737\n",
      "Epoch: 966 - time: 0.0031 - loss_train: 0.947172689600729 - loss_val: 1.0330877818197561\n",
      "Epoch: 967 - time: 0.0032 - loss_train: 0.9470433291878401 - loss_val: 1.033005513465548\n",
      "Epoch: 968 - time: 0.0031 - loss_train: 0.9469141304882643 - loss_val: 1.0329233479549467\n",
      "Epoch: 969 - time: 0.0031 - loss_train: 0.9467850931098067 - loss_val: 1.0328412846800512\n",
      "Epoch: 970 - time: 0.0031 - loss_train: 0.946656216662016 - loss_val: 1.0327593230370464\n",
      "Epoch: 971 - time: 0.0032 - loss_train: 0.9465275007561722 - loss_val: 1.0326774624261843\n",
      "Epoch: 972 - time: 0.0031 - loss_train: 0.9463989450052751 - loss_val: 1.0325957022517727\n",
      "Epoch: 973 - time: 0.0031 - loss_train: 0.9462705490240338 - loss_val: 1.0325140419221575\n",
      "Epoch: 974 - time: 0.0031 - loss_train: 0.9461423124288535 - loss_val: 1.0324324808497112\n",
      "Epoch: 975 - time: 0.0031 - loss_train: 0.946014234837825 - loss_val: 1.0323510184508138\n",
      "Epoch: 976 - time: 0.0031 - loss_train: 0.945886315870714 - loss_val: 1.032269654145839\n",
      "Epoch: 977 - time: 0.0031 - loss_train: 0.9457585551489467 - loss_val: 1.0321883873591389\n",
      "Epoch: 978 - time: 0.0031 - loss_train: 0.9456309522956028 - loss_val: 1.0321072175190316\n",
      "Epoch: 979 - time: 0.0031 - loss_train: 0.945503506935401 - loss_val: 1.0320261440577805\n",
      "Epoch: 980 - time: 0.0031 - loss_train: 0.9453762186946885 - loss_val: 1.0319451664115848\n",
      "Epoch: 981 - time: 0.0031 - loss_train: 0.9452490872014314 - loss_val: 1.0318642840205605\n",
      "Epoch: 982 - time: 0.0031 - loss_train: 0.9451221120852024 - loss_val: 1.0317834963287278\n",
      "Epoch: 983 - time: 0.0031 - loss_train: 0.9449952929771696 - loss_val: 1.031702802783996\n",
      "Epoch: 984 - time: 0.0031 - loss_train: 0.9448686295100865 - loss_val: 1.031622202838145\n",
      "Epoch: 985 - time: 0.0031 - loss_train: 0.94474212131828 - loss_val: 1.0315416959468147\n",
      "Epoch: 986 - time: 0.0031 - loss_train: 0.9446157680376414 - loss_val: 1.0314612815694881\n",
      "Epoch: 987 - time: 0.0031 - loss_train: 0.9444895693056133 - loss_val: 1.031380959169476\n",
      "Epoch: 988 - time: 0.0031 - loss_train: 0.9443635247611817 - loss_val: 1.0313007282139006\n",
      "Epoch: 989 - time: 0.0031 - loss_train: 0.9442376340448626 - loss_val: 1.0312205881736851\n",
      "Epoch: 990 - time: 0.0031 - loss_train: 0.9441118967986936 - loss_val: 1.0311405385235344\n",
      "Epoch: 991 - time: 0.0031 - loss_train: 0.9439863126662225 - loss_val: 1.03106057874192\n",
      "Epoch: 992 - time: 0.0031 - loss_train: 0.9438608812924968 - loss_val: 1.0309807083110685\n",
      "Epoch: 993 - time: 0.0031 - loss_train: 0.9437356023240537 - loss_val: 1.030900926716944\n",
      "Epoch: 994 - time: 0.0032 - loss_train: 0.9436104754089094 - loss_val: 1.0308212334492328\n",
      "Epoch: 995 - time: 0.0031 - loss_train: 0.9434855001965502 - loss_val: 1.0307416280013317\n",
      "Epoch: 996 - time: 0.0031 - loss_train: 0.9433606763379193 - loss_val: 1.0306621098703281\n",
      "Epoch: 997 - time: 0.0032 - loss_train: 0.9432360034854105 - loss_val: 1.0305826785569894\n",
      "Epoch: 998 - time: 0.0031 - loss_train: 0.9431114812928555 - loss_val: 1.0305033335657474\n",
      "Epoch: 999 - time: 0.0038 - loss_train: 0.9429871094155149 - loss_val: 1.0304240744046793\n",
      "Epoch: 1000 - time: 0.0032 - loss_train: 0.9428628875100672 - loss_val: 1.030344900585499\n",
      "Epoch: 1001 - time: 0.0031 - loss_train: 0.9427388152346008 - loss_val: 1.030265811623538\n",
      "Epoch: 1002 - time: 0.0031 - loss_train: 0.942614892248603 - loss_val: 1.0301868070377314\n",
      "Epoch: 1003 - time: 0.0031 - loss_train: 0.94249111821295 - loss_val: 1.0301078863506035\n",
      "Epoch: 1004 - time: 0.0031 - loss_train: 0.9423674927898978 - loss_val: 1.0300290490882544\n",
      "Epoch: 1005 - time: 0.0032 - loss_train: 0.9422440156430725 - loss_val: 1.0299502947803407\n",
      "Epoch: 1006 - time: 0.0031 - loss_train: 0.9421206864374594 - loss_val: 1.0298716229600673\n",
      "Epoch: 1007 - time: 0.0031 - loss_train: 0.9419975048393967 - loss_val: 1.0297930331641647\n",
      "Epoch: 1008 - time: 0.0032 - loss_train: 0.9418744705165623 - loss_val: 1.0297145249328832\n",
      "Epoch: 1009 - time: 0.0032 - loss_train: 0.9417515831379665 - loss_val: 1.0296360978099695\n",
      "Epoch: 1010 - time: 0.0031 - loss_train: 0.9416288423739421 - loss_val: 1.0295577513426566\n",
      "Epoch: 1011 - time: 0.0031 - loss_train: 0.9415062478961347 - loss_val: 1.0294794850816493\n",
      "Epoch: 1012 - time: 0.0032 - loss_train: 0.9413837993774956 - loss_val: 1.029401298581109\n",
      "Epoch: 1013 - time: 0.0031 - loss_train: 0.9412614964922688 - loss_val: 1.0293231913986363\n",
      "Epoch: 1014 - time: 0.0031 - loss_train: 0.9411393389159844 - loss_val: 1.0292451630952602\n",
      "Epoch: 1015 - time: 0.0031 - loss_train: 0.9410173263254505 - loss_val: 1.0291672132354206\n",
      "Epoch: 1016 - time: 0.0031 - loss_train: 0.9408954583987418 - loss_val: 1.0290893413869557\n",
      "Epoch: 1017 - time: 0.0032 - loss_train: 0.940773734815191 - loss_val: 1.0290115471210852\n",
      "Epoch: 1018 - time: 0.0032 - loss_train: 0.9406521552553818 - loss_val: 1.028933830012398\n",
      "Epoch: 1019 - time: 0.0032 - loss_train: 0.9405307194011373 - loss_val: 1.028856189638835\n",
      "Epoch: 1020 - time: 0.0031 - loss_train: 0.9404094269355141 - loss_val: 1.0287786255816782\n",
      "Epoch: 1021 - time: 0.0032 - loss_train: 0.9402882775427915 - loss_val: 1.0287011374255322\n",
      "Epoch: 1022 - time: 0.0032 - loss_train: 0.9401672709084624 - loss_val: 1.0286237247583103\n",
      "Epoch: 1023 - time: 0.0031 - loss_train: 0.9400464067192275 - loss_val: 1.0285463871712244\n",
      "Epoch: 1024 - time: 0.0032 - loss_train: 0.9399256846629837 - loss_val: 1.0284691242587634\n",
      "Epoch: 1025 - time: 0.0032 - loss_train: 0.9398051044288166 - loss_val: 1.028391935618684\n",
      "Epoch: 1026 - time: 0.0031 - loss_train: 0.9396846657069929 - loss_val: 1.0283148208519952\n",
      "Epoch: 1027 - time: 0.0032 - loss_train: 0.939564368188951 - loss_val: 1.0282377795629414\n",
      "Epoch: 1028 - time: 0.0032 - loss_train: 0.9394442115672927 - loss_val: 1.0281608113589924\n",
      "Epoch: 1029 - time: 0.0032 - loss_train: 0.9393241955357751 - loss_val: 1.0280839158508244\n",
      "Epoch: 1030 - time: 0.0032 - loss_train: 0.9392043197893025 - loss_val: 1.0280070926523077\n",
      "Epoch: 1031 - time: 0.0032 - loss_train: 0.9390845840239183 - loss_val: 1.0279303413804928\n",
      "Epoch: 1032 - time: 0.0032 - loss_train: 0.938964987936796 - loss_val: 1.0278536616555958\n",
      "Epoch: 1033 - time: 0.0032 - loss_train: 0.9388455312262317 - loss_val: 1.0277770531009838\n",
      "Epoch: 1034 - time: 0.0032 - loss_train: 0.9387262135916369 - loss_val: 1.0277005153431586\n",
      "Epoch: 1035 - time: 0.0032 - loss_train: 0.9386070347335282 - loss_val: 1.0276240480117484\n",
      "Epoch: 1036 - time: 0.0031 - loss_train: 0.9384879943535229 - loss_val: 1.0275476507394856\n",
      "Epoch: 1037 - time: 0.0038 - loss_train: 0.9383690921543264 - loss_val: 1.0274713231621984\n",
      "Epoch: 1038 - time: 0.0033 - loss_train: 0.938250327839729 - loss_val: 1.0273950649187946\n",
      "Epoch: 1039 - time: 0.0032 - loss_train: 0.9381317011145954 - loss_val: 1.027318875651248\n",
      "Epoch: 1040 - time: 0.0032 - loss_train: 0.9380132116848576 - loss_val: 1.0272427550045826\n",
      "Epoch: 1041 - time: 0.0036 - loss_train: 0.937894859257508 - loss_val: 1.0271667026268614\n",
      "Epoch: 1042 - time: 0.0035 - loss_train: 0.9377766435405903 - loss_val: 1.02709071816917\n",
      "Epoch: 1043 - time: 0.0032 - loss_train: 0.9376585642431926 - loss_val: 1.0270148012856029\n",
      "Epoch: 1044 - time: 0.0031 - loss_train: 0.9375406210754411 - loss_val: 1.026938951633249\n",
      "Epoch: 1045 - time: 0.0032 - loss_train: 0.9374228137484907 - loss_val: 1.0268631688721812\n",
      "Epoch: 1046 - time: 0.0032 - loss_train: 0.9373051419745182 - loss_val: 1.0267874526654364\n",
      "Epoch: 1047 - time: 0.0031 - loss_train: 0.9371876054667159 - loss_val: 1.0267118026790067\n",
      "Epoch: 1048 - time: 0.0031 - loss_train: 0.9370702039392836 - loss_val: 1.0266362185818239\n",
      "Epoch: 1049 - time: 0.0032 - loss_train: 0.9369529371074207 - loss_val: 1.0265607000457435\n",
      "Epoch: 1050 - time: 0.0031 - loss_train: 0.9368358046873194 - loss_val: 1.0264852467455339\n",
      "Epoch: 1051 - time: 0.0032 - loss_train: 0.9367188063961589 - loss_val: 1.0264098583588617\n",
      "Epoch: 1052 - time: 0.0032 - loss_train: 0.9366019419520962 - loss_val: 1.0263345345662762\n",
      "Epoch: 1053 - time: 0.0032 - loss_train: 0.93648521107426 - loss_val: 1.0262592750511983\n",
      "Epoch: 1054 - time: 0.0032 - loss_train: 0.9363686134827442 - loss_val: 1.0261840794999062\n",
      "Epoch: 1055 - time: 0.0032 - loss_train: 0.9362521488986003 - loss_val: 1.026108947601518\n",
      "Epoch: 1056 - time: 0.0031 - loss_train: 0.93613581704383 - loss_val: 1.026033879047984\n",
      "Epoch: 1057 - time: 0.0031 - loss_train: 0.9360196176413795 - loss_val: 1.0259588735340694\n",
      "Epoch: 1058 - time: 0.0031 - loss_train: 0.935903550415133 - loss_val: 1.0258839307573413\n",
      "Epoch: 1059 - time: 0.0035 - loss_train: 0.9357876150899037 - loss_val: 1.0258090504181547\n",
      "Epoch: 1060 - time: 0.0033 - loss_train: 0.935671811391429 - loss_val: 1.025734232219641\n",
      "Epoch: 1061 - time: 0.0032 - loss_train: 0.9355561390463637 - loss_val: 1.025659475867693\n",
      "Epoch: 1062 - time: 0.0032 - loss_train: 0.9354405977822733 - loss_val: 1.0255847810709504\n",
      "Epoch: 1063 - time: 0.0032 - loss_train: 0.9353251873276263 - loss_val: 1.0255101475407873\n",
      "Epoch: 1064 - time: 0.0031 - loss_train: 0.9352099074117893 - loss_val: 1.0254355749913022\n",
      "Epoch: 1065 - time: 0.0032 - loss_train: 0.9350947577650208 - loss_val: 1.025361063139299\n",
      "Epoch: 1066 - time: 0.0032 - loss_train: 0.9349797381184617 - loss_val: 1.0252866117042778\n",
      "Epoch: 1067 - time: 0.0031 - loss_train: 0.9348648482041328 - loss_val: 1.0252122204084193\n",
      "Epoch: 1068 - time: 0.0032 - loss_train: 0.9347500877549271 - loss_val: 1.0251378889765728\n",
      "Epoch: 1069 - time: 0.0031 - loss_train: 0.934635456504602 - loss_val: 1.025063617136243\n",
      "Epoch: 1070 - time: 0.0032 - loss_train: 0.9345209541877753 - loss_val: 1.0249894046175771\n",
      "Epoch: 1071 - time: 0.0032 - loss_train: 0.9344065805399179 - loss_val: 1.0249152511533508\n",
      "Epoch: 1072 - time: 0.0032 - loss_train: 0.9342923352973487 - loss_val: 1.0248411564789544\n",
      "Epoch: 1073 - time: 0.0032 - loss_train: 0.9341782181972265 - loss_val: 1.0247671203323834\n",
      "Epoch: 1074 - time: 0.0032 - loss_train: 0.9340642289775464 - loss_val: 1.0246931424542225\n",
      "Epoch: 1075 - time: 0.0033 - loss_train: 0.9339503673771317 - loss_val: 1.0246192225876327\n",
      "Epoch: 1076 - time: 0.0032 - loss_train: 0.9338366331356305 - loss_val: 1.02454536047834\n",
      "Epoch: 1077 - time: 0.0031 - loss_train: 0.933723025993507 - loss_val: 1.0244715558746216\n",
      "Epoch: 1078 - time: 0.0031 - loss_train: 0.9336095456920381 - loss_val: 1.0243978085272933\n",
      "Epoch: 1079 - time: 0.0031 - loss_train: 0.9334961919733066 - loss_val: 1.0243241181896965\n",
      "Epoch: 1080 - time: 0.0031 - loss_train: 0.9333829645801948 - loss_val: 1.0242504846176848\n",
      "Epoch: 1081 - time: 0.0031 - loss_train: 0.9332698632563796 - loss_val: 1.0241769075696139\n",
      "Epoch: 1082 - time: 0.0031 - loss_train: 0.9331568877463281 - loss_val: 1.024103386806326\n",
      "Epoch: 1083 - time: 0.0031 - loss_train: 0.9330440377952895 - loss_val: 1.0240299220911402\n",
      "Epoch: 1084 - time: 0.0031 - loss_train: 0.9329313131492911 - loss_val: 1.0239565131898354\n",
      "Epoch: 1085 - time: 0.0031 - loss_train: 0.9328187135551339 - loss_val: 1.0238831598706435\n",
      "Epoch: 1086 - time: 0.0031 - loss_train: 0.9327062387603835 - loss_val: 1.0238098619042333\n",
      "Epoch: 1087 - time: 0.0031 - loss_train: 0.9325938885133698 - loss_val: 1.023736619063698\n",
      "Epoch: 1088 - time: 0.0031 - loss_train: 0.9324816625631772 - loss_val: 1.023663431124545\n",
      "Epoch: 1089 - time: 0.0031 - loss_train: 0.9323695606596416 - loss_val: 1.0235902978646818\n",
      "Epoch: 1090 - time: 0.0031 - loss_train: 0.9322575825533447 - loss_val: 1.023517219064404\n",
      "Epoch: 1091 - time: 0.0031 - loss_train: 0.9321457279956094 - loss_val: 1.023444194506385\n",
      "Epoch: 1092 - time: 0.0031 - loss_train: 0.932033996738493 - loss_val: 1.0233712239756598\n",
      "Epoch: 1093 - time: 0.0031 - loss_train: 0.9319223885347847 - loss_val: 1.023298307259618\n",
      "Epoch: 1094 - time: 0.0031 - loss_train: 0.9318109031379971 - loss_val: 1.0232254441479878\n",
      "Epoch: 1095 - time: 0.0031 - loss_train: 0.9316995403023655 - loss_val: 1.0231526344328241\n",
      "Epoch: 1096 - time: 0.0031 - loss_train: 0.9315882997828391 - loss_val: 1.023079877908499\n",
      "Epoch: 1097 - time: 0.0031 - loss_train: 0.9314771813350773 - loss_val: 1.0230071743716902\n",
      "Epoch: 1098 - time: 0.0031 - loss_train: 0.9313661847154473 - loss_val: 1.0229345236213627\n",
      "Epoch: 1099 - time: 0.0032 - loss_train: 0.9312553096810147 - loss_val: 1.022861925458767\n",
      "Epoch: 1100 - time: 0.0031 - loss_train: 0.931144555989543 - loss_val: 1.0227893796874181\n",
      "Epoch: 1101 - time: 0.0031 - loss_train: 0.9310339233994869 - loss_val: 1.02271688611309\n",
      "Epoch: 1102 - time: 0.0031 - loss_train: 0.9309234116699867 - loss_val: 1.0226444445437999\n",
      "Epoch: 1103 - time: 0.0031 - loss_train: 0.9308130205608666 - loss_val: 1.0225720547897998\n",
      "Epoch: 1104 - time: 0.0031 - loss_train: 0.9307027498326266 - loss_val: 1.0224997166635634\n",
      "Epoch: 1105 - time: 0.0031 - loss_train: 0.9305925992464422 - loss_val: 1.0224274299797733\n",
      "Epoch: 1106 - time: 0.0031 - loss_train: 0.9304825685641542 - loss_val: 1.0223551945553124\n",
      "Epoch: 1107 - time: 0.0031 - loss_train: 0.930372657548271 - loss_val: 1.022283010209249\n",
      "Epoch: 1108 - time: 0.0031 - loss_train: 0.9302628659619584 - loss_val: 1.0222108767628295\n",
      "Epoch: 1109 - time: 0.0031 - loss_train: 0.9301531935690391 - loss_val: 1.0221387940394617\n",
      "Epoch: 1110 - time: 0.0031 - loss_train: 0.9300436401339858 - loss_val: 1.022066761864711\n",
      "Epoch: 1111 - time: 0.0031 - loss_train: 0.9299342054219191 - loss_val: 1.0219947800662808\n",
      "Epoch: 1112 - time: 0.0035 - loss_train: 0.9298248891986018 - loss_val: 1.0219228484740062\n",
      "Epoch: 1113 - time: 0.0032 - loss_train: 0.9297156912304354 - loss_val: 1.0218509669198426\n",
      "Epoch: 1114 - time: 0.0031 - loss_train: 0.929606611284456 - loss_val: 1.0217791352378545\n",
      "Epoch: 1115 - time: 0.0031 - loss_train: 0.9294976491283296 - loss_val: 1.0217073532642016\n",
      "Epoch: 1116 - time: 0.0031 - loss_train: 0.9293888045303496 - loss_val: 1.0216356208371322\n",
      "Epoch: 1117 - time: 0.0031 - loss_train: 0.9292800772594308 - loss_val: 1.0215639377969683\n",
      "Epoch: 1118 - time: 0.0031 - loss_train: 0.9291714670851072 - loss_val: 1.0214923039860986\n",
      "Epoch: 1119 - time: 0.0031 - loss_train: 0.9290629737775267 - loss_val: 1.021420719248963\n",
      "Epoch: 1120 - time: 0.0031 - loss_train: 0.9289545971074483 - loss_val: 1.0213491834320458\n",
      "Epoch: 1121 - time: 0.0031 - loss_train: 0.9288463368462384 - loss_val: 1.0212776963838635\n",
      "Epoch: 1122 - time: 0.0032 - loss_train: 0.928738192765866 - loss_val: 1.0212062579549526\n",
      "Epoch: 1123 - time: 0.0031 - loss_train: 0.9286301646389002 - loss_val: 1.0211348679978627\n",
      "Epoch: 1124 - time: 0.0031 - loss_train: 0.9285222522385053 - loss_val: 1.0210635263671404\n",
      "Epoch: 1125 - time: 0.0031 - loss_train: 0.9284144553384376 - loss_val: 1.0209922329193244\n",
      "Epoch: 1126 - time: 0.0031 - loss_train: 0.9283067737130439 - loss_val: 1.0209209875129333\n",
      "Epoch: 1127 - time: 0.0031 - loss_train: 0.9281992071372535 - loss_val: 1.0208497900084503\n",
      "Epoch: 1128 - time: 0.0031 - loss_train: 0.9280917553865795 - loss_val: 1.02077864026832\n",
      "Epoch: 1129 - time: 0.0033 - loss_train: 0.9279844182371122 - loss_val: 1.0207075381569344\n",
      "Epoch: 1130 - time: 0.0031 - loss_train: 0.9278771954655168 - loss_val: 1.0206364835406225\n",
      "Epoch: 1131 - time: 0.0031 - loss_train: 0.9277700868490304 - loss_val: 1.0205654762876404\n",
      "Epoch: 1132 - time: 0.0031 - loss_train: 0.9276630921654574 - loss_val: 1.020494516268161\n",
      "Epoch: 1133 - time: 0.0031 - loss_train: 0.9275562111931679 - loss_val: 1.0204236033542655\n",
      "Epoch: 1134 - time: 0.0032 - loss_train: 0.9274494437110928 - loss_val: 1.0203527374199297\n",
      "Epoch: 1135 - time: 0.0033 - loss_train: 0.9273427894987228 - loss_val: 1.0202819183410181\n",
      "Epoch: 1136 - time: 0.0031 - loss_train: 0.9272362483361027 - loss_val: 1.0202111459952703\n",
      "Epoch: 1137 - time: 0.0031 - loss_train: 0.9271298200038299 - loss_val: 1.0201404202622937\n",
      "Epoch: 1138 - time: 0.0031 - loss_train: 0.9270235042830502 - loss_val: 1.0200697410235517\n",
      "Epoch: 1139 - time: 0.0031 - loss_train: 0.9269173009554579 - loss_val: 1.0199991081623543\n",
      "Epoch: 1140 - time: 0.0031 - loss_train: 0.9268112098032875 - loss_val: 1.01992852156385\n",
      "Epoch: 1141 - time: 0.0031 - loss_train: 0.9267052306093158 - loss_val: 1.0198579811150128\n",
      "Epoch: 1142 - time: 0.0031 - loss_train: 0.9265993631568561 - loss_val: 1.0197874867046353\n",
      "Epoch: 1143 - time: 0.0031 - loss_train: 0.9264936072297558 - loss_val: 1.0197170382233165\n",
      "Epoch: 1144 - time: 0.0031 - loss_train: 0.9263879626123958 - loss_val: 1.019646635563456\n",
      "Epoch: 1145 - time: 0.0031 - loss_train: 0.9262824290896835 - loss_val: 1.0195762786192393\n",
      "Epoch: 1146 - time: 0.0031 - loss_train: 0.9261770064470546 - loss_val: 1.0195059672866333\n",
      "Epoch: 1147 - time: 0.0031 - loss_train: 0.9260716944704666 - loss_val: 1.0194357014633721\n",
      "Epoch: 1148 - time: 0.0035 - loss_train: 0.9259664929463993 - loss_val: 1.0193654810489523\n",
      "Epoch: 1149 - time: 0.0036 - loss_train: 0.9258614016618496 - loss_val: 1.0192953059446197\n",
      "Epoch: 1150 - time: 0.0048 - loss_train: 0.9257564204043308 - loss_val: 1.0192251760533604\n",
      "Epoch: 1151 - time: 0.0046 - loss_train: 0.9256515489618697 - loss_val: 1.019155091279895\n",
      "Epoch: 1152 - time: 0.0045 - loss_train: 0.9255467871230025 - loss_val: 1.0190850515306642\n",
      "Epoch: 1153 - time: 0.0045 - loss_train: 0.9254421346767752 - loss_val: 1.0190150567138245\n",
      "Epoch: 1154 - time: 0.0045 - loss_train: 0.9253375914127385 - loss_val: 1.0189451067392366\n",
      "Epoch: 1155 - time: 0.0046 - loss_train: 0.9252331571209466 - loss_val: 1.0188752015184528\n",
      "Epoch: 1156 - time: 0.0045 - loss_train: 0.9251288315919556 - loss_val: 1.0188053409647158\n",
      "Epoch: 1157 - time: 0.0046 - loss_train: 0.9250246146168201 - loss_val: 1.0187355249929424\n",
      "Epoch: 1158 - time: 0.0045 - loss_train: 0.9249205059870905 - loss_val: 1.0186657535197197\n",
      "Epoch: 1159 - time: 0.0046 - loss_train: 0.9248165054948133 - loss_val: 1.018596026463292\n",
      "Epoch: 1160 - time: 0.0047 - loss_train: 0.9247126129325256 - loss_val: 1.0185263437435534\n",
      "Epoch: 1161 - time: 0.0046 - loss_train: 0.9246088280932557 - loss_val: 1.0184567052820417\n",
      "Epoch: 1162 - time: 0.0046 - loss_train: 0.9245051507705188 - loss_val: 1.018387111001925\n",
      "Epoch: 1163 - time: 0.0046 - loss_train: 0.9244015807583166 - loss_val: 1.0183175608279955\n",
      "Epoch: 1164 - time: 0.0046 - loss_train: 0.9242981178511347 - loss_val: 1.018248054686659\n",
      "Epoch: 1165 - time: 0.0046 - loss_train: 0.9241947618439411 - loss_val: 1.0181785925059308\n",
      "Epoch: 1166 - time: 0.0046 - loss_train: 0.9240915125321821 - loss_val: 1.0181091742154196\n",
      "Epoch: 1167 - time: 0.0046 - loss_train: 0.9239883697117841 - loss_val: 1.0180397997463262\n",
      "Epoch: 1168 - time: 0.0046 - loss_train: 0.9238853331791479 - loss_val: 1.0179704690314295\n",
      "Epoch: 1169 - time: 0.0046 - loss_train: 0.9237824027311496 - loss_val: 1.0179011820050816\n",
      "Epoch: 1170 - time: 0.0046 - loss_train: 0.9236795781651377 - loss_val: 1.0178319386031964\n",
      "Epoch: 1171 - time: 0.0044 - loss_train: 0.9235768592789305 - loss_val: 1.0177627387632433\n",
      "Epoch: 1172 - time: 0.0044 - loss_train: 0.9234742458708174 - loss_val: 1.017693582424237\n",
      "Epoch: 1173 - time: 0.0036 - loss_train: 0.9233717377395522 - loss_val: 1.017624469526733\n",
      "Epoch: 1174 - time: 0.0036 - loss_train: 0.9232693346843559 - loss_val: 1.0175554000128118\n",
      "Epoch: 1175 - time: 0.0045 - loss_train: 0.9231670365049146 - loss_val: 1.0174863738260789\n",
      "Epoch: 1176 - time: 0.0046 - loss_train: 0.9230648430013744 - loss_val: 1.0174173909116526\n",
      "Epoch: 1177 - time: 0.0039 - loss_train: 0.9229627539743435 - loss_val: 1.017348451216152\n",
      "Epoch: 1178 - time: 0.0033 - loss_train: 0.9228607692248895 - loss_val: 1.0172795546876967\n",
      "Epoch: 1179 - time: 0.0031 - loss_train: 0.9227588885545365 - loss_val: 1.0172107012758924\n",
      "Epoch: 1180 - time: 0.0032 - loss_train: 0.9226571117652672 - loss_val: 1.0171418909318277\n",
      "Epoch: 1181 - time: 0.0032 - loss_train: 0.9225554386595167 - loss_val: 1.0170731236080597\n",
      "Epoch: 1182 - time: 0.0031 - loss_train: 0.9224538690401755 - loss_val: 1.0170043992586115\n",
      "Epoch: 1183 - time: 0.0030 - loss_train: 0.9223524027105848 - loss_val: 1.0169357178389622\n",
      "Epoch: 1184 - time: 0.0031 - loss_train: 0.9222510394745368 - loss_val: 1.016867079306039\n",
      "Epoch: 1185 - time: 0.0031 - loss_train: 0.9221497791362747 - loss_val: 1.0167984836182078\n",
      "Epoch: 1186 - time: 0.0031 - loss_train: 0.9220486215004874 - loss_val: 1.0167299307352682\n",
      "Epoch: 1187 - time: 0.0032 - loss_train: 0.9219475663723121 - loss_val: 1.0166614206184434\n",
      "Epoch: 1188 - time: 0.0032 - loss_train: 0.9218466135573326 - loss_val: 1.0165929532303715\n",
      "Epoch: 1189 - time: 0.0031 - loss_train: 0.9217457628615753 - loss_val: 1.0165245285351023\n",
      "Epoch: 1190 - time: 0.0032 - loss_train: 0.921645014091511 - loss_val: 1.0164561464980837\n",
      "Epoch: 1191 - time: 0.0031 - loss_train: 0.921544367054053 - loss_val: 1.0163878070861576\n",
      "Epoch: 1192 - time: 0.0031 - loss_train: 0.9214438215565546 - loss_val: 1.0163195102675502\n",
      "Epoch: 1193 - time: 0.0031 - loss_train: 0.9213433774068108 - loss_val: 1.0162512560118675\n",
      "Epoch: 1194 - time: 0.0032 - loss_train: 0.9212430344130549 - loss_val: 1.0161830442900817\n",
      "Epoch: 1195 - time: 0.0031 - loss_train: 0.9211427923839574 - loss_val: 1.0161148750745304\n",
      "Epoch: 1196 - time: 0.0031 - loss_train: 0.9210426511286278 - loss_val: 1.0160467483389046\n",
      "Epoch: 1197 - time: 0.0032 - loss_train: 0.9209426104566096 - loss_val: 1.0159786640582407\n",
      "Epoch: 1198 - time: 0.0031 - loss_train: 0.920842670177883 - loss_val: 1.0159106222089176\n",
      "Epoch: 1199 - time: 0.0032 - loss_train: 0.9207428301028622 - loss_val: 1.015842622768644\n",
      "Epoch: 1200 - time: 0.0031 - loss_train: 0.9206430900423942 - loss_val: 1.015774665716454\n",
      "Epoch: 1201 - time: 0.0032 - loss_train: 0.920543449807759 - loss_val: 1.0157067510326971\n",
      "Epoch: 1202 - time: 0.0032 - loss_train: 0.9204439092106689 - loss_val: 1.0156388786990338\n",
      "Epoch: 1203 - time: 0.0032 - loss_train: 0.9203444680632663 - loss_val: 1.0155710486984253\n",
      "Epoch: 1204 - time: 0.0031 - loss_train: 0.920245126178124 - loss_val: 1.0155032610151287\n",
      "Epoch: 1205 - time: 0.0031 - loss_train: 0.9201458833682448 - loss_val: 1.015435515634687\n",
      "Epoch: 1206 - time: 0.0031 - loss_train: 0.9200467394470593 - loss_val: 1.0153678125439243\n",
      "Epoch: 1207 - time: 0.0031 - loss_train: 0.9199476942284277 - loss_val: 1.0153001517309368\n",
      "Epoch: 1208 - time: 0.0031 - loss_train: 0.9198487475266359 - loss_val: 1.0152325331850844\n",
      "Epoch: 1209 - time: 0.0031 - loss_train: 0.9197498991563979 - loss_val: 1.0151649568969878\n",
      "Epoch: 1210 - time: 0.0031 - loss_train: 0.9196511489328527 - loss_val: 1.0150974228585161\n",
      "Epoch: 1211 - time: 0.0031 - loss_train: 0.9195524966715659 - loss_val: 1.0150299310627833\n",
      "Epoch: 1212 - time: 0.0031 - loss_train: 0.919453942188527 - loss_val: 1.0149624815041378\n",
      "Epoch: 1213 - time: 0.0031 - loss_train: 0.9193554853001505 - loss_val: 1.014895074178159\n",
      "Epoch: 1214 - time: 0.0031 - loss_train: 0.9192571258232751 - loss_val: 1.0148277090816467\n",
      "Epoch: 1215 - time: 0.0037 - loss_train: 0.9191588635751625 - loss_val: 1.0147603862126153\n",
      "Epoch: 1216 - time: 0.0032 - loss_train: 0.9190606983734969 - loss_val: 1.0146931055702892\n",
      "Epoch: 1217 - time: 0.0031 - loss_train: 0.9189626300363857 - loss_val: 1.0146258671550892\n",
      "Epoch: 1218 - time: 0.0031 - loss_train: 0.9188646583823581 - loss_val: 1.014558670968633\n",
      "Epoch: 1219 - time: 0.0031 - loss_train: 0.9187667832303639 - loss_val: 1.0144915170137228\n",
      "Epoch: 1220 - time: 0.0031 - loss_train: 0.9186690043997756 - loss_val: 1.0144244052943399\n",
      "Epoch: 1221 - time: 0.0031 - loss_train: 0.9185713217103848 - loss_val: 1.0143573358156377\n",
      "Epoch: 1222 - time: 0.0031 - loss_train: 0.9184737349824053 - loss_val: 1.0142903085839357\n",
      "Epoch: 1223 - time: 0.0031 - loss_train: 0.9183762440364694 - loss_val: 1.0142233236067104\n",
      "Epoch: 1224 - time: 0.0031 - loss_train: 0.9182788486936302 - loss_val: 1.01415638089259\n",
      "Epoch: 1225 - time: 0.0031 - loss_train: 0.9181815487753594 - loss_val: 1.0140894804513465\n",
      "Epoch: 1226 - time: 0.0032 - loss_train: 0.918084344103548 - loss_val: 1.0140226222938895\n",
      "Epoch: 1227 - time: 0.0031 - loss_train: 0.9179872345005069 - loss_val: 1.0139558064322571\n",
      "Epoch: 1228 - time: 0.0031 - loss_train: 0.917890219788964 - loss_val: 1.013889032879613\n",
      "Epoch: 1229 - time: 0.0031 - loss_train: 0.9177932997920667 - loss_val: 1.0138223016502361\n",
      "Epoch: 1230 - time: 0.0031 - loss_train: 0.9176964743333794 - loss_val: 1.0137556127595146\n",
      "Epoch: 1231 - time: 0.0031 - loss_train: 0.917599743236886 - loss_val: 1.0136889662239383\n",
      "Epoch: 1232 - time: 0.0031 - loss_train: 0.9175031063269867 - loss_val: 1.013622362061095\n",
      "Epoch: 1233 - time: 0.0031 - loss_train: 0.9174065634285002 - loss_val: 1.0135558002896587\n",
      "Epoch: 1234 - time: 0.0031 - loss_train: 0.9173101143666618 - loss_val: 1.0134892809293867\n",
      "Epoch: 1235 - time: 0.0031 - loss_train: 0.9172137589671244 - loss_val: 1.0134228040011115\n",
      "Epoch: 1236 - time: 0.0031 - loss_train: 0.9171174970559585 - loss_val: 1.0133563695267318\n",
      "Epoch: 1237 - time: 0.0031 - loss_train: 0.9170213284596503 - loss_val: 1.013289977529211\n",
      "Epoch: 1238 - time: 0.0031 - loss_train: 0.9169252530051045 - loss_val: 1.0132236280325644\n",
      "Epoch: 1239 - time: 0.0031 - loss_train: 0.9168292705196415 - loss_val: 1.0131573210618552\n",
      "Epoch: 1240 - time: 0.0031 - loss_train: 0.9167333808309982 - loss_val: 1.0130910566431874\n",
      "Epoch: 1241 - time: 0.0031 - loss_train: 0.9166375837673285 - loss_val: 1.0130248348037016\n",
      "Epoch: 1242 - time: 0.0031 - loss_train: 0.9165418791572036 - loss_val: 1.0129586555715628\n",
      "Epoch: 1243 - time: 0.0031 - loss_train: 0.9164462668296102 - loss_val: 1.0128925189759577\n",
      "Epoch: 1244 - time: 0.0031 - loss_train: 0.916350746613952 - loss_val: 1.0128264250470864\n",
      "Epoch: 1245 - time: 0.0031 - loss_train: 0.916255318340048 - loss_val: 1.0127603738161566\n",
      "Epoch: 1246 - time: 0.0031 - loss_train: 0.9161599818381357 - loss_val: 1.0126943653153753\n",
      "Epoch: 1247 - time: 0.0031 - loss_train: 0.9160647369388678 - loss_val: 1.0126283995779446\n",
      "Epoch: 1248 - time: 0.0031 - loss_train: 0.915969583473313 - loss_val: 1.0125624766380525\n",
      "Epoch: 1249 - time: 0.0031 - loss_train: 0.915874521272958 - loss_val: 1.0124965965308657\n",
      "Epoch: 1250 - time: 0.0031 - loss_train: 0.9157795501697042 - loss_val: 1.0124307592925261\n",
      "Epoch: 1251 - time: 0.0031 - loss_train: 0.915684669995871 - loss_val: 1.0123649649601414\n",
      "Epoch: 1252 - time: 0.0031 - loss_train: 0.9155898805841928 - loss_val: 1.0122992135717797\n",
      "Epoch: 1253 - time: 0.0035 - loss_train: 0.915495181767823 - loss_val: 1.0122335051664602\n",
      "Epoch: 1254 - time: 0.0032 - loss_train: 0.9154005733803285 - loss_val: 1.0121678397841518\n",
      "Epoch: 1255 - time: 0.0031 - loss_train: 0.9153060552556955 - loss_val: 1.0121022174657601\n",
      "Epoch: 1256 - time: 0.0031 - loss_train: 0.9152116272283265 - loss_val: 1.012036638253125\n",
      "Epoch: 1257 - time: 0.0031 - loss_train: 0.9151172891330396 - loss_val: 1.0119711021890136\n",
      "Epoch: 1258 - time: 0.0031 - loss_train: 0.9150230408050709 - loss_val: 1.01190560931711\n",
      "Epoch: 1259 - time: 0.0031 - loss_train: 0.9149288820800732 - loss_val: 1.0118401596820137\n",
      "Epoch: 1260 - time: 0.0031 - loss_train: 0.914834812794117 - loss_val: 1.011774753329228\n",
      "Epoch: 1261 - time: 0.0031 - loss_train: 0.9147408327836893 - loss_val: 1.0117093903051588\n",
      "Epoch: 1262 - time: 0.0031 - loss_train: 0.9146469418856951 - loss_val: 1.0116440706571026\n",
      "Epoch: 1263 - time: 0.0031 - loss_train: 0.9145531399374561 - loss_val: 1.0115787944332402\n",
      "Epoch: 1264 - time: 0.0031 - loss_train: 0.9144594267767113 - loss_val: 1.011513561682637\n",
      "Epoch: 1265 - time: 0.0031 - loss_train: 0.9143658022416189 - loss_val: 1.0114483724552261\n",
      "Epoch: 1266 - time: 0.0031 - loss_train: 0.9142722661707533 - loss_val: 1.0113832268018093\n",
      "Epoch: 1267 - time: 0.0032 - loss_train: 0.9141788184031076 - loss_val: 1.0113181247740461\n",
      "Epoch: 1268 - time: 0.0032 - loss_train: 0.9140854587780932 - loss_val: 1.0112530664244512\n",
      "Epoch: 1269 - time: 0.0031 - loss_train: 0.9139921871355382 - loss_val: 1.0111880518063818\n",
      "Epoch: 1270 - time: 0.0031 - loss_train: 0.9138990033156906 - loss_val: 1.0111230809740366\n",
      "Epoch: 1271 - time: 0.0031 - loss_train: 0.9138059071592155 - loss_val: 1.0110581539824457\n",
      "Epoch: 1272 - time: 0.0031 - loss_train: 0.913712898507198 - loss_val: 1.0109932708874665\n",
      "Epoch: 1273 - time: 0.0031 - loss_train: 0.9136199772011401 - loss_val: 1.0109284317457743\n",
      "Epoch: 1274 - time: 0.0031 - loss_train: 0.9135271430829641 - loss_val: 1.0108636366148565\n",
      "Epoch: 1275 - time: 0.0031 - loss_train: 0.9134343959950103 - loss_val: 1.010798885553008\n",
      "Epoch: 1276 - time: 0.0032 - loss_train: 0.9133417357800383 - loss_val: 1.0107341786193211\n",
      "Epoch: 1277 - time: 0.0031 - loss_train: 0.9132491622812268 - loss_val: 1.0106695158736811\n",
      "Epoch: 1278 - time: 0.0031 - loss_train: 0.9131566753421739 - loss_val: 1.0106048973767594\n",
      "Epoch: 1279 - time: 0.0031 - loss_train: 0.9130642748068977 - loss_val: 1.0105403231900054\n",
      "Epoch: 1280 - time: 0.0031 - loss_train: 0.9129719605198343 - loss_val: 1.0104757933756403\n",
      "Epoch: 1281 - time: 0.0031 - loss_train: 0.9128797323258406 - loss_val: 1.0104113079966521\n",
      "Epoch: 1282 - time: 0.0031 - loss_train: 0.912787590070194 - loss_val: 1.0103468671167872\n",
      "Epoch: 1283 - time: 0.0031 - loss_train: 0.9126955335985898 - loss_val: 1.010282470800545\n",
      "Epoch: 1284 - time: 0.0031 - loss_train: 0.9126035627571455 - loss_val: 1.0102181191131676\n",
      "Epoch: 1285 - time: 0.0031 - loss_train: 0.9125116773923972 - loss_val: 1.0101538121206386\n",
      "Epoch: 1286 - time: 0.0031 - loss_train: 0.9124198773513019 - loss_val: 1.0100895498896714\n",
      "Epoch: 1287 - time: 0.0031 - loss_train: 0.9123281624812366 - loss_val: 1.010025332487706\n",
      "Epoch: 1288 - time: 0.0031 - loss_train: 0.9122365326299993 - loss_val: 1.0099611599828997\n",
      "Epoch: 1289 - time: 0.0031 - loss_train: 0.9121449876458083 - loss_val: 1.0098970324441223\n",
      "Epoch: 1290 - time: 0.0031 - loss_train: 0.9120535273773026 - loss_val: 1.0098329499409489\n",
      "Epoch: 1291 - time: 0.0037 - loss_train: 0.9119621516735419 - loss_val: 1.009768912543652\n",
      "Epoch: 1292 - time: 0.0032 - loss_train: 0.9118708603840067 - loss_val: 1.009704920323196\n",
      "Epoch: 1293 - time: 0.0031 - loss_train: 0.9117796533585983 - loss_val: 1.0096409733512288\n",
      "Epoch: 1294 - time: 0.0031 - loss_train: 0.9116885304476395 - loss_val: 1.009577071700078\n",
      "Epoch: 1295 - time: 0.0031 - loss_train: 0.9115974915018735 - loss_val: 1.009513215442742\n",
      "Epoch: 1296 - time: 0.0031 - loss_train: 0.9115065363724653 - loss_val: 1.0094494046528824\n",
      "Epoch: 1297 - time: 0.0031 - loss_train: 0.9114156649110009 - loss_val: 1.009385639404821\n",
      "Epoch: 1298 - time: 0.0031 - loss_train: 0.9113248769694867 - loss_val: 1.009321919773527\n",
      "Epoch: 1299 - time: 0.0031 - loss_train: 0.9112341724003513 - loss_val: 1.0092582458346167\n",
      "Epoch: 1300 - time: 0.0031 - loss_train: 0.9111435510564443 - loss_val: 1.0091946176643425\n",
      "Epoch: 1301 - time: 0.0031 - loss_train: 0.9110530127910367 - loss_val: 1.009131035339587\n",
      "Epoch: 1302 - time: 0.0031 - loss_train: 0.9109625574578204 - loss_val: 1.0090674989378585\n",
      "Epoch: 1303 - time: 0.0031 - loss_train: 0.9108721849109099 - loss_val: 1.0090040085372793\n",
      "Epoch: 1304 - time: 0.0031 - loss_train: 0.9107818950048393 - loss_val: 1.0089405642165834\n",
      "Epoch: 1305 - time: 0.0031 - loss_train: 0.9106916875945655 - loss_val: 1.008877166055108\n",
      "Epoch: 1306 - time: 0.0031 - loss_train: 0.9106015625354659 - loss_val: 1.0088138141327883\n",
      "Epoch: 1307 - time: 0.0032 - loss_train: 0.9105115196833399 - loss_val: 1.0087505085301487\n",
      "Epoch: 1308 - time: 0.0034 - loss_train: 0.9104215588944071 - loss_val: 1.0086872493282935\n",
      "Epoch: 1309 - time: 0.0035 - loss_train: 0.9103316800253094 - loss_val: 1.0086240366089079\n",
      "Epoch: 1310 - time: 0.0033 - loss_train: 0.9102418829331098 - loss_val: 1.0085608704542421\n",
      "Epoch: 1311 - time: 0.0032 - loss_train: 0.9101521674752917 - loss_val: 1.008497750947112\n",
      "Epoch: 1312 - time: 0.0031 - loss_train: 0.9100625335097599 - loss_val: 1.0084346781708882\n",
      "Epoch: 1313 - time: 0.0031 - loss_train: 0.9099729808948406 - loss_val: 1.0083716522094892\n",
      "Epoch: 1314 - time: 0.0031 - loss_train: 0.9098835094892804 - loss_val: 1.0083086731473767\n",
      "Epoch: 1315 - time: 0.0031 - loss_train: 0.9097941191522465 - loss_val: 1.0082457410695473\n",
      "Epoch: 1316 - time: 0.0031 - loss_train: 0.9097048097433277 - loss_val: 1.0081828560615251\n",
      "Epoch: 1317 - time: 0.0031 - loss_train: 0.9096155811225319 - loss_val: 1.008120018209359\n",
      "Epoch: 1318 - time: 0.0031 - loss_train: 0.909526433150289 - loss_val: 1.0080572275996071\n",
      "Epoch: 1319 - time: 0.0031 - loss_train: 0.9094373656874473 - loss_val: 1.00799448431934\n",
      "Epoch: 1320 - time: 0.0031 - loss_train: 0.909348378595277 - loss_val: 1.007931788456127\n",
      "Epoch: 1321 - time: 0.0031 - loss_train: 0.9092594717354668 - loss_val: 1.0078691400980329\n",
      "Epoch: 1322 - time: 0.0032 - loss_train: 0.9091706449701263 - loss_val: 1.0078065393336084\n",
      "Epoch: 1323 - time: 0.0031 - loss_train: 0.9090818981617838 - loss_val: 1.0077439862518867\n",
      "Epoch: 1324 - time: 0.0031 - loss_train: 0.9089932311733872 - loss_val: 1.007681480942371\n",
      "Epoch: 1325 - time: 0.0031 - loss_train: 0.9089046438683033 - loss_val: 1.007619023495036\n",
      "Epoch: 1326 - time: 0.0031 - loss_train: 0.9088161361103182 - loss_val: 1.0075566140003136\n",
      "Epoch: 1327 - time: 0.0031 - loss_train: 0.9087277077636361 - loss_val: 1.0074942525490855\n",
      "Epoch: 1328 - time: 0.0031 - loss_train: 0.9086393586928795 - loss_val: 1.0074319392326876\n",
      "Epoch: 1329 - time: 0.0038 - loss_train: 0.9085510887630901 - loss_val: 1.0073696741428884\n",
      "Epoch: 1330 - time: 0.0032 - loss_train: 0.9084628978397254 - loss_val: 1.0073074573718916\n",
      "Epoch: 1331 - time: 0.0031 - loss_train: 0.9083747857886624 - loss_val: 1.007245289012326\n",
      "Epoch: 1332 - time: 0.0031 - loss_train: 0.9082867524761941 - loss_val: 1.007183169157239\n",
      "Epoch: 1333 - time: 0.0031 - loss_train: 0.9081987977690305 - loss_val: 1.0071210979000893\n",
      "Epoch: 1334 - time: 0.0031 - loss_train: 0.9081109215342983 - loss_val: 1.0070590753347428\n",
      "Epoch: 1335 - time: 0.0031 - loss_train: 0.9080231236395395 - loss_val: 1.0069971015554617\n",
      "Epoch: 1336 - time: 0.0031 - loss_train: 0.9079354039527139 - loss_val: 1.0069351766568997\n",
      "Epoch: 1337 - time: 0.0031 - loss_train: 0.9078477623421941 - loss_val: 1.0068733007340955\n",
      "Epoch: 1338 - time: 0.0031 - loss_train: 0.9077601986767697 - loss_val: 1.0068114738824663\n",
      "Epoch: 1339 - time: 0.0031 - loss_train: 0.9076727128256437 - loss_val: 1.0067496961977969\n",
      "Epoch: 1340 - time: 0.0031 - loss_train: 0.907585304658433 - loss_val: 1.0066879677762401\n",
      "Epoch: 1341 - time: 0.0031 - loss_train: 0.9074979740451695 - loss_val: 1.0066262887143036\n",
      "Epoch: 1342 - time: 0.0031 - loss_train: 0.9074107208562974 - loss_val: 1.0065646591088449\n",
      "Epoch: 1343 - time: 0.0031 - loss_train: 0.9073235449626734 - loss_val: 1.0065030790570666\n",
      "Epoch: 1344 - time: 0.0031 - loss_train: 0.9072364462355669 - loss_val: 1.0064415486565057\n",
      "Epoch: 1345 - time: 0.0031 - loss_train: 0.907149424546659 - loss_val: 1.006380068005032\n",
      "Epoch: 1346 - time: 0.0031 - loss_train: 0.9070624797680412 - loss_val: 1.0063186372008366\n",
      "Epoch: 1347 - time: 0.0031 - loss_train: 0.9069756117722175 - loss_val: 1.0062572563424248\n",
      "Epoch: 1348 - time: 0.0031 - loss_train: 0.9068888204320998 - loss_val: 1.006195925528614\n",
      "Epoch: 1349 - time: 0.0031 - loss_train: 0.9068021056210112 - loss_val: 1.0061346448585236\n",
      "Epoch: 1350 - time: 0.0031 - loss_train: 0.9067154672126824 - loss_val: 1.006073414431569\n",
      "Epoch: 1351 - time: 0.0031 - loss_train: 0.9066289050812534 - loss_val: 1.0060122343474511\n",
      "Epoch: 1352 - time: 0.0031 - loss_train: 0.9065424191012719 - loss_val: 1.0059511047061571\n",
      "Epoch: 1353 - time: 0.0031 - loss_train: 0.9064560091476918 - loss_val: 1.0058900256079488\n",
      "Epoch: 1354 - time: 0.0031 - loss_train: 0.9063696750958745 - loss_val: 1.005828997153355\n",
      "Epoch: 1355 - time: 0.0031 - loss_train: 0.9062834168215868 - loss_val: 1.005768019443166\n",
      "Epoch: 1356 - time: 0.0031 - loss_train: 0.9061972342009992 - loss_val: 1.0057070925784295\n",
      "Epoch: 1357 - time: 0.0031 - loss_train: 0.9061111271106895 - loss_val: 1.0056462166604396\n",
      "Epoch: 1358 - time: 0.0031 - loss_train: 0.9060250954276358 - loss_val: 1.005585391790732\n",
      "Epoch: 1359 - time: 0.0031 - loss_train: 0.9059391390292216 - loss_val: 1.0055246180710793\n",
      "Epoch: 1360 - time: 0.0031 - loss_train: 0.9058532577932319 - loss_val: 1.0054638956034774\n",
      "Epoch: 1361 - time: 0.0031 - loss_train: 0.9057674515978519 - loss_val: 1.0054032244901485\n",
      "Epoch: 1362 - time: 0.0031 - loss_train: 0.9056817203216689 - loss_val: 1.0053426048335266\n",
      "Epoch: 1363 - time: 0.0031 - loss_train: 0.9055960638436695 - loss_val: 1.0052820367362556\n",
      "Epoch: 1364 - time: 0.0031 - loss_train: 0.9055104820432391 - loss_val: 1.0052215203011778\n",
      "Epoch: 1365 - time: 0.0031 - loss_train: 0.9054249748001609 - loss_val: 1.0051610556313326\n",
      "Epoch: 1366 - time: 0.0032 - loss_train: 0.9053395419946163 - loss_val: 1.005100642829946\n",
      "Epoch: 1367 - time: 0.0035 - loss_train: 0.9052541835071825 - loss_val: 1.0050402820004256\n",
      "Epoch: 1368 - time: 0.0032 - loss_train: 0.9051688992188319 - loss_val: 1.004979973246354\n",
      "Epoch: 1369 - time: 0.0031 - loss_train: 0.9050836890109327 - loss_val: 1.0049197166714812\n",
      "Epoch: 1370 - time: 0.0031 - loss_train: 0.904998552765245 - loss_val: 1.0048595123797188\n",
      "Epoch: 1371 - time: 0.0031 - loss_train: 0.9049134903639235 - loss_val: 1.0047993604751322\n",
      "Epoch: 1372 - time: 0.0031 - loss_train: 0.9048285016895132 - loss_val: 1.0047392610619368\n",
      "Epoch: 1373 - time: 0.0031 - loss_train: 0.9047435866249512 - loss_val: 1.0046792142444885\n",
      "Epoch: 1374 - time: 0.0031 - loss_train: 0.9046587450535633 - loss_val: 1.0046192201272777\n",
      "Epoch: 1375 - time: 0.0031 - loss_train: 0.9045739768590644 - loss_val: 1.0045592788149242\n",
      "Epoch: 1376 - time: 0.0031 - loss_train: 0.904489281925558 - loss_val: 1.0044993904121702\n",
      "Epoch: 1377 - time: 0.0031 - loss_train: 0.9044046601375328 - loss_val: 1.004439555023872\n",
      "Epoch: 1378 - time: 0.0031 - loss_train: 0.9043201113798652 - loss_val: 1.0043797727549948\n",
      "Epoch: 1379 - time: 0.0031 - loss_train: 0.9042356355378145 - loss_val: 1.0043200437106083\n",
      "Epoch: 1380 - time: 0.0031 - loss_train: 0.9041512324970239 - loss_val: 1.0042603679958773\n",
      "Epoch: 1381 - time: 0.0031 - loss_train: 0.9040669021435195 - loss_val: 1.004200745716054\n",
      "Epoch: 1382 - time: 0.0031 - loss_train: 0.9039826443637081 - loss_val: 1.004141176976477\n",
      "Epoch: 1383 - time: 0.0031 - loss_train: 0.9038984590443774 - loss_val: 1.0040816618825603\n",
      "Epoch: 1384 - time: 0.0031 - loss_train: 0.9038143460726931 - loss_val: 1.0040222005397876\n",
      "Epoch: 1385 - time: 0.0031 - loss_train: 0.9037303053361994 - loss_val: 1.0039627930537078\n",
      "Epoch: 1386 - time: 0.0031 - loss_train: 0.9036463367228164 - loss_val: 1.0039034395299267\n",
      "Epoch: 1387 - time: 0.0031 - loss_train: 0.9035624401208403 - loss_val: 1.0038441400741016\n",
      "Epoch: 1388 - time: 0.0031 - loss_train: 0.9034786154189413 - loss_val: 1.003784894791936\n",
      "Epoch: 1389 - time: 0.0031 - loss_train: 0.9033948625061616 - loss_val: 1.0037257037891698\n",
      "Epoch: 1390 - time: 0.0031 - loss_train: 0.9033111812719159 - loss_val: 1.0036665671715783\n",
      "Epoch: 1391 - time: 0.0032 - loss_train: 0.9032275716059891 - loss_val: 1.0036074850449601\n",
      "Epoch: 1392 - time: 0.0031 - loss_train: 0.9031440333985354 - loss_val: 1.0035484575151363\n",
      "Epoch: 1393 - time: 0.0031 - loss_train: 0.9030605665400749 - loss_val: 1.0034894846879405\n",
      "Epoch: 1394 - time: 0.0031 - loss_train: 0.9029771709214977 - loss_val: 1.003430566669215\n",
      "Epoch: 1395 - time: 0.0031 - loss_train: 0.9028938464340549 - loss_val: 1.0033717035648024\n",
      "Epoch: 1396 - time: 0.0031 - loss_train: 0.9028105929693641 - loss_val: 1.0033128954805424\n",
      "Epoch: 1397 - time: 0.0031 - loss_train: 0.9027274104194034 - loss_val: 1.0032541425222625\n",
      "Epoch: 1398 - time: 0.0031 - loss_train: 0.902644298676513 - loss_val: 1.003195444795775\n",
      "Epoch: 1399 - time: 0.0031 - loss_train: 0.9025612576333919 - loss_val: 1.003136802406867\n",
      "Epoch: 1400 - time: 0.0031 - loss_train: 0.9024782871830975 - loss_val: 1.0030782154612996\n",
      "Epoch: 1401 - time: 0.0031 - loss_train: 0.9023953872190432 - loss_val: 1.0030196840647982\n",
      "Epoch: 1402 - time: 0.0031 - loss_train: 0.902312557634998 - loss_val: 1.002961208323047\n",
      "Epoch: 1403 - time: 0.0031 - loss_train: 0.9022297983250843 - loss_val: 1.0029027883416846\n",
      "Epoch: 1404 - time: 0.0031 - loss_train: 0.9021471091837766 - loss_val: 1.002844424226296\n",
      "Epoch: 1405 - time: 0.0035 - loss_train: 0.9020644901059 - loss_val: 1.0027861160824072\n",
      "Epoch: 1406 - time: 0.0032 - loss_train: 0.9019819409866289 - loss_val: 1.0027278640154824\n",
      "Epoch: 1407 - time: 0.0031 - loss_train: 0.9018994617214847 - loss_val: 1.0026696681309137\n",
      "Epoch: 1408 - time: 0.0031 - loss_train: 0.9018170522063353 - loss_val: 1.0026115285340185\n",
      "Epoch: 1409 - time: 0.0031 - loss_train: 0.9017347123373922 - loss_val: 1.0025534453300302\n",
      "Epoch: 1410 - time: 0.0031 - loss_train: 0.901652442011211 - loss_val: 1.0024954186240995\n",
      "Epoch: 1411 - time: 0.0031 - loss_train: 0.9015702411246869 - loss_val: 1.0024374485212784\n",
      "Epoch: 1412 - time: 0.0031 - loss_train: 0.9014881095750554 - loss_val: 1.002379535126525\n",
      "Epoch: 1413 - time: 0.0031 - loss_train: 0.9014060472598902 - loss_val: 1.0023216785446905\n",
      "Epoch: 1414 - time: 0.0031 - loss_train: 0.9013240540771003 - loss_val: 1.002263878880517\n",
      "Epoch: 1415 - time: 0.0031 - loss_train: 0.9012421299249297 - loss_val: 1.0022061362386299\n",
      "Epoch: 1416 - time: 0.0031 - loss_train: 0.901160274701956 - loss_val: 1.0021484507235359\n",
      "Epoch: 1417 - time: 0.0031 - loss_train: 0.9010784883070867 - loss_val: 1.0020908224396137\n",
      "Epoch: 1418 - time: 0.0031 - loss_train: 0.9009967706395589 - loss_val: 1.0020332514911099\n",
      "Epoch: 1419 - time: 0.0036 - loss_train: 0.9009151215989384 - loss_val: 1.001975737982134\n",
      "Epoch: 1420 - time: 0.0032 - loss_train: 0.9008335410851158 - loss_val: 1.0019182820166521\n",
      "Epoch: 1421 - time: 0.0031 - loss_train: 0.9007520289983061 - loss_val: 1.0018608836984835\n",
      "Epoch: 1422 - time: 0.0031 - loss_train: 0.9006705852390473 - loss_val: 1.0018035431312935\n",
      "Epoch: 1423 - time: 0.0031 - loss_train: 0.900589209708197 - loss_val: 1.0017462604185872\n",
      "Epoch: 1424 - time: 0.0031 - loss_train: 0.9005079023069325 - loss_val: 1.0016890356637074\n",
      "Epoch: 1425 - time: 0.0031 - loss_train: 0.9004266629367477 - loss_val: 1.0016318689698274\n",
      "Epoch: 1426 - time: 0.0031 - loss_train: 0.9003454914994513 - loss_val: 1.0015747604399445\n",
      "Epoch: 1427 - time: 0.0031 - loss_train: 0.900264387897165 - loss_val: 1.001517710176879\n",
      "Epoch: 1428 - time: 0.0031 - loss_train: 0.9001833520323232 - loss_val: 1.0014607182832642\n",
      "Epoch: 1429 - time: 0.0031 - loss_train: 0.900102383807668 - loss_val: 1.001403784861546\n",
      "Epoch: 1430 - time: 0.0031 - loss_train: 0.9000214831262506 - loss_val: 1.0013469100139718\n",
      "Epoch: 1431 - time: 0.0031 - loss_train: 0.8999406498914271 - loss_val: 1.001290093842593\n",
      "Epoch: 1432 - time: 0.0031 - loss_train: 0.8998598840068569 - loss_val: 1.001233336449255\n",
      "Epoch: 1433 - time: 0.0031 - loss_train: 0.8997791853765028 - loss_val: 1.0011766379355933\n",
      "Epoch: 1434 - time: 0.0031 - loss_train: 0.8996985539046257 - loss_val: 1.0011199984030288\n",
      "Epoch: 1435 - time: 0.0031 - loss_train: 0.8996179894957852 - loss_val: 1.0010634179527633\n",
      "Epoch: 1436 - time: 0.0031 - loss_train: 0.8995374920548369 - loss_val: 1.0010068966857757\n",
      "Epoch: 1437 - time: 0.0031 - loss_train: 0.8994570614869297 - loss_val: 1.0009504347028129\n",
      "Epoch: 1438 - time: 0.0031 - loss_train: 0.8993766976975056 - loss_val: 1.0008940321043927\n",
      "Epoch: 1439 - time: 0.0031 - loss_train: 0.8992964005922954 - loss_val: 1.0008376889907904\n",
      "Epoch: 1440 - time: 0.0031 - loss_train: 0.8992161700773172 - loss_val: 1.000781405462041\n",
      "Epoch: 1441 - time: 0.0031 - loss_train: 0.8991360060588768 - loss_val: 1.0007251816179312\n",
      "Epoch: 1442 - time: 0.0031 - loss_train: 0.8990559084435622 - loss_val: 1.0006690175579964\n",
      "Epoch: 1443 - time: 0.0037 - loss_train: 0.8989758771382433 - loss_val: 1.0006129133815151\n",
      "Epoch: 1444 - time: 0.0032 - loss_train: 0.8988959120500704 - loss_val: 1.0005568691875046\n",
      "Epoch: 1445 - time: 0.0031 - loss_train: 0.8988160130864703 - loss_val: 1.0005008850747175\n",
      "Epoch: 1446 - time: 0.0031 - loss_train: 0.898736180155146 - loss_val: 1.0004449611416368\n",
      "Epoch: 1447 - time: 0.0031 - loss_train: 0.8986564131640731 - loss_val: 1.0003890974864706\n",
      "Epoch: 1448 - time: 0.0031 - loss_train: 0.8985767120214984 - loss_val: 1.0003332942071492\n",
      "Epoch: 1449 - time: 0.0031 - loss_train: 0.8984970766359379 - loss_val: 1.0002775514013218\n",
      "Epoch: 1450 - time: 0.0031 - loss_train: 0.8984175069161746 - loss_val: 1.000221869166349\n",
      "Epoch: 1451 - time: 0.0031 - loss_train: 0.8983380027712558 - loss_val: 1.0001662475993003\n",
      "Epoch: 1452 - time: 0.0031 - loss_train: 0.8982585641104913 - loss_val: 1.0001106867969527\n",
      "Epoch: 1453 - time: 0.0031 - loss_train: 0.8981791908434515 - loss_val: 1.000055186855782\n",
      "Epoch: 1454 - time: 0.0031 - loss_train: 0.8980998828799646 - loss_val: 0.999999747871962\n",
      "Epoch: 1455 - time: 0.0031 - loss_train: 0.8980206401301147 - loss_val: 0.9999443699413605\n",
      "Epoch: 1456 - time: 0.0031 - loss_train: 0.8979414625042398 - loss_val: 0.9998890531595316\n",
      "Epoch: 1457 - time: 0.0031 - loss_train: 0.8978623499129291 - loss_val: 0.9998337976217178\n",
      "Epoch: 1458 - time: 0.0031 - loss_train: 0.8977833022670203 - loss_val: 0.9997786034228417\n",
      "Epoch: 1459 - time: 0.0031 - loss_train: 0.8977043194775998 - loss_val: 0.9997234706575032\n",
      "Epoch: 1460 - time: 0.0031 - loss_train: 0.8976254014559961 - loss_val: 0.999668399419977\n",
      "Epoch: 1461 - time: 0.0031 - loss_train: 0.8975465481137829 - loss_val: 0.9996133898042081\n",
      "Epoch: 1462 - time: 0.0031 - loss_train: 0.8974677593627722 - loss_val: 0.9995584419038076\n",
      "Epoch: 1463 - time: 0.0031 - loss_train: 0.8973890351150137 - loss_val: 0.9995035558120514\n",
      "Epoch: 1464 - time: 0.0031 - loss_train: 0.8973103752827933 - loss_val: 0.9994487316218714\n",
      "Epoch: 1465 - time: 0.0031 - loss_train: 0.8972317797786302 - loss_val: 0.9993939694258588\n",
      "Epoch: 1466 - time: 0.0031 - loss_train: 0.8971532485152734 - loss_val: 0.9993392693162575\n",
      "Epoch: 1467 - time: 0.0031 - loss_train: 0.8970747814057014 - loss_val: 0.9992846313849585\n",
      "Epoch: 1468 - time: 0.0031 - loss_train: 0.8969963783631189 - loss_val: 0.9992300557235005\n",
      "Epoch: 1469 - time: 0.0031 - loss_train: 0.8969180393009526 - loss_val: 0.9991755424230643\n",
      "Epoch: 1470 - time: 0.0031 - loss_train: 0.8968397641328539 - loss_val: 0.9991210915744698\n",
      "Epoch: 1471 - time: 0.0031 - loss_train: 0.8967615527726905 - loss_val: 0.9990667032681735\n",
      "Epoch: 1472 - time: 0.0031 - loss_train: 0.8966834051345475 - loss_val: 0.999012377594265\n",
      "Epoch: 1473 - time: 0.0031 - loss_train: 0.8966053211327248 - loss_val: 0.9989581146424635\n",
      "Epoch: 1474 - time: 0.0031 - loss_train: 0.8965273006817345 - loss_val: 0.9989039145021159\n",
      "Epoch: 1475 - time: 0.0031 - loss_train: 0.8964493436962964 - loss_val: 0.9988497772621919\n",
      "Epoch: 1476 - time: 0.0031 - loss_train: 0.8963714500913398 - loss_val: 0.9987957030112832\n",
      "Epoch: 1477 - time: 0.0031 - loss_train: 0.8962936197819967 - loss_val: 0.9987416918375995\n",
      "Epoch: 1478 - time: 0.0031 - loss_train: 0.8962158526836027 - loss_val: 0.9986877438289655\n",
      "Epoch: 1479 - time: 0.0031 - loss_train: 0.8961381487116921 - loss_val: 0.9986338590728175\n",
      "Epoch: 1480 - time: 0.0031 - loss_train: 0.8960605077819973 - loss_val: 0.9985800376562033\n",
      "Epoch: 1481 - time: 0.0035 - loss_train: 0.8959829298104456 - loss_val: 0.9985262796657769\n",
      "Epoch: 1482 - time: 0.0032 - loss_train: 0.8959054147131558 - loss_val: 0.9984725851877956\n",
      "Epoch: 1483 - time: 0.0031 - loss_train: 0.8958279624064379 - loss_val: 0.9984189543081203\n",
      "Epoch: 1484 - time: 0.0031 - loss_train: 0.8957505728067892 - loss_val: 0.9983653871122117\n",
      "Epoch: 1485 - time: 0.0031 - loss_train: 0.8956732458308909 - loss_val: 0.998311883685123\n",
      "Epoch: 1486 - time: 0.0031 - loss_train: 0.8955959813956081 - loss_val: 0.9982584441115074\n",
      "Epoch: 1487 - time: 0.0031 - loss_train: 0.895518779417985 - loss_val: 0.9982050684756052\n",
      "Epoch: 1488 - time: 0.0031 - loss_train: 0.8954416398152445 - loss_val: 0.9981517568612492\n",
      "Epoch: 1489 - time: 0.0031 - loss_train: 0.8953645625047827 - loss_val: 0.9980985093518595\n",
      "Epoch: 1490 - time: 0.0031 - loss_train: 0.89528754740417 - loss_val: 0.9980453260304398\n",
      "Epoch: 1491 - time: 0.0031 - loss_train: 0.8952105944311455 - loss_val: 0.9979922069795764\n",
      "Epoch: 1492 - time: 0.0031 - loss_train: 0.8951337035036168 - loss_val: 0.9979391522814384\n",
      "Epoch: 1493 - time: 0.0031 - loss_train: 0.8950568745396557 - loss_val: 0.9978861620177718\n",
      "Epoch: 1494 - time: 0.0031 - loss_train: 0.8949801074574971 - loss_val: 0.9978332362699005\n",
      "Epoch: 1495 - time: 0.0031 - loss_train: 0.8949034021755347 - loss_val: 0.9977803751187214\n",
      "Epoch: 1496 - time: 0.0031 - loss_train: 0.8948267586123206 - loss_val: 0.9977275786447048\n",
      "Epoch: 1497 - time: 0.0031 - loss_train: 0.8947501766865612 - loss_val: 0.9976748469278934\n",
      "Epoch: 1498 - time: 0.0031 - loss_train: 0.8946736563171155 - loss_val: 0.9976221800478966\n",
      "Epoch: 1499 - time: 0.0031 - loss_train: 0.8945971974229908 - loss_val: 0.997569578083891\n",
      "Epoch: 1500 - time: 0.0031 - loss_train: 0.8945207999233432 - loss_val: 0.9975170411146201\n",
      "Epoch: 1501 - time: 0.0031 - loss_train: 0.8944444637374727 - loss_val: 0.997464569218391\n",
      "Epoch: 1502 - time: 0.0031 - loss_train: 0.8943681887848206 - loss_val: 0.9974121624730726\n",
      "Epoch: 1503 - time: 0.0031 - loss_train: 0.8942919749849686 - loss_val: 0.9973598209560931\n",
      "Epoch: 1504 - time: 0.0031 - loss_train: 0.8942158222576341 - loss_val: 0.9973075447444415\n",
      "Epoch: 1505 - time: 0.0031 - loss_train: 0.89413973052267 - loss_val: 0.9972553339146639\n",
      "Epoch: 1506 - time: 0.0031 - loss_train: 0.8940636997000593 - loss_val: 0.9972031885428616\n",
      "Epoch: 1507 - time: 0.0031 - loss_train: 0.8939877297099151 - loss_val: 0.9971511087046908\n",
      "Epoch: 1508 - time: 0.0031 - loss_train: 0.8939118204724764 - loss_val: 0.9970990944753628\n",
      "Epoch: 1509 - time: 0.0031 - loss_train: 0.8938359719081059 - loss_val: 0.9970471459296386\n",
      "Epoch: 1510 - time: 0.0031 - loss_train: 0.8937601839372878 - loss_val: 0.9969952631418321\n",
      "Epoch: 1511 - time: 0.0031 - loss_train: 0.8936844564806249 - loss_val: 0.9969434461858045\n",
      "Epoch: 1512 - time: 0.0031 - loss_train: 0.8936087894588357 - loss_val: 0.9968916951349676\n",
      "Epoch: 1513 - time: 0.0031 - loss_train: 0.8935331827927521 - loss_val: 0.9968400100622811\n",
      "Epoch: 1514 - time: 0.0031 - loss_train: 0.8934576364033171 - loss_val: 0.9967883910402487\n",
      "Epoch: 1515 - time: 0.0031 - loss_train: 0.8933821502115807 - loss_val: 0.9967368381409217\n",
      "Epoch: 1516 - time: 0.0031 - loss_train: 0.8933067241387005 - loss_val: 0.9966853514358943\n",
      "Epoch: 1517 - time: 0.0031 - loss_train: 0.8932313581059343 - loss_val: 0.9966339309963044\n",
      "Epoch: 1518 - time: 0.0031 - loss_train: 0.8931560520346422 - loss_val: 0.9965825768928346\n",
      "Epoch: 1519 - time: 0.0035 - loss_train: 0.8930808058462808 - loss_val: 0.9965312891957081\n",
      "Epoch: 1520 - time: 0.0032 - loss_train: 0.8930056194624026 - loss_val: 0.9964800679746872\n",
      "Epoch: 1521 - time: 0.0031 - loss_train: 0.8929304928046515 - loss_val: 0.996428913299078\n",
      "Epoch: 1522 - time: 0.0031 - loss_train: 0.8928554257947612 - loss_val: 0.9963778252377267\n",
      "Epoch: 1523 - time: 0.0031 - loss_train: 0.8927804183545531 - loss_val: 0.9963268038590154\n",
      "Epoch: 1524 - time: 0.0031 - loss_train: 0.8927054704059324 - loss_val: 0.9962758492308664\n",
      "Epoch: 1525 - time: 0.0031 - loss_train: 0.892630581870887 - loss_val: 0.9962249614207414\n",
      "Epoch: 1526 - time: 0.0031 - loss_train: 0.8925557526714823 - loss_val: 0.9961741404956386\n",
      "Epoch: 1527 - time: 0.0031 - loss_train: 0.8924809827298618 - loss_val: 0.9961233865220945\n",
      "Epoch: 1528 - time: 0.0031 - loss_train: 0.8924062719682423 - loss_val: 0.9960726995661805\n",
      "Epoch: 1529 - time: 0.0031 - loss_train: 0.8923316203089113 - loss_val: 0.996022079693506\n",
      "Epoch: 1530 - time: 0.0031 - loss_train: 0.892257027674226 - loss_val: 0.9959715269692172\n",
      "Epoch: 1531 - time: 0.0031 - loss_train: 0.8921824939866079 - loss_val: 0.9959210414579949\n",
      "Epoch: 1532 - time: 0.0031 - loss_train: 0.8921080191685433 - loss_val: 0.9958706232240568\n",
      "Epoch: 1533 - time: 0.0031 - loss_train: 0.892033603142579 - loss_val: 0.995820272331157\n",
      "Epoch: 1534 - time: 0.0031 - loss_train: 0.8919592458313189 - loss_val: 0.9957699888425832\n",
      "Epoch: 1535 - time: 0.0031 - loss_train: 0.891884947157423 - loss_val: 0.9957197728211598\n",
      "Epoch: 1536 - time: 0.0031 - loss_train: 0.8918107070436031 - loss_val: 0.995669624329247\n",
      "Epoch: 1537 - time: 0.0031 - loss_train: 0.8917365254126223 - loss_val: 0.9956195434287404\n",
      "Epoch: 1538 - time: 0.0031 - loss_train: 0.8916624021872901 - loss_val: 0.9955695301810706\n",
      "Epoch: 1539 - time: 0.0031 - loss_train: 0.8915883372904618 - loss_val: 0.9955195846472052\n",
      "Epoch: 1540 - time: 0.0031 - loss_train: 0.8915143306450338 - loss_val: 0.9954697068876462\n",
      "Epoch: 1541 - time: 0.0031 - loss_train: 0.8914403821739425 - loss_val: 0.9954198969624328\n",
      "Epoch: 1542 - time: 0.0031 - loss_train: 0.8913664918001609 - loss_val: 0.9953701549311413\n",
      "Epoch: 1543 - time: 0.0031 - loss_train: 0.8912926594466969 - loss_val: 0.9953204808528824\n",
      "Epoch: 1544 - time: 0.0031 - loss_train: 0.891218885036589 - loss_val: 0.9952708747863059\n",
      "Epoch: 1545 - time: 0.0031 - loss_train: 0.891145168492905 - loss_val: 0.9952213367895975\n",
      "Epoch: 1546 - time: 0.0031 - loss_train: 0.8910715097387395 - loss_val: 0.9951718669204809\n",
      "Epoch: 1547 - time: 0.0036 - loss_train: 0.8909979086972099 - loss_val: 0.9951224652362197\n",
      "Epoch: 1548 - time: 0.0036 - loss_train: 0.8909243652914558 - loss_val: 0.9950731317936139\n",
      "Epoch: 1549 - time: 0.0036 - loss_train: 0.8908508794446343 - loss_val: 0.9950238666490046\n",
      "Epoch: 1550 - time: 0.0045 - loss_train: 0.8907774510799183 - loss_val: 0.9949746698582702\n",
      "Epoch: 1551 - time: 0.0045 - loss_train: 0.8907040801204944 - loss_val: 0.9949255414768324\n",
      "Epoch: 1552 - time: 0.0045 - loss_train: 0.8906307664895592 - loss_val: 0.9948764815596524\n",
      "Epoch: 1553 - time: 0.0036 - loss_train: 0.8905575101103175 - loss_val: 0.9948274901612326\n",
      "Epoch: 1554 - time: 0.0036 - loss_train: 0.8904843109059796 - loss_val: 0.994778567335619\n",
      "Epoch: 1555 - time: 0.0039 - loss_train: 0.8904111687997579 - loss_val: 0.9947297131364008\n",
      "Epoch: 1556 - time: 0.0037 - loss_train: 0.8903380837148653 - loss_val: 0.9946809276167098\n",
      "Epoch: 1557 - time: 0.0036 - loss_train: 0.8902650555745126 - loss_val: 0.9946322108292246\n",
      "Epoch: 1558 - time: 0.0036 - loss_train: 0.8901920843019047 - loss_val: 0.9945835628261677\n",
      "Epoch: 1559 - time: 0.0036 - loss_train: 0.8901191698202384 - loss_val: 0.9945349836593088\n",
      "Epoch: 1560 - time: 0.0036 - loss_train: 0.8900463120527018 - loss_val: 0.9944864733799659\n",
      "Epoch: 1561 - time: 0.0036 - loss_train: 0.8899735109224682 - loss_val: 0.994438032039004\n",
      "Epoch: 1562 - time: 0.0036 - loss_train: 0.8899007663526974 - loss_val: 0.9943896596868386\n",
      "Epoch: 1563 - time: 0.0041 - loss_train: 0.889828078266529 - loss_val: 0.9943413563734356\n",
      "Epoch: 1564 - time: 0.0043 - loss_train: 0.8897554465870833 - loss_val: 0.9942931221483126\n",
      "Epoch: 1565 - time: 0.0043 - loss_train: 0.8896828712374569 - loss_val: 0.9942449570605384\n",
      "Epoch: 1566 - time: 0.0044 - loss_train: 0.8896103521407199 - loss_val: 0.9941968611587385\n",
      "Epoch: 1567 - time: 0.0044 - loss_train: 0.8895378892199157 - loss_val: 0.9941488344910911\n",
      "Epoch: 1568 - time: 0.0043 - loss_train: 0.8894654823980548 - loss_val: 0.994100877105332\n",
      "Epoch: 1569 - time: 0.0045 - loss_train: 0.8893931315981157 - loss_val: 0.9940529890487518\n",
      "Epoch: 1570 - time: 0.0045 - loss_train: 0.8893208367430397 - loss_val: 0.9940051703682035\n",
      "Epoch: 1571 - time: 0.0046 - loss_train: 0.8892485977557301 - loss_val: 0.9939574211100974\n",
      "Epoch: 1572 - time: 0.0045 - loss_train: 0.889176414559049 - loss_val: 0.9939097413204052\n",
      "Epoch: 1573 - time: 0.0044 - loss_train: 0.889104287075814 - loss_val: 0.9938621310446633\n",
      "Epoch: 1574 - time: 0.0044 - loss_train: 0.8890322152287969 - loss_val: 0.9938145903279693\n",
      "Epoch: 1575 - time: 0.0043 - loss_train: 0.8889601989407216 - loss_val: 0.9937671192149893\n",
      "Epoch: 1576 - time: 0.0044 - loss_train: 0.8888882381342591 - loss_val: 0.9937197177499527\n",
      "Epoch: 1577 - time: 0.0044 - loss_train: 0.888816332732028 - loss_val: 0.9936723859766601\n",
      "Epoch: 1578 - time: 0.0046 - loss_train: 0.8887444826565893 - loss_val: 0.9936251239384799\n",
      "Epoch: 1579 - time: 0.0047 - loss_train: 0.8886726878304455 - loss_val: 0.9935779316783526\n",
      "Epoch: 1580 - time: 0.0046 - loss_train: 0.8886009481760389 - loss_val: 0.9935308092387927\n",
      "Epoch: 1581 - time: 0.0037 - loss_train: 0.888529263615746 - loss_val: 0.9934837566618863\n",
      "Epoch: 1582 - time: 0.0031 - loss_train: 0.8884576340718783 - loss_val: 0.9934367739892969\n",
      "Epoch: 1583 - time: 0.0031 - loss_train: 0.8883860594666778 - loss_val: 0.9933898612622666\n",
      "Epoch: 1584 - time: 0.0035 - loss_train: 0.8883145397223158 - loss_val: 0.9933430185216139\n",
      "Epoch: 1585 - time: 0.0032 - loss_train: 0.8882430747608892 - loss_val: 0.9932962458077405\n",
      "Epoch: 1586 - time: 0.0031 - loss_train: 0.8881716645044191 - loss_val: 0.9932495431606305\n",
      "Epoch: 1587 - time: 0.0031 - loss_train: 0.8881003088748474 - loss_val: 0.9932029106198502\n",
      "Epoch: 1588 - time: 0.0031 - loss_train: 0.8880290077940356 - loss_val: 0.9931563482245529\n",
      "Epoch: 1589 - time: 0.0031 - loss_train: 0.887957761183761 - loss_val: 0.993109856013479\n",
      "Epoch: 1590 - time: 0.0031 - loss_train: 0.8878865689657153 - loss_val: 0.9930634340249594\n",
      "Epoch: 1591 - time: 0.0031 - loss_train: 0.8878154310615014 - loss_val: 0.9930170822969145\n",
      "Epoch: 1592 - time: 0.0031 - loss_train: 0.8877443473926311 - loss_val: 0.9929708008668585\n",
      "Epoch: 1593 - time: 0.0031 - loss_train: 0.8876733178805241 - loss_val: 0.9929245897718998\n",
      "Epoch: 1594 - time: 0.0032 - loss_train: 0.8876023424465029 - loss_val: 0.9928784490487432\n",
      "Epoch: 1595 - time: 0.0031 - loss_train: 0.8875314210117936 - loss_val: 0.9928323787336929\n",
      "Epoch: 1596 - time: 0.0031 - loss_train: 0.8874605534975201 - loss_val: 0.9927863788626505\n",
      "Epoch: 1597 - time: 0.0031 - loss_train: 0.8873897398247047 - loss_val: 0.9927404494711219\n",
      "Epoch: 1598 - time: 0.0031 - loss_train: 0.8873189799142642 - loss_val: 0.9926945905942162\n",
      "Epoch: 1599 - time: 0.0031 - loss_train: 0.8872482736870075 - loss_val: 0.9926488022666483\n",
      "Epoch: 1600 - time: 0.0031 - loss_train: 0.8871776210636347 - loss_val: 0.9926030845227396\n",
      "Epoch: 1601 - time: 0.0031 - loss_train: 0.887107021964732 - loss_val: 0.9925574373964225\n",
      "Epoch: 1602 - time: 0.0031 - loss_train: 0.8870364763107725 - loss_val: 0.9925118609212396\n",
      "Epoch: 1603 - time: 0.0031 - loss_train: 0.8869659840221115 - loss_val: 0.9924663551303485\n",
      "Epoch: 1604 - time: 0.0031 - loss_train: 0.8868955450189856 - loss_val: 0.9924209200565199\n",
      "Epoch: 1605 - time: 0.0031 - loss_train: 0.8868251592215092 - loss_val: 0.9923755557321433\n",
      "Epoch: 1606 - time: 0.0031 - loss_train: 0.8867548265496746 - loss_val: 0.9923302621892256\n",
      "Epoch: 1607 - time: 0.0031 - loss_train: 0.8866845469233456 - loss_val: 0.9922850394593967\n",
      "Epoch: 1608 - time: 0.0031 - loss_train: 0.8866143202622598 - loss_val: 0.9922398875739087\n",
      "Epoch: 1609 - time: 0.0031 - loss_train: 0.8865441464860235 - loss_val: 0.9921948065636388\n",
      "Epoch: 1610 - time: 0.0031 - loss_train: 0.8864740255141091 - loss_val: 0.9921497964590914\n",
      "Epoch: 1611 - time: 0.0031 - loss_train: 0.8864039572658553 - loss_val: 0.9921048572903992\n",
      "Epoch: 1612 - time: 0.0031 - loss_train: 0.8863339416604633 - loss_val: 0.992059989087326\n",
      "Epoch: 1613 - time: 0.0031 - loss_train: 0.8862639786169942 - loss_val: 0.9920151918792705\n",
      "Epoch: 1614 - time: 0.0031 - loss_train: 0.8861940680543671 - loss_val: 0.9919704656952629\n",
      "Epoch: 1615 - time: 0.0032 - loss_train: 0.8861242098913581 - loss_val: 0.9919258105639719\n",
      "Epoch: 1616 - time: 0.0031 - loss_train: 0.8860544040465965 - loss_val: 0.9918812265137065\n",
      "Epoch: 1617 - time: 0.0031 - loss_train: 0.8859846504385641 - loss_val: 0.9918367135724158\n",
      "Epoch: 1618 - time: 0.0031 - loss_train: 0.8859149489855918 - loss_val: 0.9917922717676897\n",
      "Epoch: 1619 - time: 0.0031 - loss_train: 0.8858452996058566 - loss_val: 0.9917479011267647\n",
      "Epoch: 1620 - time: 0.0031 - loss_train: 0.8857757022173821 - loss_val: 0.9917036016765249\n",
      "Epoch: 1621 - time: 0.0031 - loss_train: 0.8857061567380365 - loss_val: 0.9916593734435017\n",
      "Epoch: 1622 - time: 0.0035 - loss_train: 0.885636663085526 - loss_val: 0.9916152164538778\n",
      "Epoch: 1623 - time: 0.0032 - loss_train: 0.8855672211773978 - loss_val: 0.9915711307334887\n",
      "Epoch: 1624 - time: 0.0031 - loss_train: 0.8854978309310347 - loss_val: 0.9915271163078251\n",
      "Epoch: 1625 - time: 0.0031 - loss_train: 0.885428492263656 - loss_val: 0.9914831732020325\n",
      "Epoch: 1626 - time: 0.0031 - loss_train: 0.8853592050923119 - loss_val: 0.991439301440917\n",
      "Epoch: 1627 - time: 0.0031 - loss_train: 0.885289969333884 - loss_val: 0.9913955010489452\n",
      "Epoch: 1628 - time: 0.0031 - loss_train: 0.8852207849050833 - loss_val: 0.9913517720502438\n",
      "Epoch: 1629 - time: 0.0031 - loss_train: 0.8851516517224463 - loss_val: 0.9913081144686072\n",
      "Epoch: 1630 - time: 0.0031 - loss_train: 0.885082569702334 - loss_val: 0.9912645283274925\n",
      "Epoch: 1631 - time: 0.0031 - loss_train: 0.8850135387609324 - loss_val: 0.9912210136500286\n",
      "Epoch: 1632 - time: 0.0031 - loss_train: 0.884944558814245 - loss_val: 0.9911775704590118\n",
      "Epoch: 1633 - time: 0.0031 - loss_train: 0.884875629778096 - loss_val: 0.9911341987769112\n",
      "Epoch: 1634 - time: 0.0031 - loss_train: 0.8848067515681259 - loss_val: 0.9910908986258692\n",
      "Epoch: 1635 - time: 0.0031 - loss_train: 0.8847379240997902 - loss_val: 0.991047670027705\n",
      "Epoch: 1636 - time: 0.0031 - loss_train: 0.8846691472883574 - loss_val: 0.9910045130039139\n",
      "Epoch: 1637 - time: 0.0031 - loss_train: 0.8846004210489068 - loss_val: 0.9909614275756709\n",
      "Epoch: 1638 - time: 0.0031 - loss_train: 0.8845317452963268 - loss_val: 0.9909184137638322\n",
      "Epoch: 1639 - time: 0.0031 - loss_train: 0.8844631199453133 - loss_val: 0.9908754715889361\n",
      "Epoch: 1640 - time: 0.0031 - loss_train: 0.8843945449103685 - loss_val: 0.9908326010712071\n",
      "Epoch: 1641 - time: 0.0031 - loss_train: 0.8843260201057972 - loss_val: 0.9907898022305532\n",
      "Epoch: 1642 - time: 0.0031 - loss_train: 0.8842575454457061 - loss_val: 0.9907470750865724\n",
      "Epoch: 1643 - time: 0.0031 - loss_train: 0.8841891208440023 - loss_val: 0.9907044196585525\n",
      "Epoch: 1644 - time: 0.0031 - loss_train: 0.8841207462143914 - loss_val: 0.9906618359654707\n",
      "Epoch: 1645 - time: 0.0031 - loss_train: 0.8840524214703751 - loss_val: 0.9906193240259993\n",
      "Epoch: 1646 - time: 0.0031 - loss_train: 0.8839841465252503 - loss_val: 0.9905768838585021\n",
      "Epoch: 1647 - time: 0.0031 - loss_train: 0.8839159212921064 - loss_val: 0.990534515481043\n",
      "Epoch: 1648 - time: 0.0031 - loss_train: 0.883847745683825 - loss_val: 0.9904922189113794\n",
      "Epoch: 1649 - time: 0.0031 - loss_train: 0.8837796196130762 - loss_val: 0.9904499941669721\n",
      "Epoch: 1650 - time: 0.0031 - loss_train: 0.8837115429923192 - loss_val: 0.990407841264978\n",
      "Epoch: 1651 - time: 0.0031 - loss_train: 0.8836435157337998 - loss_val: 0.9903657602222595\n",
      "Epoch: 1652 - time: 0.0031 - loss_train: 0.883575537749547 - loss_val: 0.9903237510553812\n",
      "Epoch: 1653 - time: 0.0031 - loss_train: 0.8835076089513741 - loss_val: 0.9902818137806124\n",
      "Epoch: 1654 - time: 0.0031 - loss_train: 0.8834397292508762 - loss_val: 0.9902399484139303\n",
      "Epoch: 1655 - time: 0.0031 - loss_train: 0.8833718985594279 - loss_val: 0.9901981549710175\n",
      "Epoch: 1656 - time: 0.0031 - loss_train: 0.8833041167881824 - loss_val: 0.9901564334672671\n",
      "Epoch: 1657 - time: 0.0031 - loss_train: 0.8832363838480689 - loss_val: 0.9901147839177802\n",
      "Epoch: 1658 - time: 0.0031 - loss_train: 0.8831686996497944 - loss_val: 0.990073206337374\n",
      "Epoch: 1659 - time: 0.0031 - loss_train: 0.8831010641038369 - loss_val: 0.9900317007405717\n",
      "Epoch: 1660 - time: 0.0035 - loss_train: 0.8830334771204496 - loss_val: 0.9899902671416158\n",
      "Epoch: 1661 - time: 0.0032 - loss_train: 0.882965938609655 - loss_val: 0.9899489055544609\n",
      "Epoch: 1662 - time: 0.0031 - loss_train: 0.8828984484812459 - loss_val: 0.9899076159927781\n",
      "Epoch: 1663 - time: 0.0031 - loss_train: 0.8828310066447833 - loss_val: 0.9898663984699558\n",
      "Epoch: 1664 - time: 0.0031 - loss_train: 0.882763613009595 - loss_val: 0.9898252529991\n",
      "Epoch: 1665 - time: 0.0031 - loss_train: 0.8826962674847753 - loss_val: 0.9897841795930347\n",
      "Epoch: 1666 - time: 0.0031 - loss_train: 0.8826289699791807 - loss_val: 0.9897431782643039\n",
      "Epoch: 1667 - time: 0.0031 - loss_train: 0.8825617204014329 - loss_val: 0.9897022490251739\n",
      "Epoch: 1668 - time: 0.0031 - loss_train: 0.8824945186599138 - loss_val: 0.9896613918876297\n",
      "Epoch: 1669 - time: 0.0031 - loss_train: 0.8824273646627666 - loss_val: 0.9896206068633803\n",
      "Epoch: 1670 - time: 0.0031 - loss_train: 0.8823602583178931 - loss_val: 0.9895798939638565\n",
      "Epoch: 1671 - time: 0.0031 - loss_train: 0.8822931995329535 - loss_val: 0.9895392532002121\n",
      "Epoch: 1672 - time: 0.0031 - loss_train: 0.8822261882153654 - loss_val: 0.9894986845833259\n",
      "Epoch: 1673 - time: 0.0031 - loss_train: 0.8821592242723012 - loss_val: 0.9894581881238018\n",
      "Epoch: 1674 - time: 0.0031 - loss_train: 0.8820923076106882 - loss_val: 0.9894177638319663\n",
      "Epoch: 1675 - time: 0.0031 - loss_train: 0.8820254381372079 - loss_val: 0.9893774117178725\n",
      "Epoch: 1676 - time: 0.0031 - loss_train: 0.8819586157582933 - loss_val: 0.9893371317913009\n",
      "Epoch: 1677 - time: 0.0031 - loss_train: 0.8818918403801297 - loss_val: 0.989296924061755\n",
      "Epoch: 1678 - time: 0.0031 - loss_train: 0.8818251119086526 - loss_val: 0.9892567885384685\n",
      "Epoch: 1679 - time: 0.0031 - loss_train: 0.881758430249547 - loss_val: 0.989216725230397\n",
      "Epoch: 1680 - time: 0.0031 - loss_train: 0.8816917953082466 - loss_val: 0.989176734146227\n",
      "Epoch: 1681 - time: 0.0031 - loss_train: 0.8816252069899327 - loss_val: 0.9891368152943687\n",
      "Epoch: 1682 - time: 0.0031 - loss_train: 0.8815586651995332 - loss_val: 0.9890969686829614\n",
      "Epoch: 1683 - time: 0.0031 - loss_train: 0.8814921698417222 - loss_val: 0.9890571943198683\n",
      "Epoch: 1684 - time: 0.0031 - loss_train: 0.8814257208209191 - loss_val: 0.9890174922126826\n",
      "Epoch: 1685 - time: 0.0031 - loss_train: 0.8813593180412868 - loss_val: 0.9889778623687212\n",
      "Epoch: 1686 - time: 0.0031 - loss_train: 0.8812929614067325 - loss_val: 0.988938304795028\n",
      "Epoch: 1687 - time: 0.0031 - loss_train: 0.8812266508209066 - loss_val: 0.9888988194983724\n",
      "Epoch: 1688 - time: 0.0031 - loss_train: 0.8811603861872015 - loss_val: 0.9888594064852507\n",
      "Epoch: 1689 - time: 0.0031 - loss_train: 0.8810941674087501 - loss_val: 0.9888200657618812\n",
      "Epoch: 1690 - time: 0.0031 - loss_train: 0.8810279943884276 - loss_val: 0.9887807973342096\n",
      "Epoch: 1691 - time: 0.0031 - loss_train: 0.880961867028849 - loss_val: 0.9887416012079031\n",
      "Epoch: 1692 - time: 0.0031 - loss_train: 0.8808957852323686 - loss_val: 0.9887024773883527\n",
      "Epoch: 1693 - time: 0.0031 - loss_train: 0.8808297489010806 - loss_val: 0.988663425880673\n",
      "Epoch: 1694 - time: 0.0031 - loss_train: 0.8807637579368179 - loss_val: 0.9886244466896975\n",
      "Epoch: 1695 - time: 0.0031 - loss_train: 0.8806978122411523 - loss_val: 0.9885855398199829\n",
      "Epoch: 1696 - time: 0.0031 - loss_train: 0.8806319117153921 - loss_val: 0.9885467052758032\n",
      "Epoch: 1697 - time: 0.0031 - loss_train: 0.8805660562605847 - loss_val: 0.9885079430611519\n",
      "Epoch: 1698 - time: 0.0035 - loss_train: 0.8805002457775135 - loss_val: 0.9884692531797407\n",
      "Epoch: 1699 - time: 0.0032 - loss_train: 0.8804344801666999 - loss_val: 0.9884306356349948\n",
      "Epoch: 1700 - time: 0.0031 - loss_train: 0.8803687593284014 - loss_val: 0.9883920904300575\n",
      "Epoch: 1701 - time: 0.0031 - loss_train: 0.8803030831626124 - loss_val: 0.988353617567782\n",
      "Epoch: 1702 - time: 0.0031 - loss_train: 0.880237451569064 - loss_val: 0.9883152170507358\n",
      "Epoch: 1703 - time: 0.0031 - loss_train: 0.8801718644472223 - loss_val: 0.9882768888811964\n",
      "Epoch: 1704 - time: 0.0031 - loss_train: 0.8801063216962905 - loss_val: 0.9882386330611471\n",
      "Epoch: 1705 - time: 0.0031 - loss_train: 0.8800408232152079 - loss_val: 0.9882004495922817\n",
      "Epoch: 1706 - time: 0.0031 - loss_train: 0.8799753689026497 - loss_val: 0.9881623384759964\n",
      "Epoch: 1707 - time: 0.0031 - loss_train: 0.8799099586570271 - loss_val: 0.9881242997133927\n",
      "Epoch: 1708 - time: 0.0032 - loss_train: 0.8798445923764877 - loss_val: 0.9880863333052684\n",
      "Epoch: 1709 - time: 0.0031 - loss_train: 0.8797792699589156 - loss_val: 0.9880484392521264\n",
      "Epoch: 1710 - time: 0.0031 - loss_train: 0.8797139913019305 - loss_val: 0.9880106175541616\n",
      "Epoch: 1711 - time: 0.0031 - loss_train: 0.8796487563028906 - loss_val: 0.987972868211264\n",
      "Epoch: 1712 - time: 0.0031 - loss_train: 0.8795835648588899 - loss_val: 0.987935191223017\n",
      "Epoch: 1713 - time: 0.0031 - loss_train: 0.8795184168667591 - loss_val: 0.9878975865886915\n",
      "Epoch: 1714 - time: 0.0031 - loss_train: 0.8794533122230689 - loss_val: 0.9878600543072458\n",
      "Epoch: 1715 - time: 0.0031 - loss_train: 0.8793882508241259 - loss_val: 0.9878225943773213\n",
      "Epoch: 1716 - time: 0.0031 - loss_train: 0.8793232325659763 - loss_val: 0.9877852067972422\n",
      "Epoch: 1717 - time: 0.0031 - loss_train: 0.8792582573444054 - loss_val: 0.9877478915650088\n",
      "Epoch: 1718 - time: 0.0031 - loss_train: 0.8791933250549375 - loss_val: 0.9877106486782975\n",
      "Epoch: 1719 - time: 0.0031 - loss_train: 0.8791284355928383 - loss_val: 0.9876734781344573\n",
      "Epoch: 1720 - time: 0.0031 - loss_train: 0.8790635888531132 - loss_val: 0.9876363799305038\n",
      "Epoch: 1721 - time: 0.0031 - loss_train: 0.8789987847305106 - loss_val: 0.9875993540631204\n",
      "Epoch: 1722 - time: 0.0031 - loss_train: 0.8789340231195192 - loss_val: 0.9875624005286509\n",
      "Epoch: 1723 - time: 0.0031 - loss_train: 0.8788693039143743 - loss_val: 0.9875255193230972\n",
      "Epoch: 1724 - time: 0.0031 - loss_train: 0.8788046270090517 - loss_val: 0.987488710442117\n",
      "Epoch: 1725 - time: 0.0031 - loss_train: 0.8787399922972745 - loss_val: 0.9874519738810167\n",
      "Epoch: 1726 - time: 0.0031 - loss_train: 0.8786753996725116 - loss_val: 0.9874153096347513\n",
      "Epoch: 1727 - time: 0.0031 - loss_train: 0.8786108490279785 - loss_val: 0.987378717697918\n",
      "Epoch: 1728 - time: 0.0031 - loss_train: 0.8785463402566391 - loss_val: 0.9873421980647527\n",
      "Epoch: 1729 - time: 0.0031 - loss_train: 0.8784818732512072 - loss_val: 0.9873057507291251\n",
      "Epoch: 1730 - time: 0.0031 - loss_train: 0.8784174479041459 - loss_val: 0.9872693756845365\n",
      "Epoch: 1731 - time: 0.0031 - loss_train: 0.8783530641076713 - loss_val: 0.9872330729241121\n",
      "Epoch: 1732 - time: 0.0031 - loss_train: 0.8782887217537527 - loss_val: 0.987196842440597\n",
      "Epoch: 1733 - time: 0.0031 - loss_train: 0.8782244207341138 - loss_val: 0.9871606842263556\n",
      "Epoch: 1734 - time: 0.0031 - loss_train: 0.8781601609402342 - loss_val: 0.9871245982733613\n",
      "Epoch: 1735 - time: 0.0032 - loss_train: 0.8780959422633514 - loss_val: 0.9870885845731925\n",
      "Epoch: 1736 - time: 0.0035 - loss_train: 0.8780317645944625 - loss_val: 0.987052643117031\n",
      "Epoch: 1737 - time: 0.0032 - loss_train: 0.8779676278243248 - loss_val: 0.9870167738956546\n",
      "Epoch: 1738 - time: 0.0031 - loss_train: 0.8779035318434585 - loss_val: 0.9869809768994289\n",
      "Epoch: 1739 - time: 0.0031 - loss_train: 0.8778394765421481 - loss_val: 0.9869452521183069\n",
      "Epoch: 1740 - time: 0.0031 - loss_train: 0.8777754618104451 - loss_val: 0.9869095995418204\n",
      "Epoch: 1741 - time: 0.0031 - loss_train: 0.8777114875381683 - loss_val: 0.9868740191590736\n",
      "Epoch: 1742 - time: 0.0031 - loss_train: 0.8776475536149071 - loss_val: 0.9868385109587403\n",
      "Epoch: 1743 - time: 0.0031 - loss_train: 0.877583659930023 - loss_val: 0.9868030749290534\n",
      "Epoch: 1744 - time: 0.0032 - loss_train: 0.8775198063726525 - loss_val: 0.9867677110578041\n",
      "Epoch: 1745 - time: 0.0032 - loss_train: 0.8774559928317078 - loss_val: 0.9867324193323311\n",
      "Epoch: 1746 - time: 0.0032 - loss_train: 0.877392219195881 - loss_val: 0.986697199739516\n",
      "Epoch: 1747 - time: 0.0031 - loss_train: 0.8773284853536444 - loss_val: 0.9866620522657774\n",
      "Epoch: 1748 - time: 0.0032 - loss_train: 0.877264791193255 - loss_val: 0.986626976897063\n",
      "Epoch: 1749 - time: 0.0032 - loss_train: 0.877201136602755 - loss_val: 0.9865919736188423\n",
      "Epoch: 1750 - time: 0.0032 - loss_train: 0.8771375214699766 - loss_val: 0.9865570424161026\n",
      "Epoch: 1751 - time: 0.0032 - loss_train: 0.8770739456825423 - loss_val: 0.9865221832733382\n",
      "Epoch: 1752 - time: 0.0032 - loss_train: 0.8770104091278692 - loss_val: 0.9864873961745456\n",
      "Epoch: 1753 - time: 0.0031 - loss_train: 0.8769469116931706 - loss_val: 0.9864526811032152\n",
      "Epoch: 1754 - time: 0.0031 - loss_train: 0.876883453265462 - loss_val: 0.9864180380423231\n",
      "Epoch: 1755 - time: 0.0031 - loss_train: 0.8768200337315587 - loss_val: 0.9863834669743262\n",
      "Epoch: 1756 - time: 0.0031 - loss_train: 0.876756652978084 - loss_val: 0.9863489678811517\n",
      "Epoch: 1757 - time: 0.0031 - loss_train: 0.8766933108914693 - loss_val: 0.986314540744188\n",
      "Epoch: 1758 - time: 0.0031 - loss_train: 0.8766300073579585 - loss_val: 0.9862801855442827\n",
      "Epoch: 1759 - time: 0.0032 - loss_train: 0.8765667422636109 - loss_val: 0.9862459022617263\n",
      "Epoch: 1760 - time: 0.0032 - loss_train: 0.8765035154943044 - loss_val: 0.98621169087625\n",
      "Epoch: 1761 - time: 0.0031 - loss_train: 0.8764403269357408 - loss_val: 0.9861775513670138\n",
      "Epoch: 1762 - time: 0.0031 - loss_train: 0.8763771764734455 - loss_val: 0.9861434837126017\n",
      "Epoch: 1763 - time: 0.0031 - loss_train: 0.8763140639927751 - loss_val: 0.9861094878910065\n",
      "Epoch: 1764 - time: 0.0031 - loss_train: 0.876250989378919 - loss_val: 0.9860755638796279\n",
      "Epoch: 1765 - time: 0.0032 - loss_train: 0.8761879525169038 - loss_val: 0.9860417116552579\n",
      "Epoch: 1766 - time: 0.0032 - loss_train: 0.8761249532915975 - loss_val: 0.9860079311940758\n",
      "Epoch: 1767 - time: 0.0031 - loss_train: 0.8760619915877121 - loss_val: 0.9859742224716359\n",
      "Epoch: 1768 - time: 0.0031 - loss_train: 0.8759990672898096 - loss_val: 0.9859405854628596\n",
      "Epoch: 1769 - time: 0.0031 - loss_train: 0.8759361802823055 - loss_val: 0.9859070201420236\n",
      "Epoch: 1770 - time: 0.0031 - loss_train: 0.8758733304494721 - loss_val: 0.9858735264827544\n",
      "Epoch: 1771 - time: 0.0031 - loss_train: 0.8758105176754442 - loss_val: 0.985840104458014\n",
      "Epoch: 1772 - time: 0.0032 - loss_train: 0.8757477418442227 - loss_val: 0.9858067540400904\n",
      "Epoch: 1773 - time: 0.0031 - loss_train: 0.8756850028396796 - loss_val: 0.9857734752005921\n",
      "Epoch: 1774 - time: 0.0038 - loss_train: 0.8756223005455632 - loss_val: 0.985740267910429\n",
      "Epoch: 1775 - time: 0.0033 - loss_train: 0.8755596348455004 - loss_val: 0.9857071321398123\n",
      "Epoch: 1776 - time: 0.0032 - loss_train: 0.8754970056230058 - loss_val: 0.9856740678582351\n",
      "Epoch: 1777 - time: 0.0031 - loss_train: 0.8754344127614822 - loss_val: 0.9856410750344663\n",
      "Epoch: 1778 - time: 0.0031 - loss_train: 0.8753718561442283 - loss_val: 0.9856081536365376\n",
      "Epoch: 1779 - time: 0.0031 - loss_train: 0.8753093356544435 - loss_val: 0.985575303631734\n",
      "Epoch: 1780 - time: 0.0035 - loss_train: 0.8752468511752332 - loss_val: 0.9855425249865829\n",
      "Epoch: 1781 - time: 0.0032 - loss_train: 0.875184402589612 - loss_val: 0.9855098176668375\n",
      "Epoch: 1782 - time: 0.0031 - loss_train: 0.8751219897805129 - loss_val: 0.9854771816374751\n",
      "Epoch: 1783 - time: 0.0031 - loss_train: 0.8750596126307904 - loss_val: 0.9854446168626763\n",
      "Epoch: 1784 - time: 0.0039 - loss_train: 0.8749972710232262 - loss_val: 0.9854121233058173\n",
      "Epoch: 1785 - time: 0.0031 - loss_train: 0.8749349648405361 - loss_val: 0.9853797009294589\n",
      "Epoch: 1786 - time: 0.0031 - loss_train: 0.8748726939653754 - loss_val: 0.9853473496953303\n",
      "Epoch: 1787 - time: 0.0031 - loss_train: 0.8748104582803433 - loss_val: 0.9853150695643219\n",
      "Epoch: 1788 - time: 0.0031 - loss_train: 0.8747482576679922 - loss_val: 0.9852828604964696\n",
      "Epoch: 1789 - time: 0.0056 - loss_train: 0.8746860920108313 - loss_val: 0.985250722450944\n",
      "Epoch: 1790 - time: 0.0046 - loss_train: 0.8746239611913328 - loss_val: 0.9852186553860381\n",
      "Epoch: 1791 - time: 0.0045 - loss_train: 0.8745618650919417 - loss_val: 0.9851866592591514\n",
      "Epoch: 1792 - time: 0.0043 - loss_train: 0.8744998035950778 - loss_val: 0.9851547340267814\n",
      "Epoch: 1793 - time: 0.0037 - loss_train: 0.874437776583145 - loss_val: 0.9851228796445077\n",
      "Epoch: 1794 - time: 0.0046 - loss_train: 0.8743757839385378 - loss_val: 0.9850910960669808\n",
      "Epoch: 1795 - time: 0.0044 - loss_train: 0.8743138255436472 - loss_val: 0.9850593832479071\n",
      "Epoch: 1796 - time: 0.0043 - loss_train: 0.8742519012808684 - loss_val: 0.9850277411400356\n",
      "Epoch: 1797 - time: 0.0047 - loss_train: 0.8741900110326087 - loss_val: 0.9849961696951476\n",
      "Epoch: 1798 - time: 0.0045 - loss_train: 0.8741281546812927 - loss_val: 0.984964668864038\n",
      "Epoch: 1799 - time: 0.0045 - loss_train: 0.8740663321093707 - loss_val: 0.9849332385965072\n",
      "Epoch: 1800 - time: 0.0044 - loss_train: 0.874004543199327 - loss_val: 0.9849018788413417\n",
      "Epoch: 1801 - time: 0.0045 - loss_train: 0.8739427878336853 - loss_val: 0.9848705895463045\n",
      "Epoch: 1802 - time: 0.0045 - loss_train: 0.873881065895019 - loss_val: 0.9848393706581186\n",
      "Epoch: 1803 - time: 0.0045 - loss_train: 0.8738193772659566 - loss_val: 0.9848082221224547\n",
      "Epoch: 1804 - time: 0.0044 - loss_train: 0.8737577218291902 - loss_val: 0.9847771438839158\n",
      "Epoch: 1805 - time: 0.0043 - loss_train: 0.873696099467485 - loss_val: 0.9847461358860211\n",
      "Epoch: 1806 - time: 0.0037 - loss_train: 0.8736345100636859 - loss_val: 0.9847151980711967\n",
      "Epoch: 1807 - time: 0.0037 - loss_train: 0.8735729535007245 - loss_val: 0.9846843303807543\n",
      "Epoch: 1808 - time: 0.0037 - loss_train: 0.8735114296616316 - loss_val: 0.9846535327548838\n",
      "Epoch: 1809 - time: 0.0031 - loss_train: 0.8734499384295417 - loss_val: 0.9846228051326303\n",
      "Epoch: 1810 - time: 0.0031 - loss_train: 0.8733884796877023 - loss_val: 0.984592147451888\n",
      "Epoch: 1811 - time: 0.0031 - loss_train: 0.8733270533194841 - loss_val: 0.9845615596493796\n",
      "Epoch: 1812 - time: 0.0031 - loss_train: 0.8732656592083893 - loss_val: 0.9845310416606403\n",
      "Epoch: 1813 - time: 0.0031 - loss_train: 0.8732042972380595 - loss_val: 0.9845005934200095\n",
      "Epoch: 1814 - time: 0.0031 - loss_train: 0.8731429672922851 - loss_val: 0.9844702148606082\n",
      "Epoch: 1815 - time: 0.0031 - loss_train: 0.8730816692550154 - loss_val: 0.9844399059143277\n",
      "Epoch: 1816 - time: 0.0031 - loss_train: 0.8730204030103679 - loss_val: 0.9844096665118143\n",
      "Epoch: 1817 - time: 0.0031 - loss_train: 0.872959168442635 - loss_val: 0.9843794965824528\n",
      "Epoch: 1818 - time: 0.0032 - loss_train: 0.8728979654362975 - loss_val: 0.9843493960543497\n",
      "Epoch: 1819 - time: 0.0031 - loss_train: 0.8728367938760309 - loss_val: 0.9843193648543231\n",
      "Epoch: 1820 - time: 0.0031 - loss_train: 0.8727756536467169 - loss_val: 0.98428940290788\n",
      "Epoch: 1821 - time: 0.0032 - loss_train: 0.8727145446334541 - loss_val: 0.984259510139206\n",
      "Epoch: 1822 - time: 0.0031 - loss_train: 0.8726534667215643 - loss_val: 0.9842296864711473\n",
      "Epoch: 1823 - time: 0.0031 - loss_train: 0.872592419796606 - loss_val: 0.9841999318251972\n",
      "Epoch: 1824 - time: 0.0031 - loss_train: 0.8725314037443841 - loss_val: 0.9841702461214777\n",
      "Epoch: 1825 - time: 0.0031 - loss_train: 0.8724704184509585 - loss_val: 0.9841406292787249\n",
      "Epoch: 1826 - time: 0.0031 - loss_train: 0.8724094638026575 - loss_val: 0.9841110812142733\n",
      "Epoch: 1827 - time: 0.0032 - loss_train: 0.8723485396860837 - loss_val: 0.9840816018440421\n",
      "Epoch: 1828 - time: 0.0031 - loss_train: 0.8722876459881298 - loss_val: 0.9840521910825152\n",
      "Epoch: 1829 - time: 0.0032 - loss_train: 0.8722267825959856 - loss_val: 0.9840228488427286\n",
      "Epoch: 1830 - time: 0.0032 - loss_train: 0.8721659493971502 - loss_val: 0.9839935750362531\n",
      "Epoch: 1831 - time: 0.0032 - loss_train: 0.8721051462794435 - loss_val: 0.9839643695731803\n",
      "Epoch: 1832 - time: 0.0032 - loss_train: 0.8720443731310157 - loss_val: 0.9839352323621047\n",
      "Epoch: 1833 - time: 0.0031 - loss_train: 0.8719836298403607 - loss_val: 0.9839061633101104\n",
      "Epoch: 1834 - time: 0.0031 - loss_train: 0.8719229162963249 - loss_val: 0.9838771623227518\n",
      "Epoch: 1835 - time: 0.0031 - loss_train: 0.87186223238812 - loss_val: 0.9838482293040417\n",
      "Epoch: 1836 - time: 0.0031 - loss_train: 0.8718015780053348 - loss_val: 0.9838193641564337\n",
      "Epoch: 1837 - time: 0.0031 - loss_train: 0.8717409530379447 - loss_val: 0.9837905667808052\n",
      "Epoch: 1838 - time: 0.0031 - loss_train: 0.871680357376327 - loss_val: 0.9837618370764467\n",
      "Epoch: 1839 - time: 0.0031 - loss_train: 0.8716197909112686 - loss_val: 0.9837331749410401\n",
      "Epoch: 1840 - time: 0.0031 - loss_train: 0.8715592535339803 - loss_val: 0.9837045802706471\n",
      "Epoch: 1841 - time: 0.0032 - loss_train: 0.8714987451361084 - loss_val: 0.983676052959693\n",
      "Epoch: 1842 - time: 0.0032 - loss_train: 0.8714382656097465 - loss_val: 0.9836475929009524\n",
      "Epoch: 1843 - time: 0.0034 - loss_train: 0.871377814847447 - loss_val: 0.9836191999855296\n",
      "Epoch: 1844 - time: 0.0032 - loss_train: 0.8713173927422343 - loss_val: 0.9835908741028501\n",
      "Epoch: 1845 - time: 0.0032 - loss_train: 0.8712569991876178 - loss_val: 0.98356261514064\n",
      "Epoch: 1846 - time: 0.0031 - loss_train: 0.8711966340776016 - loss_val: 0.9835344229849142\n",
      "Epoch: 1847 - time: 0.0031 - loss_train: 0.871136297306699 - loss_val: 0.9835062975199599\n",
      "Epoch: 1848 - time: 0.0032 - loss_train: 0.8710759887699452 - loss_val: 0.983478238628322\n",
      "Epoch: 1849 - time: 0.0032 - loss_train: 0.8710157083629092 - loss_val: 0.9834502461907902\n",
      "Epoch: 1850 - time: 0.0035 - loss_train: 0.8709554559817062 - loss_val: 0.9834223200863829\n",
      "Epoch: 1851 - time: 0.0036 - loss_train: 0.8708952315230113 - loss_val: 0.9833944601923329\n",
      "Epoch: 1852 - time: 0.0032 - loss_train: 0.870835034884071 - loss_val: 0.9833666663840738\n",
      "Epoch: 1853 - time: 0.0032 - loss_train: 0.8707748659627174 - loss_val: 0.9833389385352257\n",
      "Epoch: 1854 - time: 0.0032 - loss_train: 0.8707147246573819 - loss_val: 0.9833112765175819\n",
      "Epoch: 1855 - time: 0.0031 - loss_train: 0.8706546108671048 - loss_val: 0.983283680201094\n",
      "Epoch: 1856 - time: 0.0031 - loss_train: 0.8705945244915521 - loss_val: 0.9832561494538609\n",
      "Epoch: 1857 - time: 0.0032 - loss_train: 0.8705344654310266 - loss_val: 0.9832286841421121\n",
      "Epoch: 1858 - time: 0.0032 - loss_train: 0.8704744335864814 - loss_val: 0.9832012841301977\n",
      "Epoch: 1859 - time: 0.0031 - loss_train: 0.8704144288595339 - loss_val: 0.9831739492805724\n",
      "Epoch: 1860 - time: 0.0031 - loss_train: 0.8703544511524781 - loss_val: 0.9831466794537882\n",
      "Epoch: 1861 - time: 0.0032 - loss_train: 0.8702945003682983 - loss_val: 0.9831194745084751\n",
      "Epoch: 1862 - time: 0.0032 - loss_train: 0.8702345764106819 - loss_val: 0.9830923343013338\n",
      "Epoch: 1863 - time: 0.0032 - loss_train: 0.8701746791840358 - loss_val: 0.9830652586871234\n",
      "Epoch: 1864 - time: 0.0032 - loss_train: 0.8701148085934938 - loss_val: 0.9830382475186457\n",
      "Epoch: 1865 - time: 0.0031 - loss_train: 0.8700549645449364 - loss_val: 0.9830113006467401\n",
      "Epoch: 1866 - time: 0.0031 - loss_train: 0.8699951469449998 - loss_val: 0.9829844179202678\n",
      "Epoch: 1867 - time: 0.0031 - loss_train: 0.8699353557010925 - loss_val: 0.9829575991861028\n",
      "Epoch: 1868 - time: 0.0032 - loss_train: 0.8698755907214061 - loss_val: 0.982930844289121\n",
      "Epoch: 1869 - time: 0.0031 - loss_train: 0.869815851914931 - loss_val: 0.9829041530721893\n",
      "Epoch: 1870 - time: 0.0031 - loss_train: 0.8697561391914689 - loss_val: 0.9828775253761587\n",
      "Epoch: 1871 - time: 0.0031 - loss_train: 0.8696964524616453 - loss_val: 0.982850961039849\n",
      "Epoch: 1872 - time: 0.0031 - loss_train: 0.8696367916369253 - loss_val: 0.9828244599000473\n",
      "Epoch: 1873 - time: 0.0032 - loss_train: 0.8695771566296258 - loss_val: 0.9827980217914924\n",
      "Epoch: 1874 - time: 0.0032 - loss_train: 0.8695175473529289 - loss_val: 0.9827716465468695\n",
      "Epoch: 1875 - time: 0.0031 - loss_train: 0.8694579637208961 - loss_val: 0.9827453339968019\n",
      "Epoch: 1876 - time: 0.0032 - loss_train: 0.8693984056484801 - loss_val: 0.9827190839698419\n",
      "Epoch: 1877 - time: 0.0032 - loss_train: 0.8693388730515406 - loss_val: 0.9826928962924661\n",
      "Epoch: 1878 - time: 0.0031 - loss_train: 0.8692793658468558 - loss_val: 0.9826667707890654\n",
      "Epoch: 1879 - time: 0.0031 - loss_train: 0.8692198839521371 - loss_val: 0.9826407072819404\n",
      "Epoch: 1880 - time: 0.0034 - loss_train: 0.8691604272860413 - loss_val: 0.9826147055912948\n",
      "Epoch: 1881 - time: 0.0032 - loss_train: 0.8691009957681842 - loss_val: 0.9825887655352312\n",
      "Epoch: 1882 - time: 0.0031 - loss_train: 0.8690415893191545 - loss_val: 0.9825628869297426\n",
      "Epoch: 1883 - time: 0.0031 - loss_train: 0.8689822078605263 - loss_val: 0.9825370695887083\n",
      "Epoch: 1884 - time: 0.0031 - loss_train: 0.8689228513148723 - loss_val: 0.9825113133238951\n",
      "Epoch: 1885 - time: 0.0031 - loss_train: 0.8688635196057765 - loss_val: 0.9824856179449446\n",
      "Epoch: 1886 - time: 0.0031 - loss_train: 0.8688042126578489 - loss_val: 0.9824599832593779\n",
      "Epoch: 1887 - time: 0.0031 - loss_train: 0.8687449303967351 - loss_val: 0.9824344090725865\n",
      "Epoch: 1888 - time: 0.0032 - loss_train: 0.8686856727491319 - loss_val: 0.9824088951878337\n",
      "Epoch: 1889 - time: 0.0032 - loss_train: 0.8686264396428002 - loss_val: 0.9823834414062549\n",
      "Epoch: 1890 - time: 0.0031 - loss_train: 0.868567231006575 - loss_val: 0.9823580475268481\n",
      "Epoch: 1891 - time: 0.0031 - loss_train: 0.8685080467703797 - loss_val: 0.9823327133464821\n",
      "Epoch: 1892 - time: 0.0031 - loss_train: 0.8684488868652391 - loss_val: 0.982307438659891\n",
      "Epoch: 1893 - time: 0.0031 - loss_train: 0.86838975122329 - loss_val: 0.9822822232596772\n",
      "Epoch: 1894 - time: 0.0032 - loss_train: 0.8683306397777943 - loss_val: 0.9822570669363083\n",
      "Epoch: 1895 - time: 0.0031 - loss_train: 0.8682715524631509 - loss_val: 0.9822319694781257\n",
      "Epoch: 1896 - time: 0.0031 - loss_train: 0.8682124892149082 - loss_val: 0.9822069306713408\n",
      "Epoch: 1897 - time: 0.0031 - loss_train: 0.8681534499697743 - loss_val: 0.9821819503000381\n",
      "Epoch: 1898 - time: 0.0031 - loss_train: 0.8680944346656302 - loss_val: 0.9821570281461809\n",
      "Epoch: 1899 - time: 0.0032 - loss_train: 0.86803544324154 - loss_val: 0.9821321639896138\n",
      "Epoch: 1900 - time: 0.0031 - loss_train: 0.8679764756377635 - loss_val: 0.9821073576080691\n",
      "Epoch: 1901 - time: 0.0031 - loss_train: 0.8679175317957664 - loss_val: 0.982082608777167\n",
      "Epoch: 1902 - time: 0.0031 - loss_train: 0.8678586116582309 - loss_val: 0.9820579172704281\n",
      "Epoch: 1903 - time: 0.0031 - loss_train: 0.867799715169068 - loss_val: 0.9820332828592753\n",
      "Epoch: 1904 - time: 0.0031 - loss_train: 0.8677408422734265 - loss_val: 0.9820087053130426\n",
      "Epoch: 1905 - time: 0.0031 - loss_train: 0.8676819929177048 - loss_val: 0.9819841843989809\n",
      "Epoch: 1906 - time: 0.0031 - loss_train: 0.867623167049559 - loss_val: 0.9819597198822698\n",
      "Epoch: 1907 - time: 0.0031 - loss_train: 0.8675643646179152 - loss_val: 0.9819353115260238\n",
      "Epoch: 1908 - time: 0.0031 - loss_train: 0.8675055855729793 - loss_val: 0.9819109590913035\n",
      "Epoch: 1909 - time: 0.0031 - loss_train: 0.8674468298662434 - loss_val: 0.9818866623371273\n",
      "Epoch: 1910 - time: 0.0031 - loss_train: 0.8673880974504994 - loss_val: 0.9818624210204775\n",
      "Epoch: 1911 - time: 0.0032 - loss_train: 0.8673293882798446 - loss_val: 0.9818382348963198\n",
      "Epoch: 1912 - time: 0.0031 - loss_train: 0.8672707023096926 - loss_val: 0.9818141037176105\n",
      "Epoch: 1913 - time: 0.0031 - loss_train: 0.8672120394967824 - loss_val: 0.9817900272353106\n",
      "Epoch: 1914 - time: 0.0031 - loss_train: 0.8671533997991842 - loss_val: 0.9817660051984031\n",
      "Epoch: 1915 - time: 0.0031 - loss_train: 0.8670947831763097 - loss_val: 0.9817420373539006\n",
      "Epoch: 1916 - time: 0.0031 - loss_train: 0.8670361895889196 - loss_val: 0.9817181234468717\n",
      "Epoch: 1917 - time: 0.0041 - loss_train: 0.8669776189991313 - loss_val: 0.9816942632204464\n",
      "Epoch: 1918 - time: 0.0032 - loss_train: 0.8669190713704247 - loss_val: 0.9816704564158415\n",
      "Epoch: 1919 - time: 0.0032 - loss_train: 0.8668605466676518 - loss_val: 0.9816467027723736\n",
      "Epoch: 1920 - time: 0.0031 - loss_train: 0.8668020448570407 - loss_val: 0.9816230020274777\n",
      "Epoch: 1921 - time: 0.0031 - loss_train: 0.8667435659062048 - loss_val: 0.9815993539167291\n",
      "Epoch: 1922 - time: 0.0031 - loss_train: 0.8666851097841468 - loss_val: 0.9815757581738637\n",
      "Epoch: 1923 - time: 0.0031 - loss_train: 0.8666266764612656 - loss_val: 0.9815522145307938\n",
      "Epoch: 1924 - time: 0.0031 - loss_train: 0.8665682659093611 - loss_val: 0.9815287227176367\n",
      "Epoch: 1925 - time: 0.0031 - loss_train: 0.8665098781016409 - loss_val: 0.9815052824627307\n",
      "Epoch: 1926 - time: 0.0031 - loss_train: 0.8664515130127229 - loss_val: 0.9814818934926641\n",
      "Epoch: 1927 - time: 0.0031 - loss_train: 0.8663931706186424 - loss_val: 0.9814585555322933\n",
      "Epoch: 1928 - time: 0.0031 - loss_train: 0.8663348508968549 - loss_val: 0.9814352683047741\n",
      "Epoch: 1929 - time: 0.0031 - loss_train: 0.8662765538262392 - loss_val: 0.98141203153158\n",
      "Epoch: 1930 - time: 0.0031 - loss_train: 0.8662182793871033 - loss_val: 0.9813888449325332\n",
      "Epoch: 1931 - time: 0.0031 - loss_train: 0.8661600275611852 - loss_val: 0.98136570822583\n",
      "Epoch: 1932 - time: 0.0031 - loss_train: 0.8661017983316581 - loss_val: 0.9813426211280706\n",
      "Epoch: 1933 - time: 0.0032 - loss_train: 0.8660435916831295 - loss_val: 0.9813195833542834\n",
      "Epoch: 1934 - time: 0.0031 - loss_train: 0.8659854076016483 - loss_val: 0.9812965946179587\n",
      "Epoch: 1935 - time: 0.0032 - loss_train: 0.8659272460747013 - loss_val: 0.9812736546310771\n",
      "Epoch: 1936 - time: 0.0032 - loss_train: 0.8658691070912174 - loss_val: 0.9812507631041378\n",
      "Epoch: 1937 - time: 0.0031 - loss_train: 0.8658109906415691 - loss_val: 0.9812279197461968\n",
      "Epoch: 1938 - time: 0.0031 - loss_train: 0.8657528967175719 - loss_val: 0.9812051242648899\n",
      "Epoch: 1939 - time: 0.0031 - loss_train: 0.8656948253124845 - loss_val: 0.9811823763664754\n",
      "Epoch: 1940 - time: 0.0031 - loss_train: 0.8656367764210093 - loss_val: 0.9811596757558614\n",
      "Epoch: 1941 - time: 0.0031 - loss_train: 0.8655787500392916 - loss_val: 0.9811370221366438\n",
      "Epoch: 1942 - time: 0.0044 - loss_train: 0.8655207461649177 - loss_val: 0.9811144152111365\n",
      "Epoch: 1943 - time: 0.0043 - loss_train: 0.8654627647969162 - loss_val: 0.9810918546804166\n",
      "Epoch: 1944 - time: 0.0044 - loss_train: 0.865404805935753 - loss_val: 0.981069340244352\n",
      "Epoch: 1945 - time: 0.0044 - loss_train: 0.8653468695833314 - loss_val: 0.9810468716016444\n",
      "Epoch: 1946 - time: 0.0044 - loss_train: 0.8652889557429896 - loss_val: 0.9810244484498644\n",
      "Epoch: 1947 - time: 0.0045 - loss_train: 0.8652310644194955 - loss_val: 0.9810020704854926\n",
      "Epoch: 1948 - time: 0.0045 - loss_train: 0.8651731956190458 - loss_val: 0.980979737403959\n",
      "Epoch: 1949 - time: 0.0045 - loss_train: 0.8651153493492617 - loss_val: 0.9809574488996785\n",
      "Epoch: 1950 - time: 0.0045 - loss_train: 0.8650575256191833 - loss_val: 0.9809352046661014\n",
      "Epoch: 1951 - time: 0.0042 - loss_train: 0.8649997244392664 - loss_val: 0.9809130043957452\n",
      "Epoch: 1952 - time: 0.0040 - loss_train: 0.864941945821377 - loss_val: 0.9808908477802414\n",
      "Epoch: 1953 - time: 0.0039 - loss_train: 0.8648841897787868 - loss_val: 0.980868734510379\n",
      "Epoch: 1954 - time: 0.0040 - loss_train: 0.8648264563261651 - loss_val: 0.9808466642761452\n",
      "Epoch: 1955 - time: 0.0045 - loss_train: 0.8647687454795748 - loss_val: 0.9808246367667721\n",
      "Epoch: 1956 - time: 0.0046 - loss_train: 0.8647110572564646 - loss_val: 0.9808026516707794\n",
      "Epoch: 1957 - time: 0.0046 - loss_train: 0.8646533916756621 - loss_val: 0.9807807086760179\n",
      "Epoch: 1958 - time: 0.0046 - loss_train: 0.8645957487573661 - loss_val: 0.9807588074697231\n",
      "Epoch: 1959 - time: 0.0045 - loss_train: 0.864538128523139 - loss_val: 0.9807369477385505\n",
      "Epoch: 1960 - time: 0.0045 - loss_train: 0.8644805309958986 - loss_val: 0.9807151291686304\n",
      "Epoch: 1961 - time: 0.0045 - loss_train: 0.8644229561999084 - loss_val: 0.9806933514456141\n",
      "Epoch: 1962 - time: 0.0045 - loss_train: 0.8643654041607695 - loss_val: 0.9806716142547173\n",
      "Epoch: 1963 - time: 0.0045 - loss_train: 0.8643078749054101 - loss_val: 0.9806499172807724\n",
      "Epoch: 1964 - time: 0.0045 - loss_train: 0.8642503684620764 - loss_val: 0.9806282602082782\n",
      "Epoch: 1965 - time: 0.0042 - loss_train: 0.864192884860321 - loss_val: 0.9806066427214465\n",
      "Epoch: 1966 - time: 0.0036 - loss_train: 0.864135424130994 - loss_val: 0.9805850645042514\n",
      "Epoch: 1967 - time: 0.0036 - loss_train: 0.8640779863062295 - loss_val: 0.9805635252404824\n",
      "Epoch: 1968 - time: 0.0036 - loss_train: 0.8640205714194348 - loss_val: 0.9805420246137919\n",
      "Epoch: 1969 - time: 0.0032 - loss_train: 0.8639631795052797 - loss_val: 0.9805205623077463\n",
      "Epoch: 1970 - time: 0.0032 - loss_train: 0.863905810599682 - loss_val: 0.9804991380058812\n",
      "Epoch: 1971 - time: 0.0031 - loss_train: 0.863848464739797 - loss_val: 0.9804777513917461\n",
      "Epoch: 1972 - time: 0.0031 - loss_train: 0.8637911419640022 - loss_val: 0.9804564021489639\n",
      "Epoch: 1973 - time: 0.0031 - loss_train: 0.8637338423118843 - loss_val: 0.9804350899612745\n",
      "Epoch: 1974 - time: 0.0031 - loss_train: 0.8636765658242268 - loss_val: 0.9804138145125959\n",
      "Epoch: 1975 - time: 0.0031 - loss_train: 0.8636193125429932 - loss_val: 0.9803925754870706\n",
      "Epoch: 1976 - time: 0.0031 - loss_train: 0.8635620825113146 - loss_val: 0.9803713725691209\n",
      "Epoch: 1977 - time: 0.0031 - loss_train: 0.8635048757734737 - loss_val: 0.980350205443501\n",
      "Epoch: 1978 - time: 0.0031 - loss_train: 0.8634476923748894 - loss_val: 0.980329073795351\n",
      "Epoch: 1979 - time: 0.0031 - loss_train: 0.8633905323621006 - loss_val: 0.9803079773102523\n",
      "Epoch: 1980 - time: 0.0031 - loss_train: 0.8633333957827523 - loss_val: 0.9802869156742743\n",
      "Epoch: 1981 - time: 0.0031 - loss_train: 0.863276282685576 - loss_val: 0.9802658885740368\n",
      "Epoch: 1982 - time: 0.0031 - loss_train: 0.8632191931203761 - loss_val: 0.980244895696758\n",
      "Epoch: 1983 - time: 0.0034 - loss_train: 0.8631621271380107 - loss_val: 0.9802239367303103\n",
      "Epoch: 1984 - time: 0.0032 - loss_train: 0.8631050847903755 - loss_val: 0.9802030113632717\n",
      "Epoch: 1985 - time: 0.0031 - loss_train: 0.8630480661303854 - loss_val: 0.9801821192849827\n",
      "Epoch: 1986 - time: 0.0031 - loss_train: 0.8629910712119577 - loss_val: 0.9801612601855991\n",
      "Epoch: 1987 - time: 0.0031 - loss_train: 0.8629341000899924 - loss_val: 0.9801404337561458\n",
      "Epoch: 1988 - time: 0.0031 - loss_train: 0.8628771528203549 - loss_val: 0.980119639688568\n",
      "Epoch: 1989 - time: 0.0032 - loss_train: 0.8628202294598568 - loss_val: 0.9800988776757906\n",
      "Epoch: 1990 - time: 0.0031 - loss_train: 0.8627633300662375 - loss_val: 0.9800781474117641\n",
      "Epoch: 1991 - time: 0.0032 - loss_train: 0.8627064546981431 - loss_val: 0.9800574485915244\n",
      "Epoch: 1992 - time: 0.0031 - loss_train: 0.8626496034151093 - loss_val: 0.9800367809112424\n",
      "Epoch: 1993 - time: 0.0031 - loss_train: 0.8625927762775405 - loss_val: 0.9800161440682776\n",
      "Epoch: 1994 - time: 0.0031 - loss_train: 0.8625359733466899 - loss_val: 0.9799955377612337\n",
      "Epoch: 1995 - time: 0.0031 - loss_train: 0.8624791946846385 - loss_val: 0.9799749616900042\n",
      "Epoch: 1996 - time: 0.0031 - loss_train: 0.8624224403542773 - loss_val: 0.9799544155558331\n",
      "Epoch: 1997 - time: 0.0031 - loss_train: 0.8623657104192836 - loss_val: 0.9799338990613607\n",
      "Epoch: 1998 - time: 0.0031 - loss_train: 0.862309004944102 - loss_val: 0.9799134119106775\n",
      "Epoch: 1999 - time: 0.0031 - loss_train: 0.8622523239939237 - loss_val: 0.979892953809378\n",
      "Epoch: 2000 - time: 0.0031 - loss_train: 0.8621956676346652 - loss_val: 0.9798725244646053\n",
      "Epoch: 2001 - time: 0.0031 - loss_train: 0.8621390359329457 - loss_val: 0.9798521235851076\n",
      "Epoch: 2002 - time: 0.0031 - loss_train: 0.8620824289560673 - loss_val: 0.9798317508812848\n",
      "Epoch: 2003 - time: 0.0031 - loss_train: 0.8620258467719945 - loss_val: 0.9798114060652401\n",
      "Epoch: 2004 - time: 0.0031 - loss_train: 0.8619692894493286 - loss_val: 0.9797910888508291\n",
      "Epoch: 2005 - time: 0.0031 - loss_train: 0.8619127570572903 - loss_val: 0.979770798953707\n",
      "Epoch: 2006 - time: 0.0031 - loss_train: 0.8618562496656963 - loss_val: 0.9797505360913779\n",
      "Epoch: 2007 - time: 0.0031 - loss_train: 0.8617997673449354 - loss_val: 0.979730299983242\n",
      "Epoch: 2008 - time: 0.0031 - loss_train: 0.8617433101659507 - loss_val: 0.979710090350645\n",
      "Epoch: 2009 - time: 0.0031 - loss_train: 0.8616868782002136 - loss_val: 0.9796899069169216\n",
      "Epoch: 2010 - time: 0.0031 - loss_train: 0.8616304715197034 - loss_val: 0.9796697494074398\n",
      "Epoch: 2011 - time: 0.0031 - loss_train: 0.8615740901968864 - loss_val: 0.979649617549654\n",
      "Epoch: 2012 - time: 0.0031 - loss_train: 0.8615177343046905 - loss_val: 0.9796295110731396\n",
      "Epoch: 2013 - time: 0.0031 - loss_train: 0.8614614039164867 - loss_val: 0.9796094297096452\n",
      "Epoch: 2014 - time: 0.0031 - loss_train: 0.8614050991060644 - loss_val: 0.9795893731931312\n",
      "Epoch: 2015 - time: 0.0031 - loss_train: 0.8613488199476094 - loss_val: 0.9795693412598152\n",
      "Epoch: 2016 - time: 0.0031 - loss_train: 0.8612925665156838 - loss_val: 0.9795493336482107\n",
      "Epoch: 2017 - time: 0.0031 - loss_train: 0.8612363388852015 - loss_val: 0.97952935009917\n",
      "Epoch: 2018 - time: 0.0031 - loss_train: 0.8611801371314066 - loss_val: 0.9795093903559261\n",
      "Epoch: 2019 - time: 0.0031 - loss_train: 0.8611239613298524 - loss_val: 0.979489454164129\n",
      "Epoch: 2020 - time: 0.0031 - loss_train: 0.8610678115563786 - loss_val: 0.979469541271887\n",
      "Epoch: 2021 - time: 0.0035 - loss_train: 0.8610116878870899 - loss_val: 0.9794496514298017\n",
      "Epoch: 2022 - time: 0.0032 - loss_train: 0.8609555903983328 - loss_val: 0.9794297843910101\n",
      "Epoch: 2023 - time: 0.0032 - loss_train: 0.8608995191666758 - loss_val: 0.9794099399112137\n",
      "Epoch: 2024 - time: 0.0031 - loss_train: 0.8608434742688867 - loss_val: 0.9793901177487219\n",
      "Epoch: 2025 - time: 0.0031 - loss_train: 0.8607874557819108 - loss_val: 0.9793703176644798\n",
      "Epoch: 2026 - time: 0.0031 - loss_train: 0.8607314637828505 - loss_val: 0.9793505394221041\n",
      "Epoch: 2027 - time: 0.0031 - loss_train: 0.8606754983489427 - loss_val: 0.9793307827879164\n",
      "Epoch: 2028 - time: 0.0031 - loss_train: 0.8606195595575387 - loss_val: 0.9793110475309734\n",
      "Epoch: 2029 - time: 0.0031 - loss_train: 0.8605636474860833 - loss_val: 0.9792913334230999\n",
      "Epoch: 2030 - time: 0.0031 - loss_train: 0.8605077622120928 - loss_val: 0.9792716402389172\n",
      "Epoch: 2031 - time: 0.0031 - loss_train: 0.8604519038131362 - loss_val: 0.9792519677558691\n",
      "Epoch: 2032 - time: 0.0031 - loss_train: 0.8603960723668131 - loss_val: 0.9792323157542557\n",
      "Epoch: 2033 - time: 0.0031 - loss_train: 0.8603402679507346 - loss_val: 0.979212684017255\n",
      "Epoch: 2034 - time: 0.0031 - loss_train: 0.8602844906425019 - loss_val: 0.9791930723309518\n",
      "Epoch: 2035 - time: 0.0031 - loss_train: 0.8602287405196876 - loss_val: 0.9791734804843606\n",
      "Epoch: 2036 - time: 0.0031 - loss_train: 0.8601730176598167 - loss_val: 0.979153908269449\n",
      "Epoch: 2037 - time: 0.0031 - loss_train: 0.8601173221403451 - loss_val: 0.9791343554811638\n",
      "Epoch: 2038 - time: 0.0031 - loss_train: 0.8600616540386421 - loss_val: 0.9791148219174495\n",
      "Epoch: 2039 - time: 0.0031 - loss_train: 0.8600060134319708 - loss_val: 0.9790953073792695\n",
      "Epoch: 2040 - time: 0.0031 - loss_train: 0.8599504003974696 - loss_val: 0.9790758116706265\n",
      "Epoch: 2041 - time: 0.0031 - loss_train: 0.8598948150121345 - loss_val: 0.9790563345985809\n",
      "Epoch: 2042 - time: 0.0031 - loss_train: 0.8598392573527994 - loss_val: 0.979036875973268\n",
      "Epoch: 2043 - time: 0.0031 - loss_train: 0.859783727496119 - loss_val: 0.9790174356079148\n",
      "Epoch: 2044 - time: 0.0031 - loss_train: 0.8597282255185523 - loss_val: 0.9789980133188544\n",
      "Epoch: 2045 - time: 0.0031 - loss_train: 0.8596727514963436 - loss_val: 0.9789786089255422\n",
      "Epoch: 2046 - time: 0.0034 - loss_train: 0.8596173055055057 - loss_val: 0.9789592222505676\n",
      "Epoch: 2047 - time: 0.0031 - loss_train: 0.8595618876218052 - loss_val: 0.9789398531196668\n",
      "Epoch: 2048 - time: 0.0031 - loss_train: 0.8595064979207424 - loss_val: 0.9789205013617327\n",
      "Epoch: 2049 - time: 0.0031 - loss_train: 0.8594511364775399 - loss_val: 0.9789011668088282\n",
      "Epoch: 2050 - time: 0.0031 - loss_train: 0.8593958033671215 - loss_val: 0.9788818492961909\n",
      "Epoch: 2051 - time: 0.0031 - loss_train: 0.8593404986641019 - loss_val: 0.9788625486622441\n",
      "Epoch: 2052 - time: 0.0031 - loss_train: 0.8592852224427677 - loss_val: 0.9788432647486021\n",
      "Epoch: 2053 - time: 0.0032 - loss_train: 0.8592299747770651 - loss_val: 0.9788239974000786\n",
      "Epoch: 2054 - time: 0.0031 - loss_train: 0.8591747557405834 - loss_val: 0.978804746464686\n",
      "Epoch: 2055 - time: 0.0031 - loss_train: 0.8591195654065426 - loss_val: 0.978785511793645\n",
      "Epoch: 2056 - time: 0.0031 - loss_train: 0.8590644038477778 - loss_val: 0.9787662932413834\n",
      "Epoch: 2057 - time: 0.0031 - loss_train: 0.8590092711367276 - loss_val: 0.9787470906655406\n",
      "Epoch: 2058 - time: 0.0031 - loss_train: 0.8589541673454203 - loss_val: 0.9787279039269654\n",
      "Epoch: 2059 - time: 0.0036 - loss_train: 0.8588990925454609 - loss_val: 0.9787087328897153\n",
      "Epoch: 2060 - time: 0.0032 - loss_train: 0.8588440468080177 - loss_val: 0.97868957742106\n",
      "Epoch: 2061 - time: 0.0031 - loss_train: 0.8587890302038127 - loss_val: 0.9786704373914714\n",
      "Epoch: 2062 - time: 0.0031 - loss_train: 0.858734042803108 - loss_val: 0.9786513126746265\n",
      "Epoch: 2063 - time: 0.0031 - loss_train: 0.8586790846756949 - loss_val: 0.978632203147399\n",
      "Epoch: 2064 - time: 0.0031 - loss_train: 0.858624155890883 - loss_val: 0.9786131086898568\n",
      "Epoch: 2065 - time: 0.0031 - loss_train: 0.8585692565174895 - loss_val: 0.9785940291852523\n",
      "Epoch: 2066 - time: 0.0031 - loss_train: 0.8585143866238293 - loss_val: 0.9785749645200175\n",
      "Epoch: 2067 - time: 0.0031 - loss_train: 0.8584595462777047 - loss_val: 0.9785559145837522\n",
      "Epoch: 2068 - time: 0.0031 - loss_train: 0.8584047355463958 - loss_val: 0.9785368792692212\n",
      "Epoch: 2069 - time: 0.0031 - loss_train: 0.8583499544966506 - loss_val: 0.9785178584723366\n",
      "Epoch: 2070 - time: 0.0031 - loss_train: 0.8582952031946801 - loss_val: 0.9784988520921514\n",
      "Epoch: 2071 - time: 0.0031 - loss_train: 0.8582404817061424 - loss_val: 0.9784798600308454\n",
      "Epoch: 2072 - time: 0.0031 - loss_train: 0.8581857900961427 - loss_val: 0.978460882193714\n",
      "Epoch: 2073 - time: 0.0031 - loss_train: 0.8581311284292199 - loss_val: 0.9784419184891505\n",
      "Epoch: 2074 - time: 0.0031 - loss_train: 0.8580764967693422 - loss_val: 0.9784229688286369\n",
      "Epoch: 2075 - time: 0.0031 - loss_train: 0.8580218951798987 - loss_val: 0.9784040331267224\n",
      "Epoch: 2076 - time: 0.0031 - loss_train: 0.8579673237236926 - loss_val: 0.9783851113010126\n",
      "Epoch: 2077 - time: 0.0031 - loss_train: 0.8579127824629366 - loss_val: 0.978366203272148\n",
      "Epoch: 2078 - time: 0.0031 - loss_train: 0.8578582714592444 - loss_val: 0.978347308963789\n",
      "Epoch: 2079 - time: 0.0031 - loss_train: 0.8578037907736277 - loss_val: 0.9783284283025926\n",
      "Epoch: 2080 - time: 0.0031 - loss_train: 0.8577493404664893 - loss_val: 0.9783095612182001\n",
      "Epoch: 2081 - time: 0.0031 - loss_train: 0.8576949205976178 - loss_val: 0.9782907076432096\n",
      "Epoch: 2082 - time: 0.0031 - loss_train: 0.8576405312261848 - loss_val: 0.9782718675131586\n",
      "Epoch: 2083 - time: 0.0031 - loss_train: 0.8575861724107401 - loss_val: 0.9782530407665005\n",
      "Epoch: 2084 - time: 0.0031 - loss_train: 0.8575318442092059 - loss_val: 0.978234227344585\n",
      "Epoch: 2085 - time: 0.0031 - loss_train: 0.8574775466788765 - loss_val: 0.9782154271916301\n",
      "Epoch: 2086 - time: 0.0031 - loss_train: 0.8574232798764119 - loss_val: 0.9781966402547032\n",
      "Epoch: 2087 - time: 0.0031 - loss_train: 0.857369043857837 - loss_val: 0.9781778664836949\n",
      "Epoch: 2088 - time: 0.0031 - loss_train: 0.8573148386785387 - loss_val: 0.9781591058312904\n",
      "Epoch: 2089 - time: 0.0031 - loss_train: 0.8572606643932631 - loss_val: 0.978140358252949\n",
      "Epoch: 2090 - time: 0.0031 - loss_train: 0.8572065210561136 - loss_val: 0.9781216237068743\n",
      "Epoch: 2091 - time: 0.0031 - loss_train: 0.8571524087205498 - loss_val: 0.9781029021539897\n",
      "Epoch: 2092 - time: 0.0032 - loss_train: 0.857098327439386 - loss_val: 0.9780841935579074\n",
      "Epoch: 2093 - time: 0.0031 - loss_train: 0.8570442772647887 - loss_val: 0.9780654978849049\n",
      "Epoch: 2094 - time: 0.0031 - loss_train: 0.8569902582482796 - loss_val: 0.978046815103892\n",
      "Epoch: 2095 - time: 0.0032 - loss_train: 0.8569362704407315 - loss_val: 0.978028145186385\n",
      "Epoch: 2096 - time: 0.0031 - loss_train: 0.8568823138923691 - loss_val: 0.9780094881064758\n",
      "Epoch: 2097 - time: 0.0035 - loss_train: 0.856828388652771 - loss_val: 0.977990843840801\n",
      "Epoch: 2098 - time: 0.0032 - loss_train: 0.8567744947708672 - loss_val: 0.9779722123685144\n",
      "Epoch: 2099 - time: 0.0031 - loss_train: 0.8567206322949424 - loss_val: 0.9779535936712515\n",
      "Epoch: 2100 - time: 0.0031 - loss_train: 0.8566668012726356 - loss_val: 0.9779349877331049\n",
      "Epoch: 2101 - time: 0.0031 - loss_train: 0.856613001750942 - loss_val: 0.9779163945405838\n",
      "Epoch: 2102 - time: 0.0032 - loss_train: 0.8565592337762135 - loss_val: 0.9778978140825899\n",
      "Epoch: 2103 - time: 0.0032 - loss_train: 0.8565054973941617 - loss_val: 0.9778792463503818\n",
      "Epoch: 2104 - time: 0.0032 - loss_train: 0.8564517926498604 - loss_val: 0.9778606913375419\n",
      "Epoch: 2105 - time: 0.0032 - loss_train: 0.856398119587745 - loss_val: 0.9778421490399424\n",
      "Epoch: 2106 - time: 0.0031 - loss_train: 0.8563444782516179 - loss_val: 0.977823619455716\n",
      "Epoch: 2107 - time: 0.0031 - loss_train: 0.8562908686846511 - loss_val: 0.9778051025852181\n",
      "Epoch: 2108 - time: 0.0031 - loss_train: 0.8562372909293864 - loss_val: 0.977786598430994\n",
      "Epoch: 2109 - time: 0.0031 - loss_train: 0.8561837450277426 - loss_val: 0.9777681069977472\n",
      "Epoch: 2110 - time: 0.0031 - loss_train: 0.8561302310210159 - loss_val: 0.977749628292301\n",
      "Epoch: 2111 - time: 0.0031 - loss_train: 0.8560767489498847 - loss_val: 0.9777311623235676\n",
      "Epoch: 2112 - time: 0.0032 - loss_train: 0.856023298854413 - loss_val: 0.9777127091025121\n",
      "Epoch: 2113 - time: 0.0031 - loss_train: 0.8559698807740556 - loss_val: 0.9776942686421154\n",
      "Epoch: 2114 - time: 0.0031 - loss_train: 0.8559164947476604 - loss_val: 0.9776758409573438\n",
      "Epoch: 2115 - time: 0.0031 - loss_train: 0.8558631408134749 - loss_val: 0.9776574260651092\n",
      "Epoch: 2116 - time: 0.0032 - loss_train: 0.85580981900915 - loss_val: 0.9776390239842372\n",
      "Epoch: 2117 - time: 0.0031 - loss_train: 0.8557565293717442 - loss_val: 0.9776206347354294\n",
      "Epoch: 2118 - time: 0.0032 - loss_train: 0.8557032719377291 - loss_val: 0.9776022583412303\n",
      "Epoch: 2119 - time: 0.0031 - loss_train: 0.8556500467429954 - loss_val: 0.9775838948259882\n",
      "Epoch: 2120 - time: 0.0035 - loss_train: 0.8555968538228566 - loss_val: 0.9775655442158232\n",
      "Epoch: 2121 - time: 0.0036 - loss_train: 0.8555436932120563 - loss_val: 0.9775472065385898\n",
      "Epoch: 2122 - time: 0.0031 - loss_train: 0.8554905649447717 - loss_val: 0.9775288818238422\n",
      "Epoch: 2123 - time: 0.0031 - loss_train: 0.8554374690546218 - loss_val: 0.9775105701027957\n",
      "Epoch: 2124 - time: 0.0032 - loss_train: 0.8553844055746718 - loss_val: 0.9774922714082978\n",
      "Epoch: 2125 - time: 0.0032 - loss_train: 0.8553313745374399 - loss_val: 0.9774739857747843\n",
      "Epoch: 2126 - time: 0.0031 - loss_train: 0.8552783759749039 - loss_val: 0.9774557132382495\n",
      "Epoch: 2127 - time: 0.0031 - loss_train: 0.8552254099185049 - loss_val: 0.9774374538362083\n",
      "Epoch: 2128 - time: 0.0031 - loss_train: 0.8551724763991582 - loss_val: 0.9774192076076613\n",
      "Epoch: 2129 - time: 0.0031 - loss_train: 0.8551195754472558 - loss_val: 0.9774009745930593\n",
      "Epoch: 2130 - time: 0.0031 - loss_train: 0.8550667070926766 - loss_val: 0.9773827548342713\n",
      "Epoch: 2131 - time: 0.0031 - loss_train: 0.8550138713647909 - loss_val: 0.9773645483745403\n",
      "Epoch: 2132 - time: 0.0031 - loss_train: 0.854961068292468 - loss_val: 0.9773463552584599\n",
      "Epoch: 2133 - time: 0.0035 - loss_train: 0.8549082979040827 - loss_val: 0.9773281755319319\n",
      "Epoch: 2134 - time: 0.0032 - loss_train: 0.8548555602275248 - loss_val: 0.9773100092421328\n",
      "Epoch: 2135 - time: 0.0046 - loss_train: 0.8548028552902031 - loss_val: 0.9772918564374807\n",
      "Epoch: 2136 - time: 0.0045 - loss_train: 0.8547501831190558 - loss_val: 0.9772737171675999\n",
      "Epoch: 2137 - time: 0.0044 - loss_train: 0.8546975437405553 - loss_val: 0.9772555914832876\n",
      "Epoch: 2138 - time: 0.0031 - loss_train: 0.8546449371807173 - loss_val: 0.9772374794364794\n",
      "Epoch: 2139 - time: 0.0031 - loss_train: 0.8545923634651088 - loss_val: 0.9772193810802139\n",
      "Epoch: 2140 - time: 0.0031 - loss_train: 0.8545398226188535 - loss_val: 0.9772012964686023\n",
      "Epoch: 2141 - time: 0.0031 - loss_train: 0.854487314666643 - loss_val: 0.9771832256567923\n",
      "Epoch: 2142 - time: 0.0031 - loss_train: 0.8544348396327405 - loss_val: 0.9771651687009368\n",
      "Epoch: 2143 - time: 0.0031 - loss_train: 0.8543823975409923 - loss_val: 0.977147125658161\n",
      "Epoch: 2144 - time: 0.0031 - loss_train: 0.8543299884148343 - loss_val: 0.9771290965865265\n",
      "Epoch: 2145 - time: 0.0031 - loss_train: 0.8542776122772989 - loss_val: 0.9771110815450047\n",
      "Epoch: 2146 - time: 0.0031 - loss_train: 0.8542252691510245 - loss_val: 0.977093080593439\n",
      "Epoch: 2147 - time: 0.0031 - loss_train: 0.8541729590582635 - loss_val: 0.9770750937925174\n",
      "Epoch: 2148 - time: 0.0031 - loss_train: 0.8541206820208898 - loss_val: 0.9770571212037389\n",
      "Epoch: 2149 - time: 0.0031 - loss_train: 0.8540684380604062 - loss_val: 0.9770391628893822\n",
      "Epoch: 2150 - time: 0.0031 - loss_train: 0.8540162271979553 - loss_val: 0.9770212189124754\n",
      "Epoch: 2151 - time: 0.0031 - loss_train: 0.8539640494543242 - loss_val: 0.9770032893367656\n",
      "Epoch: 2152 - time: 0.0031 - loss_train: 0.853911904849956 - loss_val: 0.9769853742266892\n",
      "Epoch: 2153 - time: 0.0031 - loss_train: 0.8538597934049549 - loss_val: 0.97696747364734\n",
      "Epoch: 2154 - time: 0.0031 - loss_train: 0.8538077151390967 - loss_val: 0.9769495876644401\n",
      "Epoch: 2155 - time: 0.0031 - loss_train: 0.853755670071837 - loss_val: 0.9769317163443141\n",
      "Epoch: 2156 - time: 0.0031 - loss_train: 0.8537036582223183 - loss_val: 0.9769138597538551\n",
      "Epoch: 2157 - time: 0.0031 - loss_train: 0.8536516796093789 - loss_val: 0.9768960179604999\n",
      "Epoch: 2158 - time: 0.0031 - loss_train: 0.8535997342515618 - loss_val: 0.9768781910321992\n",
      "Epoch: 2159 - time: 0.0031 - loss_train: 0.8535478221671214 - loss_val: 0.9768603790373886\n",
      "Epoch: 2160 - time: 0.0031 - loss_train: 0.8534959433740339 - loss_val: 0.9768425820449657\n",
      "Epoch: 2161 - time: 0.0031 - loss_train: 0.8534440978900037 - loss_val: 0.976824800124258\n",
      "Epoch: 2162 - time: 0.0031 - loss_train: 0.853392285732473 - loss_val: 0.9768070333449977\n",
      "Epoch: 2163 - time: 0.0031 - loss_train: 0.8533405069186295 - loss_val: 0.9767892817772972\n",
      "Epoch: 2164 - time: 0.0031 - loss_train: 0.8532887614654147 - loss_val: 0.9767715454916215\n",
      "Epoch: 2165 - time: 0.0031 - loss_train: 0.8532370493895312 - loss_val: 0.9767538245587629\n",
      "Epoch: 2166 - time: 0.0031 - loss_train: 0.8531853707074538 - loss_val: 0.9767361190498157\n",
      "Epoch: 2167 - time: 0.0031 - loss_train: 0.8531337254354344 - loss_val: 0.9767184290361516\n",
      "Epoch: 2168 - time: 0.0031 - loss_train: 0.8530821135895122 - loss_val: 0.9767007545893965\n",
      "Epoch: 2169 - time: 0.0031 - loss_train: 0.8530305351855204 - loss_val: 0.9766830957814039\n",
      "Epoch: 2170 - time: 0.0031 - loss_train: 0.852978990239096 - loss_val: 0.9766654526842338\n",
      "Epoch: 2171 - time: 0.0035 - loss_train: 0.8529274787656866 - loss_val: 0.9766478253701283\n",
      "Epoch: 2172 - time: 0.0032 - loss_train: 0.8528760007805584 - loss_val: 0.9766302139114904\n",
      "Epoch: 2173 - time: 0.0031 - loss_train: 0.8528245562988053 - loss_val: 0.9766126183808573\n",
      "Epoch: 2174 - time: 0.0031 - loss_train: 0.8527731453353555 - loss_val: 0.9765950388508856\n",
      "Epoch: 2175 - time: 0.0031 - loss_train: 0.8527217679049808 - loss_val: 0.9765774753943222\n",
      "Epoch: 2176 - time: 0.0031 - loss_train: 0.852670424022303 - loss_val: 0.9765599280839887\n",
      "Epoch: 2177 - time: 0.0031 - loss_train: 0.8526191137018022 - loss_val: 0.976542396992758\n",
      "Epoch: 2178 - time: 0.0031 - loss_train: 0.852567836957826 - loss_val: 0.976524882193533\n",
      "Epoch: 2179 - time: 0.0031 - loss_train: 0.852516593804594 - loss_val: 0.9765073837592315\n",
      "Epoch: 2180 - time: 0.0031 - loss_train: 0.8524653842562092 - loss_val: 0.9764899017627608\n",
      "Epoch: 2181 - time: 0.0031 - loss_train: 0.8524142083266629 - loss_val: 0.976472436277003\n",
      "Epoch: 2182 - time: 0.0031 - loss_train: 0.8523630660298422 - loss_val: 0.9764549873747931\n",
      "Epoch: 2183 - time: 0.0031 - loss_train: 0.8523119573795402 - loss_val: 0.9764375551289028\n",
      "Epoch: 2184 - time: 0.0031 - loss_train: 0.8522608823894595 - loss_val: 0.9764201396120218\n",
      "Epoch: 2185 - time: 0.0031 - loss_train: 0.8522098410732228 - loss_val: 0.9764027408967414\n",
      "Epoch: 2186 - time: 0.0031 - loss_train: 0.8521588334443776 - loss_val: 0.9763853590555355\n",
      "Epoch: 2187 - time: 0.0031 - loss_train: 0.8521078595164056 - loss_val: 0.9763679941607448\n",
      "Epoch: 2188 - time: 0.0031 - loss_train: 0.8520569193027278 - loss_val: 0.976350646284562\n",
      "Epoch: 2189 - time: 0.0031 - loss_train: 0.8520060128167128 - loss_val: 0.976333315499014\n",
      "Epoch: 2190 - time: 0.0031 - loss_train: 0.8519551400716827 - loss_val: 0.9763160018759464\n",
      "Epoch: 2191 - time: 0.0031 - loss_train: 0.8519043010809214 - loss_val: 0.9762987054870096\n",
      "Epoch: 2192 - time: 0.0031 - loss_train: 0.8518534958576794 - loss_val: 0.976281426403644\n",
      "Epoch: 2193 - time: 0.0031 - loss_train: 0.8518027244151827 - loss_val: 0.9762641646970647\n",
      "Epoch: 2194 - time: 0.0031 - loss_train: 0.8517519867666362 - loss_val: 0.9762469204382497\n",
      "Epoch: 2195 - time: 0.0031 - loss_train: 0.8517012829252337 - loss_val: 0.9762296936979221\n",
      "Epoch: 2196 - time: 0.0031 - loss_train: 0.8516506129041621 - loss_val: 0.9762124845465416\n",
      "Epoch: 2197 - time: 0.0031 - loss_train: 0.8515999767166081 - loss_val: 0.9761952930542914\n",
      "Epoch: 2198 - time: 0.0031 - loss_train: 0.8515493743757647 - loss_val: 0.9761781192910605\n",
      "Epoch: 2199 - time: 0.0031 - loss_train: 0.8514988058948361 - loss_val: 0.9761609633264391\n",
      "Epoch: 2200 - time: 0.0031 - loss_train: 0.8514482712870455 - loss_val: 0.9761438252297014\n",
      "Epoch: 2201 - time: 0.0031 - loss_train: 0.8513977705656401 - loss_val: 0.9761267050697978\n",
      "Epoch: 2202 - time: 0.0031 - loss_train: 0.8513473037438962 - loss_val: 0.9761096029153402\n",
      "Epoch: 2203 - time: 0.0031 - loss_train: 0.851296870835126 - loss_val: 0.9760925188345966\n",
      "Epoch: 2204 - time: 0.0031 - loss_train: 0.8512464718526812 - loss_val: 0.9760754528954766\n",
      "Epoch: 2205 - time: 0.0031 - loss_train: 0.8511961068099616 - loss_val: 0.9760584051655241\n",
      "Epoch: 2206 - time: 0.0031 - loss_train: 0.8511457757204175 - loss_val: 0.9760413757119059\n",
      "Epoch: 2207 - time: 0.0031 - loss_train: 0.8510954785975557 - loss_val: 0.9760243646014037\n",
      "Epoch: 2208 - time: 0.0031 - loss_train: 0.8510452154549458 - loss_val: 0.9760073719004061\n",
      "Epoch: 2209 - time: 0.0035 - loss_train: 0.8509949863062228 - loss_val: 0.9759903976748981\n",
      "Epoch: 2210 - time: 0.0032 - loss_train: 0.8509447911650941 - loss_val: 0.9759734419904539\n",
      "Epoch: 2211 - time: 0.0031 - loss_train: 0.8508946300453437 - loss_val: 0.975956504912232\n",
      "Epoch: 2212 - time: 0.0031 - loss_train: 0.8508445029608358 - loss_val: 0.9759395865049618\n",
      "Epoch: 2213 - time: 0.0031 - loss_train: 0.8507944099255196 - loss_val: 0.9759226868329424\n",
      "Epoch: 2214 - time: 0.0031 - loss_train: 0.8507443509534348 - loss_val: 0.9759058059600306\n",
      "Epoch: 2215 - time: 0.0031 - loss_train: 0.8506943260587141 - loss_val: 0.9758889439496398\n",
      "Epoch: 2216 - time: 0.0031 - loss_train: 0.8506443352555892 - loss_val: 0.9758721008647296\n",
      "Epoch: 2217 - time: 0.0031 - loss_train: 0.8505943785583923 - loss_val: 0.9758552767678008\n",
      "Epoch: 2218 - time: 0.0031 - loss_train: 0.8505444559815617 - loss_val: 0.9758384717208926\n",
      "Epoch: 2219 - time: 0.0031 - loss_train: 0.8504945675396447 - loss_val: 0.9758216857855725\n",
      "Epoch: 2220 - time: 0.0031 - loss_train: 0.8504447132473022 - loss_val: 0.9758049190229351\n",
      "Epoch: 2221 - time: 0.0031 - loss_train: 0.8503948931193104 - loss_val: 0.9757881714935974\n",
      "Epoch: 2222 - time: 0.0031 - loss_train: 0.8503451071705658 - loss_val: 0.9757714432576916\n",
      "Epoch: 2223 - time: 0.0031 - loss_train: 0.8502953554160865 - loss_val: 0.9757547343748628\n",
      "Epoch: 2224 - time: 0.0031 - loss_train: 0.8502456378710167 - loss_val: 0.9757380449042664\n",
      "Epoch: 2225 - time: 0.0031 - loss_train: 0.8501959545506289 - loss_val: 0.9757213749045609\n",
      "Epoch: 2226 - time: 0.0031 - loss_train: 0.8501463054703267 - loss_val: 0.9757047244339085\n",
      "Epoch: 2227 - time: 0.0031 - loss_train: 0.8500966906456462 - loss_val: 0.9756880935499701\n",
      "Epoch: 2228 - time: 0.0031 - loss_train: 0.8500471100922616 - loss_val: 0.9756714823099016\n",
      "Epoch: 2229 - time: 0.0031 - loss_train: 0.8499975638259839 - loss_val: 0.9756548907703536\n",
      "Epoch: 2230 - time: 0.0031 - loss_train: 0.8499480518627647 - loss_val: 0.9756383189874668\n",
      "Epoch: 2231 - time: 0.0031 - loss_train: 0.8498985742186977 - loss_val: 0.9756217670168716\n",
      "Epoch: 2232 - time: 0.0031 - loss_train: 0.8498491309100212 - loss_val: 0.9756052349136864\n",
      "Epoch: 2233 - time: 0.0031 - loss_train: 0.8497997219531194 - loss_val: 0.9755887227325141\n",
      "Epoch: 2234 - time: 0.0031 - loss_train: 0.8497503473645235 - loss_val: 0.9755722305274422\n",
      "Epoch: 2235 - time: 0.0031 - loss_train: 0.8497010071609136 - loss_val: 0.9755557583520404\n",
      "Epoch: 2236 - time: 0.0031 - loss_train: 0.8496517013591192 - loss_val: 0.9755393062593639\n",
      "Epoch: 2237 - time: 0.0031 - loss_train: 0.849602429976122 - loss_val: 0.9755228743019447\n",
      "Epoch: 2238 - time: 0.0031 - loss_train: 0.849553193029055 - loss_val: 0.9755064625317996\n",
      "Epoch: 2239 - time: 0.0031 - loss_train: 0.8495039905352028 - loss_val: 0.9754900710004226\n",
      "Epoch: 2240 - time: 0.0031 - loss_train: 0.8494548225120057 - loss_val: 0.9754736997587905\n",
      "Epoch: 2241 - time: 0.0031 - loss_train: 0.8494056889770552 - loss_val: 0.9754573488573611\n",
      "Epoch: 2242 - time: 0.0031 - loss_train: 0.8493565899480995 - loss_val: 0.9754410183460696\n",
      "Epoch: 2243 - time: 0.0031 - loss_train: 0.8493075254430389 - loss_val: 0.9754247082743357\n",
      "Epoch: 2244 - time: 0.0031 - loss_train: 0.8492584954799297 - loss_val: 0.9754084186910595\n",
      "Epoch: 2245 - time: 0.0031 - loss_train: 0.8492095000769814 - loss_val: 0.9753921496446228\n",
      "Epoch: 2246 - time: 0.0031 - loss_train: 0.8491605392525577 - loss_val: 0.9753759011828931\n",
      "Epoch: 2247 - time: 0.0035 - loss_train: 0.8491116130251763 - loss_val: 0.975359673353221\n",
      "Epoch: 2248 - time: 0.0032 - loss_train: 0.8490627214135069 - loss_val: 0.9753434662024415\n",
      "Epoch: 2249 - time: 0.0031 - loss_train: 0.8490138644363717 - loss_val: 0.9753272797768798\n",
      "Epoch: 2250 - time: 0.0031 - loss_train: 0.8489650421127456 - loss_val: 0.9753111141223483\n",
      "Epoch: 2251 - time: 0.0031 - loss_train: 0.8489162544617513 - loss_val: 0.9752949692841494\n",
      "Epoch: 2252 - time: 0.0031 - loss_train: 0.848867501502662 - loss_val: 0.9752788453070788\n",
      "Epoch: 2253 - time: 0.0031 - loss_train: 0.848818783254899 - loss_val: 0.9752627422354272\n",
      "Epoch: 2254 - time: 0.0031 - loss_train: 0.8487700997380295 - loss_val: 0.9752466601129791\n",
      "Epoch: 2255 - time: 0.0031 - loss_train: 0.8487214509717655 - loss_val: 0.975230598983022\n",
      "Epoch: 2256 - time: 0.0031 - loss_train: 0.8486728369759612 - loss_val: 0.9752145588883392\n",
      "Epoch: 2257 - time: 0.0031 - loss_train: 0.8486242577706133 - loss_val: 0.9751985398712223\n",
      "Epoch: 2258 - time: 0.0031 - loss_train: 0.8485757133758561 - loss_val: 0.9751825419734662\n",
      "Epoch: 2259 - time: 0.0031 - loss_train: 0.8485272038119624 - loss_val: 0.9751665652363756\n",
      "Epoch: 2260 - time: 0.0031 - loss_train: 0.8484787290993372 - loss_val: 0.9751506097007668\n",
      "Epoch: 2261 - time: 0.0031 - loss_train: 0.8484302892585193 - loss_val: 0.9751346754069697\n",
      "Epoch: 2262 - time: 0.0031 - loss_train: 0.8483818843101767 - loss_val: 0.9751187623948343\n",
      "Epoch: 2263 - time: 0.0031 - loss_train: 0.848333514275103 - loss_val: 0.9751028707037278\n",
      "Epoch: 2264 - time: 0.0031 - loss_train: 0.8482851791742165 - loss_val: 0.9750870003725436\n",
      "Epoch: 2265 - time: 0.0031 - loss_train: 0.848236879028556 - loss_val: 0.9750711514397001\n",
      "Epoch: 2266 - time: 0.0031 - loss_train: 0.8481886138592782 - loss_val: 0.97505532394315\n",
      "Epoch: 2267 - time: 0.0031 - loss_train: 0.8481403836876539 - loss_val: 0.9750395179203747\n",
      "Epoch: 2268 - time: 0.0031 - loss_train: 0.8480921885350644 - loss_val: 0.9750237334083973\n",
      "Epoch: 2269 - time: 0.0031 - loss_train: 0.8480440284229993 - loss_val: 0.9750079704437781\n",
      "Epoch: 2270 - time: 0.0031 - loss_train: 0.8479959033730506 - loss_val: 0.9749922290626231\n",
      "Epoch: 2271 - time: 0.0031 - loss_train: 0.8479478134069117 - loss_val: 0.9749765093005889\n",
      "Epoch: 2272 - time: 0.0031 - loss_train: 0.8478997585463711 - loss_val: 0.9749608111928799\n",
      "Epoch: 2273 - time: 0.0031 - loss_train: 0.8478517388133093 - loss_val: 0.9749451347742588\n",
      "Epoch: 2274 - time: 0.0031 - loss_train: 0.8478037542296947 - loss_val: 0.9749294800790462\n",
      "Epoch: 2275 - time: 0.0031 - loss_train: 0.84775580481758 - loss_val: 0.9749138471411263\n",
      "Epoch: 2276 - time: 0.0031 - loss_train: 0.8477078905990957 - loss_val: 0.9748982359939513\n",
      "Epoch: 2277 - time: 0.0031 - loss_train: 0.8476600115964479 - loss_val: 0.9748826466705434\n",
      "Epoch: 2278 - time: 0.0031 - loss_train: 0.8476121678319125 - loss_val: 0.9748670792035004\n",
      "Epoch: 2279 - time: 0.0031 - loss_train: 0.847564359327831 - loss_val: 0.9748515336249995\n",
      "Epoch: 2280 - time: 0.0031 - loss_train: 0.8475165861066057 - loss_val: 0.9748360099668\n",
      "Epoch: 2281 - time: 0.0031 - loss_train: 0.847468848190693 - loss_val: 0.9748205082602492\n",
      "Epoch: 2282 - time: 0.0031 - loss_train: 0.8474211456026018 - loss_val: 0.9748050285362843\n",
      "Epoch: 2283 - time: 0.0031 - loss_train: 0.847373478364885 - loss_val: 0.9747895708254394\n",
      "Epoch: 2284 - time: 0.0031 - loss_train: 0.8473258465001368 - loss_val: 0.974774135157847\n",
      "Epoch: 2285 - time: 0.0035 - loss_train: 0.8472782500309857 - loss_val: 0.9747587215632427\n",
      "Epoch: 2286 - time: 0.0032 - loss_train: 0.8472306889800901 - loss_val: 0.9747433300709718\n",
      "Epoch: 2287 - time: 0.0031 - loss_train: 0.8471831633701327 - loss_val: 0.9747279607099878\n",
      "Epoch: 2288 - time: 0.0031 - loss_train: 0.8471356732238139 - loss_val: 0.9747126135088628\n",
      "Epoch: 2289 - time: 0.0031 - loss_train: 0.8470882185638476 - loss_val: 0.9746972884957886\n",
      "Epoch: 2290 - time: 0.0031 - loss_train: 0.8470407994129546 - loss_val: 0.9746819856985787\n",
      "Epoch: 2291 - time: 0.0031 - loss_train: 0.8469934157938569 - loss_val: 0.9746667051446769\n",
      "Epoch: 2292 - time: 0.0031 - loss_train: 0.8469460677292723 - loss_val: 0.9746514468611582\n",
      "Epoch: 2293 - time: 0.0031 - loss_train: 0.8468987552419076 - loss_val: 0.974636210874735\n",
      "Epoch: 2294 - time: 0.0031 - loss_train: 0.8468514783544537 - loss_val: 0.9746209972117584\n",
      "Epoch: 2295 - time: 0.0031 - loss_train: 0.8468042370895784 - loss_val: 0.9746058058982252\n",
      "Epoch: 2296 - time: 0.0031 - loss_train: 0.8467570314699208 - loss_val: 0.9745906369597794\n",
      "Epoch: 2297 - time: 0.0031 - loss_train: 0.8467098615180855 - loss_val: 0.9745754904217188\n",
      "Epoch: 2298 - time: 0.0031 - loss_train: 0.8466627272566352 - loss_val: 0.9745603663089956\n",
      "Epoch: 2299 - time: 0.0031 - loss_train: 0.8466156287080855 - loss_val: 0.974545264646224\n",
      "Epoch: 2300 - time: 0.0031 - loss_train: 0.8465685658948987 - loss_val: 0.9745301854576819\n",
      "Epoch: 2301 - time: 0.0031 - loss_train: 0.8465215388394755 - loss_val: 0.9745151287673155\n",
      "Epoch: 2302 - time: 0.0031 - loss_train: 0.8464745475641512 - loss_val: 0.9745000945987408\n",
      "Epoch: 2303 - time: 0.0031 - loss_train: 0.8464275920911873 - loss_val: 0.9744850829752523\n",
      "Epoch: 2304 - time: 0.0031 - loss_train: 0.8463806724427657 - loss_val: 0.9744700939198233\n",
      "Epoch: 2305 - time: 0.0031 - loss_train: 0.8463337886409826 - loss_val: 0.9744551274551091\n",
      "Epoch: 2306 - time: 0.0031 - loss_train: 0.8462869407078404 - loss_val: 0.9744401836034524\n",
      "Epoch: 2307 - time: 0.0031 - loss_train: 0.8462401286652432 - loss_val: 0.9744252623868881\n",
      "Epoch: 2308 - time: 0.0031 - loss_train: 0.8461933525349884 - loss_val: 0.9744103638271427\n",
      "Epoch: 2309 - time: 0.0031 - loss_train: 0.846146612338761 - loss_val: 0.9743954879456425\n",
      "Epoch: 2310 - time: 0.0031 - loss_train: 0.8460999080981269 - loss_val: 0.9743806347635136\n",
      "Epoch: 2311 - time: 0.0031 - loss_train: 0.8460532398345249 - loss_val: 0.9743658043015868\n",
      "Epoch: 2312 - time: 0.0031 - loss_train: 0.8460066075692627 - loss_val: 0.9743509965804017\n",
      "Epoch: 2313 - time: 0.0031 - loss_train: 0.8459600113235085 - loss_val: 0.9743362116202087\n",
      "Epoch: 2314 - time: 0.0031 - loss_train: 0.8459134511182835 - loss_val: 0.9743214494409748\n",
      "Epoch: 2315 - time: 0.0031 - loss_train: 0.8458669269744565 - loss_val: 0.9743067100623808\n",
      "Epoch: 2316 - time: 0.0031 - loss_train: 0.8458204389127374 - loss_val: 0.9742919935038341\n",
      "Epoch: 2317 - time: 0.0031 - loss_train: 0.8457739869536698 - loss_val: 0.9742772997844615\n",
      "Epoch: 2318 - time: 0.0031 - loss_train: 0.8457275711176244 - loss_val: 0.9742626289231202\n",
      "Epoch: 2319 - time: 0.0031 - loss_train: 0.845681191424793 - loss_val: 0.9742479809383963\n",
      "Epoch: 2320 - time: 0.0031 - loss_train: 0.8456348478951807 - loss_val: 0.9742333558486101\n",
      "Epoch: 2321 - time: 0.0031 - loss_train: 0.8455885405486017 - loss_val: 0.9742187536718175\n",
      "Epoch: 2322 - time: 0.0031 - loss_train: 0.8455422694046684 - loss_val: 0.9742041744258134\n",
      "Epoch: 2323 - time: 0.0035 - loss_train: 0.8454960344827889 - loss_val: 0.9741896181281356\n",
      "Epoch: 2324 - time: 0.0032 - loss_train: 0.8454498358021598 - loss_val: 0.9741750847960647\n",
      "Epoch: 2325 - time: 0.0031 - loss_train: 0.8454036733817576 - loss_val: 0.9741605744466301\n",
      "Epoch: 2326 - time: 0.0031 - loss_train: 0.8453575472403339 - loss_val: 0.9741460870966109\n",
      "Epoch: 2327 - time: 0.0031 - loss_train: 0.8453114573964083 - loss_val: 0.9741316227625373\n",
      "Epoch: 2328 - time: 0.0031 - loss_train: 0.8452654038682639 - loss_val: 0.9741171814606944\n",
      "Epoch: 2329 - time: 0.0031 - loss_train: 0.8452193866739378 - loss_val: 0.974102763207125\n",
      "Epoch: 2330 - time: 0.0031 - loss_train: 0.8451734058312168 - loss_val: 0.9740883680176325\n",
      "Epoch: 2331 - time: 0.0031 - loss_train: 0.8451274613576312 - loss_val: 0.9740739959077792\n",
      "Epoch: 2332 - time: 0.0031 - loss_train: 0.845081553270448 - loss_val: 0.9740596468928945\n",
      "Epoch: 2333 - time: 0.0031 - loss_train: 0.8450356815866646 - loss_val: 0.9740453209880711\n",
      "Epoch: 2334 - time: 0.0031 - loss_train: 0.8449898463230038 - loss_val: 0.9740310182081707\n",
      "Epoch: 2335 - time: 0.0031 - loss_train: 0.8449440474959071 - loss_val: 0.9740167385678271\n",
      "Epoch: 2336 - time: 0.0031 - loss_train: 0.8448982851215271 - loss_val: 0.974002482081443\n",
      "Epoch: 2337 - time: 0.0031 - loss_train: 0.8448525592157252 - loss_val: 0.9739882487631966\n",
      "Epoch: 2338 - time: 0.0031 - loss_train: 0.8448068697940637 - loss_val: 0.9739740386270423\n",
      "Epoch: 2339 - time: 0.0043 - loss_train: 0.8447612168717995 - loss_val: 0.973959851686711\n",
      "Epoch: 2340 - time: 0.0044 - loss_train: 0.8447156004638786 - loss_val: 0.9739456879557132\n",
      "Epoch: 2341 - time: 0.0044 - loss_train: 0.8446700205849329 - loss_val: 0.9739315474473401\n",
      "Epoch: 2342 - time: 0.0044 - loss_train: 0.8446244772492715 - loss_val: 0.9739174301746645\n",
      "Epoch: 2343 - time: 0.0043 - loss_train: 0.8445789704708766 - loss_val: 0.9739033361505453\n",
      "Epoch: 2344 - time: 0.0044 - loss_train: 0.8445335002633989 - loss_val: 0.9738892653876231\n",
      "Epoch: 2345 - time: 0.0043 - loss_train: 0.8444880666401514 - loss_val: 0.9738752178983273\n",
      "Epoch: 2346 - time: 0.0044 - loss_train: 0.8444426696141041 - loss_val: 0.9738611936948759\n",
      "Epoch: 2347 - time: 0.0044 - loss_train: 0.8443973091978799 - loss_val: 0.9738471927892738\n",
      "Epoch: 2348 - time: 0.0044 - loss_train: 0.8443519854037486 - loss_val: 0.9738332151933177\n",
      "Epoch: 2349 - time: 0.0043 - loss_train: 0.8443066982436224 - loss_val: 0.9738192609185952\n",
      "Epoch: 2350 - time: 0.0043 - loss_train: 0.8442614477290513 - loss_val: 0.973805329976487\n",
      "Epoch: 2351 - time: 0.0044 - loss_train: 0.8442162338712178 - loss_val: 0.9737914223781652\n",
      "Epoch: 2352 - time: 0.0044 - loss_train: 0.8441710566809341 - loss_val: 0.9737775381345987\n",
      "Epoch: 2353 - time: 0.0045 - loss_train: 0.844125916168634 - loss_val: 0.9737636772565514\n",
      "Epoch: 2354 - time: 0.0046 - loss_train: 0.8440808123443723 - loss_val: 0.973749839754583\n",
      "Epoch: 2355 - time: 0.0047 - loss_train: 0.8440357452178188 - loss_val: 0.9737360256390484\n",
      "Epoch: 2356 - time: 0.0046 - loss_train: 0.8439907147982533 - loss_val: 0.9737222349201026\n",
      "Epoch: 2357 - time: 0.0046 - loss_train: 0.843945721094564 - loss_val: 0.9737084676076974\n",
      "Epoch: 2358 - time: 0.0042 - loss_train: 0.8439007641152405 - loss_val: 0.9736947237115843\n",
      "Epoch: 2359 - time: 0.0036 - loss_train: 0.8438558438683714 - loss_val: 0.9736810032413126\n",
      "Epoch: 2360 - time: 0.0036 - loss_train: 0.8438109603616419 - loss_val: 0.9736673062062364\n",
      "Epoch: 2361 - time: 0.0036 - loss_train: 0.843766113602328 - loss_val: 0.9736536326155035\n",
      "Epoch: 2362 - time: 0.0036 - loss_train: 0.8437213035972931 - loss_val: 0.9736399824780677\n",
      "Epoch: 2363 - time: 0.0037 - loss_train: 0.8436765303529866 - loss_val: 0.9736263558026829\n",
      "Epoch: 2364 - time: 0.0036 - loss_train: 0.8436317938754386 - loss_val: 0.9736127525979025\n",
      "Epoch: 2365 - time: 0.0043 - loss_train: 0.8435870941702563 - loss_val: 0.9735991728720842\n",
      "Epoch: 2366 - time: 0.0044 - loss_train: 0.8435424312426243 - loss_val: 0.9735856166333869\n",
      "Epoch: 2367 - time: 0.0043 - loss_train: 0.8434978050972971 - loss_val: 0.9735720838897723\n",
      "Epoch: 2368 - time: 0.0044 - loss_train: 0.8434532157385995 - loss_val: 0.9735585746490054\n",
      "Epoch: 2369 - time: 0.0045 - loss_train: 0.8434086631704232 - loss_val: 0.9735450889186508\n",
      "Epoch: 2370 - time: 0.0045 - loss_train: 0.8433641473962235 - loss_val: 0.9735316267060794\n",
      "Epoch: 2371 - time: 0.0045 - loss_train: 0.8433196684190157 - loss_val: 0.9735181880184623\n",
      "Epoch: 2372 - time: 0.0045 - loss_train: 0.8432752262413774 - loss_val: 0.9735047728627758\n",
      "Epoch: 2373 - time: 0.0044 - loss_train: 0.8432308208654398 - loss_val: 0.973491381245796\n",
      "Epoch: 2374 - time: 0.0044 - loss_train: 0.843186452292891 - loss_val: 0.973478013174105\n",
      "Epoch: 2375 - time: 0.0031 - loss_train: 0.8431421205249703 - loss_val: 0.9734646686540848\n",
      "Epoch: 2376 - time: 0.0032 - loss_train: 0.8430978255624696 - loss_val: 0.9734513476919221\n",
      "Epoch: 2377 - time: 0.0031 - loss_train: 0.8430535674057276 - loss_val: 0.9734380502936039\n",
      "Epoch: 2378 - time: 0.0032 - loss_train: 0.843009346054632 - loss_val: 0.973424776464921\n",
      "Epoch: 2379 - time: 0.0031 - loss_train: 0.8429651615086159 - loss_val: 0.9734115262114664\n",
      "Epoch: 2380 - time: 0.0031 - loss_train: 0.8429210137666573 - loss_val: 0.9733982995386345\n",
      "Epoch: 2381 - time: 0.0031 - loss_train: 0.842876902827276 - loss_val: 0.97338509645162\n",
      "Epoch: 2382 - time: 0.0032 - loss_train: 0.8428328286885353 - loss_val: 0.9733719169554208\n",
      "Epoch: 2383 - time: 0.0031 - loss_train: 0.842788791348039 - loss_val: 0.9733587610548349\n",
      "Epoch: 2384 - time: 0.0031 - loss_train: 0.8427447908029299 - loss_val: 0.9733456287544613\n",
      "Epoch: 2385 - time: 0.0031 - loss_train: 0.842700827049891 - loss_val: 0.9733325200586995\n",
      "Epoch: 2386 - time: 0.0037 - loss_train: 0.8426569000851434 - loss_val: 0.9733194349717483\n",
      "Epoch: 2387 - time: 0.0035 - loss_train: 0.8426130099044461 - loss_val: 0.9733063734976097\n",
      "Epoch: 2388 - time: 0.0032 - loss_train: 0.8425691565030957 - loss_val: 0.9732933356400779\n",
      "Epoch: 2389 - time: 0.0031 - loss_train: 0.8425253398759247 - loss_val: 0.9732803214027533\n",
      "Epoch: 2390 - time: 0.0031 - loss_train: 0.8424815600173041 - loss_val: 0.9732673307890316\n",
      "Epoch: 2391 - time: 0.0031 - loss_train: 0.84243781692114 - loss_val: 0.9732543638021075\n",
      "Epoch: 2392 - time: 0.0032 - loss_train: 0.8423941105808758 - loss_val: 0.973241420444972\n",
      "Epoch: 2393 - time: 0.0031 - loss_train: 0.842350440989492 - loss_val: 0.9732285007204161\n",
      "Epoch: 2394 - time: 0.0031 - loss_train: 0.8423068081395052 - loss_val: 0.9732156046310242\n",
      "Epoch: 2395 - time: 0.0031 - loss_train: 0.8422632120229689 - loss_val: 0.9732027321791811\n",
      "Epoch: 2396 - time: 0.0031 - loss_train: 0.8422196526314758 - loss_val: 0.9731898833670652\n",
      "Epoch: 2397 - time: 0.0031 - loss_train: 0.8421761299561559 - loss_val: 0.9731770581966527\n",
      "Epoch: 2398 - time: 0.0031 - loss_train: 0.842132643987676 - loss_val: 0.9731642566697101\n",
      "Epoch: 2399 - time: 0.0031 - loss_train: 0.8420891947162465 - loss_val: 0.9731514787878045\n",
      "Epoch: 2400 - time: 0.0031 - loss_train: 0.8420457821316146 - loss_val: 0.9731387245522947\n",
      "Epoch: 2401 - time: 0.0031 - loss_train: 0.8420024062230707 - loss_val: 0.9731259939643331\n",
      "Epoch: 2402 - time: 0.0031 - loss_train: 0.8419590669794468 - loss_val: 0.9731132870248667\n",
      "Epoch: 2403 - time: 0.0031 - loss_train: 0.8419157643891183 - loss_val: 0.9731006037346334\n",
      "Epoch: 2404 - time: 0.0031 - loss_train: 0.8418724984400056 - loss_val: 0.9730879440941665\n",
      "Epoch: 2405 - time: 0.0032 - loss_train: 0.841829269119575 - loss_val: 0.9730753081037911\n",
      "Epoch: 2406 - time: 0.0031 - loss_train: 0.8417860764148408 - loss_val: 0.9730626957636211\n",
      "Epoch: 2407 - time: 0.0031 - loss_train: 0.8417429203123659 - loss_val: 0.9730501070735642\n",
      "Epoch: 2408 - time: 0.0031 - loss_train: 0.8416998007982631 - loss_val: 0.9730375420333204\n",
      "Epoch: 2409 - time: 0.0031 - loss_train: 0.8416567178581987 - loss_val: 0.9730250006423772\n",
      "Epoch: 2410 - time: 0.0031 - loss_train: 0.8416136714773933 - loss_val: 0.9730124829000137\n",
      "Epoch: 2411 - time: 0.0031 - loss_train: 0.8415706616406228 - loss_val: 0.972999988805299\n",
      "Epoch: 2412 - time: 0.0031 - loss_train: 0.8415276883322209 - loss_val: 0.9729875183570919\n",
      "Epoch: 2413 - time: 0.0031 - loss_train: 0.8414847515360823 - loss_val: 0.9729750715540406\n",
      "Epoch: 2414 - time: 0.0031 - loss_train: 0.8414418512356628 - loss_val: 0.9729626483945807\n",
      "Epoch: 2415 - time: 0.0031 - loss_train: 0.8413989874139838 - loss_val: 0.9729502488769372\n",
      "Epoch: 2416 - time: 0.0031 - loss_train: 0.8413561600536329 - loss_val: 0.9729378729991252\n",
      "Epoch: 2417 - time: 0.0031 - loss_train: 0.8413133691367671 - loss_val: 0.972925520758944\n",
      "Epoch: 2418 - time: 0.0031 - loss_train: 0.8412706146451148 - loss_val: 0.9729131921539838\n",
      "Epoch: 2419 - time: 0.0031 - loss_train: 0.8412278965599779 - loss_val: 0.9729008871816214\n",
      "Epoch: 2420 - time: 0.0031 - loss_train: 0.8411852148622364 - loss_val: 0.9728886058390208\n",
      "Epoch: 2421 - time: 0.0031 - loss_train: 0.8411425695323487 - loss_val: 0.9728763481231326\n",
      "Epoch: 2422 - time: 0.0031 - loss_train: 0.8410999605503562 - loss_val: 0.9728641140306948\n",
      "Epoch: 2423 - time: 0.0038 - loss_train: 0.8410573878958844 - loss_val: 0.9728519035582317\n",
      "Epoch: 2424 - time: 0.0033 - loss_train: 0.8410148515481474 - loss_val: 0.9728397167020566\n",
      "Epoch: 2425 - time: 0.0031 - loss_train: 0.8409723514859497 - loss_val: 0.9728275534582651\n",
      "Epoch: 2426 - time: 0.0032 - loss_train: 0.8409298876876898 - loss_val: 0.9728154138227424\n",
      "Epoch: 2427 - time: 0.0031 - loss_train: 0.8408874601313632 - loss_val: 0.9728032977911594\n",
      "Epoch: 2428 - time: 0.0032 - loss_train: 0.8408450687945648 - loss_val: 0.9727912053589727\n",
      "Epoch: 2429 - time: 0.0031 - loss_train: 0.8408027136544947 - loss_val: 0.9727791365214254\n",
      "Epoch: 2430 - time: 0.0031 - loss_train: 0.8407603946879569 - loss_val: 0.9727670912735482\n",
      "Epoch: 2431 - time: 0.0031 - loss_train: 0.8407181118713671 - loss_val: 0.972755069610156\n",
      "Epoch: 2432 - time: 0.0031 - loss_train: 0.8406758651807527 - loss_val: 0.9727430715258513\n",
      "Epoch: 2433 - time: 0.0031 - loss_train: 0.8406336545917589 - loss_val: 0.9727310970150227\n",
      "Epoch: 2434 - time: 0.0031 - loss_train: 0.8405914800796501 - loss_val: 0.9727191460718465\n",
      "Epoch: 2435 - time: 0.0031 - loss_train: 0.8405493416193143 - loss_val: 0.9727072186902838\n",
      "Epoch: 2436 - time: 0.0031 - loss_train: 0.840507239185267 - loss_val: 0.9726953148640832\n",
      "Epoch: 2437 - time: 0.0032 - loss_train: 0.8404651727516537 - loss_val: 0.9726834345867825\n",
      "Epoch: 2438 - time: 0.0031 - loss_train: 0.8404231422922537 - loss_val: 0.9726715778517034\n",
      "Epoch: 2439 - time: 0.0031 - loss_train: 0.8403811477804862 - loss_val: 0.9726597446519575\n",
      "Epoch: 2440 - time: 0.0032 - loss_train: 0.8403391891894093 - loss_val: 0.9726479349804432\n",
      "Epoch: 2441 - time: 0.0031 - loss_train: 0.8402972664917281 - loss_val: 0.9726361488298466\n",
      "Epoch: 2442 - time: 0.0031 - loss_train: 0.840255379659797 - loss_val: 0.9726243861926439\n",
      "Epoch: 2443 - time: 0.0032 - loss_train: 0.8402135286656224 - loss_val: 0.9726126470610977\n",
      "Epoch: 2444 - time: 0.0031 - loss_train: 0.840171713480867 - loss_val: 0.9726009314272619\n",
      "Epoch: 2445 - time: 0.0031 - loss_train: 0.8401299340768561 - loss_val: 0.972589239282978\n",
      "Epoch: 2446 - time: 0.0031 - loss_train: 0.8400881904245777 - loss_val: 0.972577570619879\n",
      "Epoch: 2447 - time: 0.0031 - loss_train: 0.840046482494689 - loss_val: 0.9725659254293886\n",
      "Epoch: 2448 - time: 0.0031 - loss_train: 0.8400048102575187 - loss_val: 0.9725543037027193\n",
      "Epoch: 2449 - time: 0.0031 - loss_train: 0.8399631736830734 - loss_val: 0.9725427054308766\n",
      "Epoch: 2450 - time: 0.0031 - loss_train: 0.839921572741039 - loss_val: 0.9725311306046587\n",
      "Epoch: 2451 - time: 0.0031 - loss_train: 0.8398800074007852 - loss_val: 0.9725195792146542\n",
      "Epoch: 2452 - time: 0.0031 - loss_train: 0.8398384776313713 - loss_val: 0.9725080512512468\n",
      "Epoch: 2453 - time: 0.0031 - loss_train: 0.8397969834015487 - loss_val: 0.9724965467046133\n",
      "Epoch: 2454 - time: 0.0031 - loss_train: 0.8397555246797642 - loss_val: 0.9724850655647238\n",
      "Epoch: 2455 - time: 0.0031 - loss_train: 0.8397141014341666 - loss_val: 0.9724736078213456\n",
      "Epoch: 2456 - time: 0.0031 - loss_train: 0.8396727136326084 - loss_val: 0.9724621734640402\n",
      "Epoch: 2457 - time: 0.0031 - loss_train: 0.8396313612426511 - loss_val: 0.9724507624821679\n",
      "Epoch: 2458 - time: 0.0031 - loss_train: 0.8395900442315692 - loss_val: 0.9724393748648829\n",
      "Epoch: 2459 - time: 0.0031 - loss_train: 0.8395487625663537 - loss_val: 0.9724280106011406\n",
      "Epoch: 2460 - time: 0.0031 - loss_train: 0.8395075162137168 - loss_val: 0.9724166696796935\n",
      "Epoch: 2461 - time: 0.0041 - loss_train: 0.8394663051400966 - loss_val: 0.9724053520890955\n",
      "Epoch: 2462 - time: 0.0032 - loss_train: 0.8394251293116595 - loss_val: 0.9723940578176995\n",
      "Epoch: 2463 - time: 0.0031 - loss_train: 0.8393839886943054 - loss_val: 0.9723827868536606\n",
      "Epoch: 2464 - time: 0.0031 - loss_train: 0.8393428832536733 - loss_val: 0.9723715391849376\n",
      "Epoch: 2465 - time: 0.0031 - loss_train: 0.8393018129551414 - loss_val: 0.9723603147992905\n",
      "Epoch: 2466 - time: 0.0031 - loss_train: 0.8392607777638358 - loss_val: 0.9723491136842846\n",
      "Epoch: 2467 - time: 0.0031 - loss_train: 0.8392197776446323 - loss_val: 0.9723379358272927\n",
      "Epoch: 2468 - time: 0.0032 - loss_train: 0.8391788125621598 - loss_val: 0.9723267812154903\n",
      "Epoch: 2469 - time: 0.0031 - loss_train: 0.8391378824808057 - loss_val: 0.9723156498358635\n",
      "Epoch: 2470 - time: 0.0031 - loss_train: 0.8390969873647212 - loss_val: 0.9723045416752047\n",
      "Epoch: 2471 - time: 0.0031 - loss_train: 0.8390561271778219 - loss_val: 0.9722934567201186\n",
      "Epoch: 2472 - time: 0.0031 - loss_train: 0.8390153018837948 - loss_val: 0.972282394957017\n",
      "Epoch: 2473 - time: 0.0031 - loss_train: 0.8389745114461019 - loss_val: 0.9722713563721267\n",
      "Epoch: 2474 - time: 0.0031 - loss_train: 0.8389337558279838 - loss_val: 0.9722603409514858\n",
      "Epoch: 2475 - time: 0.0031 - loss_train: 0.8388930349924634 - loss_val: 0.9722493486809476\n",
      "Epoch: 2476 - time: 0.0031 - loss_train: 0.838852348902351 - loss_val: 0.9722383795461803\n",
      "Epoch: 2477 - time: 0.0031 - loss_train: 0.8388116975202472 - loss_val: 0.9722274335326692\n",
      "Epoch: 2478 - time: 0.0031 - loss_train: 0.8387710808085482 - loss_val: 0.9722165106257159\n",
      "Epoch: 2479 - time: 0.0031 - loss_train: 0.8387304987294488 - loss_val: 0.9722056108104444\n",
      "Epoch: 2480 - time: 0.0031 - loss_train: 0.8386899512449463 - loss_val: 0.972194734071795\n",
      "Epoch: 2481 - time: 0.0031 - loss_train: 0.8386494383168454 - loss_val: 0.9721838803945329\n",
      "Epoch: 2482 - time: 0.0031 - loss_train: 0.838608959906762 - loss_val: 0.9721730497632455\n",
      "Epoch: 2483 - time: 0.0031 - loss_train: 0.8385685159761264 - loss_val: 0.9721622421623436\n",
      "Epoch: 2484 - time: 0.0031 - loss_train: 0.8385281064861875 - loss_val: 0.9721514575760647\n",
      "Epoch: 2485 - time: 0.0031 - loss_train: 0.838487731398017 - loss_val: 0.9721406959884735\n",
      "Epoch: 2486 - time: 0.0031 - loss_train: 0.8384473906725128 - loss_val: 0.9721299573834623\n",
      "Epoch: 2487 - time: 0.0031 - loss_train: 0.8384070842704042 - loss_val: 0.9721192417447535\n",
      "Epoch: 2488 - time: 0.0031 - loss_train: 0.8383668121522534 - loss_val: 0.972108549055902\n",
      "Epoch: 2489 - time: 0.0031 - loss_train: 0.8383265742784618 - loss_val: 0.9720978793002946\n",
      "Epoch: 2490 - time: 0.0032 - loss_train: 0.8382863706092719 - loss_val: 0.9720872324611511\n",
      "Epoch: 2491 - time: 0.0035 - loss_train: 0.8382462011047722 - loss_val: 0.97207660852153\n",
      "Epoch: 2492 - time: 0.0032 - loss_train: 0.8382060657249001 - loss_val: 0.9720660074643246\n",
      "Epoch: 2493 - time: 0.0031 - loss_train: 0.8381659644294466 - loss_val: 0.972055429272266\n",
      "Epoch: 2494 - time: 0.0031 - loss_train: 0.8381258971780594 - loss_val: 0.9720448739279282\n",
      "Epoch: 2495 - time: 0.0031 - loss_train: 0.8380858639302455 - loss_val: 0.972034341413724\n",
      "Epoch: 2496 - time: 0.0031 - loss_train: 0.8380458646453781 - loss_val: 0.972023831711913\n",
      "Epoch: 2497 - time: 0.0031 - loss_train: 0.8380058992826966 - loss_val: 0.9720133448045951\n",
      "Epoch: 2498 - time: 0.0031 - loss_train: 0.8379659678013108 - loss_val: 0.97200288067372\n",
      "Epoch: 2499 - time: 0.0037 - loss_train: 0.8379260701602074 - loss_val: 0.9719924393010843\n",
      "Epoch: 2500 - time: 0.0032 - loss_train: 0.8378862063182502 - loss_val: 0.9719820206683324\n",
      "Epoch: 2501 - time: 0.0031 - loss_train: 0.8378463762341848 - loss_val: 0.9719716247569621\n",
      "Epoch: 2502 - time: 0.0031 - loss_train: 0.8378065798666423 - loss_val: 0.9719612515483218\n",
      "Epoch: 2503 - time: 0.0031 - loss_train: 0.8377668171741426 - loss_val: 0.9719509010236169\n",
      "Epoch: 2504 - time: 0.0031 - loss_train: 0.8377270881150973 - loss_val: 0.9719405731639047\n",
      "Epoch: 2505 - time: 0.0031 - loss_train: 0.837687392647814 - loss_val: 0.9719302679501017\n",
      "Epoch: 2506 - time: 0.0031 - loss_train: 0.8376477307304988 - loss_val: 0.9719199853629853\n",
      "Epoch: 2507 - time: 0.0031 - loss_train: 0.8376081023212596 - loss_val: 0.9719097253831905\n",
      "Epoch: 2508 - time: 0.0031 - loss_train: 0.8375685073781102 - loss_val: 0.971899487991217\n",
      "Epoch: 2509 - time: 0.0031 - loss_train: 0.837528945858973 - loss_val: 0.9718892731674267\n",
      "Epoch: 2510 - time: 0.0031 - loss_train: 0.837489417721682 - loss_val: 0.9718790808920474\n",
      "Epoch: 2511 - time: 0.0031 - loss_train: 0.8374499229239858 - loss_val: 0.9718689111451764\n",
      "Epoch: 2512 - time: 0.0031 - loss_train: 0.8374104614235527 - loss_val: 0.9718587639067764\n",
      "Epoch: 2513 - time: 0.0031 - loss_train: 0.8373710331779701 - loss_val: 0.9718486391566821\n",
      "Epoch: 2514 - time: 0.0031 - loss_train: 0.8373316381447516 - loss_val: 0.9718385368746018\n",
      "Epoch: 2515 - time: 0.0031 - loss_train: 0.8372922762813374 - loss_val: 0.9718284570401162\n",
      "Epoch: 2516 - time: 0.0031 - loss_train: 0.837252947545098 - loss_val: 0.9718183996326816\n",
      "Epoch: 2517 - time: 0.0031 - loss_train: 0.8372136518933373 - loss_val: 0.9718083646316311\n",
      "Epoch: 2518 - time: 0.0031 - loss_train: 0.8371743892832955 - loss_val: 0.9717983520161779\n",
      "Epoch: 2519 - time: 0.0031 - loss_train: 0.8371351596721524 - loss_val: 0.9717883617654156\n",
      "Epoch: 2520 - time: 0.0031 - loss_train: 0.8370959630170294 - loss_val: 0.9717783938583199\n",
      "Epoch: 2521 - time: 0.0031 - loss_train: 0.8370567992749933 - loss_val: 0.9717684482737489\n",
      "Epoch: 2522 - time: 0.0031 - loss_train: 0.8370176684030585 - loss_val: 0.9717585249904482\n",
      "Epoch: 2523 - time: 0.0031 - loss_train: 0.8369785703581895 - loss_val: 0.9717486239870493\n",
      "Epoch: 2524 - time: 0.0032 - loss_train: 0.8369395050973044 - loss_val: 0.9717387452420753\n",
      "Epoch: 2525 - time: 0.0031 - loss_train: 0.8369004725772773 - loss_val: 0.9717288887339364\n",
      "Epoch: 2526 - time: 0.0031 - loss_train: 0.83686147275494 - loss_val: 0.9717190544409366\n",
      "Epoch: 2527 - time: 0.0032 - loss_train: 0.8368225055870872 - loss_val: 0.9717092423412744\n",
      "Epoch: 2528 - time: 0.0031 - loss_train: 0.8367835710304764 - loss_val: 0.9716994524130433\n",
      "Epoch: 2529 - time: 0.0031 - loss_train: 0.8367446690418316 - loss_val: 0.9716896846342343\n",
      "Epoch: 2530 - time: 0.0031 - loss_train: 0.8367057995778459 - loss_val: 0.971679938982737\n",
      "Epoch: 2531 - time: 0.0031 - loss_train: 0.8366669625951833 - loss_val: 0.9716702154363416\n",
      "Epoch: 2532 - time: 0.0031 - loss_train: 0.8366281580504822 - loss_val: 0.9716605139727412\n",
      "Epoch: 2533 - time: 0.0031 - loss_train: 0.8365893859003573 - loss_val: 0.9716508345695328\n",
      "Epoch: 2534 - time: 0.0031 - loss_train: 0.8365506461014022 - loss_val: 0.9716411772042174\n",
      "Epoch: 2535 - time: 0.0031 - loss_train: 0.8365119386101909 - loss_val: 0.971631541854205\n",
      "Epoch: 2536 - time: 0.0031 - loss_train: 0.8364732633832813 - loss_val: 0.9716219284968137\n",
      "Epoch: 2537 - time: 0.0035 - loss_train: 0.8364346203772169 - loss_val: 0.9716123371092731\n",
      "Epoch: 2538 - time: 0.0032 - loss_train: 0.836396009548529 - loss_val: 0.9716027676687221\n",
      "Epoch: 2539 - time: 0.0031 - loss_train: 0.8363574308537393 - loss_val: 0.9715932201522157\n",
      "Epoch: 2540 - time: 0.0031 - loss_train: 0.8363188842493614 - loss_val: 0.971583694536725\n",
      "Epoch: 2541 - time: 0.0031 - loss_train: 0.8362803696919042 - loss_val: 0.9715741907991353\n",
      "Epoch: 2542 - time: 0.0031 - loss_train: 0.8362418871378722 - loss_val: 0.9715647089162522\n",
      "Epoch: 2543 - time: 0.0031 - loss_train: 0.8362034365437694 - loss_val: 0.9715552488648012\n",
      "Epoch: 2544 - time: 0.0031 - loss_train: 0.8361650178661006 - loss_val: 0.9715458106214292\n",
      "Epoch: 2545 - time: 0.0031 - loss_train: 0.8361266310613732 - loss_val: 0.9715363941627058\n",
      "Epoch: 2546 - time: 0.0031 - loss_train: 0.836088276086099 - loss_val: 0.9715269994651273\n",
      "Epoch: 2547 - time: 0.0031 - loss_train: 0.8360499528967976 - loss_val: 0.9715176265051145\n",
      "Epoch: 2548 - time: 0.0031 - loss_train: 0.836011661449996 - loss_val: 0.9715082752590176\n",
      "Epoch: 2549 - time: 0.0031 - loss_train: 0.8359734017022329 - loss_val: 0.9714989457031153\n",
      "Epoch: 2550 - time: 0.0031 - loss_train: 0.835935173610059 - loss_val: 0.9714896378136182\n",
      "Epoch: 2551 - time: 0.0031 - loss_train: 0.8358969771300394 - loss_val: 0.9714803515666679\n",
      "Epoch: 2552 - time: 0.0031 - loss_train: 0.835858812218755 - loss_val: 0.9714710869383422\n",
      "Epoch: 2553 - time: 0.0031 - loss_train: 0.8358206788328053 - loss_val: 0.9714618439046528\n",
      "Epoch: 2554 - time: 0.0031 - loss_train: 0.8357825769288086 - loss_val: 0.9714526224415498\n",
      "Epoch: 2555 - time: 0.0031 - loss_train: 0.8357445064634055 - loss_val: 0.9714434225249216\n",
      "Epoch: 2556 - time: 0.0031 - loss_train: 0.8357064673932587 - loss_val: 0.9714342441305942\n",
      "Epoch: 2557 - time: 0.0031 - loss_train: 0.8356684596750557 - loss_val: 0.9714250872343404\n",
      "Epoch: 2558 - time: 0.0031 - loss_train: 0.8356304832655107 - loss_val: 0.9714159518118708\n",
      "Epoch: 2559 - time: 0.0031 - loss_train: 0.8355925381213659 - loss_val: 0.9714068378388429\n",
      "Epoch: 2560 - time: 0.0031 - loss_train: 0.8355546241993927 - loss_val: 0.9713977452908602\n",
      "Epoch: 2561 - time: 0.0031 - loss_train: 0.8355167414563932 - loss_val: 0.9713886741434724\n",
      "Epoch: 2562 - time: 0.0031 - loss_train: 0.8354788898492029 - loss_val: 0.9713796243721784\n",
      "Epoch: 2563 - time: 0.0031 - loss_train: 0.8354410693346895 - loss_val: 0.971370595952428\n",
      "Epoch: 2564 - time: 0.0031 - loss_train: 0.8354032798697587 - loss_val: 0.9713615888596214\n",
      "Epoch: 2565 - time: 0.0031 - loss_train: 0.8353655214113511 - loss_val: 0.9713526030691125\n",
      "Epoch: 2566 - time: 0.0031 - loss_train: 0.8353277939164463 - loss_val: 0.971343638556209\n",
      "Epoch: 2567 - time: 0.0031 - loss_train: 0.8352900973420633 - loss_val: 0.9713346952961738\n",
      "Epoch: 2568 - time: 0.0032 - loss_train: 0.8352524316452623 - loss_val: 0.9713257732642274\n",
      "Epoch: 2569 - time: 0.0031 - loss_train: 0.8352147967831454 - loss_val: 0.9713168724355494\n",
      "Epoch: 2570 - time: 0.0031 - loss_train: 0.8351771927128591 - loss_val: 0.9713079927852765\n",
      "Epoch: 2571 - time: 0.0031 - loss_train: 0.8351396193915931 - loss_val: 0.971299134288509\n",
      "Epoch: 2572 - time: 0.0031 - loss_train: 0.835102076776585 - loss_val: 0.9712902969203078\n",
      "Epoch: 2573 - time: 0.0031 - loss_train: 0.8350645648251193 - loss_val: 0.9712814806556979\n",
      "Epoch: 2574 - time: 0.0031 - loss_train: 0.8350270834945273 - loss_val: 0.9712726854696694\n",
      "Epoch: 2575 - time: 0.0034 - loss_train: 0.8349896327421924 - loss_val: 0.9712639113371767\n",
      "Epoch: 2576 - time: 0.0032 - loss_train: 0.8349522125255471 - loss_val: 0.9712551582331437\n",
      "Epoch: 2577 - time: 0.0031 - loss_train: 0.8349148228020761 - loss_val: 0.9712464261324626\n",
      "Epoch: 2578 - time: 0.0031 - loss_train: 0.8348774635293177 - loss_val: 0.9712377150099923\n",
      "Epoch: 2579 - time: 0.0031 - loss_train: 0.8348401346648634 - loss_val: 0.9712290248405671\n",
      "Epoch: 2580 - time: 0.0031 - loss_train: 0.83480283616636 - loss_val: 0.9712203555989894\n",
      "Epoch: 2581 - time: 0.0031 - loss_train: 0.8347655679915108 - loss_val: 0.9712117072600377\n",
      "Epoch: 2582 - time: 0.0031 - loss_train: 0.8347283300980757 - loss_val: 0.9712030797984632\n",
      "Epoch: 2583 - time: 0.0031 - loss_train: 0.8346911224438727 - loss_val: 0.9711944731889941\n",
      "Epoch: 2584 - time: 0.0031 - loss_train: 0.8346539449867791 - loss_val: 0.971185887406335\n",
      "Epoch: 2585 - time: 0.0031 - loss_train: 0.834616797684732 - loss_val: 0.9711773224251663\n",
      "Epoch: 2586 - time: 0.0031 - loss_train: 0.8345796804957295 - loss_val: 0.971168778220151\n",
      "Epoch: 2587 - time: 0.0031 - loss_train: 0.8345425933778305 - loss_val: 0.9711602547659295\n",
      "Epoch: 2588 - time: 0.0031 - loss_train: 0.8345055362891577 - loss_val: 0.9711517520371237\n",
      "Epoch: 2589 - time: 0.0031 - loss_train: 0.8344685091878964 - loss_val: 0.9711432700083397\n",
      "Epoch: 2590 - time: 0.0031 - loss_train: 0.8344315120322966 - loss_val: 0.9711348086541643\n",
      "Epoch: 2591 - time: 0.0031 - loss_train: 0.8343945447806732 - loss_val: 0.97112636794917\n",
      "Epoch: 2592 - time: 0.0032 - loss_train: 0.8343576073914066 - loss_val: 0.9711179478679152\n",
      "Epoch: 2593 - time: 0.0031 - loss_train: 0.8343206998229441 - loss_val: 0.971109548384942\n",
      "Epoch: 2594 - time: 0.0031 - loss_train: 0.8342838220338006 - loss_val: 0.9711011694747843\n",
      "Epoch: 2595 - time: 0.0031 - loss_train: 0.8342469739825581 - loss_val: 0.9710928111119611\n",
      "Epoch: 2596 - time: 0.0031 - loss_train: 0.8342101556278683 - loss_val: 0.9710844732709808\n",
      "Epoch: 2597 - time: 0.0031 - loss_train: 0.8341733669284519 - loss_val: 0.971076155926344\n",
      "Epoch: 2598 - time: 0.0031 - loss_train: 0.834136607843099 - loss_val: 0.9710678590525422\n",
      "Epoch: 2599 - time: 0.0031 - loss_train: 0.8340998783306722 - loss_val: 0.9710595826240567\n",
      "Epoch: 2600 - time: 0.0031 - loss_train: 0.8340631783501038 - loss_val: 0.9710513266153654\n",
      "Epoch: 2601 - time: 0.0031 - loss_train: 0.8340265078603989 - loss_val: 0.9710430910009383\n",
      "Epoch: 2602 - time: 0.0031 - loss_train: 0.8339898668206345 - loss_val: 0.9710348757552406\n",
      "Epoch: 2603 - time: 0.0031 - loss_train: 0.8339532551899613 - loss_val: 0.9710266808527337\n",
      "Epoch: 2604 - time: 0.0031 - loss_train: 0.8339166729276042 - loss_val: 0.9710185062678752\n",
      "Epoch: 2605 - time: 0.0031 - loss_train: 0.8338801199928603 - loss_val: 0.9710103519751208\n",
      "Epoch: 2606 - time: 0.0032 - loss_train: 0.833843596345104 - loss_val: 0.9710022179489245\n",
      "Epoch: 2607 - time: 0.0031 - loss_train: 0.833807101943783 - loss_val: 0.9709941041637393\n",
      "Epoch: 2608 - time: 0.0031 - loss_train: 0.8337706367484222 - loss_val: 0.9709860105940186\n",
      "Epoch: 2609 - time: 0.0031 - loss_train: 0.8337342007186215 - loss_val: 0.9709779372142163\n",
      "Epoch: 2610 - time: 0.0031 - loss_train: 0.8336977938140585 - loss_val: 0.9709698839987881\n",
      "Epoch: 2611 - time: 0.0031 - loss_train: 0.8336614159944873 - loss_val: 0.9709618509221932\n",
      "Epoch: 2612 - time: 0.0031 - loss_train: 0.8336250672197401 - loss_val: 0.9709538379588923\n",
      "Epoch: 2613 - time: 0.0034 - loss_train: 0.8335887474497261 - loss_val: 0.9709458450833505\n",
      "Epoch: 2614 - time: 0.0032 - loss_train: 0.8335524566444346 - loss_val: 0.9709378722700394\n",
      "Epoch: 2615 - time: 0.0031 - loss_train: 0.8335161947639319 - loss_val: 0.9709299194934322\n",
      "Epoch: 2616 - time: 0.0031 - loss_train: 0.8334799617683646 - loss_val: 0.9709219867280128\n",
      "Epoch: 2617 - time: 0.0031 - loss_train: 0.8334437576179586 - loss_val: 0.9709140739482683\n",
      "Epoch: 2618 - time: 0.0031 - loss_train: 0.8334075822730195 - loss_val: 0.9709061811286954\n",
      "Epoch: 2619 - time: 0.0031 - loss_train: 0.8333714356939332 - loss_val: 0.9708983082437981\n",
      "Epoch: 2620 - time: 0.0031 - loss_train: 0.8333353178411658 - loss_val: 0.9708904552680901\n",
      "Epoch: 2621 - time: 0.0031 - loss_train: 0.833299228675265 - loss_val: 0.9708826221760934\n",
      "Epoch: 2622 - time: 0.0031 - loss_train: 0.8332631681568589 - loss_val: 0.970874808942341\n",
      "Epoch: 2623 - time: 0.0031 - loss_train: 0.8332271362466575 - loss_val: 0.9708670155413767\n",
      "Epoch: 2624 - time: 0.0031 - loss_train: 0.8331911329054521 - loss_val: 0.9708592419477554\n",
      "Epoch: 2625 - time: 0.0031 - loss_train: 0.8331551580941167 - loss_val: 0.9708514881360445\n",
      "Epoch: 2626 - time: 0.0031 - loss_train: 0.8331192117736063 - loss_val: 0.9708437540808225\n",
      "Epoch: 2627 - time: 0.0032 - loss_train: 0.8330832939049596 - loss_val: 0.9708360397566828\n",
      "Epoch: 2628 - time: 0.0031 - loss_train: 0.8330474044492973 - loss_val: 0.9708283451382326\n",
      "Epoch: 2629 - time: 0.0031 - loss_train: 0.8330115433678225 - loss_val: 0.9708206702000911\n",
      "Epoch: 2630 - time: 0.0031 - loss_train: 0.8329757106218226 - loss_val: 0.9708130149168953\n",
      "Epoch: 2631 - time: 0.0031 - loss_train: 0.8329399061726672 - loss_val: 0.9708053792632946\n",
      "Epoch: 2632 - time: 0.0031 - loss_train: 0.83290412998181 - loss_val: 0.9707977632139568\n",
      "Epoch: 2633 - time: 0.0031 - loss_train: 0.832868382010788 - loss_val: 0.9707901667435656\n",
      "Epoch: 2634 - time: 0.0031 - loss_train: 0.8328326622212225 - loss_val: 0.9707825898268201\n",
      "Epoch: 2635 - time: 0.0031 - loss_train: 0.8327969705748179 - loss_val: 0.9707750324384372\n",
      "Epoch: 2636 - time: 0.0031 - loss_train: 0.8327613070333635 - loss_val: 0.9707674945531526\n",
      "Epoch: 2637 - time: 0.0031 - loss_train: 0.8327256715587318 - loss_val: 0.9707599761457196\n",
      "Epoch: 2638 - time: 0.0031 - loss_train: 0.8326900641128814 - loss_val: 0.9707524771909104\n",
      "Epoch: 2639 - time: 0.0031 - loss_train: 0.8326544846578534 - loss_val: 0.9707449976635174\n",
      "Epoch: 2640 - time: 0.0031 - loss_train: 0.8326189331557753 - loss_val: 0.9707375375383499\n",
      "Epoch: 2641 - time: 0.0031 - loss_train: 0.8325834095688567 - loss_val: 0.970730096790239\n",
      "Epoch: 2642 - time: 0.0031 - loss_train: 0.8325479138593953 - loss_val: 0.9707226753940368\n",
      "Epoch: 2643 - time: 0.0031 - loss_train: 0.8325124459897711 - loss_val: 0.9707152733246146\n",
      "Epoch: 2644 - time: 0.0031 - loss_train: 0.83247700592245 - loss_val: 0.9707078905568668\n",
      "Epoch: 2645 - time: 0.0031 - loss_train: 0.8324415936199823 - loss_val: 0.9707005270657069\n",
      "Epoch: 2646 - time: 0.0031 - loss_train: 0.832406209045004 - loss_val: 0.9706931828260731\n",
      "Epoch: 2647 - time: 0.0031 - loss_train: 0.8323708521602362 - loss_val: 0.9706858578129227\n",
      "Epoch: 2648 - time: 0.0031 - loss_train: 0.8323355229284842 - loss_val: 0.9706785520012383\n",
      "Epoch: 2649 - time: 0.0031 - loss_train: 0.8323002213126396 - loss_val: 0.9706712653660254\n",
      "Epoch: 2650 - time: 0.0031 - loss_train: 0.8322649472756782 - loss_val: 0.9706639978823103\n",
      "Epoch: 2651 - time: 0.0035 - loss_train: 0.8322297007806615 - loss_val: 0.9706567495251449\n",
      "Epoch: 2652 - time: 0.0033 - loss_train: 0.8321944817907363 - loss_val: 0.970649520269605\n",
      "Epoch: 2653 - time: 0.0032 - loss_train: 0.832159290269134 - loss_val: 0.9706423100907899\n",
      "Epoch: 2654 - time: 0.0031 - loss_train: 0.8321241261791719 - loss_val: 0.9706351189638234\n",
      "Epoch: 2655 - time: 0.0031 - loss_train: 0.8320889894842524 - loss_val: 0.9706279468638532\n",
      "Epoch: 2656 - time: 0.0031 - loss_train: 0.8320538801478622 - loss_val: 0.9706207937660543\n",
      "Epoch: 2657 - time: 0.0031 - loss_train: 0.8320187981335746 - loss_val: 0.9706136596456252\n",
      "Epoch: 2658 - time: 0.0031 - loss_train: 0.8319837434050464 - loss_val: 0.9706065444777896\n",
      "Epoch: 2659 - time: 0.0031 - loss_train: 0.8319487159260216 - loss_val: 0.9705994482377982\n",
      "Epoch: 2660 - time: 0.0031 - loss_train: 0.8319137156603269 - loss_val: 0.9705923709009273\n",
      "Epoch: 2661 - time: 0.0031 - loss_train: 0.8318787425718754 - loss_val: 0.9705853124424787\n",
      "Epoch: 2662 - time: 0.0031 - loss_train: 0.8318437966246651 - loss_val: 0.9705782728377806\n",
      "Epoch: 2663 - time: 0.0031 - loss_train: 0.8318088777827788 - loss_val: 0.970571252062188\n",
      "Epoch: 2664 - time: 0.0031 - loss_train: 0.8317739860103837 - loss_val: 0.9705642500910828\n",
      "Epoch: 2665 - time: 0.0032 - loss_train: 0.8317391212717324 - loss_val: 0.9705572668998754\n",
      "Epoch: 2666 - time: 0.0036 - loss_train: 0.8317042835311614 - loss_val: 0.9705503024639984\n",
      "Epoch: 2667 - time: 0.0036 - loss_train: 0.8316694727530928 - loss_val: 0.9705433567589181\n",
      "Epoch: 2668 - time: 0.0031 - loss_train: 0.8316346889020328 - loss_val: 0.9705364297601231\n",
      "Epoch: 2669 - time: 0.0031 - loss_train: 0.8315999319425718 - loss_val: 0.970529521443132\n",
      "Epoch: 2670 - time: 0.0031 - loss_train: 0.8315652018393851 - loss_val: 0.9705226317834914\n",
      "Epoch: 2671 - time: 0.0031 - loss_train: 0.8315304985572317 - loss_val: 0.9705157607567743\n",
      "Epoch: 2672 - time: 0.0031 - loss_train: 0.8314958220609551 - loss_val: 0.9705089083385828\n",
      "Epoch: 2673 - time: 0.0031 - loss_train: 0.8314611723154833 - loss_val: 0.9705020745045456\n",
      "Epoch: 2674 - time: 0.0031 - loss_train: 0.831426549285827 - loss_val: 0.9704952592303214\n",
      "Epoch: 2675 - time: 0.0032 - loss_train: 0.8313919529370821 - loss_val: 0.9704884624915967\n",
      "Epoch: 2676 - time: 0.0031 - loss_train: 0.8313573832344273 - loss_val: 0.9704816842640857\n",
      "Epoch: 2677 - time: 0.0032 - loss_train: 0.8313228401431253 - loss_val: 0.9704749245235322\n",
      "Epoch: 2678 - time: 0.0031 - loss_train: 0.8312883236285227 - loss_val: 0.9704681832457064\n",
      "Epoch: 2679 - time: 0.0031 - loss_train: 0.8312538336560481 - loss_val: 0.9704614604064097\n",
      "Epoch: 2680 - time: 0.0031 - loss_train: 0.8312193701912153 - loss_val: 0.9704547559814702\n",
      "Epoch: 2681 - time: 0.0031 - loss_train: 0.8311849331996193 - loss_val: 0.9704480699467465\n",
      "Epoch: 2682 - time: 0.0031 - loss_train: 0.8311505226469392 - loss_val: 0.9704414022781253\n",
      "Epoch: 2683 - time: 0.0032 - loss_train: 0.8311161384989362 - loss_val: 0.97043475295152\n",
      "Epoch: 2684 - time: 0.0031 - loss_train: 0.8310817807214551 - loss_val: 0.970428121942877\n",
      "Epoch: 2685 - time: 0.0031 - loss_train: 0.8310474492804221 - loss_val: 0.9704215092281677\n",
      "Epoch: 2686 - time: 0.0031 - loss_train: 0.8310131441418467 - loss_val: 0.9704149147833948\n",
      "Epoch: 2687 - time: 0.0031 - loss_train: 0.8309788652718197 - loss_val: 0.9704083385845883\n",
      "Epoch: 2688 - time: 0.0031 - loss_train: 0.8309446126365153 - loss_val: 0.9704017806078096\n",
      "Epoch: 2689 - time: 0.0038 - loss_train: 0.8309103862021879 - loss_val: 0.970395240829146\n",
      "Epoch: 2690 - time: 0.0032 - loss_train: 0.8308761859351751 - loss_val: 0.9703887192247159\n",
      "Epoch: 2691 - time: 0.0031 - loss_train: 0.830842011801895 - loss_val: 0.9703822157706661\n",
      "Epoch: 2692 - time: 0.0031 - loss_train: 0.8308078637688474 - loss_val: 0.9703757304431715\n",
      "Epoch: 2693 - time: 0.0031 - loss_train: 0.8307737418026138 - loss_val: 0.9703692632184373\n",
      "Epoch: 2694 - time: 0.0031 - loss_train: 0.8307396458698563 - loss_val: 0.9703628140726958\n",
      "Epoch: 2695 - time: 0.0031 - loss_train: 0.8307055759373176 - loss_val: 0.97035638298221\n",
      "Epoch: 2696 - time: 0.0031 - loss_train: 0.8306715319718223 - loss_val: 0.9703499699232698\n",
      "Epoch: 2697 - time: 0.0031 - loss_train: 0.8306375139402742 - loss_val: 0.9703435748721966\n",
      "Epoch: 2698 - time: 0.0031 - loss_train: 0.8306035218096577 - loss_val: 0.9703371978053373\n",
      "Epoch: 2699 - time: 0.0031 - loss_train: 0.8305695555470375 - loss_val: 0.9703308386990697\n",
      "Epoch: 2700 - time: 0.0031 - loss_train: 0.8305356151195585 - loss_val: 0.970324497529798\n",
      "Epoch: 2701 - time: 0.0031 - loss_train: 0.830501700494445 - loss_val: 0.9703181742739582\n",
      "Epoch: 2702 - time: 0.0031 - loss_train: 0.8304678116390016 - loss_val: 0.9703118689080122\n",
      "Epoch: 2703 - time: 0.0031 - loss_train: 0.8304339485206116 - loss_val: 0.9703055814084507\n",
      "Epoch: 2704 - time: 0.0031 - loss_train: 0.8304001111067371 - loss_val: 0.9702993117517924\n",
      "Epoch: 2705 - time: 0.0031 - loss_train: 0.8303662993649203 - loss_val: 0.9702930599145845\n",
      "Epoch: 2706 - time: 0.0031 - loss_train: 0.8303325132627811 - loss_val: 0.9702868258734045\n",
      "Epoch: 2707 - time: 0.0031 - loss_train: 0.8302987527680195 - loss_val: 0.970280609604854\n",
      "Epoch: 2708 - time: 0.0031 - loss_train: 0.8302650178484117 - loss_val: 0.9702744110855649\n",
      "Epoch: 2709 - time: 0.0031 - loss_train: 0.8302313084718145 - loss_val: 0.9702682302921969\n",
      "Epoch: 2710 - time: 0.0031 - loss_train: 0.8301976246061611 - loss_val: 0.9702620672014357\n",
      "Epoch: 2711 - time: 0.0031 - loss_train: 0.8301639662194628 - loss_val: 0.9702559217899974\n",
      "Epoch: 2712 - time: 0.0031 - loss_train: 0.8301303332798086 - loss_val: 0.9702497940346237\n",
      "Epoch: 2713 - time: 0.0031 - loss_train: 0.8300967257553654 - loss_val: 0.9702436839120826\n",
      "Epoch: 2714 - time: 0.0031 - loss_train: 0.8300631436143763 - loss_val: 0.9702375913991713\n",
      "Epoch: 2715 - time: 0.0031 - loss_train: 0.8300295868251623 - loss_val: 0.9702315164727136\n",
      "Epoch: 2716 - time: 0.0031 - loss_train: 0.8299960553561204 - loss_val: 0.9702254591095605\n",
      "Epoch: 2717 - time: 0.0031 - loss_train: 0.8299625491757241 - loss_val: 0.9702194192865884\n",
      "Epoch: 2718 - time: 0.0031 - loss_train: 0.8299290682525248 - loss_val: 0.9702133969807019\n",
      "Epoch: 2719 - time: 0.0031 - loss_train: 0.8298956125551474 - loss_val: 0.9702073921688307\n",
      "Epoch: 2720 - time: 0.0031 - loss_train: 0.8298621820522946 - loss_val: 0.9702014048279327\n",
      "Epoch: 2721 - time: 0.0031 - loss_train: 0.8298287767127445 - loss_val: 0.9701954349349896\n",
      "Epoch: 2722 - time: 0.0031 - loss_train: 0.8297953965053503 - loss_val: 0.9701894824670128\n",
      "Epoch: 2723 - time: 0.0031 - loss_train: 0.8297620413990403 - loss_val: 0.9701835474010357\n",
      "Epoch: 2724 - time: 0.0031 - loss_train: 0.8297287113628183 - loss_val: 0.9701776297141189\n",
      "Epoch: 2725 - time: 0.0031 - loss_train: 0.8296954063657627 - loss_val: 0.9701717293833498\n",
      "Epoch: 2726 - time: 0.0031 - loss_train: 0.8296621263770264 - loss_val: 0.9701658463858394\n",
      "Epoch: 2727 - time: 0.0035 - loss_train: 0.8296288713658369 - loss_val: 0.9701599806987246\n",
      "Epoch: 2728 - time: 0.0032 - loss_train: 0.8295956413014953 - loss_val: 0.9701541322991672\n",
      "Epoch: 2729 - time: 0.0031 - loss_train: 0.8295624361533778 - loss_val: 0.9701483011643542\n",
      "Epoch: 2730 - time: 0.0031 - loss_train: 0.8295292558909325 - loss_val: 0.970142487271497\n",
      "Epoch: 2731 - time: 0.0031 - loss_train: 0.8294961004836825 - loss_val: 0.9701366905978323\n",
      "Epoch: 2732 - time: 0.0031 - loss_train: 0.8294629699012241 - loss_val: 0.9701309111206197\n",
      "Epoch: 2733 - time: 0.0031 - loss_train: 0.829429864113226 - loss_val: 0.9701251488171424\n",
      "Epoch: 2734 - time: 0.0031 - loss_train: 0.8293967830894288 - loss_val: 0.9701194036647106\n",
      "Epoch: 2735 - time: 0.0031 - loss_train: 0.8293637267996479 - loss_val: 0.9701136756406552\n",
      "Epoch: 2736 - time: 0.0031 - loss_train: 0.8293306952137696 - loss_val: 0.9701079647223316\n",
      "Epoch: 2737 - time: 0.0031 - loss_train: 0.8292976883017528 - loss_val: 0.9701022708871193\n",
      "Epoch: 2738 - time: 0.0031 - loss_train: 0.8292647060336278 - loss_val: 0.9700965941124187\n",
      "Epoch: 2739 - time: 0.0031 - loss_train: 0.829231748379497 - loss_val: 0.9700909343756559\n",
      "Epoch: 2740 - time: 0.0031 - loss_train: 0.8291988153095342 - loss_val: 0.9700852916542778\n",
      "Epoch: 2741 - time: 0.0037 - loss_train: 0.8291659067939845 - loss_val: 0.9700796659257531\n",
      "Epoch: 2742 - time: 0.0036 - loss_train: 0.8291330228031641 - loss_val: 0.9700740571675768\n",
      "Epoch: 2743 - time: 0.0036 - loss_train: 0.8291001633074591 - loss_val: 0.9700684653572597\n",
      "Epoch: 2744 - time: 0.0036 - loss_train: 0.8290673282773271 - loss_val: 0.9700628904723396\n",
      "Epoch: 2745 - time: 0.0036 - loss_train: 0.8290345176832958 - loss_val: 0.970057332490374\n",
      "Epoch: 2746 - time: 0.0036 - loss_train: 0.829001731495963 - loss_val: 0.970051791388941\n",
      "Epoch: 2747 - time: 0.0036 - loss_train: 0.8289689696859958 - loss_val: 0.9700462671456417\n",
      "Epoch: 2748 - time: 0.0036 - loss_train: 0.8289362322241316 - loss_val: 0.9700407597380956\n",
      "Epoch: 2749 - time: 0.0036 - loss_train: 0.8289035190811769 - loss_val: 0.9700352691439459\n",
      "Epoch: 2750 - time: 0.0036 - loss_train: 0.8288708302280077 - loss_val: 0.9700297953408537\n",
      "Epoch: 2751 - time: 0.0036 - loss_train: 0.8288381656355682 - loss_val: 0.9700243383065005\n",
      "Epoch: 2752 - time: 0.0036 - loss_train: 0.8288055252748722 - loss_val: 0.9700188980185908\n",
      "Epoch: 2753 - time: 0.0036 - loss_train: 0.8287729091170011 - loss_val: 0.9700134744548449\n",
      "Epoch: 2754 - time: 0.0035 - loss_train: 0.8287403171331055 - loss_val: 0.9700080675930056\n",
      "Epoch: 2755 - time: 0.0036 - loss_train: 0.8287077492944033 - loss_val: 0.9700026774108326\n",
      "Epoch: 2756 - time: 0.0036 - loss_train: 0.8286752055721807 - loss_val: 0.9699973038861057\n",
      "Epoch: 2757 - time: 0.0036 - loss_train: 0.8286426859377903 - loss_val: 0.9699919469966244\n",
      "Epoch: 2758 - time: 0.0036 - loss_train: 0.8286101903626545 - loss_val: 0.9699866067202059\n",
      "Epoch: 2759 - time: 0.0038 - loss_train: 0.8285777188182604 - loss_val: 0.9699812830346839\n",
      "Epoch: 2760 - time: 0.0039 - loss_train: 0.8285452712761628 - loss_val: 0.9699759759179146\n",
      "Epoch: 2761 - time: 0.0039 - loss_train: 0.8285128477079831 - loss_val: 0.9699706853477669\n",
      "Epoch: 2762 - time: 0.0055 - loss_train: 0.8284804480854098 - loss_val: 0.9699654113021312\n",
      "Epoch: 2763 - time: 0.0038 - loss_train: 0.8284480723801971 - loss_val: 0.9699601537589138\n",
      "Epoch: 2764 - time: 0.0038 - loss_train: 0.8284157205641646 - loss_val: 0.9699549126960382\n",
      "Epoch: 2765 - time: 0.0039 - loss_train: 0.8283833926091984 - loss_val: 0.969949688091443\n",
      "Epoch: 2766 - time: 0.0039 - loss_train: 0.8283510884872506 - loss_val: 0.9699444799230866\n",
      "Epoch: 2767 - time: 0.0039 - loss_train: 0.8283188081703371 - loss_val: 0.9699392881689414\n",
      "Epoch: 2768 - time: 0.0037 - loss_train: 0.82828655163054 - loss_val: 0.9699341128069959\n",
      "Epoch: 2769 - time: 0.0036 - loss_train: 0.8282543188400059 - loss_val: 0.9699289538152561\n",
      "Epoch: 2770 - time: 0.0036 - loss_train: 0.8282221097709462 - loss_val: 0.969923811171741\n",
      "Epoch: 2771 - time: 0.0036 - loss_train: 0.8281899243956368 - loss_val: 0.9699186848544866\n",
      "Epoch: 2772 - time: 0.0036 - loss_train: 0.8281577626864173 - loss_val: 0.9699135748415451\n",
      "Epoch: 2773 - time: 0.0036 - loss_train: 0.8281256246156912 - loss_val: 0.9699084811109813\n",
      "Epoch: 2774 - time: 0.0039 - loss_train: 0.8280935101559267 - loss_val: 0.9699034036408747\n",
      "Epoch: 2775 - time: 0.0039 - loss_train: 0.8280614192796545 - loss_val: 0.9698983424093194\n",
      "Epoch: 2776 - time: 0.0040 - loss_train: 0.828029351959469 - loss_val: 0.9698932973944246\n",
      "Epoch: 2777 - time: 0.0039 - loss_train: 0.8279973081680275 - loss_val: 0.9698882685743127\n",
      "Epoch: 2778 - time: 0.0039 - loss_train: 0.82796528787805 - loss_val: 0.9698832559271181\n",
      "Epoch: 2779 - time: 0.0031 - loss_train: 0.8279332910623199 - loss_val: 0.9698782594309894\n",
      "Epoch: 2780 - time: 0.0032 - loss_train: 0.8279013176936816 - loss_val: 0.9698732790640897\n",
      "Epoch: 2781 - time: 0.0031 - loss_train: 0.8278693677450433 - loss_val: 0.9698683148045932\n",
      "Epoch: 2782 - time: 0.0031 - loss_train: 0.8278374411893737 - loss_val: 0.9698633666306857\n",
      "Epoch: 2783 - time: 0.0031 - loss_train: 0.8278055379997042 - loss_val: 0.9698584345205667\n",
      "Epoch: 2784 - time: 0.0031 - loss_train: 0.8277736581491267 - loss_val: 0.9698535184524489\n",
      "Epoch: 2785 - time: 0.0031 - loss_train: 0.8277418016107962 - loss_val: 0.9698486184045529\n",
      "Epoch: 2786 - time: 0.0045 - loss_train: 0.8277099683579268 - loss_val: 0.9698437343551142\n",
      "Epoch: 2787 - time: 0.0044 - loss_train: 0.8276781583637942 - loss_val: 0.9698388662823769\n",
      "Epoch: 2788 - time: 0.0044 - loss_train: 0.8276463716017348 - loss_val: 0.9698340141645976\n",
      "Epoch: 2789 - time: 0.0045 - loss_train: 0.8276146080451453 - loss_val: 0.9698291779800436\n",
      "Epoch: 2790 - time: 0.0044 - loss_train: 0.8275828676674835 - loss_val: 0.9698243577069912\n",
      "Epoch: 2791 - time: 0.0044 - loss_train: 0.8275511504422651 - loss_val: 0.9698195533237276\n",
      "Epoch: 2792 - time: 0.0044 - loss_train: 0.8275194563430676 - loss_val: 0.9698147648085512\n",
      "Epoch: 2793 - time: 0.0044 - loss_train: 0.8274877853435267 - loss_val: 0.9698099921397673\n",
      "Epoch: 2794 - time: 0.0045 - loss_train: 0.8274561374173387 - loss_val: 0.9698052352956923\n",
      "Epoch: 2795 - time: 0.0044 - loss_train: 0.8274245125382574 - loss_val: 0.9698004942546511\n",
      "Epoch: 2796 - time: 0.0043 - loss_train: 0.8273929106800968 - loss_val: 0.9697957689949775\n",
      "Epoch: 2797 - time: 0.0044 - loss_train: 0.8273613318167292 - loss_val: 0.969791059495014\n",
      "Epoch: 2798 - time: 0.0044 - loss_train: 0.8273297759220852 - loss_val: 0.9697863657331114\n",
      "Epoch: 2799 - time: 0.0044 - loss_train: 0.8272982429701539 - loss_val: 0.969781687687628\n",
      "Epoch: 2800 - time: 0.0043 - loss_train: 0.8272667329349818 - loss_val: 0.9697770253369303\n",
      "Epoch: 2801 - time: 0.0043 - loss_train: 0.8272352457906745 - loss_val: 0.9697723786593931\n",
      "Epoch: 2802 - time: 0.0043 - loss_train: 0.827203781511394 - loss_val: 0.9697677476333952\n",
      "Epoch: 2803 - time: 0.0043 - loss_train: 0.8271723400713599 - loss_val: 0.9697631322373277\n",
      "Epoch: 2804 - time: 0.0043 - loss_train: 0.82714092144485 - loss_val: 0.9697585324495843\n",
      "Epoch: 2805 - time: 0.0044 - loss_train: 0.8271095256061974 - loss_val: 0.9697539482485663\n",
      "Epoch: 2806 - time: 0.0044 - loss_train: 0.8270781525297934 - loss_val: 0.9697493796126814\n",
      "Epoch: 2807 - time: 0.0044 - loss_train: 0.8270468021900856 - loss_val: 0.969744826520343\n",
      "Epoch: 2808 - time: 0.0043 - loss_train: 0.8270154745615772 - loss_val: 0.9697402889499703\n",
      "Epoch: 2809 - time: 0.0043 - loss_train: 0.8269841696188287 - loss_val: 0.9697357668799881\n",
      "Epoch: 2810 - time: 0.0036 - loss_train: 0.8269528873364557 - loss_val: 0.9697312602888267\n",
      "Epoch: 2811 - time: 0.0031 - loss_train: 0.8269216276891294 - loss_val: 0.9697267691549216\n",
      "Epoch: 2812 - time: 0.0031 - loss_train: 0.8268903906515772 - loss_val: 0.9697222934567118\n",
      "Epoch: 2813 - time: 0.0031 - loss_train: 0.8268591761985813 - loss_val: 0.9697178331726406\n",
      "Epoch: 2814 - time: 0.0031 - loss_train: 0.8268279843049796 - loss_val: 0.9697133882811583\n",
      "Epoch: 2815 - time: 0.0031 - loss_train: 0.8267968149456643 - loss_val: 0.9697089587607148\n",
      "Epoch: 2816 - time: 0.0031 - loss_train: 0.8267656680955827 - loss_val: 0.9697045445897666\n",
      "Epoch: 2817 - time: 0.0031 - loss_train: 0.8267345437297362 - loss_val: 0.969700145746775\n",
      "Epoch: 2818 - time: 0.0031 - loss_train: 0.826703441823181 - loss_val: 0.969695762210201\n",
      "Epoch: 2819 - time: 0.0031 - loss_train: 0.8266723623510271 - loss_val: 0.9696913939585111\n",
      "Epoch: 2820 - time: 0.0031 - loss_train: 0.8266413052884385 - loss_val: 0.9696870409701723\n",
      "Epoch: 2821 - time: 0.0032 - loss_train: 0.8266102706106332 - loss_val: 0.9696827032236562\n",
      "Epoch: 2822 - time: 0.0031 - loss_train: 0.8265792582928817 - loss_val: 0.9696783806974366\n",
      "Epoch: 2823 - time: 0.0031 - loss_train: 0.8265482683105088 - loss_val: 0.9696740733699873\n",
      "Epoch: 2824 - time: 0.0031 - loss_train: 0.8265173006388921 - loss_val: 0.9696697812197856\n",
      "Epoch: 2825 - time: 0.0046 - loss_train: 0.8264863552534624 - loss_val: 0.9696655042253096\n",
      "Epoch: 2826 - time: 0.0045 - loss_train: 0.8264554321297023 - loss_val: 0.9696612423650393\n",
      "Epoch: 2827 - time: 0.0045 - loss_train: 0.826424531243148 - loss_val: 0.9696569956174557\n",
      "Epoch: 2828 - time: 0.0045 - loss_train: 0.8263936525693867 - loss_val: 0.9696527639610387\n",
      "Epoch: 2829 - time: 0.0036 - loss_train: 0.8263627960840594 - loss_val: 0.9696485473742716\n",
      "Epoch: 2830 - time: 0.0031 - loss_train: 0.8263319617628581 - loss_val: 0.9696443458356371\n",
      "Epoch: 2831 - time: 0.0031 - loss_train: 0.8263011495815253 - loss_val: 0.9696401593236167\n",
      "Epoch: 2832 - time: 0.0031 - loss_train: 0.826270359515858 - loss_val: 0.9696359878166929\n",
      "Epoch: 2833 - time: 0.0031 - loss_train: 0.8262395915417019 - loss_val: 0.969631831293347\n",
      "Epoch: 2834 - time: 0.0031 - loss_train: 0.8262088456349546 - loss_val: 0.9696276897320626\n",
      "Epoch: 2835 - time: 0.0031 - loss_train: 0.8261781217715652 - loss_val: 0.9696235631113175\n",
      "Epoch: 2836 - time: 0.0031 - loss_train: 0.8261474199275328 - loss_val: 0.9696194514095925\n",
      "Epoch: 2837 - time: 0.0031 - loss_train: 0.8261167400789076 - loss_val: 0.9696153546053659\n",
      "Epoch: 2838 - time: 0.0031 - loss_train: 0.8260860822017899 - loss_val: 0.9696112726771149\n",
      "Epoch: 2839 - time: 0.0031 - loss_train: 0.8260554462723305 - loss_val: 0.9696072056033127\n",
      "Epoch: 2840 - time: 0.0031 - loss_train: 0.8260248322667297 - loss_val: 0.9696031533624333\n",
      "Epoch: 2841 - time: 0.0031 - loss_train: 0.8259942401612381 - loss_val: 0.9695991159329485\n",
      "Epoch: 2842 - time: 0.0031 - loss_train: 0.8259636699321552 - loss_val: 0.969595093293326\n",
      "Epoch: 2843 - time: 0.0031 - loss_train: 0.8259331215558309 - loss_val: 0.9695910854220317\n",
      "Epoch: 2844 - time: 0.0035 - loss_train: 0.8259025950086636 - loss_val: 0.9695870922975283\n",
      "Epoch: 2845 - time: 0.0033 - loss_train: 0.825872090267101 - loss_val: 0.9695831138982767\n",
      "Epoch: 2846 - time: 0.0031 - loss_train: 0.8258416073076393 - loss_val: 0.9695791502027323\n",
      "Epoch: 2847 - time: 0.0031 - loss_train: 0.8258111461068247 - loss_val: 0.969575201189351\n",
      "Epoch: 2848 - time: 0.0031 - loss_train: 0.8257807066412501 - loss_val: 0.9695712668365798\n",
      "Epoch: 2849 - time: 0.0031 - loss_train: 0.8257502888875579 - loss_val: 0.9695673471228659\n",
      "Epoch: 2850 - time: 0.0031 - loss_train: 0.8257198928224379 - loss_val: 0.9695634420266507\n",
      "Epoch: 2851 - time: 0.0031 - loss_train: 0.8256895184226285 - loss_val: 0.969559551526372\n",
      "Epoch: 2852 - time: 0.0031 - loss_train: 0.8256591656649157 - loss_val: 0.9695556756004613\n",
      "Epoch: 2853 - time: 0.0031 - loss_train: 0.8256288345261323 - loss_val: 0.9695518142273479\n",
      "Epoch: 2854 - time: 0.0031 - loss_train: 0.8255985249831594 - loss_val: 0.9695479673854556\n",
      "Epoch: 2855 - time: 0.0031 - loss_train: 0.8255682370129258 - loss_val: 0.969544135053202\n",
      "Epoch: 2856 - time: 0.0031 - loss_train: 0.8255379705924059 - loss_val: 0.9695403172089998\n",
      "Epoch: 2857 - time: 0.0031 - loss_train: 0.8255077256986215 - loss_val: 0.9695365138312564\n",
      "Epoch: 2858 - time: 0.0031 - loss_train: 0.8254775023086414 - loss_val: 0.9695327248983743\n",
      "Epoch: 2859 - time: 0.0031 - loss_train: 0.8254473003995808 - loss_val: 0.969528950388748\n",
      "Epoch: 2860 - time: 0.0035 - loss_train: 0.8254171199486016 - loss_val: 0.9695251902807686\n",
      "Epoch: 2861 - time: 0.0033 - loss_train: 0.8253869609329104 - loss_val: 0.9695214445528177\n",
      "Epoch: 2862 - time: 0.0031 - loss_train: 0.8253568233297612 - loss_val: 0.9695177131832738\n",
      "Epoch: 2863 - time: 0.0031 - loss_train: 0.8253267071164537 - loss_val: 0.9695139961505067\n",
      "Epoch: 2864 - time: 0.0031 - loss_train: 0.8252966122703321 - loss_val: 0.9695102934328798\n",
      "Epoch: 2865 - time: 0.0031 - loss_train: 0.8252665387687875 - loss_val: 0.9695066050087502\n",
      "Epoch: 2866 - time: 0.0031 - loss_train: 0.8252364865892555 - loss_val: 0.9695029308564656\n",
      "Epoch: 2867 - time: 0.0031 - loss_train: 0.8252064557092162 - loss_val: 0.9694992709543694\n",
      "Epoch: 2868 - time: 0.0031 - loss_train: 0.8251764461061957 - loss_val: 0.9694956252807952\n",
      "Epoch: 2869 - time: 0.0031 - loss_train: 0.8251464577577642 - loss_val: 0.9694919938140689\n",
      "Epoch: 2870 - time: 0.0031 - loss_train: 0.8251164906415372 - loss_val: 0.9694883765325095\n",
      "Epoch: 2871 - time: 0.0031 - loss_train: 0.8250865447351734 - loss_val: 0.9694847734144275\n",
      "Epoch: 2872 - time: 0.0031 - loss_train: 0.8250566200163767 - loss_val: 0.9694811844381257\n",
      "Epoch: 2873 - time: 0.0031 - loss_train: 0.8250267164628947 - loss_val: 0.9694776095818967\n",
      "Epoch: 2874 - time: 0.0031 - loss_train: 0.824996834052519 - loss_val: 0.9694740488240261\n",
      "Epoch: 2875 - time: 0.0031 - loss_train: 0.8249669727630851 - loss_val: 0.9694705021427896\n",
      "Epoch: 2876 - time: 0.0031 - loss_train: 0.8249371325724717 - loss_val: 0.9694669695164555\n",
      "Epoch: 2877 - time: 0.0031 - loss_train: 0.8249073134586002 - loss_val: 0.9694634509232818\n",
      "Epoch: 2878 - time: 0.0031 - loss_train: 0.8248775153994369 - loss_val: 0.9694599463415174\n",
      "Epoch: 2879 - time: 0.0031 - loss_train: 0.8248477383729903 - loss_val: 0.9694564557494011\n",
      "Epoch: 2880 - time: 0.0031 - loss_train: 0.8248179823573114 - loss_val: 0.9694529791251636\n",
      "Epoch: 2881 - time: 0.0031 - loss_train: 0.824788247330494 - loss_val: 0.9694495164470247\n",
      "Epoch: 2882 - time: 0.0031 - loss_train: 0.8247585332706758 - loss_val: 0.9694460676931936\n",
      "Epoch: 2883 - time: 0.0031 - loss_train: 0.8247288401560343 - loss_val: 0.9694426328418715\n",
      "Epoch: 2884 - time: 0.0031 - loss_train: 0.8246991679647921 - loss_val: 0.9694392118712484\n",
      "Epoch: 2885 - time: 0.0031 - loss_train: 0.8246695166752113 - loss_val: 0.9694358047595034\n",
      "Epoch: 2886 - time: 0.0031 - loss_train: 0.8246398862655978 - loss_val: 0.9694324114848055\n",
      "Epoch: 2887 - time: 0.0031 - loss_train: 0.8246102767142987 - loss_val: 0.9694290320253124\n",
      "Epoch: 2888 - time: 0.0031 - loss_train: 0.8245806879997015 - loss_val: 0.9694256663591717\n",
      "Epoch: 2889 - time: 0.0031 - loss_train: 0.8245511201002369 - loss_val: 0.9694223144645198\n",
      "Epoch: 2890 - time: 0.0031 - loss_train: 0.8245215729943756 - loss_val: 0.9694189763194829\n",
      "Epoch: 2891 - time: 0.0031 - loss_train: 0.8244920466606305 - loss_val: 0.9694156519021742\n",
      "Epoch: 2892 - time: 0.0031 - loss_train: 0.8244625410775538 - loss_val: 0.9694123411906966\n",
      "Epoch: 2893 - time: 0.0031 - loss_train: 0.8244330562237401 - loss_val: 0.9694090441631409\n",
      "Epoch: 2894 - time: 0.0031 - loss_train: 0.8244035920778234 - loss_val: 0.9694057607975862\n",
      "Epoch: 2895 - time: 0.0031 - loss_train: 0.8243741486184796 - loss_val: 0.9694024910721013\n",
      "Epoch: 2896 - time: 0.0031 - loss_train: 0.8243447258244225 - loss_val: 0.9693992349647411\n",
      "Epoch: 2897 - time: 0.0032 - loss_train: 0.8243153236744087 - loss_val: 0.9693959924535496\n",
      "Epoch: 2898 - time: 0.0035 - loss_train: 0.824285942147233 - loss_val: 0.9693927635165571\n",
      "Epoch: 2899 - time: 0.0032 - loss_train: 0.8242565812217312 - loss_val: 0.9693895481317842\n",
      "Epoch: 2900 - time: 0.0032 - loss_train: 0.8242272408767776 - loss_val: 0.9693863462772365\n",
      "Epoch: 2901 - time: 0.0031 - loss_train: 0.8241979210912863 - loss_val: 0.9693831579309079\n",
      "Epoch: 2902 - time: 0.0031 - loss_train: 0.8241686218442121 - loss_val: 0.9693799830707812\n",
      "Epoch: 2903 - time: 0.0031 - loss_train: 0.8241393431145473 - loss_val: 0.9693768216748233\n",
      "Epoch: 2904 - time: 0.0031 - loss_train: 0.8241100848813235 - loss_val: 0.96937367372099\n",
      "Epoch: 2905 - time: 0.0031 - loss_train: 0.8240808471236127 - loss_val: 0.9693705391872254\n",
      "Epoch: 2906 - time: 0.0031 - loss_train: 0.8240516298205237 - loss_val: 0.9693674180514565\n",
      "Epoch: 2907 - time: 0.0031 - loss_train: 0.8240224329512051 - loss_val: 0.969364310291601\n",
      "Epoch: 2908 - time: 0.0031 - loss_train: 0.8239932564948437 - loss_val: 0.9693612158855616\n",
      "Epoch: 2909 - time: 0.0031 - loss_train: 0.8239641004306638 - loss_val: 0.9693581348112259\n",
      "Epoch: 2910 - time: 0.0031 - loss_train: 0.8239349647379293 - loss_val: 0.969355067046471\n",
      "Epoch: 2911 - time: 0.0031 - loss_train: 0.8239058493959408 - loss_val: 0.9693520125691594\n",
      "Epoch: 2912 - time: 0.0031 - loss_train: 0.8238767543840378 - loss_val: 0.9693489713571366\n",
      "Epoch: 2913 - time: 0.0031 - loss_train: 0.8238476796815969 - loss_val: 0.9693459433882378\n",
      "Epoch: 2914 - time: 0.0031 - loss_train: 0.8238186252680321 - loss_val: 0.9693429286402846\n",
      "Epoch: 2915 - time: 0.0031 - loss_train: 0.8237895911227949 - loss_val: 0.9693399270910813\n",
      "Epoch: 2916 - time: 0.0031 - loss_train: 0.823760577225374 - loss_val: 0.9693369387184201\n",
      "Epoch: 2917 - time: 0.0031 - loss_train: 0.8237315835552962 - loss_val: 0.9693339635000779\n",
      "Epoch: 2918 - time: 0.0031 - loss_train: 0.823702610092124 - loss_val: 0.9693310014138186\n",
      "Epoch: 2919 - time: 0.0031 - loss_train: 0.823673656815457 - loss_val: 0.9693280524373904\n",
      "Epoch: 2920 - time: 0.0031 - loss_train: 0.8236447237049317 - loss_val: 0.969325116548526\n",
      "Epoch: 2921 - time: 0.0031 - loss_train: 0.8236158107402213 - loss_val: 0.9693221937249469\n",
      "Epoch: 2922 - time: 0.0031 - loss_train: 0.8235869179010351 - loss_val: 0.9693192839443556\n",
      "Epoch: 2923 - time: 0.0032 - loss_train: 0.8235580451671184 - loss_val: 0.9693163871844428\n",
      "Epoch: 2924 - time: 0.0031 - loss_train: 0.8235291925182533 - loss_val: 0.9693135034228826\n",
      "Epoch: 2925 - time: 0.0031 - loss_train: 0.8235003599342572 - loss_val: 0.9693106326373349\n",
      "Epoch: 2926 - time: 0.0031 - loss_train: 0.8234715473949834 - loss_val: 0.9693077748054436\n",
      "Epoch: 2927 - time: 0.0031 - loss_train: 0.8234427548803214 - loss_val: 0.9693049299048397\n",
      "Epoch: 2928 - time: 0.0035 - loss_train: 0.8234139823701956 - loss_val: 0.9693020979131356\n",
      "Epoch: 2929 - time: 0.0036 - loss_train: 0.8233852298445659 - loss_val: 0.9692992788079307\n",
      "Epoch: 2930 - time: 0.0032 - loss_train: 0.8233564972834283 - loss_val: 0.969296472566809\n",
      "Epoch: 2931 - time: 0.0031 - loss_train: 0.8233277846668127 - loss_val: 0.9692936791673379\n",
      "Epoch: 2932 - time: 0.0031 - loss_train: 0.8232990919747845 - loss_val: 0.96929089858707\n",
      "Epoch: 2933 - time: 0.0031 - loss_train: 0.8232704191874437 - loss_val: 0.9692881308035416\n",
      "Epoch: 2934 - time: 0.0031 - loss_train: 0.8232417662849258 - loss_val: 0.9692853757942737\n",
      "Epoch: 2935 - time: 0.0032 - loss_train: 0.8232131332474 - loss_val: 0.9692826335367727\n",
      "Epoch: 2936 - time: 0.0038 - loss_train: 0.8231845200550699 - loss_val: 0.9692799040085278\n",
      "Epoch: 2937 - time: 0.0032 - loss_train: 0.823155926688174 - loss_val: 0.9692771871870125\n",
      "Epoch: 2938 - time: 0.0031 - loss_train: 0.8231273531269846 - loss_val: 0.9692744830496847\n",
      "Epoch: 2939 - time: 0.0031 - loss_train: 0.823098799351808 - loss_val: 0.9692717915739867\n",
      "Epoch: 2940 - time: 0.0031 - loss_train: 0.8230702653429847 - loss_val: 0.9692691127373437\n",
      "Epoch: 2941 - time: 0.0031 - loss_train: 0.823041751080888 - loss_val: 0.9692664465171661\n",
      "Epoch: 2942 - time: 0.0031 - loss_train: 0.823013256545926 - loss_val: 0.9692637928908466\n",
      "Epoch: 2943 - time: 0.0031 - loss_train: 0.8229847817185402 - loss_val: 0.9692611518357632\n",
      "Epoch: 2944 - time: 0.0031 - loss_train: 0.8229563265792037 - loss_val: 0.969258523329277\n",
      "Epoch: 2945 - time: 0.0031 - loss_train: 0.8229278911084255 - loss_val: 0.9692559073487335\n",
      "Epoch: 2946 - time: 0.0031 - loss_train: 0.8228994752867455 - loss_val: 0.9692533038714602\n",
      "Epoch: 2947 - time: 0.0031 - loss_train: 0.8228710790947374 - loss_val: 0.969250712874771\n",
      "Epoch: 2948 - time: 0.0031 - loss_train: 0.8228427025130082 - loss_val: 0.9692481343359596\n",
      "Epoch: 2949 - time: 0.0031 - loss_train: 0.8228143455221961 - loss_val: 0.969245568232307\n",
      "Epoch: 2950 - time: 0.0031 - loss_train: 0.8227860081029738 - loss_val: 0.9692430145410745\n",
      "Epoch: 2951 - time: 0.0031 - loss_train: 0.8227576902360447 - loss_val: 0.9692404732395109\n",
      "Epoch: 2952 - time: 0.0031 - loss_train: 0.8227293919021457 - loss_val: 0.9692379443048446\n",
      "Epoch: 2953 - time: 0.0030 - loss_train: 0.8227011130820456 - loss_val: 0.9692354277142885\n",
      "Epoch: 2954 - time: 0.0031 - loss_train: 0.822672853756544 - loss_val: 0.9692329234450395\n",
      "Epoch: 2955 - time: 0.0031 - loss_train: 0.8226446139064747 - loss_val: 0.9692304314742778\n",
      "Epoch: 2956 - time: 0.0031 - loss_train: 0.8226163935127011 - loss_val: 0.9692279517791664\n",
      "Epoch: 2957 - time: 0.0031 - loss_train: 0.8225881925561197 - loss_val: 0.9692254843368517\n",
      "Epoch: 2958 - time: 0.0031 - loss_train: 0.8225600110176579 - loss_val: 0.9692230291244643\n",
      "Epoch: 2959 - time: 0.0031 - loss_train: 0.8225318488782745 - loss_val: 0.9692205861191167\n",
      "Epoch: 2960 - time: 0.0031 - loss_train: 0.8225037061189602 - loss_val: 0.969218155297905\n",
      "Epoch: 2961 - time: 0.0031 - loss_train: 0.8224755827207356 - loss_val: 0.9692157366379088\n",
      "Epoch: 2962 - time: 0.0031 - loss_train: 0.8224474786646535 - loss_val: 0.9692133301161916\n",
      "Epoch: 2963 - time: 0.0031 - loss_train: 0.8224193939317976 - loss_val: 0.9692109357097979\n",
      "Epoch: 2964 - time: 0.0031 - loss_train: 0.8223913285032817 - loss_val: 0.9692085533957577\n",
      "Epoch: 2965 - time: 0.0031 - loss_train: 0.8223632823602502 - loss_val: 0.9692061831510828\n",
      "Epoch: 2966 - time: 0.0031 - loss_train: 0.8223352554838788 - loss_val: 0.9692038249527678\n",
      "Epoch: 2967 - time: 0.0031 - loss_train: 0.822307247855373 - loss_val: 0.9692014787777925\n",
      "Epoch: 2968 - time: 0.0031 - loss_train: 0.8222792594559688 - loss_val: 0.9691991446031165\n",
      "Epoch: 2969 - time: 0.0031 - loss_train: 0.8222512902669328 - loss_val: 0.9691968224056856\n",
      "Epoch: 2970 - time: 0.0031 - loss_train: 0.8222233402695607 - loss_val: 0.9691945121624279\n",
      "Epoch: 2971 - time: 0.0031 - loss_train: 0.8221954094451787 - loss_val: 0.9691922138502532\n",
      "Epoch: 2972 - time: 0.0031 - loss_train: 0.8221674977751433 - loss_val: 0.9691899274460551\n",
      "Epoch: 2973 - time: 0.0031 - loss_train: 0.8221396052408395 - loss_val: 0.9691876529267115\n",
      "Epoch: 2974 - time: 0.0031 - loss_train: 0.8221117318236827 - loss_val: 0.9691853902690808\n",
      "Epoch: 2975 - time: 0.0032 - loss_train: 0.8220838775051177 - loss_val: 0.9691831394500077\n",
      "Epoch: 2976 - time: 0.0031 - loss_train: 0.8220560422666185 - loss_val: 0.9691809004463173\n",
      "Epoch: 2977 - time: 0.0031 - loss_train: 0.8220282260896884 - loss_val: 0.9691786732348191\n",
      "Epoch: 2978 - time: 0.0031 - loss_train: 0.8220004289558599 - loss_val: 0.9691764577923061\n",
      "Epoch: 2979 - time: 0.0031 - loss_train: 0.8219726508466937 - loss_val: 0.9691742540955518\n",
      "Epoch: 2980 - time: 0.0031 - loss_train: 0.8219448917437805 - loss_val: 0.9691720621213173\n",
      "Epoch: 2981 - time: 0.0031 - loss_train: 0.8219171516287388 - loss_val: 0.9691698818463425\n",
      "Epoch: 2982 - time: 0.0031 - loss_train: 0.8218894304832167 - loss_val: 0.9691677132473526\n",
      "Epoch: 2983 - time: 0.0031 - loss_train: 0.8218617282888897 - loss_val: 0.9691655563010554\n",
      "Epoch: 2984 - time: 0.0031 - loss_train: 0.821834045027463 - loss_val: 0.9691634109841428\n",
      "Epoch: 2985 - time: 0.0031 - loss_train: 0.8218063806806688 - loss_val: 0.9691612772732878\n",
      "Epoch: 2986 - time: 0.0031 - loss_train: 0.8217787352302683 - loss_val: 0.9691591551451484\n",
      "Epoch: 2987 - time: 0.0031 - loss_train: 0.8217511086580503 - loss_val: 0.9691570445763662\n",
      "Epoch: 2988 - time: 0.0031 - loss_train: 0.821723500945832 - loss_val: 0.9691549455435636\n",
      "Epoch: 2989 - time: 0.0031 - loss_train: 0.8216959120754582 - loss_val: 0.9691528580233483\n",
      "Epoch: 2990 - time: 0.0031 - loss_train: 0.8216683420288013 - loss_val: 0.9691507819923113\n",
      "Epoch: 2991 - time: 0.0031 - loss_train: 0.8216407907877618 - loss_val: 0.9691487174270261\n",
      "Epoch: 2992 - time: 0.0031 - loss_train: 0.8216132583342666 - loss_val: 0.9691466643040498\n",
      "Epoch: 2993 - time: 0.0031 - loss_train: 0.8215857446502712 - loss_val: 0.9691446225999226\n",
      "Epoch: 2994 - time: 0.0031 - loss_train: 0.821558249717758 - loss_val: 0.969142592291169\n",
      "Epoch: 2995 - time: 0.0031 - loss_train: 0.8215307735187364 - loss_val: 0.9691405733542963\n",
      "Epoch: 2996 - time: 0.0031 - loss_train: 0.8215033160352425 - loss_val: 0.9691385657657944\n",
      "Epoch: 2997 - time: 0.0031 - loss_train: 0.8214758772493407 - loss_val: 0.9691365695021384\n",
      "Epoch: 2998 - time: 0.0031 - loss_train: 0.8214484571431206 - loss_val: 0.9691345845397855\n",
      "Epoch: 2999 - time: 0.0031 - loss_train: 0.8214210556986996 - loss_val: 0.9691326108551767\n",
      "Epoch: 3000 - time: 0.0031 - loss_train: 0.8213936728982211 - loss_val: 0.969130648424738\n",
      "Epoch: 3001 - time: 0.0031 - loss_train: 0.821366308723856 - loss_val: 0.9691286972248775\n",
      "Epoch: 3002 - time: 0.0031 - loss_train: 0.8213389631577998 - loss_val: 0.969126757231987\n",
      "Epoch: 3003 - time: 0.0031 - loss_train: 0.8213116361822768 - loss_val: 0.9691248284224425\n",
      "Epoch: 3004 - time: 0.0031 - loss_train: 0.8212843277795348 - loss_val: 0.9691229107726052\n",
      "Epoch: 3005 - time: 0.0031 - loss_train: 0.8212570379318499 - loss_val: 0.969121004258816\n",
      "Epoch: 3006 - time: 0.0031 - loss_train: 0.8212297666215228 - loss_val: 0.9691191088574048\n",
      "Epoch: 3007 - time: 0.0031 - loss_train: 0.8212025138308813 - loss_val: 0.9691172245446819\n",
      "Epoch: 3008 - time: 0.0031 - loss_train: 0.8211752795422774 - loss_val: 0.9691153512969413\n",
      "Epoch: 3009 - time: 0.0031 - loss_train: 0.8211480637380905 - loss_val: 0.969113489090464\n",
      "Epoch: 3010 - time: 0.0031 - loss_train: 0.8211208664007239 - loss_val: 0.9691116379015131\n",
      "Epoch: 3011 - time: 0.0031 - loss_train: 0.8210936875126077 - loss_val: 0.9691097977063348\n",
      "Epoch: 3012 - time: 0.0031 - loss_train: 0.8210665270561966 - loss_val: 0.9691079684811617\n",
      "Epoch: 3013 - time: 0.0032 - loss_train: 0.821039385013971 - loss_val: 0.9691061502022079\n",
      "Epoch: 3014 - time: 0.0031 - loss_train: 0.8210122613684366 - loss_val: 0.969104342845676\n",
      "Epoch: 3015 - time: 0.0031 - loss_train: 0.8209851561021225 - loss_val: 0.9691025463877474\n",
      "Epoch: 3016 - time: 0.0031 - loss_train: 0.8209580691975853 - loss_val: 0.9691007608045937\n",
      "Epoch: 3017 - time: 0.0031 - loss_train: 0.8209310006374052 - loss_val: 0.9690989860723658\n",
      "Epoch: 3018 - time: 0.0031 - loss_train: 0.8209039504041868 - loss_val: 0.969097222167202\n",
      "Epoch: 3019 - time: 0.0031 - loss_train: 0.8208769184805593 - loss_val: 0.9690954690652241\n",
      "Epoch: 3020 - time: 0.0031 - loss_train: 0.8208499048491783 - loss_val: 0.9690937267425399\n",
      "Epoch: 3021 - time: 0.0031 - loss_train: 0.8208229094927207 - loss_val: 0.9690919951752396\n",
      "Epoch: 3022 - time: 0.0031 - loss_train: 0.8207959323938906 - loss_val: 0.9690902743394006\n",
      "Epoch: 3023 - time: 0.0031 - loss_train: 0.8207689735354149 - loss_val: 0.9690885642110826\n",
      "Epoch: 3024 - time: 0.0031 - loss_train: 0.8207420329000452 - loss_val: 0.9690868647663329\n",
      "Epoch: 3025 - time: 0.0031 - loss_train: 0.8207151104705568 - loss_val: 0.9690851759811817\n",
      "Epoch: 3026 - time: 0.0031 - loss_train: 0.8206882062297491 - loss_val: 0.9690834978316442\n",
      "Epoch: 3027 - time: 0.0031 - loss_train: 0.8206613201604455 - loss_val: 0.9690818302937221\n",
      "Epoch: 3028 - time: 0.0031 - loss_train: 0.8206344522454931 - loss_val: 0.9690801733434022\n",
      "Epoch: 3029 - time: 0.0031 - loss_train: 0.8206076024677625 - loss_val: 0.969078526956655\n",
      "Epoch: 3030 - time: 0.0031 - loss_train: 0.8205807708101482 - loss_val: 0.9690768911094365\n",
      "Epoch: 3031 - time: 0.0031 - loss_train: 0.8205539572555681 - loss_val: 0.9690752657776905\n",
      "Epoch: 3032 - time: 0.0031 - loss_train: 0.8205271617869629 - loss_val: 0.9690736509373437\n",
      "Epoch: 3033 - time: 0.0031 - loss_train: 0.8205003843872976 - loss_val: 0.9690720465643092\n",
      "Epoch: 3034 - time: 0.0031 - loss_train: 0.8204736250395592 - loss_val: 0.9690704526344851\n",
      "Epoch: 3035 - time: 0.0031 - loss_train: 0.8204468837267596 - loss_val: 0.9690688691237574\n",
      "Epoch: 3036 - time: 0.0031 - loss_train: 0.8204201604319314 - loss_val: 0.9690672960079949\n",
      "Epoch: 3037 - time: 0.0031 - loss_train: 0.8203934551381322 - loss_val: 0.969065733263054\n",
      "Epoch: 3038 - time: 0.0031 - loss_train: 0.8203667678284408 - loss_val: 0.969064180864777\n",
      "Epoch: 3039 - time: 0.0031 - loss_train: 0.82034009848596 - loss_val: 0.9690626387889918\n",
      "Epoch: 3040 - time: 0.0031 - loss_train: 0.8203134470938144 - loss_val: 0.9690611070115125\n",
      "Epoch: 3041 - time: 0.0031 - loss_train: 0.8202868136351514 - loss_val: 0.96905958550814\n",
      "Epoch: 3042 - time: 0.0031 - loss_train: 0.8202601980931412 - loss_val: 0.9690580742546597\n",
      "Epoch: 3043 - time: 0.0031 - loss_train: 0.8202336004509762 - loss_val: 0.9690565732268462\n",
      "Epoch: 3044 - time: 0.0031 - loss_train: 0.8202070206918705 - loss_val: 0.9690550824004575\n",
      "Epoch: 3045 - time: 0.0031 - loss_train: 0.8201804587990612 - loss_val: 0.9690536017512406\n",
      "Epoch: 3046 - time: 0.0031 - loss_train: 0.8201539147558065 - loss_val: 0.9690521312549275\n",
      "Epoch: 3047 - time: 0.0031 - loss_train: 0.8201273885453879 - loss_val: 0.969050670887239\n",
      "Epoch: 3048 - time: 0.0031 - loss_train: 0.8201008801511082 - loss_val: 0.9690492206238802\n",
      "Epoch: 3049 - time: 0.0031 - loss_train: 0.8200743895562913 - loss_val: 0.9690477804405447\n",
      "Epoch: 3050 - time: 0.0037 - loss_train: 0.820047916744284 - loss_val: 0.9690463503129126\n",
      "Epoch: 3051 - time: 0.0032 - loss_train: 0.8200214616984547 - loss_val: 0.969044930216651\n",
      "Epoch: 3052 - time: 0.0031 - loss_train: 0.8199950244021919 - loss_val: 0.9690435201274153\n",
      "Epoch: 3053 - time: 0.0031 - loss_train: 0.8199686048389073 - loss_val: 0.9690421200208462\n",
      "Epoch: 3054 - time: 0.0031 - loss_train: 0.8199422029920331 - loss_val: 0.9690407298725747\n",
      "Epoch: 3055 - time: 0.0031 - loss_train: 0.8199158188450234 - loss_val: 0.9690393496582163\n",
      "Epoch: 3056 - time: 0.0031 - loss_train: 0.8198894523813525 - loss_val: 0.9690379793533755\n",
      "Epoch: 3057 - time: 0.0031 - loss_train: 0.8198631035845172 - loss_val: 0.9690366189336442\n",
      "Epoch: 3058 - time: 0.0031 - loss_train: 0.8198367724380339 - loss_val: 0.9690352683746033\n",
      "Epoch: 3059 - time: 0.0031 - loss_train: 0.819810458925441 - loss_val: 0.9690339276518198\n",
      "Epoch: 3060 - time: 0.0031 - loss_train: 0.8197841630302971 - loss_val: 0.9690325967408501\n",
      "Epoch: 3061 - time: 0.0031 - loss_train: 0.8197578847361829 - loss_val: 0.9690312756172377\n",
      "Epoch: 3062 - time: 0.0031 - loss_train: 0.8197316240266982 - loss_val: 0.9690299642565154\n",
      "Epoch: 3063 - time: 0.0031 - loss_train: 0.8197053808854642 - loss_val: 0.9690286626342041\n",
      "Epoch: 3064 - time: 0.0031 - loss_train: 0.8196791552961222 - loss_val: 0.9690273707258115\n",
      "Epoch: 3065 - time: 0.0031 - loss_train: 0.8196529472423344 - loss_val: 0.9690260885068366\n",
      "Epoch: 3066 - time: 0.0031 - loss_train: 0.8196267567077837 - loss_val: 0.9690248159527641\n",
      "Epoch: 3067 - time: 0.0031 - loss_train: 0.8196005836761726 - loss_val: 0.969023553039071\n",
      "Epoch: 3068 - time: 0.0031 - loss_train: 0.8195744281312243 - loss_val: 0.96902229974122\n",
      "Epoch: 3069 - time: 0.0031 - loss_train: 0.8195482900566816 - loss_val: 0.9690210560346635\n",
      "Epoch: 3070 - time: 0.0031 - loss_train: 0.8195221694363076 - loss_val: 0.9690198218948445\n",
      "Epoch: 3071 - time: 0.0031 - loss_train: 0.8194960662538858 - loss_val: 0.9690185972971936\n",
      "Epoch: 3072 - time: 0.0031 - loss_train: 0.8194699804932193 - loss_val: 0.9690173822171322\n",
      "Epoch: 3073 - time: 0.0031 - loss_train: 0.8194439121381306 - loss_val: 0.9690161766300696\n",
      "Epoch: 3074 - time: 0.0031 - loss_train: 0.8194178611724624 - loss_val: 0.9690149805114054\n",
      "Epoch: 3075 - time: 0.0031 - loss_train: 0.8193918275800771 - loss_val: 0.969013793836529\n",
      "Epoch: 3076 - time: 0.0031 - loss_train: 0.8193658113448562 - loss_val: 0.9690126165808197\n",
      "Epoch: 3077 - time: 0.0031 - loss_train: 0.8193398124507015 - loss_val: 0.9690114487196463\n",
      "Epoch: 3078 - time: 0.0031 - loss_train: 0.819313830881533 - loss_val: 0.9690102902283677\n",
      "Epoch: 3079 - time: 0.0031 - loss_train: 0.8192878666212916 - loss_val: 0.9690091410823325\n",
      "Epoch: 3080 - time: 0.0031 - loss_train: 0.819261919653936 - loss_val: 0.9690080012568809\n",
      "Epoch: 3081 - time: 0.0031 - loss_train: 0.8192359899634452 - loss_val: 0.9690068707273423\n",
      "Epoch: 3082 - time: 0.0031 - loss_train: 0.8192100775338165 - loss_val: 0.9690057494690371\n",
      "Epoch: 3083 - time: 0.0031 - loss_train: 0.8191841823490665 - loss_val: 0.9690046374572765\n",
      "Epoch: 3084 - time: 0.0031 - loss_train: 0.8191583043932312 - loss_val: 0.9690035346673621\n",
      "Epoch: 3085 - time: 0.0031 - loss_train: 0.8191324436503651 - loss_val: 0.9690024410745866\n",
      "Epoch: 3086 - time: 0.0031 - loss_train: 0.8191066001045412 - loss_val: 0.9690013566542325\n",
      "Epoch: 3087 - time: 0.0031 - loss_train: 0.8190807737398512 - loss_val: 0.9690002813815763\n",
      "Epoch: 3088 - time: 0.0031 - loss_train: 0.8190549645404069 - loss_val: 0.9689992152318826\n",
      "Epoch: 3089 - time: 0.0032 - loss_train: 0.8190291724903368 - loss_val: 0.9689981581804095\n",
      "Epoch: 3090 - time: 0.0031 - loss_train: 0.8190033975737888 - loss_val: 0.9689971102024051\n",
      "Epoch: 3091 - time: 0.0031 - loss_train: 0.8189776397749292 - loss_val: 0.9689960712731107\n",
      "Epoch: 3092 - time: 0.0031 - loss_train: 0.8189518990779427 - loss_val: 0.968995041367757\n",
      "Epoch: 3093 - time: 0.0031 - loss_train: 0.818926175467032 - loss_val: 0.9689940204615692\n",
      "Epoch: 3094 - time: 0.0031 - loss_train: 0.8189004689264182 - loss_val: 0.9689930085297642\n",
      "Epoch: 3095 - time: 0.0031 - loss_train: 0.8188747794403407 - loss_val: 0.9689920055475488\n",
      "Epoch: 3096 - time: 0.0031 - loss_train: 0.8188491069930568 - loss_val: 0.9689910114901245\n",
      "Epoch: 3097 - time: 0.0031 - loss_train: 0.8188234515688417 - loss_val: 0.9689900263326833\n",
      "Epoch: 3098 - time: 0.0031 - loss_train: 0.818797813151989 - loss_val: 0.968989050050412\n",
      "Epoch: 3099 - time: 0.0031 - loss_train: 0.8187721917268094 - loss_val: 0.9689880826184868\n",
      "Epoch: 3100 - time: 0.0031 - loss_train: 0.8187465872776319 - loss_val: 0.96898712401208\n",
      "Epoch: 3101 - time: 0.0031 - loss_train: 0.8187209997888031 - loss_val: 0.9689861742063556\n",
      "Epoch: 3102 - time: 0.0031 - loss_train: 0.8186954292446874 - loss_val: 0.9689852331764698\n",
      "Epoch: 3103 - time: 0.0031 - loss_train: 0.8186698756296665 - loss_val: 0.9689843008975723\n",
      "Epoch: 3104 - time: 0.0031 - loss_train: 0.8186443389281398 - loss_val: 0.9689833773448077\n",
      "Epoch: 3105 - time: 0.0031 - loss_train: 0.8186188191245243 - loss_val: 0.9689824624933107\n",
      "Epoch: 3106 - time: 0.0031 - loss_train: 0.818593316203254 - loss_val: 0.9689815563182148\n",
      "Epoch: 3107 - time: 0.0031 - loss_train: 0.8185678301487804 - loss_val: 0.9689806587946423\n",
      "Epoch: 3108 - time: 0.0031 - loss_train: 0.8185423609455723 - loss_val: 0.9689797698977113\n",
      "Epoch: 3109 - time: 0.0031 - loss_train: 0.8185169085781155 - loss_val: 0.9689788896025346\n",
      "Epoch: 3110 - time: 0.0031 - loss_train: 0.8184914730309126 - loss_val: 0.9689780178842174\n",
      "Epoch: 3111 - time: 0.0031 - loss_train: 0.8184660542884844 - loss_val: 0.968977154717861\n",
      "Epoch: 3112 - time: 0.0031 - loss_train: 0.8184406523353678 - loss_val: 0.9689763000785598\n",
      "Epoch: 3113 - time: 0.0031 - loss_train: 0.818415267156116 - loss_val: 0.968975453941403\n",
      "Epoch: 3114 - time: 0.0031 - loss_train: 0.8183898987353 - loss_val: 0.9689746162814767\n",
      "Epoch: 3115 - time: 0.0031 - loss_train: 0.8183645470575079 - loss_val: 0.9689737870738574\n",
      "Epoch: 3116 - time: 0.0031 - loss_train: 0.818339212107343 - loss_val: 0.9689729662936193\n",
      "Epoch: 3117 - time: 0.0031 - loss_train: 0.8183138938694271 - loss_val: 0.9689721539158329\n",
      "Epoch: 3118 - time: 0.0031 - loss_train: 0.8182885923283966 - loss_val: 0.9689713499155613\n",
      "Epoch: 3119 - time: 0.0031 - loss_train: 0.8182633074689063 - loss_val: 0.9689705542678653\n",
      "Epoch: 3120 - time: 0.0031 - loss_train: 0.8182380392756261 - loss_val: 0.9689697669477985\n",
      "Epoch: 3121 - time: 0.0031 - loss_train: 0.818212787733243 - loss_val: 0.9689689879304135\n",
      "Epoch: 3122 - time: 0.0031 - loss_train: 0.8181875528264602 - loss_val: 0.968968217190756\n",
      "Epoch: 3123 - time: 0.0031 - loss_train: 0.8181623345399966 - loss_val: 0.9689674547038678\n",
      "Epoch: 3124 - time: 0.0031 - loss_train: 0.8181371328585884 - loss_val: 0.9689667004447893\n",
      "Epoch: 3125 - time: 0.0031 - loss_train: 0.8181119477669861 - loss_val: 0.9689659543885546\n",
      "Epoch: 3126 - time: 0.0031 - loss_train: 0.8180867792499591 - loss_val: 0.9689652165101958\n",
      "Epoch: 3127 - time: 0.0032 - loss_train: 0.8180616272922904 - loss_val: 0.96896448678474\n",
      "Epoch: 3128 - time: 0.0031 - loss_train: 0.8180364918787796 - loss_val: 0.9689637651872118\n",
      "Epoch: 3129 - time: 0.0031 - loss_train: 0.8180113729942421 - loss_val: 0.9689630516926334\n",
      "Epoch: 3130 - time: 0.0031 - loss_train: 0.8179862706235096 - loss_val: 0.968962346276022\n",
      "Epoch: 3131 - time: 0.0031 - loss_train: 0.8179611847514293 - loss_val: 0.968961648912395\n",
      "Epoch: 3132 - time: 0.0031 - loss_train: 0.8179361153628639 - loss_val: 0.9689609595767631\n",
      "Epoch: 3133 - time: 0.0031 - loss_train: 0.8179110624426927 - loss_val: 0.9689602782441369\n",
      "Epoch: 3134 - time: 0.0031 - loss_train: 0.817886025975809 - loss_val: 0.9689596048895244\n",
      "Epoch: 3135 - time: 0.0031 - loss_train: 0.8178610059471227 - loss_val: 0.9689589394879309\n",
      "Epoch: 3136 - time: 0.0035 - loss_train: 0.817836002341559 - loss_val: 0.9689582820143596\n",
      "Epoch: 3137 - time: 0.0044 - loss_train: 0.8178110151440585 - loss_val: 0.9689576324438111\n",
      "Epoch: 3138 - time: 0.0044 - loss_train: 0.8177860443395768 - loss_val: 0.968956990751285\n",
      "Epoch: 3139 - time: 0.0044 - loss_train: 0.8177610899130854 - loss_val: 0.96895635691178\n",
      "Epoch: 3140 - time: 0.0035 - loss_train: 0.8177361518495707 - loss_val: 0.9689557309002902\n",
      "Epoch: 3141 - time: 0.0035 - loss_train: 0.8177112301340342 - loss_val: 0.9689551126918111\n",
      "Epoch: 3142 - time: 0.0035 - loss_train: 0.8176863247514927 - loss_val: 0.9689545022613363\n",
      "Epoch: 3143 - time: 0.0035 - loss_train: 0.817661435686978 - loss_val: 0.9689538995838565\n",
      "Epoch: 3144 - time: 0.0036 - loss_train: 0.8176365629255368 - loss_val: 0.9689533046343642\n",
      "Epoch: 3145 - time: 0.0035 - loss_train: 0.8176117064522307 - loss_val: 0.96895271738785\n",
      "Epoch: 3146 - time: 0.0036 - loss_train: 0.8175868662521368 - loss_val: 0.9689521378193021\n",
      "Epoch: 3147 - time: 0.0035 - loss_train: 0.8175620423103467 - loss_val: 0.9689515659037102\n",
      "Epoch: 3148 - time: 0.0043 - loss_train: 0.8175372346119657 - loss_val: 0.9689510016160636\n",
      "Epoch: 3149 - time: 0.0043 - loss_train: 0.8175124431421156 - loss_val: 0.96895044493135\n",
      "Epoch: 3150 - time: 0.0043 - loss_train: 0.8174876678859321 - loss_val: 0.9689498958245577\n",
      "Epoch: 3151 - time: 0.0043 - loss_train: 0.8174629088285651 - loss_val: 0.9689493542706757\n",
      "Epoch: 3152 - time: 0.0043 - loss_train: 0.8174381659551798 - loss_val: 0.9689488202446922\n",
      "Epoch: 3153 - time: 0.0044 - loss_train: 0.8174134392509557 - loss_val: 0.9689482937215963\n",
      "Epoch: 3154 - time: 0.0039 - loss_train: 0.8173887287010861 - loss_val: 0.968947774676377\n",
      "Epoch: 3155 - time: 0.0035 - loss_train: 0.8173640342907799 - loss_val: 0.9689472630840248\n",
      "Epoch: 3156 - time: 0.0035 - loss_train: 0.8173393560052593 - loss_val: 0.9689467589195307\n",
      "Epoch: 3157 - time: 0.0035 - loss_train: 0.8173146938297614 - loss_val: 0.9689462621578867\n",
      "Epoch: 3158 - time: 0.0035 - loss_train: 0.8172900477495376 - loss_val: 0.9689457727740863\n",
      "Epoch: 3159 - time: 0.0036 - loss_train: 0.8172654177498525 - loss_val: 0.9689452907431223\n",
      "Epoch: 3160 - time: 0.0035 - loss_train: 0.8172408038159863 - loss_val: 0.9689448160399914\n",
      "Epoch: 3161 - time: 0.0035 - loss_train: 0.8172162059332325 - loss_val: 0.9689443486396901\n",
      "Epoch: 3162 - time: 0.0036 - loss_train: 0.817191624086899 - loss_val: 0.9689438885172181\n",
      "Epoch: 3163 - time: 0.0036 - loss_train: 0.8171670582623067 - loss_val: 0.968943435647576\n",
      "Epoch: 3164 - time: 0.0036 - loss_train: 0.8171425084447919 - loss_val: 0.9689429900057667\n",
      "Epoch: 3165 - time: 0.0036 - loss_train: 0.8171179746197034 - loss_val: 0.9689425515667944\n",
      "Epoch: 3166 - time: 0.0036 - loss_train: 0.8170934567724057 - loss_val: 0.9689421203056677\n",
      "Epoch: 3167 - time: 0.0045 - loss_train: 0.8170689548882747 - loss_val: 0.968941696197395\n",
      "Epoch: 3168 - time: 0.0045 - loss_train: 0.8170444689527019 - loss_val: 0.9689412792169901\n",
      "Epoch: 3169 - time: 0.0045 - loss_train: 0.8170199989510916 - loss_val: 0.968940869339467\n",
      "Epoch: 3170 - time: 0.0045 - loss_train: 0.8169955448688623 - loss_val: 0.9689404665398442\n",
      "Epoch: 3171 - time: 0.0044 - loss_train: 0.8169711066914451 - loss_val: 0.9689400707931426\n",
      "Epoch: 3172 - time: 0.0044 - loss_train: 0.8169466844042864 - loss_val: 0.968939682074387\n",
      "Epoch: 3173 - time: 0.0036 - loss_train: 0.8169222779928446 - loss_val: 0.9689393003586052\n",
      "Epoch: 3174 - time: 0.0032 - loss_train: 0.8168978874425918 - loss_val: 0.9689389256208283\n",
      "Epoch: 3175 - time: 0.0031 - loss_train: 0.8168735127390137 - loss_val: 0.9689385578360914\n",
      "Epoch: 3176 - time: 0.0031 - loss_train: 0.8168491538676101 - loss_val: 0.9689381969794331\n",
      "Epoch: 3177 - time: 0.0031 - loss_train: 0.8168248108138926 - loss_val: 0.9689378430258957\n",
      "Epoch: 3178 - time: 0.0031 - loss_train: 0.8168004835633872 - loss_val: 0.9689374959505268\n",
      "Epoch: 3179 - time: 0.0031 - loss_train: 0.8167761721016329 - loss_val: 0.968937155728378\n",
      "Epoch: 3180 - time: 0.0031 - loss_train: 0.8167518764141813 - loss_val: 0.9689368223345047\n",
      "Epoch: 3181 - time: 0.0031 - loss_train: 0.816727596486598 - loss_val: 0.9689364957439668\n",
      "Epoch: 3182 - time: 0.0032 - loss_train: 0.8167033323044613 - loss_val: 0.968936175931829\n",
      "Epoch: 3183 - time: 0.0032 - loss_train: 0.8166790838533623 - loss_val: 0.9689358628731621\n",
      "Epoch: 3184 - time: 0.0031 - loss_train: 0.8166548511189051 - loss_val: 0.9689355565430405\n",
      "Epoch: 3185 - time: 0.0031 - loss_train: 0.8166306340867074 - loss_val: 0.9689352569165451\n",
      "Epoch: 3186 - time: 0.0031 - loss_train: 0.8166064327423992 - loss_val: 0.96893496396876\n",
      "Epoch: 3187 - time: 0.0031 - loss_train: 0.8165822470716235 - loss_val: 0.968934677674778\n",
      "Epoch: 3188 - time: 0.0031 - loss_train: 0.8165580770600362 - loss_val: 0.9689343980096942\n",
      "Epoch: 3189 - time: 0.0031 - loss_train: 0.8165339226933058 - loss_val: 0.9689341249486115\n",
      "Epoch: 3190 - time: 0.0031 - loss_train: 0.8165097839571133 - loss_val: 0.9689338584666395\n",
      "Epoch: 3191 - time: 0.0031 - loss_train: 0.8164856608371539 - loss_val: 0.9689335985388908\n",
      "Epoch: 3192 - time: 0.0032 - loss_train: 0.8164615533191332 - loss_val: 0.9689333451404882\n",
      "Epoch: 3193 - time: 0.0032 - loss_train: 0.8164374613887704 - loss_val: 0.9689330982465575\n",
      "Epoch: 3194 - time: 0.0031 - loss_train: 0.816413385031798 - loss_val: 0.9689328578322332\n",
      "Epoch: 3195 - time: 0.0031 - loss_train: 0.8163893242339598 - loss_val: 0.968932623872656\n",
      "Epoch: 3196 - time: 0.0031 - loss_train: 0.8163652789810133 - loss_val: 0.9689323963429731\n",
      "Epoch: 3197 - time: 0.0031 - loss_train: 0.816341249258727 - loss_val: 0.9689321752183386\n",
      "Epoch: 3198 - time: 0.0031 - loss_train: 0.8163172350528827 - loss_val: 0.9689319604739144\n",
      "Epoch: 3199 - time: 0.0035 - loss_train: 0.8162932363492749 - loss_val: 0.9689317520848696\n",
      "Epoch: 3200 - time: 0.0043 - loss_train: 0.8162692531337097 - loss_val: 0.96893155002638\n",
      "Epoch: 3201 - time: 0.0032 - loss_train: 0.8162452853920055 - loss_val: 0.9689313542736302\n",
      "Epoch: 3202 - time: 0.0031 - loss_train: 0.8162213331099936 - loss_val: 0.9689311648018122\n",
      "Epoch: 3203 - time: 0.0031 - loss_train: 0.8161973962735165 - loss_val: 0.9689309815861246\n",
      "Epoch: 3204 - time: 0.0031 - loss_train: 0.8161734748684294 - loss_val: 0.9689308046017762\n",
      "Epoch: 3205 - time: 0.0031 - loss_train: 0.8161495688806002 - loss_val: 0.9689306338239826\n",
      "Epoch: 3206 - time: 0.0036 - loss_train: 0.8161256782959074 - loss_val: 0.9689304692279691\n",
      "Epoch: 3207 - time: 0.0036 - loss_train: 0.8161018031002429 - loss_val: 0.9689303107889673\n",
      "Epoch: 3208 - time: 0.0031 - loss_train: 0.8160779432795106 - loss_val: 0.9689301584822201\n",
      "Epoch: 3209 - time: 0.0031 - loss_train: 0.8160540988196247 - loss_val: 0.9689300122829764\n",
      "Epoch: 3210 - time: 0.0031 - loss_train: 0.8160302697065135 - loss_val: 0.9689298721664968\n",
      "Epoch: 3211 - time: 0.0031 - loss_train: 0.8160064559261156 - loss_val: 0.9689297381080492\n",
      "Epoch: 3212 - time: 0.0031 - loss_train: 0.8159826574643821 - loss_val: 0.9689296100829129\n",
      "Epoch: 3213 - time: 0.0031 - loss_train: 0.8159588743072761 - loss_val: 0.9689294880663732\n",
      "Epoch: 3214 - time: 0.0031 - loss_train: 0.8159351064407719 - loss_val: 0.9689293720337275\n",
      "Epoch: 3215 - time: 0.0031 - loss_train: 0.8159113538508563 - loss_val: 0.9689292619602833\n",
      "Epoch: 3216 - time: 0.0031 - loss_train: 0.8158876165235268 - loss_val: 0.9689291578213555\n",
      "Epoch: 3217 - time: 0.0031 - loss_train: 0.8158638944447935 - loss_val: 0.9689290595922716\n",
      "Epoch: 3218 - time: 0.0031 - loss_train: 0.8158401876006773 - loss_val: 0.9689289672483681\n",
      "Epoch: 3219 - time: 0.0031 - loss_train: 0.8158164959772113 - loss_val: 0.9689288807649914\n",
      "Epoch: 3220 - time: 0.0031 - loss_train: 0.8157928195604401 - loss_val: 0.968928800117499\n",
      "Epoch: 3221 - time: 0.0031 - loss_train: 0.8157691583364198 - loss_val: 0.9689287252812598\n",
      "Epoch: 3222 - time: 0.0031 - loss_train: 0.815745512291218 - loss_val: 0.968928656231651\n",
      "Epoch: 3223 - time: 0.0031 - loss_train: 0.8157218814109128 - loss_val: 0.9689285929440637\n",
      "Epoch: 3224 - time: 0.0031 - loss_train: 0.8156982656815954 - loss_val: 0.9689285353938979\n",
      "Epoch: 3225 - time: 0.0031 - loss_train: 0.8156746650893671 - loss_val: 0.9689284835565648\n",
      "Epoch: 3226 - time: 0.0031 - loss_train: 0.8156510796203414 - loss_val: 0.9689284374074889\n",
      "Epoch: 3227 - time: 0.0031 - loss_train: 0.8156275092606425 - loss_val: 0.9689283969221045\n",
      "Epoch: 3228 - time: 0.0031 - loss_train: 0.815603953996406 - loss_val: 0.9689283620758579\n",
      "Epoch: 3229 - time: 0.0036 - loss_train: 0.8155804138137789 - loss_val: 0.9689283328442068\n",
      "Epoch: 3230 - time: 0.0032 - loss_train: 0.8155568886989193 - loss_val: 0.9689283092026219\n",
      "Epoch: 3231 - time: 0.0031 - loss_train: 0.8155333786379966 - loss_val: 0.968928291126586\n",
      "Epoch: 3232 - time: 0.0031 - loss_train: 0.8155098836171913 - loss_val: 0.9689282785915919\n",
      "Epoch: 3233 - time: 0.0031 - loss_train: 0.8154864036226948 - loss_val: 0.9689282715731479\n",
      "Epoch: 3234 - time: 0.0031 - loss_train: 0.8154629386407103 - loss_val: 0.9689282700467721\n",
      "Epoch: 3235 - time: 0.0031 - loss_train: 0.8154394886574508 - loss_val: 0.9689282739879969\n",
      "Epoch: 3236 - time: 0.0031 - loss_train: 0.8154160536591414 - loss_val: 0.9689282833723659\n",
      "Epoch: 3237 - time: 0.0031 - loss_train: 0.8153926336320183 - loss_val: 0.9689282981754384\n",
      "Epoch: 3238 - time: 0.0031 - loss_train: 0.815369228562328 - loss_val: 0.968928318372785\n",
      "Epoch: 3239 - time: 0.0031 - loss_train: 0.8153458384363276 - loss_val: 0.9689283439399888\n",
      "Epoch: 3240 - time: 0.0031 - loss_train: 0.8153224632402865 - loss_val: 0.9689283748526473\n",
      "Epoch: 3241 - time: 0.0031 - loss_train: 0.8152991029604834 - loss_val: 0.9689284110863718\n",
      "Epoch: 3242 - time: 0.0031 - loss_train: 0.8152757575832086 - loss_val: 0.9689284526167861\n",
      "Epoch: 3243 - time: 0.0031 - loss_train: 0.8152524270947635 - loss_val: 0.968928499419529\n",
      "Epoch: 3244 - time: 0.0031 - loss_train: 0.8152291114814603 - loss_val: 0.9689285514702535\n",
      "Epoch: 3245 - time: 0.0031 - loss_train: 0.8152058107296208 - loss_val: 0.9689286087446242\n",
      "Epoch: 3246 - time: 0.0031 - loss_train: 0.8151825248255785 - loss_val: 0.9689286712183232\n",
      "Epoch: 3247 - time: 0.0031 - loss_train: 0.8151592537556779 - loss_val: 0.9689287388670436\n",
      "Epoch: 3248 - time: 0.0031 - loss_train: 0.8151359975062735 - loss_val: 0.9689288116664965\n",
      "Epoch: 3249 - time: 0.0031 - loss_train: 0.8151127560637297 - loss_val: 0.9689288895924064\n",
      "Epoch: 3250 - time: 0.0031 - loss_train: 0.8150895294144237 - loss_val: 0.9689289726205098\n",
      "Epoch: 3251 - time: 0.0031 - loss_train: 0.8150663175447412 - loss_val: 0.968929060726562\n",
      "Epoch: 3252 - time: 0.0031 - loss_train: 0.8150431204410797 - loss_val: 0.9689291538863322\n",
      "Epoch: 3253 - time: 0.0031 - loss_train: 0.8150199380898464 - loss_val: 0.9689292520756045\n",
      "Epoch: 3254 - time: 0.0031 - loss_train: 0.8149967704774596 - loss_val: 0.9689293552701763\n",
      "Epoch: 3255 - time: 0.0031 - loss_train: 0.8149736175903475 - loss_val: 0.9689294634458647\n",
      "Epoch: 3256 - time: 0.0031 - loss_train: 0.8149504794149496 - loss_val: 0.9689295765784987\n",
      "Epoch: 3257 - time: 0.0031 - loss_train: 0.8149273559377143 - loss_val: 0.9689296946439259\n",
      "Epoch: 3258 - time: 0.0031 - loss_train: 0.8149042471451026 - loss_val: 0.9689298176180077\n",
      "Epoch: 3259 - time: 0.0031 - loss_train: 0.8148811530235837 - loss_val: 0.9689299454766218\n",
      "Epoch: 3260 - time: 0.0031 - loss_train: 0.8148580735596385 - loss_val: 0.9689300781956628\n",
      "Epoch: 3261 - time: 0.0031 - loss_train: 0.8148350087397572 - loss_val: 0.9689302157510419\n",
      "Epoch: 3262 - time: 0.0031 - loss_train: 0.8148119585504416 - loss_val: 0.9689303581186859\n",
      "Epoch: 3263 - time: 0.0031 - loss_train: 0.8147889229782029 - loss_val: 0.9689305052745386\n",
      "Epoch: 3264 - time: 0.0031 - loss_train: 0.8147659020095622 - loss_val: 0.9689306571945594\n",
      "Epoch: 3265 - time: 0.0031 - loss_train: 0.8147428956310516 - loss_val: 0.9689308138547269\n",
      "Epoch: 3266 - time: 0.0031 - loss_train: 0.8147199038292124 - loss_val: 0.9689309752310334\n",
      "Epoch: 3267 - time: 0.0036 - loss_train: 0.8146969265905976 - loss_val: 0.9689311412994925\n",
      "Epoch: 3268 - time: 0.0032 - loss_train: 0.8146739639017686 - loss_val: 0.9689313120361319\n",
      "Epoch: 3269 - time: 0.0031 - loss_train: 0.8146510157492982 - loss_val: 0.9689314874169966\n",
      "Epoch: 3270 - time: 0.0031 - loss_train: 0.8146280821197686 - loss_val: 0.9689316674181517\n",
      "Epoch: 3271 - time: 0.0031 - loss_train: 0.8146051629997729 - loss_val: 0.968931852015676\n",
      "Epoch: 3272 - time: 0.0031 - loss_train: 0.8145822583759126 - loss_val: 0.9689320411856706\n",
      "Epoch: 3273 - time: 0.0031 - loss_train: 0.8145593682348006 - loss_val: 0.9689322349042514\n",
      "Epoch: 3274 - time: 0.0031 - loss_train: 0.8145364925630596 - loss_val: 0.9689324331475533\n",
      "Epoch: 3275 - time: 0.0032 - loss_train: 0.8145136313473219 - loss_val: 0.9689326358917292\n",
      "Epoch: 3276 - time: 0.0031 - loss_train: 0.8144907845742299 - loss_val: 0.9689328431129508\n",
      "Epoch: 3277 - time: 0.0031 - loss_train: 0.814467952230436 - loss_val: 0.9689330547874073\n",
      "Epoch: 3278 - time: 0.0031 - loss_train: 0.8144451343026026 - loss_val: 0.9689332708913075\n",
      "Epoch: 3279 - time: 0.0031 - loss_train: 0.8144223307774013 - loss_val: 0.968933491400878\n",
      "Epoch: 3280 - time: 0.0031 - loss_train: 0.814399541641515 - loss_val: 0.9689337162923648\n",
      "Epoch: 3281 - time: 0.0031 - loss_train: 0.8143767668816347 - loss_val: 0.9689339455420333\n",
      "Epoch: 3282 - time: 0.0031 - loss_train: 0.8143540064844622 - loss_val: 0.9689341791261661\n",
      "Epoch: 3283 - time: 0.0031 - loss_train: 0.8143312604367091 - loss_val: 0.9689344170210681\n",
      "Epoch: 3284 - time: 0.0031 - loss_train: 0.8143085287250967 - loss_val: 0.9689346592030597\n",
      "Epoch: 3285 - time: 0.0031 - loss_train: 0.814285811336355 - loss_val: 0.9689349056484848\n",
      "Epoch: 3286 - time: 0.0031 - loss_train: 0.8142631082572261 - loss_val: 0.9689351563337029\n",
      "Epoch: 3287 - time: 0.0032 - loss_train: 0.8142404194744589 - loss_val: 0.9689354112350971\n",
      "Epoch: 3288 - time: 0.0031 - loss_train: 0.8142177449748148 - loss_val: 0.9689356703290671\n",
      "Epoch: 3289 - time: 0.0031 - loss_train: 0.8141950847450625 - loss_val: 0.9689359335920351\n",
      "Epoch: 3290 - time: 0.0031 - loss_train: 0.8141724387719819 - loss_val: 0.9689362010004405\n",
      "Epoch: 3291 - time: 0.0031 - loss_train: 0.8141498070423618 - loss_val: 0.9689364725307467\n",
      "Epoch: 3292 - time: 0.0031 - loss_train: 0.8141271895430009 - loss_val: 0.9689367481594341\n",
      "Epoch: 3293 - time: 0.0032 - loss_train: 0.8141045862607075 - loss_val: 0.9689370278630051\n",
      "Epoch: 3294 - time: 0.0031 - loss_train: 0.8140819971822989 - loss_val: 0.9689373116179829\n",
      "Epoch: 3295 - time: 0.0031 - loss_train: 0.8140594222946029 - loss_val: 0.9689375994009102\n",
      "Epoch: 3296 - time: 0.0031 - loss_train: 0.8140368615844557 - loss_val: 0.9689378911883524\n",
      "Epoch: 3297 - time: 0.0031 - loss_train: 0.8140143150387041 - loss_val: 0.9689381869568927\n",
      "Epoch: 3298 - time: 0.0031 - loss_train: 0.8139917826442042 - loss_val: 0.9689384866831406\n",
      "Epoch: 3299 - time: 0.0031 - loss_train: 0.8139692643878212 - loss_val: 0.9689387903437207\n",
      "Epoch: 3300 - time: 0.0031 - loss_train: 0.8139467602564292 - loss_val: 0.9689390979152838\n",
      "Epoch: 3301 - time: 0.0031 - loss_train: 0.8139242702369135 - loss_val: 0.9689394093744996\n",
      "Epoch: 3302 - time: 0.0031 - loss_train: 0.8139017943161668 - loss_val: 0.9689397246980601\n",
      "Epoch: 3303 - time: 0.0031 - loss_train: 0.8138793324810925 - loss_val: 0.9689400438626784\n",
      "Epoch: 3304 - time: 0.0031 - loss_train: 0.8138568847186032 - loss_val: 0.9689403668450899\n",
      "Epoch: 3305 - time: 0.0036 - loss_train: 0.8138344510156199 - loss_val: 0.9689406936220526\n",
      "Epoch: 3306 - time: 0.0032 - loss_train: 0.8138120313590747 - loss_val: 0.968941024170345\n",
      "Epoch: 3307 - time: 0.0031 - loss_train: 0.813789625735908 - loss_val: 0.9689413584667697\n",
      "Epoch: 3308 - time: 0.0031 - loss_train: 0.813767234133069 - loss_val: 0.96894169648815\n",
      "Epoch: 3309 - time: 0.0031 - loss_train: 0.8137448565375169 - loss_val: 0.9689420382113313\n",
      "Epoch: 3310 - time: 0.0031 - loss_train: 0.8137224929362206 - loss_val: 0.9689423836131827\n",
      "Epoch: 3311 - time: 0.0032 - loss_train: 0.8137001433161573 - loss_val: 0.9689427326705966\n",
      "Epoch: 3312 - time: 0.0031 - loss_train: 0.8136778076643141 - loss_val: 0.9689430853604851\n",
      "Epoch: 3313 - time: 0.0031 - loss_train: 0.8136554859676869 - loss_val: 0.9689434416597861\n",
      "Epoch: 3314 - time: 0.0031 - loss_train: 0.8136331782132813 - loss_val: 0.9689438015454604\n",
      "Epoch: 3315 - time: 0.0031 - loss_train: 0.8136108843881119 - loss_val: 0.9689441649944894\n",
      "Epoch: 3316 - time: 0.0031 - loss_train: 0.8135886044792023 - loss_val: 0.96894453198388\n",
      "Epoch: 3317 - time: 0.0031 - loss_train: 0.8135663384735856 - loss_val: 0.9689449024906615\n",
      "Epoch: 3318 - time: 0.0031 - loss_train: 0.8135440863583036 - loss_val: 0.9689452764918872\n",
      "Epoch: 3319 - time: 0.0031 - loss_train: 0.813521848120408 - loss_val: 0.9689456539646325\n",
      "Epoch: 3320 - time: 0.0031 - loss_train: 0.8134996237469588 - loss_val: 0.9689460348859978\n",
      "Epoch: 3321 - time: 0.0031 - loss_train: 0.8134774132250255 - loss_val: 0.9689464192331075\n",
      "Epoch: 3322 - time: 0.0031 - loss_train: 0.8134552165416871 - loss_val: 0.9689468069831085\n",
      "Epoch: 3323 - time: 0.0031 - loss_train: 0.8134330336840303 - loss_val: 0.9689471981131733\n",
      "Epoch: 3324 - time: 0.0031 - loss_train: 0.8134108646391535 - loss_val: 0.9689475926004967\n",
      "Epoch: 3325 - time: 0.0031 - loss_train: 0.8133887093941606 - loss_val: 0.9689479904222994\n",
      "Epoch: 3326 - time: 0.0031 - loss_train: 0.8133665679361681 - loss_val: 0.9689483915558251\n",
      "Epoch: 3327 - time: 0.0031 - loss_train: 0.8133444402522989 - loss_val: 0.9689487959783426\n",
      "Epoch: 3328 - time: 0.0031 - loss_train: 0.8133223263296868 - loss_val: 0.9689492036671449\n",
      "Epoch: 3329 - time: 0.0031 - loss_train: 0.8133002261554722 - loss_val: 0.9689496145995513\n",
      "Epoch: 3330 - time: 0.0031 - loss_train: 0.8132781397168078 - loss_val: 0.9689500287529014\n",
      "Epoch: 3331 - time: 0.0031 - loss_train: 0.8132560670008523 - loss_val: 0.9689504461045646\n",
      "Epoch: 3332 - time: 0.0031 - loss_train: 0.8132340079947755 - loss_val: 0.9689508666319328\n",
      "Epoch: 3333 - time: 0.0031 - loss_train: 0.8132119626857539 - loss_val: 0.9689512903124232\n",
      "Epoch: 3334 - time: 0.0031 - loss_train: 0.8131899310609753 - loss_val: 0.9689517171234788\n",
      "Epoch: 3335 - time: 0.0031 - loss_train: 0.8131679131076354 - loss_val: 0.9689521470425673\n",
      "Epoch: 3336 - time: 0.0031 - loss_train: 0.8131459088129387 - loss_val: 0.9689525800471813\n",
      "Epoch: 3337 - time: 0.0031 - loss_train: 0.8131239181640983 - loss_val: 0.9689530161148392\n",
      "Epoch: 3338 - time: 0.0031 - loss_train: 0.8131019411483371 - loss_val: 0.9689534552230865\n",
      "Epoch: 3339 - time: 0.0031 - loss_train: 0.813079977752886 - loss_val: 0.9689538973494923\n",
      "Epoch: 3340 - time: 0.0031 - loss_train: 0.8130580279649857 - loss_val: 0.9689543424716511\n",
      "Epoch: 3341 - time: 0.0032 - loss_train: 0.8130360917718852 - loss_val: 0.9689547905671866\n",
      "Epoch: 3342 - time: 0.0031 - loss_train: 0.8130141691608417 - loss_val: 0.9689552416137444\n",
      "Epoch: 3343 - time: 0.0034 - loss_train: 0.8129922601191226 - loss_val: 0.968955695589\n",
      "Epoch: 3344 - time: 0.0032 - loss_train: 0.8129703646340033 - loss_val: 0.9689561524706503\n",
      "Epoch: 3345 - time: 0.0031 - loss_train: 0.8129484826927684 - loss_val: 0.9689566122364242\n",
      "Epoch: 3346 - time: 0.0031 - loss_train: 0.8129266142827105 - loss_val: 0.9689570748640723\n",
      "Epoch: 3347 - time: 0.0031 - loss_train: 0.812904759391132 - loss_val: 0.968957540331374\n",
      "Epoch: 3348 - time: 0.0031 - loss_train: 0.8128829180053436 - loss_val: 0.9689580086161356\n",
      "Epoch: 3349 - time: 0.0031 - loss_train: 0.812861090112665 - loss_val: 0.9689584796961876\n",
      "Epoch: 3350 - time: 0.0031 - loss_train: 0.8128392757004244 - loss_val: 0.9689589535493899\n",
      "Epoch: 3351 - time: 0.0032 - loss_train: 0.8128174747559586 - loss_val: 0.9689594301536276\n",
      "Epoch: 3352 - time: 0.0031 - loss_train: 0.8127956872666139 - loss_val: 0.9689599094868142\n",
      "Epoch: 3353 - time: 0.0031 - loss_train: 0.8127739132197446 - loss_val: 0.968960391526889\n",
      "Epoch: 3354 - time: 0.0031 - loss_train: 0.8127521526027138 - loss_val: 0.9689608762518187\n",
      "Epoch: 3355 - time: 0.0031 - loss_train: 0.812730405402894 - loss_val: 0.9689613636395977\n",
      "Epoch: 3356 - time: 0.0031 - loss_train: 0.8127086716076656 - loss_val: 0.9689618536682476\n",
      "Epoch: 3357 - time: 0.0031 - loss_train: 0.8126869512044181 - loss_val: 0.9689623463158173\n",
      "Epoch: 3358 - time: 0.0031 - loss_train: 0.8126652441805495 - loss_val: 0.9689628415603828\n",
      "Epoch: 3359 - time: 0.0031 - loss_train: 0.8126435505234667 - loss_val: 0.968963339380048\n",
      "Epoch: 3360 - time: 0.0031 - loss_train: 0.8126218702205851 - loss_val: 0.9689638397529443\n",
      "Epoch: 3361 - time: 0.0031 - loss_train: 0.812600203259329 - loss_val: 0.9689643426572332\n",
      "Epoch: 3362 - time: 0.0031 - loss_train: 0.8125785496271309 - loss_val: 0.9689648480711011\n",
      "Epoch: 3363 - time: 0.0031 - loss_train: 0.812556909311433 - loss_val: 0.9689653559727615\n",
      "Epoch: 3364 - time: 0.0031 - loss_train: 0.8125352822996841 - loss_val: 0.9689658663404603\n",
      "Epoch: 3365 - time: 0.0031 - loss_train: 0.8125136685793438 - loss_val: 0.9689663791524681\n",
      "Epoch: 3366 - time: 0.0031 - loss_train: 0.8124920681378794 - loss_val: 0.9689668943870856\n",
      "Epoch: 3367 - time: 0.0031 - loss_train: 0.812470480962767 - loss_val: 0.9689674120226396\n",
      "Epoch: 3368 - time: 0.0031 - loss_train: 0.8124489070414906 - loss_val: 0.9689679320374877\n",
      "Epoch: 3369 - time: 0.0031 - loss_train: 0.8124273463615439 - loss_val: 0.9689684544100148\n",
      "Epoch: 3370 - time: 0.0031 - loss_train: 0.8124057989104283 - loss_val: 0.968968979118635\n",
      "Epoch: 3371 - time: 0.0031 - loss_train: 0.8123842646756545 - loss_val: 0.9689695061417902\n",
      "Epoch: 3372 - time: 0.0031 - loss_train: 0.8123627436447414 - loss_val: 0.9689700354579512\n",
      "Epoch: 3373 - time: 0.0031 - loss_train: 0.812341235805216 - loss_val: 0.9689705670456183\n",
      "Epoch: 3374 - time: 0.0031 - loss_train: 0.8123197411446154 - loss_val: 0.968971100883322\n",
      "Epoch: 3375 - time: 0.0031 - loss_train: 0.8122982596504835 - loss_val: 0.9689716369496166\n",
      "Epoch: 3376 - time: 0.0031 - loss_train: 0.8122767913103737 - loss_val: 0.9689721752230928\n",
      "Epoch: 3377 - time: 0.0031 - loss_train: 0.8122553361118479 - loss_val: 0.9689727156823651\n",
      "Epoch: 3378 - time: 0.0031 - loss_train: 0.8122338940424764 - loss_val: 0.9689732583060795\n",
      "Epoch: 3379 - time: 0.0032 - loss_train: 0.8122124650898376 - loss_val: 0.9689738030729104\n",
      "Epoch: 3380 - time: 0.0031 - loss_train: 0.8121910492415195 - loss_val: 0.9689743499615636\n",
      "Epoch: 3381 - time: 0.0034 - loss_train: 0.8121696464851177 - loss_val: 0.9689748989507706\n",
      "Epoch: 3382 - time: 0.0032 - loss_train: 0.8121482568082369 - loss_val: 0.9689754500192966\n",
      "Epoch: 3383 - time: 0.0031 - loss_train: 0.8121268801984896 - loss_val: 0.9689760031459336\n",
      "Epoch: 3384 - time: 0.0031 - loss_train: 0.8121055166434973 - loss_val: 0.9689765583095048\n",
      "Epoch: 3385 - time: 0.0031 - loss_train: 0.8120841661308903 - loss_val: 0.9689771154888631\n",
      "Epoch: 3386 - time: 0.0031 - loss_train: 0.8120628286483068 - loss_val: 0.9689776746628903\n",
      "Epoch: 3387 - time: 0.0031 - loss_train: 0.8120415041833937 - loss_val: 0.9689782358105001\n",
      "Epoch: 3388 - time: 0.0031 - loss_train: 0.812020192723807 - loss_val: 0.9689787989106344\n",
      "Epoch: 3389 - time: 0.0031 - loss_train: 0.8119988942572096 - loss_val: 0.9689793639422661\n",
      "Epoch: 3390 - time: 0.0031 - loss_train: 0.8119776087712749 - loss_val: 0.9689799308843977\n",
      "Epoch: 3391 - time: 0.0031 - loss_train: 0.8119563362536829 - loss_val: 0.9689804997160631\n",
      "Epoch: 3392 - time: 0.0031 - loss_train: 0.8119350766921236 - loss_val: 0.9689810704163254\n",
      "Epoch: 3393 - time: 0.0031 - loss_train: 0.8119138300742946 - loss_val: 0.9689816429642792\n",
      "Epoch: 3394 - time: 0.0031 - loss_train: 0.8118925963879021 - loss_val: 0.9689822173390481\n",
      "Epoch: 3395 - time: 0.0031 - loss_train: 0.8118713756206606 - loss_val: 0.9689827935197884\n",
      "Epoch: 3396 - time: 0.0032 - loss_train: 0.8118501677602937 - loss_val: 0.9689833714856848\n",
      "Epoch: 3397 - time: 0.0031 - loss_train: 0.8118289727945328 - loss_val: 0.9689839512159554\n",
      "Epoch: 3398 - time: 0.0031 - loss_train: 0.8118077907111179 - loss_val: 0.9689845326898455\n",
      "Epoch: 3399 - time: 0.0031 - loss_train: 0.8117866214977976 - loss_val: 0.9689851158866352\n",
      "Epoch: 3400 - time: 0.0031 - loss_train: 0.8117654651423286 - loss_val: 0.968985700785632\n",
      "Epoch: 3401 - time: 0.0031 - loss_train: 0.8117443216324769 - loss_val: 0.9689862873661789\n",
      "Epoch: 3402 - time: 0.0031 - loss_train: 0.8117231909560155 - loss_val: 0.9689868756076434\n",
      "Epoch: 3403 - time: 0.0031 - loss_train: 0.8117020731007272 - loss_val: 0.9689874654894307\n",
      "Epoch: 3404 - time: 0.0031 - loss_train: 0.811680968054402 - loss_val: 0.9689880569909738\n",
      "Epoch: 3405 - time: 0.0031 - loss_train: 0.8116598758048399 - loss_val: 0.9689886500917362\n",
      "Epoch: 3406 - time: 0.0031 - loss_train: 0.8116387963398474 - loss_val: 0.9689892447712165\n",
      "Epoch: 3407 - time: 0.0031 - loss_train: 0.8116177296472414 - loss_val: 0.968989841008941\n",
      "Epoch: 3408 - time: 0.0031 - loss_train: 0.8115966757148453 - loss_val: 0.9689904387844699\n",
      "Epoch: 3409 - time: 0.0031 - loss_train: 0.811575634530492 - loss_val: 0.9689910380773926\n",
      "Epoch: 3410 - time: 0.0031 - loss_train: 0.8115546060820233 - loss_val: 0.9689916388673332\n",
      "Epoch: 3411 - time: 0.0031 - loss_train: 0.8115335903572878 - loss_val: 0.9689922411339451\n",
      "Epoch: 3412 - time: 0.0031 - loss_train: 0.8115125873441438 - loss_val: 0.968992844856914\n",
      "Epoch: 3413 - time: 0.0031 - loss_train: 0.8114915970304578 - loss_val: 0.9689934500159568\n",
      "Epoch: 3414 - time: 0.0031 - loss_train: 0.8114706194041043 - loss_val: 0.9689940565908252\n",
      "Epoch: 3415 - time: 0.0031 - loss_train: 0.8114496544529664 - loss_val: 0.9689946645612993\n",
      "Epoch: 3416 - time: 0.0031 - loss_train: 0.8114287021649352 - loss_val: 0.9689952739071932\n",
      "Epoch: 3417 - time: 0.0031 - loss_train: 0.8114077625279115 - loss_val: 0.968995884608352\n",
      "Epoch: 3418 - time: 0.0031 - loss_train: 0.811386835529803 - loss_val: 0.9689964966446537\n",
      "Epoch: 3419 - time: 0.0034 - loss_train: 0.8113659211585262 - loss_val: 0.9689971099960092\n",
      "Epoch: 3420 - time: 0.0032 - loss_train: 0.8113450194020064 - loss_val: 0.9689977246423589\n",
      "Epoch: 3421 - time: 0.0031 - loss_train: 0.8113241302481772 - loss_val: 0.9689983405636787\n",
      "Epoch: 3422 - time: 0.0031 - loss_train: 0.81130325368498 - loss_val: 0.9689989577399746\n",
      "Epoch: 3423 - time: 0.0031 - loss_train: 0.8112823897003648 - loss_val: 0.9689995761512872\n",
      "Epoch: 3424 - time: 0.0031 - loss_train: 0.8112615382822908 - loss_val: 0.9690001957776874\n",
      "Epoch: 3425 - time: 0.0031 - loss_train: 0.8112406994187247 - loss_val: 0.9690008165992804\n",
      "Epoch: 3426 - time: 0.0031 - loss_train: 0.8112198730976409 - loss_val: 0.969001438596202\n",
      "Epoch: 3427 - time: 0.0031 - loss_train: 0.8111990593070245 - loss_val: 0.9690020617486237\n",
      "Epoch: 3428 - time: 0.0031 - loss_train: 0.8111782580348668 - loss_val: 0.9690026860367458\n",
      "Epoch: 3429 - time: 0.0031 - loss_train: 0.8111574692691682 - loss_val: 0.9690033114408049\n",
      "Epoch: 3430 - time: 0.0031 - loss_train: 0.8111366929979374 - loss_val: 0.9690039379410689\n",
      "Epoch: 3431 - time: 0.0031 - loss_train: 0.8111159292091918 - loss_val: 0.9690045655178384\n",
      "Epoch: 3432 - time: 0.0031 - loss_train: 0.8110951778909572 - loss_val: 0.969005194151447\n",
      "Epoch: 3433 - time: 0.0031 - loss_train: 0.8110744390312669 - loss_val: 0.9690058238222614\n",
      "Epoch: 3434 - time: 0.0031 - loss_train: 0.8110537126181632 - loss_val: 0.9690064545106829\n",
      "Epoch: 3435 - time: 0.0031 - loss_train: 0.8110329986396969 - loss_val: 0.9690070861971435\n",
      "Epoch: 3436 - time: 0.0031 - loss_train: 0.811012297083927 - loss_val: 0.96900771886211\n",
      "Epoch: 3437 - time: 0.0031 - loss_train: 0.8109916079389213 - loss_val: 0.9690083524860806\n",
      "Epoch: 3438 - time: 0.0031 - loss_train: 0.8109709311927548 - loss_val: 0.9690089870495895\n",
      "Epoch: 3439 - time: 0.0031 - loss_train: 0.8109502668335115 - loss_val: 0.9690096225332018\n",
      "Epoch: 3440 - time: 0.0031 - loss_train: 0.8109296148492845 - loss_val: 0.9690102589175166\n",
      "Epoch: 3441 - time: 0.0031 - loss_train: 0.8109089752281745 - loss_val: 0.969010896183167\n",
      "Epoch: 3442 - time: 0.0031 - loss_train: 0.8108883479582903 - loss_val: 0.9690115343108199\n",
      "Epoch: 3443 - time: 0.0031 - loss_train: 0.8108677330277495 - loss_val: 0.9690121732811735\n",
      "Epoch: 3444 - time: 0.0031 - loss_train: 0.8108471304246784 - loss_val: 0.9690128130749629\n",
      "Epoch: 3445 - time: 0.0031 - loss_train: 0.810826540137211 - loss_val: 0.9690134536729533\n",
      "Epoch: 3446 - time: 0.0031 - loss_train: 0.8108059621534903 - loss_val: 0.9690140950559464\n",
      "Epoch: 3447 - time: 0.0031 - loss_train: 0.8107853964616666 - loss_val: 0.9690147372047765\n",
      "Epoch: 3448 - time: 0.0031 - loss_train: 0.8107648430499 - loss_val: 0.9690153801003103\n",
      "Epoch: 3449 - time: 0.0031 - loss_train: 0.8107443019063578 - loss_val: 0.969016023723451\n",
      "Epoch: 3450 - time: 0.0031 - loss_train: 0.8107237730192165 - loss_val: 0.9690166680551342\n",
      "Epoch: 3451 - time: 0.0031 - loss_train: 0.8107032563766602 - loss_val: 0.9690173130763277\n",
      "Epoch: 3452 - time: 0.0031 - loss_train: 0.8106827519668822 - loss_val: 0.9690179587680384\n",
      "Epoch: 3453 - time: 0.0031 - loss_train: 0.8106622597780834 - loss_val: 0.9690186051113007\n",
      "Epoch: 3454 - time: 0.0031 - loss_train: 0.8106417797984732 - loss_val: 0.969019252087187\n",
      "Epoch: 3455 - time: 0.0031 - loss_train: 0.8106213120162703 - loss_val: 0.969019899676803\n",
      "Epoch: 3456 - time: 0.0031 - loss_train: 0.8106008564197005 - loss_val: 0.9690205478612877\n",
      "Epoch: 3457 - time: 0.0031 - loss_train: 0.8105804129969983 - loss_val: 0.9690211966218155\n",
      "Epoch: 3458 - time: 0.0032 - loss_train: 0.810559981736408 - loss_val: 0.9690218459395956\n",
      "Epoch: 3459 - time: 0.0031 - loss_train: 0.8105395626261795 - loss_val: 0.9690224957958674\n",
      "Epoch: 3460 - time: 0.0031 - loss_train: 0.8105191556545742 - loss_val: 0.9690231461719109\n",
      "Epoch: 3461 - time: 0.0031 - loss_train: 0.8104987608098593 - loss_val: 0.9690237970490336\n",
      "Epoch: 3462 - time: 0.0031 - loss_train: 0.8104783780803115 - loss_val: 0.9690244484085815\n",
      "Epoch: 3463 - time: 0.0031 - loss_train: 0.8104580074542164 - loss_val: 0.9690251002319353\n",
      "Epoch: 3464 - time: 0.0031 - loss_train: 0.8104376489198669 - loss_val: 0.9690257525005082\n",
      "Epoch: 3465 - time: 0.0031 - loss_train: 0.8104173024655652 - loss_val: 0.969026405195749\n",
      "Epoch: 3466 - time: 0.0031 - loss_train: 0.810396968079621 - loss_val: 0.9690270582991399\n",
      "Epoch: 3467 - time: 0.0031 - loss_train: 0.8103766457503532 - loss_val: 0.9690277117921992\n",
      "Epoch: 3468 - time: 0.0031 - loss_train: 0.8103563354660891 - loss_val: 0.9690283656564787\n",
      "Epoch: 3469 - time: 0.0031 - loss_train: 0.8103360372151633 - loss_val: 0.9690290198735647\n",
      "Epoch: 3470 - time: 0.0031 - loss_train: 0.8103157509859198 - loss_val: 0.9690296744250788\n",
      "Epoch: 3471 - time: 0.0031 - loss_train: 0.8102954767667109 - loss_val: 0.9690303292926776\n",
      "Epoch: 3472 - time: 0.0031 - loss_train: 0.8102752145458975 - loss_val: 0.969030984458051\n",
      "Epoch: 3473 - time: 0.0031 - loss_train: 0.8102549643118482 - loss_val: 0.969031639902926\n",
      "Epoch: 3474 - time: 0.0031 - loss_train: 0.8102347260529402 - loss_val: 0.9690322956090606\n",
      "Epoch: 3475 - time: 0.0031 - loss_train: 0.8102144997575592 - loss_val: 0.9690329515582513\n",
      "Epoch: 3476 - time: 0.0031 - loss_train: 0.8101942854141 - loss_val: 0.9690336077323284\n",
      "Epoch: 3477 - time: 0.0031 - loss_train: 0.8101740830109647 - loss_val: 0.9690342641131555\n",
      "Epoch: 3478 - time: 0.0031 - loss_train: 0.8101538925365647 - loss_val: 0.9690349206826344\n",
      "Epoch: 3479 - time: 0.0031 - loss_train: 0.8101337139793189 - loss_val: 0.9690355774226973\n",
      "Epoch: 3480 - time: 0.0039 - loss_train: 0.8101135473276556 - loss_val: 0.9690362343153164\n",
      "Epoch: 3481 - time: 0.0042 - loss_train: 0.8100933925700108 - loss_val: 0.9690368913424952\n",
      "Epoch: 3482 - time: 0.0032 - loss_train: 0.8100732496948292 - loss_val: 0.9690375484862731\n",
      "Epoch: 3483 - time: 0.0031 - loss_train: 0.8100531186905643 - loss_val: 0.9690382057287262\n",
      "Epoch: 3484 - time: 0.0031 - loss_train: 0.8100329995456773 - loss_val: 0.9690388630519642\n",
      "Epoch: 3485 - time: 0.0031 - loss_train: 0.810012892248638 - loss_val: 0.9690395204381318\n",
      "Epoch: 3486 - time: 0.0031 - loss_train: 0.8099927967879257 - loss_val: 0.96904017786941\n",
      "Epoch: 3487 - time: 0.0031 - loss_train: 0.8099727131520262 - loss_val: 0.9690408353280132\n",
      "Epoch: 3488 - time: 0.0031 - loss_train: 0.8099526413294353 - loss_val: 0.9690414927961924\n",
      "Epoch: 3489 - time: 0.0031 - loss_train: 0.8099325813086571 - loss_val: 0.9690421502562349\n",
      "Epoch: 3490 - time: 0.0031 - loss_train: 0.8099125330782032 - loss_val: 0.9690428076904601\n",
      "Epoch: 3491 - time: 0.0031 - loss_train: 0.8098924966265947 - loss_val: 0.9690434650812262\n",
      "Epoch: 3492 - time: 0.0031 - loss_train: 0.80987247194236 - loss_val: 0.9690441224109245\n",
      "Epoch: 3493 - time: 0.0031 - loss_train: 0.8098524590140379 - loss_val: 0.969044779661981\n",
      "Epoch: 3494 - time: 0.0031 - loss_train: 0.809832457830173 - loss_val: 0.9690454368168601\n",
      "Epoch: 3495 - time: 0.0033 - loss_train: 0.8098124683793207 - loss_val: 0.9690460938580591\n",
      "Epoch: 3496 - time: 0.0032 - loss_train: 0.8097924906500437 - loss_val: 0.9690467507681128\n",
      "Epoch: 3497 - time: 0.0031 - loss_train: 0.8097725246309138 - loss_val: 0.969047407529587\n",
      "Epoch: 3498 - time: 0.0031 - loss_train: 0.8097525703105102 - loss_val: 0.969048064125089\n",
      "Epoch: 3499 - time: 0.0031 - loss_train: 0.8097326276774217 - loss_val: 0.9690487205372567\n",
      "Epoch: 3500 - time: 0.0031 - loss_train: 0.8097126967202453 - loss_val: 0.9690493767487667\n",
      "Epoch: 3501 - time: 0.0031 - loss_train: 0.8096927774275859 - loss_val: 0.9690500327423306\n",
      "Epoch: 3502 - time: 0.0031 - loss_train: 0.8096728697880576 - loss_val: 0.9690506885006924\n",
      "Epoch: 3503 - time: 0.0031 - loss_train: 0.8096529737902827 - loss_val: 0.9690513440066365\n",
      "Epoch: 3504 - time: 0.0031 - loss_train: 0.809633089422892 - loss_val: 0.9690519992429802\n",
      "Epoch: 3505 - time: 0.0031 - loss_train: 0.8096132166745247 - loss_val: 0.9690526541925754\n",
      "Epoch: 3506 - time: 0.0031 - loss_train: 0.8095933555338288 - loss_val: 0.9690533088383132\n",
      "Epoch: 3507 - time: 0.0031 - loss_train: 0.8095735059894603 - loss_val: 0.9690539631631172\n",
      "Epoch: 3508 - time: 0.0031 - loss_train: 0.8095536680300846 - loss_val: 0.9690546171499471\n",
      "Epoch: 3509 - time: 0.0031 - loss_train: 0.8095338416443747 - loss_val: 0.9690552707817992\n",
      "Epoch: 3510 - time: 0.0031 - loss_train: 0.8095140268210124 - loss_val: 0.9690559240417063\n",
      "Epoch: 3511 - time: 0.0031 - loss_train: 0.8094942235486878 - loss_val: 0.9690565769127351\n",
      "Epoch: 3512 - time: 0.0031 - loss_train: 0.8094744318161008 - loss_val: 0.9690572293779888\n",
      "Epoch: 3513 - time: 0.0031 - loss_train: 0.8094546516119584 - loss_val: 0.9690578814206062\n",
      "Epoch: 3514 - time: 0.0031 - loss_train: 0.8094348829249755 - loss_val: 0.9690585330237622\n",
      "Epoch: 3515 - time: 0.0031 - loss_train: 0.8094151257438784 - loss_val: 0.9690591841706683\n",
      "Epoch: 3516 - time: 0.0031 - loss_train: 0.8093953800573989 - loss_val: 0.9690598348445697\n",
      "Epoch: 3517 - time: 0.0031 - loss_train: 0.8093756458542791 - loss_val: 0.9690604850287492\n",
      "Epoch: 3518 - time: 0.0031 - loss_train: 0.8093559231232687 - loss_val: 0.969061134706525\n",
      "Epoch: 3519 - time: 0.0031 - loss_train: 0.8093362118531269 - loss_val: 0.969061783861251\n",
      "Epoch: 3520 - time: 0.0031 - loss_train: 0.8093165120326208 - loss_val: 0.9690624324763174\n",
      "Epoch: 3521 - time: 0.0031 - loss_train: 0.8092968236505262 - loss_val: 0.9690630805351493\n",
      "Epoch: 3522 - time: 0.0031 - loss_train: 0.8092771466956276 - loss_val: 0.9690637280212082\n",
      "Epoch: 3523 - time: 0.0031 - loss_train: 0.8092574811567175 - loss_val: 0.9690643749179925\n",
      "Epoch: 3524 - time: 0.0031 - loss_train: 0.8092378270225979 - loss_val: 0.9690650212090359\n",
      "Epoch: 3525 - time: 0.0031 - loss_train: 0.8092181842820789 - loss_val: 0.969065666877906\n",
      "Epoch: 3526 - time: 0.0031 - loss_train: 0.8091985529239791 - loss_val: 0.9690663119082112\n",
      "Epoch: 3527 - time: 0.0031 - loss_train: 0.8091789329371258 - loss_val: 0.9690669562835899\n",
      "Epoch: 3528 - time: 0.0031 - loss_train: 0.8091593243103548 - loss_val: 0.9690675999877214\n",
      "Epoch: 3529 - time: 0.0031 - loss_train: 0.8091397270325108 - loss_val: 0.9690682430043178\n",
      "Epoch: 3530 - time: 0.0031 - loss_train: 0.8091201410924467 - loss_val: 0.9690688853171291\n",
      "Epoch: 3531 - time: 0.0031 - loss_train: 0.809100566479024 - loss_val: 0.9690695269099412\n",
      "Epoch: 3532 - time: 0.0034 - loss_train: 0.8090810031811135 - loss_val: 0.9690701677665745\n",
      "Epoch: 3533 - time: 0.0032 - loss_train: 0.8090614511875934 - loss_val: 0.9690708078708864\n",
      "Epoch: 3534 - time: 0.0031 - loss_train: 0.809041910487352 - loss_val: 0.9690714472067706\n",
      "Epoch: 3535 - time: 0.0031 - loss_train: 0.8090223810692846 - loss_val: 0.969072085758157\n",
      "Epoch: 3536 - time: 0.0031 - loss_train: 0.8090028629222971 - loss_val: 0.9690727235090102\n",
      "Epoch: 3537 - time: 0.0031 - loss_train: 0.8089833560353018 - loss_val: 0.969073360443333\n",
      "Epoch: 3538 - time: 0.0031 - loss_train: 0.8089638603972215 - loss_val: 0.9690739965451614\n",
      "Epoch: 3539 - time: 0.0031 - loss_train: 0.8089443759969867 - loss_val: 0.9690746317985707\n",
      "Epoch: 3540 - time: 0.0031 - loss_train: 0.8089249028235368 - loss_val: 0.9690752661876694\n",
      "Epoch: 3541 - time: 0.0031 - loss_train: 0.8089054408658195 - loss_val: 0.9690758996966042\n",
      "Epoch: 3542 - time: 0.0031 - loss_train: 0.8088859901127914 - loss_val: 0.9690765323095564\n",
      "Epoch: 3543 - time: 0.0031 - loss_train: 0.8088665505534186 - loss_val: 0.9690771640107451\n",
      "Epoch: 3544 - time: 0.0036 - loss_train: 0.8088471221766739 - loss_val: 0.9690777947844224\n",
      "Epoch: 3545 - time: 0.0036 - loss_train: 0.8088277049715411 - loss_val: 0.9690784246148806\n",
      "Epoch: 3546 - time: 0.0036 - loss_train: 0.8088082989270112 - loss_val: 0.9690790534864456\n",
      "Epoch: 3547 - time: 0.0036 - loss_train: 0.8087889040320838 - loss_val: 0.9690796813834783\n",
      "Epoch: 3548 - time: 0.0044 - loss_train: 0.8087695202757679 - loss_val: 0.9690803082903797\n",
      "Epoch: 3549 - time: 0.0036 - loss_train: 0.8087501476470804 - loss_val: 0.9690809341915831\n",
      "Epoch: 3550 - time: 0.0036 - loss_train: 0.8087307861350486 - loss_val: 0.9690815590715589\n",
      "Epoch: 3551 - time: 0.0036 - loss_train: 0.8087114357287062 - loss_val: 0.9690821829148148\n",
      "Epoch: 3552 - time: 0.0036 - loss_train: 0.8086920964170969 - loss_val: 0.9690828057058934\n",
      "Epoch: 3553 - time: 0.0036 - loss_train: 0.8086727681892731 - loss_val: 0.969083427429374\n",
      "Epoch: 3554 - time: 0.0036 - loss_train: 0.8086534510342959 - loss_val: 0.9690840480698717\n",
      "Epoch: 3555 - time: 0.0036 - loss_train: 0.8086341449412343 - loss_val: 0.9690846676120383\n",
      "Epoch: 3556 - time: 0.0036 - loss_train: 0.8086148498991672 - loss_val: 0.9690852860405611\n",
      "Epoch: 3557 - time: 0.0038 - loss_train: 0.8085955658971818 - loss_val: 0.9690859033401639\n",
      "Epoch: 3558 - time: 0.0038 - loss_train: 0.8085762929243733 - loss_val: 0.9690865194956054\n",
      "Epoch: 3559 - time: 0.0038 - loss_train: 0.8085570309698471 - loss_val: 0.9690871344916826\n",
      "Epoch: 3560 - time: 0.0039 - loss_train: 0.808537780022716 - loss_val: 0.9690877483132275\n",
      "Epoch: 3561 - time: 0.0039 - loss_train: 0.808518540072102 - loss_val: 0.9690883609451082\n",
      "Epoch: 3562 - time: 0.0039 - loss_train: 0.8084993111071362 - loss_val: 0.9690889723722267\n",
      "Epoch: 3563 - time: 0.0038 - loss_train: 0.8084800931169579 - loss_val: 0.9690895825795274\n",
      "Epoch: 3564 - time: 0.0039 - loss_train: 0.8084608860907161 - loss_val: 0.969090191551984\n",
      "Epoch: 3565 - time: 0.0038 - loss_train: 0.8084416900175675 - loss_val: 0.9690907992746095\n",
      "Epoch: 3566 - time: 0.0045 - loss_train: 0.8084225048866777 - loss_val: 0.969091405732453\n",
      "Epoch: 3567 - time: 0.0038 - loss_train: 0.8084033306872214 - loss_val: 0.9690920109105989\n",
      "Epoch: 3568 - time: 0.0039 - loss_train: 0.8083841674083826 - loss_val: 0.9690926147941685\n",
      "Epoch: 3569 - time: 0.0039 - loss_train: 0.8083650150393532 - loss_val: 0.9690932173683182\n",
      "Epoch: 3570 - time: 0.0039 - loss_train: 0.8083458735693347 - loss_val: 0.9690938186182418\n",
      "Epoch: 3571 - time: 0.0039 - loss_train: 0.8083267429875366 - loss_val: 0.9690944185291678\n",
      "Epoch: 3572 - time: 0.0038 - loss_train: 0.8083076232831775 - loss_val: 0.9690950170863615\n",
      "Epoch: 3573 - time: 0.0039 - loss_train: 0.8082885144454849 - loss_val: 0.9690956142751245\n",
      "Epoch: 3574 - time: 0.0039 - loss_train: 0.8082694164636953 - loss_val: 0.9690962100807942\n",
      "Epoch: 3575 - time: 0.0039 - loss_train: 0.8082503293270535 - loss_val: 0.9690968044887434\n",
      "Epoch: 3576 - time: 0.0040 - loss_train: 0.808231253024814 - loss_val: 0.9690973974843823\n",
      "Epoch: 3577 - time: 0.0047 - loss_train: 0.8082121875462396 - loss_val: 0.9690979890531561\n",
      "Epoch: 3578 - time: 0.0078 - loss_train: 0.808193132880601 - loss_val: 0.9690985791805466\n",
      "Epoch: 3579 - time: 0.0046 - loss_train: 0.80817408901718 - loss_val: 0.969099167852071\n",
      "Epoch: 3580 - time: 0.0046 - loss_train: 0.8081550559452644 - loss_val: 0.9690997550532832\n",
      "Epoch: 3581 - time: 0.0045 - loss_train: 0.8081360336541539 - loss_val: 0.9691003407697736\n",
      "Epoch: 3582 - time: 0.0045 - loss_train: 0.8081170221331543 - loss_val: 0.9691009249871659\n",
      "Epoch: 3583 - time: 0.0045 - loss_train: 0.808098021371582 - loss_val: 0.9691015076911227\n",
      "Epoch: 3584 - time: 0.0045 - loss_train: 0.8080790313587622 - loss_val: 0.9691020888673432\n",
      "Epoch: 3585 - time: 0.0045 - loss_train: 0.808060052084028 - loss_val: 0.9691026685015585\n",
      "Epoch: 3586 - time: 0.0045 - loss_train: 0.8080410835367221 - loss_val: 0.96910324657954\n",
      "Epoch: 3587 - time: 0.0044 - loss_train: 0.808022125706196 - loss_val: 0.9691038230870929\n",
      "Epoch: 3588 - time: 0.0043 - loss_train: 0.8080031785818094 - loss_val: 0.9691043980100575\n",
      "Epoch: 3589 - time: 0.0045 - loss_train: 0.8079842421529324 - loss_val: 0.969104971334313\n",
      "Epoch: 3590 - time: 0.0043 - loss_train: 0.8079653164089428 - loss_val: 0.9691055430457716\n",
      "Epoch: 3591 - time: 0.0032 - loss_train: 0.8079464013392276 - loss_val: 0.9691061131303841\n",
      "Epoch: 3592 - time: 0.0031 - loss_train: 0.8079274969331826 - loss_val: 0.9691066815741327\n",
      "Epoch: 3593 - time: 0.0031 - loss_train: 0.8079086031802128 - loss_val: 0.9691072483630414\n",
      "Epoch: 3594 - time: 0.0031 - loss_train: 0.8078897200697315 - loss_val: 0.9691078134831661\n",
      "Epoch: 3595 - time: 0.0048 - loss_train: 0.8078708475911619 - loss_val: 0.9691083769206\n",
      "Epoch: 3596 - time: 0.0045 - loss_train: 0.8078519857339359 - loss_val: 0.9691089386614705\n",
      "Epoch: 3597 - time: 0.0046 - loss_train: 0.8078331344874933 - loss_val: 0.9691094986919443\n",
      "Epoch: 3598 - time: 0.0045 - loss_train: 0.8078142938412841 - loss_val: 0.9691100569982202\n",
      "Epoch: 3599 - time: 0.0045 - loss_train: 0.8077954637847667 - loss_val: 0.9691106135665347\n",
      "Epoch: 3600 - time: 0.0045 - loss_train: 0.8077766443074086 - loss_val: 0.9691111683831602\n",
      "Epoch: 3601 - time: 0.0046 - loss_train: 0.8077578353986855 - loss_val: 0.9691117214344038\n",
      "Epoch: 3602 - time: 0.0045 - loss_train: 0.8077390370480839 - loss_val: 0.9691122727066099\n",
      "Epoch: 3603 - time: 0.0045 - loss_train: 0.8077202492450972 - loss_val: 0.9691128221861577\n",
      "Epoch: 3604 - time: 0.0045 - loss_train: 0.8077014719792294 - loss_val: 0.9691133698594608\n",
      "Epoch: 3605 - time: 0.0045 - loss_train: 0.807682705239992 - loss_val: 0.9691139157129723\n",
      "Epoch: 3606 - time: 0.0045 - loss_train: 0.8076639490169069 - loss_val: 0.9691144597331772\n",
      "Epoch: 3607 - time: 0.0045 - loss_train: 0.807645203299504 - loss_val: 0.969115001906598\n",
      "Epoch: 3608 - time: 0.0045 - loss_train: 0.8076264680773224 - loss_val: 0.9691155422197926\n",
      "Epoch: 3609 - time: 0.0045 - loss_train: 0.8076077433399109 - loss_val: 0.9691160806593553\n",
      "Epoch: 3610 - time: 0.0045 - loss_train: 0.8075890290768264 - loss_val: 0.969116617211913\n",
      "Epoch: 3611 - time: 0.0045 - loss_train: 0.8075703252776352 - loss_val: 0.9691171518641334\n",
      "Epoch: 3612 - time: 0.0045 - loss_train: 0.8075516319319127 - loss_val: 0.9691176846027145\n",
      "Epoch: 3613 - time: 0.0045 - loss_train: 0.8075329490292431 - loss_val: 0.9691182154143948\n",
      "Epoch: 3614 - time: 0.0044 - loss_train: 0.8075142765592197 - loss_val: 0.9691187442859441\n",
      "Epoch: 3615 - time: 0.0045 - loss_train: 0.8074956145114449 - loss_val: 0.9691192712041699\n",
      "Epoch: 3616 - time: 0.0045 - loss_train: 0.8074769628755303 - loss_val: 0.9691197961559146\n",
      "Epoch: 3617 - time: 0.0045 - loss_train: 0.8074583216410965 - loss_val: 0.9691203191280574\n",
      "Epoch: 3618 - time: 0.0045 - loss_train: 0.8074396907977726 - loss_val: 0.969120840107511\n",
      "Epoch: 3619 - time: 0.0045 - loss_train: 0.8074210703351968 - loss_val: 0.9691213590812258\n",
      "Epoch: 3620 - time: 0.0045 - loss_train: 0.807402460243018 - loss_val: 0.9691218760361847\n",
      "Epoch: 3621 - time: 0.0048 - loss_train: 0.807383860510892 - loss_val: 0.9691223909594101\n",
      "Epoch: 3622 - time: 0.0046 - loss_train: 0.8073652711284842 - loss_val: 0.9691229038379554\n",
      "Epoch: 3623 - time: 0.0037 - loss_train: 0.8073466920854703 - loss_val: 0.9691234146589133\n",
      "Epoch: 3624 - time: 0.0037 - loss_train: 0.8073281233715338 - loss_val: 0.9691239234094083\n",
      "Epoch: 3625 - time: 0.0037 - loss_train: 0.8073095649763676 - loss_val: 0.9691244300766041\n",
      "Epoch: 3626 - time: 0.0036 - loss_train: 0.8072910168896742 - loss_val: 0.9691249346476961\n",
      "Epoch: 3627 - time: 0.0037 - loss_train: 0.8072724791011643 - loss_val: 0.9691254371099176\n",
      "Epoch: 3628 - time: 0.0037 - loss_train: 0.8072539516005585 - loss_val: 0.9691259374505357\n",
      "Epoch: 3629 - time: 0.0031 - loss_train: 0.8072354343775866 - loss_val: 0.969126435656854\n",
      "Epoch: 3630 - time: 0.0031 - loss_train: 0.8072169274219861 - loss_val: 0.9691269317162093\n",
      "Epoch: 3631 - time: 0.0032 - loss_train: 0.807198430723505 - loss_val: 0.9691274256159764\n",
      "Epoch: 3632 - time: 0.0032 - loss_train: 0.8071799442719007 - loss_val: 0.9691279173435642\n",
      "Epoch: 3633 - time: 0.0031 - loss_train: 0.8071614680569381 - loss_val: 0.9691284068864153\n",
      "Epoch: 3634 - time: 0.0031 - loss_train: 0.807143002068393 - loss_val: 0.9691288942320091\n",
      "Epoch: 3635 - time: 0.0033 - loss_train: 0.8071245462960491 - loss_val: 0.9691293793678599\n",
      "Epoch: 3636 - time: 0.0031 - loss_train: 0.8071061007297 - loss_val: 0.9691298622815161\n",
      "Epoch: 3637 - time: 0.0031 - loss_train: 0.8070876653591478 - loss_val: 0.9691303429605639\n",
      "Epoch: 3638 - time: 0.0031 - loss_train: 0.8070692401742047 - loss_val: 0.9691308213926212\n",
      "Epoch: 3639 - time: 0.0031 - loss_train: 0.8070508251646904 - loss_val: 0.969131297565343\n",
      "Epoch: 3640 - time: 0.0031 - loss_train: 0.8070324203204355 - loss_val: 0.9691317714664184\n",
      "Epoch: 3641 - time: 0.0032 - loss_train: 0.8070140256312793 - loss_val: 0.9691322430835719\n",
      "Epoch: 3642 - time: 0.0031 - loss_train: 0.8069956410870694 - loss_val: 0.969132712404563\n",
      "Epoch: 3643 - time: 0.0031 - loss_train: 0.8069772666776635 - loss_val: 0.9691331794171874\n",
      "Epoch: 3644 - time: 0.0031 - loss_train: 0.8069589023929279 - loss_val: 0.9691336441092719\n",
      "Epoch: 3645 - time: 0.0031 - loss_train: 0.8069405482227394 - loss_val: 0.9691341064686828\n",
      "Epoch: 3646 - time: 0.0031 - loss_train: 0.8069222041569818 - loss_val: 0.9691345664833185\n",
      "Epoch: 3647 - time: 0.0031 - loss_train: 0.8069038701855503 - loss_val: 0.9691350241411126\n",
      "Epoch: 3648 - time: 0.0031 - loss_train: 0.8068855462983474 - loss_val: 0.9691354794300336\n",
      "Epoch: 3649 - time: 0.0031 - loss_train: 0.8068672324852862 - loss_val: 0.9691359323380859\n",
      "Epoch: 3650 - time: 0.0031 - loss_train: 0.8068489287362881 - loss_val: 0.9691363828533074\n",
      "Epoch: 3651 - time: 0.0031 - loss_train: 0.8068306350412846 - loss_val: 0.9691368309637712\n",
      "Epoch: 3652 - time: 0.0031 - loss_train: 0.8068123513902158 - loss_val: 0.9691372766575845\n",
      "Epoch: 3653 - time: 0.0031 - loss_train: 0.8067940777730308 - loss_val: 0.9691377199228914\n",
      "Epoch: 3654 - time: 0.0031 - loss_train: 0.8067758141796887 - loss_val: 0.9691381607478661\n",
      "Epoch: 3655 - time: 0.0031 - loss_train: 0.8067575606001571 - loss_val: 0.9691385991207238\n",
      "Epoch: 3656 - time: 0.0031 - loss_train: 0.8067393170244136 - loss_val: 0.9691390350297077\n",
      "Epoch: 3657 - time: 0.0031 - loss_train: 0.8067210834424441 - loss_val: 0.9691394684631005\n",
      "Epoch: 3658 - time: 0.0038 - loss_train: 0.8067028598442448 - loss_val: 0.969139899409216\n",
      "Epoch: 3659 - time: 0.0031 - loss_train: 0.8066846462198202 - loss_val: 0.9691403278564069\n",
      "Epoch: 3660 - time: 0.0031 - loss_train: 0.8066664425591846 - loss_val: 0.9691407537930551\n",
      "Epoch: 3661 - time: 0.0031 - loss_train: 0.8066482488523615 - loss_val: 0.9691411772075811\n",
      "Epoch: 3662 - time: 0.0031 - loss_train: 0.8066300650893835 - loss_val: 0.9691415980884374\n",
      "Epoch: 3663 - time: 0.0031 - loss_train: 0.8066118912602929 - loss_val: 0.969142016424111\n",
      "Epoch: 3664 - time: 0.0031 - loss_train: 0.8065937273551406 - loss_val: 0.9691424322031261\n",
      "Epoch: 3665 - time: 0.0031 - loss_train: 0.8065755733639873 - loss_val: 0.969142845414037\n",
      "Epoch: 3666 - time: 0.0031 - loss_train: 0.8065574292769027 - loss_val: 0.9691432560454355\n",
      "Epoch: 3667 - time: 0.0031 - loss_train: 0.8065392950839658 - loss_val: 0.9691436640859469\n",
      "Epoch: 3668 - time: 0.0031 - loss_train: 0.8065211707752656 - loss_val: 0.9691440695242302\n",
      "Epoch: 3669 - time: 0.0031 - loss_train: 0.8065030563408997 - loss_val: 0.9691444723489777\n",
      "Epoch: 3670 - time: 0.0031 - loss_train: 0.8064849517709742 - loss_val: 0.9691448725489193\n",
      "Epoch: 3671 - time: 0.0031 - loss_train: 0.8064668570556064 - loss_val: 0.9691452701128154\n",
      "Epoch: 3672 - time: 0.0031 - loss_train: 0.806448772184922 - loss_val: 0.9691456650294614\n",
      "Epoch: 3673 - time: 0.0031 - loss_train: 0.8064306971490555 - loss_val: 0.9691460572876882\n",
      "Epoch: 3674 - time: 0.0031 - loss_train: 0.8064126319381512 - loss_val: 0.9691464468763616\n",
      "Epoch: 3675 - time: 0.0031 - loss_train: 0.806394576542363 - loss_val: 0.9691468337843759\n",
      "Epoch: 3676 - time: 0.0031 - loss_train: 0.8063765309518535 - loss_val: 0.9691472180006669\n",
      "Epoch: 3677 - time: 0.0031 - loss_train: 0.8063584951567957 - loss_val: 0.9691475995142002\n",
      "Epoch: 3678 - time: 0.0031 - loss_train: 0.8063404691473707 - loss_val: 0.9691479783139735\n",
      "Epoch: 3679 - time: 0.0031 - loss_train: 0.8063224529137692 - loss_val: 0.9691483543890221\n",
      "Epoch: 3680 - time: 0.0031 - loss_train: 0.806304446446192 - loss_val: 0.9691487277284156\n",
      "Epoch: 3681 - time: 0.0031 - loss_train: 0.8062864497348484 - loss_val: 0.9691490983212523\n",
      "Epoch: 3682 - time: 0.0031 - loss_train: 0.806268462769958 - loss_val: 0.9691494661566701\n",
      "Epoch: 3683 - time: 0.0031 - loss_train: 0.8062504855417487 - loss_val: 0.9691498312238378\n",
      "Epoch: 3684 - time: 0.0031 - loss_train: 0.8062325180404588 - loss_val: 0.9691501935119589\n",
      "Epoch: 3685 - time: 0.0031 - loss_train: 0.8062145602563348 - loss_val: 0.9691505530102693\n",
      "Epoch: 3686 - time: 0.0031 - loss_train: 0.8061966121796336 - loss_val: 0.9691509097080393\n",
      "Epoch: 3687 - time: 0.0031 - loss_train: 0.8061786738006208 - loss_val: 0.9691512635945732\n",
      "Epoch: 3688 - time: 0.0031 - loss_train: 0.8061607451095724 - loss_val: 0.9691516146592091\n",
      "Epoch: 3689 - time: 0.0031 - loss_train: 0.8061428260967722 - loss_val: 0.9691519628913174\n",
      "Epoch: 3690 - time: 0.0031 - loss_train: 0.8061249167525146 - loss_val: 0.9691523082803033\n",
      "Epoch: 3691 - time: 0.0031 - loss_train: 0.8061070170671032 - loss_val: 0.9691526508156055\n",
      "Epoch: 3692 - time: 0.0031 - loss_train: 0.8060891270308511 - loss_val: 0.9691529904866939\n",
      "Epoch: 3693 - time: 0.0031 - loss_train: 0.8060712466340799 - loss_val: 0.9691533272830755\n",
      "Epoch: 3694 - time: 0.0031 - loss_train: 0.8060533758671216 - loss_val: 0.9691536611942884\n",
      "Epoch: 3695 - time: 0.0035 - loss_train: 0.8060355147203174 - loss_val: 0.9691539922099052\n",
      "Epoch: 3696 - time: 0.0033 - loss_train: 0.8060176631840177 - loss_val: 0.9691543203195294\n",
      "Epoch: 3697 - time: 0.0031 - loss_train: 0.8059998212485824 - loss_val: 0.9691546455128015\n",
      "Epoch: 3698 - time: 0.0031 - loss_train: 0.8059819889043809 - loss_val: 0.9691549677793913\n",
      "Epoch: 3699 - time: 0.0031 - loss_train: 0.8059641661417919 - loss_val: 0.9691552871090054\n",
      "Epoch: 3700 - time: 0.0031 - loss_train: 0.8059463529512034 - loss_val: 0.9691556034913817\n",
      "Epoch: 3701 - time: 0.0031 - loss_train: 0.8059285493230138 - loss_val: 0.9691559169162918\n",
      "Epoch: 3702 - time: 0.0031 - loss_train: 0.8059107552476296 - loss_val: 0.969156227373539\n",
      "Epoch: 3703 - time: 0.0031 - loss_train: 0.8058929707154671 - loss_val: 0.9691565348529617\n",
      "Epoch: 3704 - time: 0.0031 - loss_train: 0.8058751957169525 - loss_val: 0.9691568393444299\n",
      "Epoch: 3705 - time: 0.0032 - loss_train: 0.8058574302425218 - loss_val: 0.9691571408378482\n",
      "Epoch: 3706 - time: 0.0031 - loss_train: 0.8058396742826194 - loss_val: 0.9691574393231532\n",
      "Epoch: 3707 - time: 0.0031 - loss_train: 0.8058219278276995 - loss_val: 0.9691577347903139\n",
      "Epoch: 3708 - time: 0.0031 - loss_train: 0.8058041908682261 - loss_val: 0.9691580272293315\n",
      "Epoch: 3709 - time: 0.0031 - loss_train: 0.8057864633946724 - loss_val: 0.9691583166302437\n",
      "Epoch: 3710 - time: 0.0032 - loss_train: 0.8057687453975211 - loss_val: 0.9691586029831172\n",
      "Epoch: 3711 - time: 0.0031 - loss_train: 0.8057510368672649 - loss_val: 0.9691588862780529\n",
      "Epoch: 3712 - time: 0.0031 - loss_train: 0.805733337794405 - loss_val: 0.9691591665051846\n",
      "Epoch: 3713 - time: 0.0031 - loss_train: 0.8057156481694525 - loss_val: 0.969159443654679\n",
      "Epoch: 3714 - time: 0.0031 - loss_train: 0.8056979679829285 - loss_val: 0.9691597177167344\n",
      "Epoch: 3715 - time: 0.0031 - loss_train: 0.8056802972253627 - loss_val: 0.9691599886815827\n",
      "Epoch: 3716 - time: 0.0031 - loss_train: 0.8056626358872953 - loss_val: 0.9691602565394883\n",
      "Epoch: 3717 - time: 0.0031 - loss_train: 0.8056449839592749 - loss_val: 0.9691605212807483\n",
      "Epoch: 3718 - time: 0.0031 - loss_train: 0.8056273414318602 - loss_val: 0.9691607828956912\n",
      "Epoch: 3719 - time: 0.0031 - loss_train: 0.8056097082956197 - loss_val: 0.9691610413746794\n",
      "Epoch: 3720 - time: 0.0031 - loss_train: 0.8055920845411308 - loss_val: 0.9691612967081076\n",
      "Epoch: 3721 - time: 0.0031 - loss_train: 0.8055744701589809 - loss_val: 0.9691615488864017\n",
      "Epoch: 3722 - time: 0.0031 - loss_train: 0.8055568651397663 - loss_val: 0.9691617979000205\n",
      "Epoch: 3723 - time: 0.0031 - loss_train: 0.8055392694740935 - loss_val: 0.9691620437394562\n",
      "Epoch: 3724 - time: 0.0032 - loss_train: 0.8055216831525779 - loss_val: 0.9691622863952315\n",
      "Epoch: 3725 - time: 0.0031 - loss_train: 0.8055041061658453 - loss_val: 0.9691625258579026\n",
      "Epoch: 3726 - time: 0.0031 - loss_train: 0.8054865385045296 - loss_val: 0.969162762118059\n",
      "Epoch: 3727 - time: 0.0031 - loss_train: 0.8054689801592756 - loss_val: 0.9691629951663184\n",
      "Epoch: 3728 - time: 0.0031 - loss_train: 0.8054514311207377 - loss_val: 0.9691632249933355\n",
      "Epoch: 3729 - time: 0.0031 - loss_train: 0.805433891379578 - loss_val: 0.9691634515897931\n",
      "Epoch: 3730 - time: 0.0031 - loss_train: 0.8054163609264705 - loss_val: 0.9691636749464084\n",
      "Epoch: 3731 - time: 0.0031 - loss_train: 0.8053988397520967 - loss_val: 0.9691638950539313\n",
      "Epoch: 3732 - time: 0.0031 - loss_train: 0.8053813278471493 - loss_val: 0.9691641119031397\n",
      "Epoch: 3733 - time: 0.0035 - loss_train: 0.8053638252023296 - loss_val: 0.9691643254848468\n",
      "Epoch: 3734 - time: 0.0040 - loss_train: 0.8053463318083484 - loss_val: 0.9691645357898994\n",
      "Epoch: 3735 - time: 0.0042 - loss_train: 0.8053288476559269 - loss_val: 0.969164742809171\n",
      "Epoch: 3736 - time: 0.0032 - loss_train: 0.805311372735795 - loss_val: 0.9691649465335704\n",
      "Epoch: 3737 - time: 0.0031 - loss_train: 0.8052939070386926 - loss_val: 0.9691651469540379\n",
      "Epoch: 3738 - time: 0.0031 - loss_train: 0.8052764505553687 - loss_val: 0.9691653440615446\n",
      "Epoch: 3739 - time: 0.0031 - loss_train: 0.805259003276582 - loss_val: 0.9691655378470935\n",
      "Epoch: 3740 - time: 0.0031 - loss_train: 0.805241565193102 - loss_val: 0.9691657283017199\n",
      "Epoch: 3741 - time: 0.0031 - loss_train: 0.8052241362957059 - loss_val: 0.9691659154164899\n",
      "Epoch: 3742 - time: 0.0032 - loss_train: 0.8052067165751812 - loss_val: 0.969166099182502\n",
      "Epoch: 3743 - time: 0.0031 - loss_train: 0.8051893060223256 - loss_val: 0.9691662795908846\n",
      "Epoch: 3744 - time: 0.0031 - loss_train: 0.8051719046279456 - loss_val: 0.9691664566328007\n",
      "Epoch: 3745 - time: 0.0031 - loss_train: 0.8051545123828571 - loss_val: 0.969166630299441\n",
      "Epoch: 3746 - time: 0.0031 - loss_train: 0.805137129277887 - loss_val: 0.9691668005820306\n",
      "Epoch: 3747 - time: 0.0031 - loss_train: 0.8051197553038699 - loss_val: 0.9691669674718242\n",
      "Epoch: 3748 - time: 0.0031 - loss_train: 0.8051023904516517 - loss_val: 0.9691671309601089\n",
      "Epoch: 3749 - time: 0.0031 - loss_train: 0.8050850347120869 - loss_val: 0.9691672910382017\n",
      "Epoch: 3750 - time: 0.0031 - loss_train: 0.8050676880760393 - loss_val: 0.9691674476974523\n",
      "Epoch: 3751 - time: 0.0031 - loss_train: 0.8050503505343831 - loss_val: 0.9691676009292408\n",
      "Epoch: 3752 - time: 0.0031 - loss_train: 0.8050330220780018 - loss_val: 0.9691677507249792\n",
      "Epoch: 3753 - time: 0.0031 - loss_train: 0.8050157026977888 - loss_val: 0.9691678970761093\n",
      "Epoch: 3754 - time: 0.0031 - loss_train: 0.8049983923846467 - loss_val: 0.9691680399741048\n",
      "Epoch: 3755 - time: 0.0031 - loss_train: 0.8049810911294875 - loss_val: 0.9691681794104717\n",
      "Epoch: 3756 - time: 0.0031 - loss_train: 0.8049637989232334 - loss_val: 0.9691683153767442\n",
      "Epoch: 3757 - time: 0.0031 - loss_train: 0.8049465157568161 - loss_val: 0.9691684478644889\n",
      "Epoch: 3758 - time: 0.0031 - loss_train: 0.8049292416211764 - loss_val: 0.9691685768653044\n",
      "Epoch: 3759 - time: 0.0031 - loss_train: 0.8049119765072655 - loss_val: 0.9691687023708175\n",
      "Epoch: 3760 - time: 0.0031 - loss_train: 0.8048947204060435 - loss_val: 0.9691688243726887\n",
      "Epoch: 3761 - time: 0.0031 - loss_train: 0.8048774733084808 - loss_val: 0.9691689428626078\n",
      "Epoch: 3762 - time: 0.0031 - loss_train: 0.8048602352055564 - loss_val: 0.9691690578322946\n",
      "Epoch: 3763 - time: 0.0031 - loss_train: 0.8048430060882604 - loss_val: 0.9691691692735017\n",
      "Epoch: 3764 - time: 0.0031 - loss_train: 0.8048257859475911 - loss_val: 0.9691692771780102\n",
      "Epoch: 3765 - time: 0.0031 - loss_train: 0.8048085747745578 - loss_val: 0.9691693815376331\n",
      "Epoch: 3766 - time: 0.0031 - loss_train: 0.8047913725601783 - loss_val: 0.9691694823442129\n",
      "Epoch: 3767 - time: 0.0031 - loss_train: 0.80477417929548 - loss_val: 0.9691695795896249\n",
      "Epoch: 3768 - time: 0.0031 - loss_train: 0.804756994971501 - loss_val: 0.969169673265772\n",
      "Epoch: 3769 - time: 0.0031 - loss_train: 0.804739819579288 - loss_val: 0.9691697633645886\n",
      "Epoch: 3770 - time: 0.0031 - loss_train: 0.8047226531098979 - loss_val: 0.9691698498780409\n",
      "Epoch: 3771 - time: 0.0033 - loss_train: 0.8047054955543972 - loss_val: 0.9691699327981228\n",
      "Epoch: 3772 - time: 0.0031 - loss_train: 0.8046883469038625 - loss_val: 0.9691700121168617\n",
      "Epoch: 3773 - time: 0.0031 - loss_train: 0.8046712071493785 - loss_val: 0.9691700878263114\n",
      "Epoch: 3774 - time: 0.0031 - loss_train: 0.8046540762820412 - loss_val: 0.9691701599185596\n",
      "Epoch: 3775 - time: 0.0031 - loss_train: 0.8046369542929552 - loss_val: 0.9691702283857222\n",
      "Epoch: 3776 - time: 0.0031 - loss_train: 0.8046198411732355 - loss_val: 0.9691702932199442\n",
      "Epoch: 3777 - time: 0.0031 - loss_train: 0.8046027369140067 - loss_val: 0.9691703544134043\n",
      "Epoch: 3778 - time: 0.0031 - loss_train: 0.8045856415064022 - loss_val: 0.9691704119583084\n",
      "Epoch: 3779 - time: 0.0031 - loss_train: 0.8045685549415658 - loss_val: 0.9691704658468918\n",
      "Epoch: 3780 - time: 0.0031 - loss_train: 0.8045514772106511 - loss_val: 0.9691705160714236\n",
      "Epoch: 3781 - time: 0.0031 - loss_train: 0.8045344083048213 - loss_val: 0.9691705626241969\n",
      "Epoch: 3782 - time: 0.0031 - loss_train: 0.8045173482152481 - loss_val: 0.9691706054975396\n",
      "Epoch: 3783 - time: 0.0031 - loss_train: 0.8045002969331151 - loss_val: 0.9691706446838082\n",
      "Epoch: 3784 - time: 0.0031 - loss_train: 0.804483254449613 - loss_val: 0.9691706801753879\n",
      "Epoch: 3785 - time: 0.0031 - loss_train: 0.8044662207559443 - loss_val: 0.9691707119646937\n",
      "Epoch: 3786 - time: 0.0031 - loss_train: 0.8044491958433201 - loss_val: 0.9691707400441721\n",
      "Epoch: 3787 - time: 0.0031 - loss_train: 0.8044321797029613 - loss_val: 0.9691707644062973\n",
      "Epoch: 3788 - time: 0.0031 - loss_train: 0.8044151723260987 - loss_val: 0.9691707850435741\n",
      "Epoch: 3789 - time: 0.0031 - loss_train: 0.804398173703973 - loss_val: 0.9691708019485372\n",
      "Epoch: 3790 - time: 0.0031 - loss_train: 0.804381183827834 - loss_val: 0.9691708151137477\n",
      "Epoch: 3791 - time: 0.0031 - loss_train: 0.8043642026889413 - loss_val: 0.9691708245318025\n",
      "Epoch: 3792 - time: 0.0031 - loss_train: 0.8043472302785645 - loss_val: 0.9691708301953197\n",
      "Epoch: 3793 - time: 0.0031 - loss_train: 0.8043302665879825 - loss_val: 0.9691708320969543\n",
      "Epoch: 3794 - time: 0.0031 - loss_train: 0.8043133116084846 - loss_val: 0.9691708302293862\n",
      "Epoch: 3795 - time: 0.0031 - loss_train: 0.8042963653313686 - loss_val: 0.9691708245853268\n",
      "Epoch: 3796 - time: 0.0031 - loss_train: 0.8042794277479429 - loss_val: 0.9691708151575131\n",
      "Epoch: 3797 - time: 0.0031 - loss_train: 0.8042624988495256 - loss_val: 0.9691708019387182\n",
      "Epoch: 3798 - time: 0.0031 - loss_train: 0.8042455786274442 - loss_val: 0.9691707849217371\n",
      "Epoch: 3799 - time: 0.0031 - loss_train: 0.8042286670730356 - loss_val: 0.9691707640993977\n",
      "Epoch: 3800 - time: 0.0031 - loss_train: 0.8042117641776473 - loss_val: 0.9691707394645559\n",
      "Epoch: 3801 - time: 0.0031 - loss_train: 0.8041948699326353 - loss_val: 0.9691707110100976\n",
      "Epoch: 3802 - time: 0.0031 - loss_train: 0.8041779843293666 - loss_val: 0.9691706787289366\n",
      "Epoch: 3803 - time: 0.0031 - loss_train: 0.8041611073592168 - loss_val: 0.969170642614016\n",
      "Epoch: 3804 - time: 0.0031 - loss_train: 0.8041442390135716 - loss_val: 0.9691706026583078\n",
      "Epoch: 3805 - time: 0.0032 - loss_train: 0.8041273792838264 - loss_val: 0.9691705588548134\n",
      "Epoch: 3806 - time: 0.0031 - loss_train: 0.8041105281613868 - loss_val: 0.969170511196562\n",
      "Epoch: 3807 - time: 0.0031 - loss_train: 0.804093685637667 - loss_val: 0.9691704596766118\n",
      "Epoch: 3808 - time: 0.0031 - loss_train: 0.804076851704092 - loss_val: 0.96917040428805\n",
      "Epoch: 3809 - time: 0.0032 - loss_train: 0.8040600263520955 - loss_val: 0.9691703450239927\n",
      "Epoch: 3810 - time: 0.0031 - loss_train: 0.8040432095731223 - loss_val: 0.9691702818775837\n",
      "Epoch: 3811 - time: 0.0031 - loss_train: 0.8040264013586252 - loss_val: 0.9691702148419957\n",
      "Epoch: 3812 - time: 0.0031 - loss_train: 0.8040096017000681 - loss_val: 0.9691701439104309\n",
      "Epoch: 3813 - time: 0.0031 - loss_train: 0.803992810588924 - loss_val: 0.9691700690761195\n",
      "Epoch: 3814 - time: 0.0031 - loss_train: 0.8039760280166752 - loss_val: 0.969169990332319\n",
      "Epoch: 3815 - time: 0.0031 - loss_train: 0.8039592539748148 - loss_val: 0.9691699076723169\n",
      "Epoch: 3816 - time: 0.0031 - loss_train: 0.8039424884548446 - loss_val: 0.9691698210894272\n",
      "Epoch: 3817 - time: 0.0031 - loss_train: 0.8039257314482764 - loss_val: 0.9691697305769942\n",
      "Epoch: 3818 - time: 0.0031 - loss_train: 0.8039089829466324 - loss_val: 0.9691696361283892\n",
      "Epoch: 3819 - time: 0.0031 - loss_train: 0.8038922429414433 - loss_val: 0.9691695377370119\n",
      "Epoch: 3820 - time: 0.0031 - loss_train: 0.8038755114242505 - loss_val: 0.9691694353962905\n",
      "Epoch: 3821 - time: 0.0031 - loss_train: 0.8038587883866044 - loss_val: 0.9691693290996803\n",
      "Epoch: 3822 - time: 0.0031 - loss_train: 0.8038420738200659 - loss_val: 0.9691692188406671\n",
      "Epoch: 3823 - time: 0.0031 - loss_train: 0.8038253677162048 - loss_val: 0.9691691046127613\n",
      "Epoch: 3824 - time: 0.0031 - loss_train: 0.8038086700666014 - loss_val: 0.9691689864095048\n",
      "Epoch: 3825 - time: 0.0031 - loss_train: 0.8037919808628449 - loss_val: 0.9691688642244639\n",
      "Epoch: 3826 - time: 0.0031 - loss_train: 0.8037753000965352 - loss_val: 0.9691687380512366\n",
      "Epoch: 3827 - time: 0.0031 - loss_train: 0.8037586277592802 - loss_val: 0.9691686078834444\n",
      "Epoch: 3828 - time: 0.0031 - loss_train: 0.8037419638427002 - loss_val: 0.9691684737147405\n",
      "Epoch: 3829 - time: 0.0031 - loss_train: 0.803725308338422 - loss_val: 0.9691683355388035\n",
      "Epoch: 3830 - time: 0.0031 - loss_train: 0.8037086612380856 - loss_val: 0.9691681933493403\n",
      "Epoch: 3831 - time: 0.0031 - loss_train: 0.8036920225333372 - loss_val: 0.9691680471400872\n",
      "Epoch: 3832 - time: 0.0031 - loss_train: 0.8036753922158356 - loss_val: 0.9691678969048049\n",
      "Epoch: 3833 - time: 0.0031 - loss_train: 0.8036587702772476 - loss_val: 0.9691677426372832\n",
      "Epoch: 3834 - time: 0.0031 - loss_train: 0.8036421567092505 - loss_val: 0.9691675843313395\n",
      "Epoch: 3835 - time: 0.0031 - loss_train: 0.8036255515035309 - loss_val: 0.9691674219808205\n",
      "Epoch: 3836 - time: 0.0031 - loss_train: 0.8036089546517855 - loss_val: 0.9691672555795966\n",
      "Epoch: 3837 - time: 0.0031 - loss_train: 0.8035923661457207 - loss_val: 0.969167085121568\n",
      "Epoch: 3838 - time: 0.0031 - loss_train: 0.8035757859770518 - loss_val: 0.9691669106006611\n",
      "Epoch: 3839 - time: 0.0031 - loss_train: 0.803559214137505 - loss_val: 0.9691667320108309\n",
      "Epoch: 3840 - time: 0.0031 - loss_train: 0.8035426506188152 - loss_val: 0.9691665493460593\n",
      "Epoch: 3841 - time: 0.0031 - loss_train: 0.8035260954127285 - loss_val: 0.9691663626003542\n",
      "Epoch: 3842 - time: 0.0032 - loss_train: 0.8035095485109985 - loss_val: 0.969166171767752\n",
      "Epoch: 3843 - time: 0.0032 - loss_train: 0.8034930099053909 - loss_val: 0.9691659768423153\n",
      "Epoch: 3844 - time: 0.0031 - loss_train: 0.8034764795876788 - loss_val: 0.9691657778181343\n",
      "Epoch: 3845 - time: 0.0031 - loss_train: 0.8034599575496468 - loss_val: 0.9691655746893263\n",
      "Epoch: 3846 - time: 0.0034 - loss_train: 0.8034434437830891 - loss_val: 0.9691653674500347\n",
      "Epoch: 3847 - time: 0.0032 - loss_train: 0.8034269382798078 - loss_val: 0.969165156094431\n",
      "Epoch: 3848 - time: 0.0031 - loss_train: 0.8034104410316172 - loss_val: 0.9691649406167128\n",
      "Epoch: 3849 - time: 0.0031 - loss_train: 0.8033939520303398 - loss_val: 0.9691647210111052\n",
      "Epoch: 3850 - time: 0.0032 - loss_train: 0.803377471267808 - loss_val: 0.9691644972718588\n",
      "Epoch: 3851 - time: 0.0031 - loss_train: 0.8033609987358645 - loss_val: 0.9691642693932524\n",
      "Epoch: 3852 - time: 0.0031 - loss_train: 0.8033445344263608 - loss_val: 0.9691640373695907\n",
      "Epoch: 3853 - time: 0.0031 - loss_train: 0.803328078331159 - loss_val: 0.9691638011952048\n",
      "Epoch: 3854 - time: 0.0031 - loss_train: 0.8033116304421306 - loss_val: 0.9691635608644529\n",
      "Epoch: 3855 - time: 0.0031 - loss_train: 0.8032951907511565 - loss_val: 0.9691633163717204\n",
      "Epoch: 3856 - time: 0.0031 - loss_train: 0.8032787592501277 - loss_val: 0.9691630677114179\n",
      "Epoch: 3857 - time: 0.0031 - loss_train: 0.8032623359309446 - loss_val: 0.9691628148779831\n",
      "Epoch: 3858 - time: 0.0031 - loss_train: 0.8032459207855182 - loss_val: 0.96916255786588\n",
      "Epoch: 3859 - time: 0.0031 - loss_train: 0.8032295138057676 - loss_val: 0.9691622966695989\n",
      "Epoch: 3860 - time: 0.0031 - loss_train: 0.8032131149836234 - loss_val: 0.969162031283657\n",
      "Epoch: 3861 - time: 0.0031 - loss_train: 0.8031967243110242 - loss_val: 0.969161761702597\n",
      "Epoch: 3862 - time: 0.0031 - loss_train: 0.8031803417799203 - loss_val: 0.9691614879209877\n",
      "Epoch: 3863 - time: 0.0031 - loss_train: 0.8031639673822697 - loss_val: 0.9691612099334249\n",
      "Epoch: 3864 - time: 0.0031 - loss_train: 0.803147601110041 - loss_val: 0.9691609277345302\n",
      "Epoch: 3865 - time: 0.0031 - loss_train: 0.8031312429552129 - loss_val: 0.9691606413189513\n",
      "Epoch: 3866 - time: 0.0031 - loss_train: 0.8031148929097734 - loss_val: 0.9691603506813621\n",
      "Epoch: 3867 - time: 0.0031 - loss_train: 0.80309855096572 - loss_val: 0.9691600558164619\n",
      "Epoch: 3868 - time: 0.0031 - loss_train: 0.8030822171150606 - loss_val: 0.9691597567189765\n",
      "Epoch: 3869 - time: 0.0031 - loss_train: 0.8030658913498123 - loss_val: 0.9691594533836576\n",
      "Epoch: 3870 - time: 0.0031 - loss_train: 0.8030495736620009 - loss_val: 0.9691591458052827\n",
      "Epoch: 3871 - time: 0.0031 - loss_train: 0.8030332640436646 - loss_val: 0.9691588339786544\n",
      "Epoch: 3872 - time: 0.0031 - loss_train: 0.8030169624868484 - loss_val: 0.969158517898603\n",
      "Epoch: 3873 - time: 0.0031 - loss_train: 0.8030006689836087 - loss_val: 0.9691581975599824\n",
      "Epoch: 3874 - time: 0.0031 - loss_train: 0.8029843835260116 - loss_val: 0.9691578729576728\n",
      "Epoch: 3875 - time: 0.0031 - loss_train: 0.8029681061061323 - loss_val: 0.9691575440865802\n",
      "Epoch: 3876 - time: 0.0031 - loss_train: 0.8029518367160557 - loss_val: 0.9691572109416378\n",
      "Epoch: 3877 - time: 0.0031 - loss_train: 0.802935575347877 - loss_val: 0.9691568735178003\n",
      "Epoch: 3878 - time: 0.0031 - loss_train: 0.8029193219936998 - loss_val: 0.9691565318100522\n",
      "Epoch: 3879 - time: 0.0031 - loss_train: 0.802903076645639 - loss_val: 0.9691561858134018\n",
      "Epoch: 3880 - time: 0.0031 - loss_train: 0.8028868392958189 - loss_val: 0.969155835522882\n",
      "Epoch: 3881 - time: 0.0031 - loss_train: 0.8028706099363722 - loss_val: 0.9691554809335522\n",
      "Epoch: 3882 - time: 0.0032 - loss_train: 0.8028543885594429 - loss_val: 0.9691551220404956\n",
      "Epoch: 3883 - time: 0.0031 - loss_train: 0.8028381751571835 - loss_val: 0.9691547588388216\n",
      "Epoch: 3884 - time: 0.0035 - loss_train: 0.8028219697217571 - loss_val: 0.9691543913236672\n",
      "Epoch: 3885 - time: 0.0032 - loss_train: 0.8028057722453359 - loss_val: 0.9691540194901898\n",
      "Epoch: 3886 - time: 0.0031 - loss_train: 0.802789582720102 - loss_val: 0.9691536433335763\n",
      "Epoch: 3887 - time: 0.0031 - loss_train: 0.8027734011382475 - loss_val: 0.9691532628490351\n",
      "Epoch: 3888 - time: 0.0031 - loss_train: 0.8027572274919733 - loss_val: 0.9691528780318028\n",
      "Epoch: 3889 - time: 0.0031 - loss_train: 0.8027410617734907 - loss_val: 0.9691524888771391\n",
      "Epoch: 3890 - time: 0.0031 - loss_train: 0.8027249039750208 - loss_val: 0.9691520953803283\n",
      "Epoch: 3891 - time: 0.0031 - loss_train: 0.8027087540887939 - loss_val: 0.9691516975366817\n",
      "Epoch: 3892 - time: 0.0031 - loss_train: 0.8026926121070503 - loss_val: 0.9691512953415335\n",
      "Epoch: 3893 - time: 0.0031 - loss_train: 0.8026764780220397 - loss_val: 0.9691508887902432\n",
      "Epoch: 3894 - time: 0.0031 - loss_train: 0.8026603518260221 - loss_val: 0.9691504778781955\n",
      "Epoch: 3895 - time: 0.0031 - loss_train: 0.8026442335112666 - loss_val: 0.9691500626007994\n",
      "Epoch: 3896 - time: 0.0031 - loss_train: 0.8026281230700519 - loss_val: 0.969149642953489\n",
      "Epoch: 3897 - time: 0.0031 - loss_train: 0.8026120204946671 - loss_val: 0.9691492189317228\n",
      "Epoch: 3898 - time: 0.0032 - loss_train: 0.8025959257774095 - loss_val: 0.9691487905309848\n",
      "Epoch: 3899 - time: 0.0031 - loss_train: 0.8025798389105883 - loss_val: 0.9691483577467807\n",
      "Epoch: 3900 - time: 0.0031 - loss_train: 0.8025637598865202 - loss_val: 0.9691479205746434\n",
      "Epoch: 3901 - time: 0.0031 - loss_train: 0.8025476886975332 - loss_val: 0.9691474790101294\n",
      "Epoch: 3902 - time: 0.0031 - loss_train: 0.8025316253359638 - loss_val: 0.9691470330488209\n",
      "Epoch: 3903 - time: 0.0031 - loss_train: 0.8025155697941585 - loss_val: 0.9691465826863209\n",
      "Epoch: 3904 - time: 0.0031 - loss_train: 0.8024995220644743 - loss_val: 0.9691461279182605\n",
      "Epoch: 3905 - time: 0.0031 - loss_train: 0.8024834821392764 - loss_val: 0.9691456687402927\n",
      "Epoch: 3906 - time: 0.0031 - loss_train: 0.8024674500109413 - loss_val: 0.9691452051480981\n",
      "Epoch: 3907 - time: 0.0031 - loss_train: 0.8024514256718535 - loss_val: 0.9691447371373756\n",
      "Epoch: 3908 - time: 0.0031 - loss_train: 0.8024354091144084 - loss_val: 0.9691442647038538\n",
      "Epoch: 3909 - time: 0.0031 - loss_train: 0.8024194003310104 - loss_val: 0.9691437878432826\n",
      "Epoch: 3910 - time: 0.0031 - loss_train: 0.802403399314074 - loss_val: 0.9691433065514359\n",
      "Epoch: 3911 - time: 0.0031 - loss_train: 0.8023874060560231 - loss_val: 0.969142820824114\n",
      "Epoch: 3912 - time: 0.0031 - loss_train: 0.8023714205492907 - loss_val: 0.9691423306571376\n",
      "Epoch: 3913 - time: 0.0031 - loss_train: 0.802355442786321 - loss_val: 0.9691418360463543\n",
      "Epoch: 3914 - time: 0.0031 - loss_train: 0.8023394727595662 - loss_val: 0.9691413369876335\n",
      "Epoch: 3915 - time: 0.0031 - loss_train: 0.8023235104614888 - loss_val: 0.9691408334768699\n",
      "Epoch: 3916 - time: 0.0031 - loss_train: 0.8023075558845614 - loss_val: 0.9691403255099817\n",
      "Epoch: 3917 - time: 0.0031 - loss_train: 0.8022916090212654 - loss_val: 0.9691398130829095\n",
      "Epoch: 3918 - time: 0.0031 - loss_train: 0.8022756698640923 - loss_val: 0.9691392961916189\n",
      "Epoch: 3919 - time: 0.0031 - loss_train: 0.8022597384055437 - loss_val: 0.9691387748320988\n",
      "Epoch: 3920 - time: 0.0031 - loss_train: 0.8022438146381297 - loss_val: 0.9691382490003628\n",
      "Epoch: 3921 - time: 0.0031 - loss_train: 0.8022278985543704 - loss_val: 0.9691377186924458\n",
      "Epoch: 3922 - time: 0.0034 - loss_train: 0.8022119901467968 - loss_val: 0.9691371839044073\n",
      "Epoch: 3923 - time: 0.0032 - loss_train: 0.802196089407948 - loss_val: 0.9691366446323311\n",
      "Epoch: 3924 - time: 0.0032 - loss_train: 0.8021801963303726 - loss_val: 0.9691361008723232\n",
      "Epoch: 3925 - time: 0.0035 - loss_train: 0.8021643109066311 - loss_val: 0.9691355526205139\n",
      "Epoch: 3926 - time: 0.0032 - loss_train: 0.80214843312929 - loss_val: 0.9691349998730547\n",
      "Epoch: 3927 - time: 0.0042 - loss_train: 0.8021325629909284 - loss_val: 0.9691344426261244\n",
      "Epoch: 3928 - time: 0.0044 - loss_train: 0.8021167004841342 - loss_val: 0.9691338808759208\n",
      "Epoch: 3929 - time: 0.0044 - loss_train: 0.8021008456015045 - loss_val: 0.9691333146186679\n",
      "Epoch: 3930 - time: 0.0044 - loss_train: 0.8020849983356463 - loss_val: 0.9691327438506111\n",
      "Epoch: 3931 - time: 0.0045 - loss_train: 0.8020691586791758 - loss_val: 0.9691321685680198\n",
      "Epoch: 3932 - time: 0.0044 - loss_train: 0.8020533266247198 - loss_val: 0.9691315887671864\n",
      "Epoch: 3933 - time: 0.0043 - loss_train: 0.8020375021649138 - loss_val: 0.9691310044444249\n",
      "Epoch: 3934 - time: 0.0036 - loss_train: 0.8020216852924027 - loss_val: 0.9691304155960743\n",
      "Epoch: 3935 - time: 0.0036 - loss_train: 0.8020058759998424 - loss_val: 0.9691298222184964\n",
      "Epoch: 3936 - time: 0.0036 - loss_train: 0.8019900742798968 - loss_val: 0.9691292243080738\n",
      "Epoch: 3937 - time: 0.0036 - loss_train: 0.8019742801252399 - loss_val: 0.9691286218612144\n",
      "Epoch: 3938 - time: 0.0036 - loss_train: 0.8019584935285563 - loss_val: 0.9691280148743476\n",
      "Epoch: 3939 - time: 0.0036 - loss_train: 0.8019427144825387 - loss_val: 0.9691274033439249\n",
      "Epoch: 3940 - time: 0.0039 - loss_train: 0.8019269429798901 - loss_val: 0.9691267872664221\n",
      "Epoch: 3941 - time: 0.0039 - loss_train: 0.8019111790133231 - loss_val: 0.9691261666383362\n",
      "Epoch: 3942 - time: 0.0039 - loss_train: 0.80189542257556 - loss_val: 0.9691255414561887\n",
      "Epoch: 3943 - time: 0.0039 - loss_train: 0.8018796736593322 - loss_val: 0.969124911716522\n",
      "Epoch: 3944 - time: 0.0039 - loss_train: 0.8018639322573815 - loss_val: 0.9691242774159018\n",
      "Epoch: 3945 - time: 0.0039 - loss_train: 0.8018481983624575 - loss_val: 0.9691236385509147\n",
      "Epoch: 3946 - time: 0.0038 - loss_train: 0.8018324719673222 - loss_val: 0.9691229951181731\n",
      "Epoch: 3947 - time: 0.0038 - loss_train: 0.8018167530647449 - loss_val: 0.9691223471143079\n",
      "Epoch: 3948 - time: 0.0038 - loss_train: 0.8018010416475048 - loss_val: 0.9691216945359752\n",
      "Epoch: 3949 - time: 0.0046 - loss_train: 0.8017853377083911 - loss_val: 0.9691210373798524\n",
      "Epoch: 3950 - time: 0.0045 - loss_train: 0.8017696412402029 - loss_val: 0.9691203756426389\n",
      "Epoch: 3951 - time: 0.0045 - loss_train: 0.8017539522357481 - loss_val: 0.9691197093210578\n",
      "Epoch: 3952 - time: 0.0045 - loss_train: 0.801738270687845 - loss_val: 0.9691190384118509\n",
      "Epoch: 3953 - time: 0.0046 - loss_train: 0.8017225965893198 - loss_val: 0.9691183629117868\n",
      "Epoch: 3954 - time: 0.0045 - loss_train: 0.8017069299330106 - loss_val: 0.9691176828176531\n",
      "Epoch: 3955 - time: 0.0046 - loss_train: 0.8016912707117632 - loss_val: 0.9691169981262592\n",
      "Epoch: 3956 - time: 0.0046 - loss_train: 0.8016756189184335 - loss_val: 0.9691163088344383\n",
      "Epoch: 3957 - time: 0.0045 - loss_train: 0.801659974545887 - loss_val: 0.9691156149390454\n",
      "Epoch: 3958 - time: 0.0045 - loss_train: 0.8016443375869993 - loss_val: 0.969114916436956\n",
      "Epoch: 3959 - time: 0.0045 - loss_train: 0.8016287080346545 - loss_val: 0.9691142133250689\n",
      "Epoch: 3960 - time: 0.0032 - loss_train: 0.8016130858817471 - loss_val: 0.9691135056003032\n",
      "Epoch: 3961 - time: 0.0031 - loss_train: 0.8015974711211802 - loss_val: 0.9691127932596021\n",
      "Epoch: 3962 - time: 0.0031 - loss_train: 0.8015818637458667 - loss_val: 0.9691120762999279\n",
      "Epoch: 3963 - time: 0.0031 - loss_train: 0.8015662637487306 - loss_val: 0.9691113547182656\n",
      "Epoch: 3964 - time: 0.0031 - loss_train: 0.8015506711227028 - loss_val: 0.9691106285116241\n",
      "Epoch: 3965 - time: 0.0031 - loss_train: 0.8015350858607259 - loss_val: 0.9691098976770294\n",
      "Epoch: 3966 - time: 0.0031 - loss_train: 0.8015195079557508 - loss_val: 0.9691091622115343\n",
      "Epoch: 3967 - time: 0.0031 - loss_train: 0.8015039374007379 - loss_val: 0.9691084221122078\n",
      "Epoch: 3968 - time: 0.0031 - loss_train: 0.8014883741886576 - loss_val: 0.9691076773761454\n",
      "Epoch: 3969 - time: 0.0031 - loss_train: 0.80147281831249 - loss_val: 0.9691069280004605\n",
      "Epoch: 3970 - time: 0.0031 - loss_train: 0.8014572697652238 - loss_val: 0.9691061739822893\n",
      "Epoch: 3971 - time: 0.0031 - loss_train: 0.8014417285398583 - loss_val: 0.9691054153187889\n",
      "Epoch: 3972 - time: 0.0031 - loss_train: 0.8014261946294011 - loss_val: 0.9691046520071387\n",
      "Epoch: 3973 - time: 0.0031 - loss_train: 0.8014106680268706 - loss_val: 0.9691038840445387\n",
      "Epoch: 3974 - time: 0.0044 - loss_train: 0.8013951487252932 - loss_val: 0.9691031114282097\n",
      "Epoch: 3975 - time: 0.0044 - loss_train: 0.8013796367177062 - loss_val: 0.969102334155394\n",
      "Epoch: 3976 - time: 0.0044 - loss_train: 0.8013641319971555 - loss_val: 0.9691015522233553\n",
      "Epoch: 3977 - time: 0.0038 - loss_train: 0.8013486345566969 - loss_val: 0.9691007656293786\n",
      "Epoch: 3978 - time: 0.0031 - loss_train: 0.8013331443893952 - loss_val: 0.9690999743707693\n",
      "Epoch: 3979 - time: 0.0032 - loss_train: 0.8013176614883253 - loss_val: 0.969099178444855\n",
      "Epoch: 3980 - time: 0.0032 - loss_train: 0.8013021858465709 - loss_val: 0.9690983778489827\n",
      "Epoch: 3981 - time: 0.0031 - loss_train: 0.8012867174572255 - loss_val: 0.969097572580522\n",
      "Epoch: 3982 - time: 0.0031 - loss_train: 0.8012712563133926 - loss_val: 0.9690967626368608\n",
      "Epoch: 3983 - time: 0.0031 - loss_train: 0.8012558024081838 - loss_val: 0.9690959480154113\n",
      "Epoch: 3984 - time: 0.0031 - loss_train: 0.8012403557347217 - loss_val: 0.969095128713604\n",
      "Epoch: 3985 - time: 0.0031 - loss_train: 0.8012249162861369 - loss_val: 0.9690943047288914\n",
      "Epoch: 3986 - time: 0.0034 - loss_train: 0.8012094840555706 - loss_val: 0.9690934760587457\n",
      "Epoch: 3987 - time: 0.0031 - loss_train: 0.801194059036173 - loss_val: 0.9690926427006613\n",
      "Epoch: 3988 - time: 0.0031 - loss_train: 0.801178641221103 - loss_val: 0.9690918046521513\n",
      "Epoch: 3989 - time: 0.0031 - loss_train: 0.8011632306035301 - loss_val: 0.9690909619107514\n",
      "Epoch: 3990 - time: 0.0031 - loss_train: 0.8011478271766331 - loss_val: 0.9690901144740167\n",
      "Epoch: 3991 - time: 0.0031 - loss_train: 0.8011324309335996 - loss_val: 0.9690892623395233\n",
      "Epoch: 3992 - time: 0.0031 - loss_train: 0.8011170418676267 - loss_val: 0.9690884055048674\n",
      "Epoch: 3993 - time: 0.0031 - loss_train: 0.801101659971921 - loss_val: 0.9690875439676643\n",
      "Epoch: 3994 - time: 0.0031 - loss_train: 0.8010862852396995 - loss_val: 0.9690866777255529\n",
      "Epoch: 3995 - time: 0.0031 - loss_train: 0.8010709176641865 - loss_val: 0.9690858067761913\n",
      "Epoch: 3996 - time: 0.0031 - loss_train: 0.8010555572386183 - loss_val: 0.9690849311172561\n",
      "Epoch: 3997 - time: 0.0031 - loss_train: 0.8010402039562377 - loss_val: 0.9690840507464454\n",
      "Epoch: 3998 - time: 0.0031 - loss_train: 0.8010248578102999 - loss_val: 0.9690831656614786\n",
      "Epoch: 3999 - time: 0.0031 - loss_train: 0.8010095187940672 - loss_val: 0.9690822758600934\n",
      "Epoch: 4000 - time: 0.0031 - loss_train: 0.8009941869008119 - loss_val: 0.9690813813400492\n",
      "Epoch: 4001 - time: 0.0031 - loss_train: 0.8009788621238167 - loss_val: 0.9690804820991251\n",
      "Epoch: 4002 - time: 0.0031 - loss_train: 0.8009635444563722 - loss_val: 0.9690795781351189\n",
      "Epoch: 4003 - time: 0.0045 - loss_train: 0.8009482338917792 - loss_val: 0.9690786694458502\n",
      "Epoch: 4004 - time: 0.0045 - loss_train: 0.8009329304233477 - loss_val: 0.9690777560291584\n",
      "Epoch: 4005 - time: 0.0044 - loss_train: 0.8009176340443973 - loss_val: 0.9690768378829011\n",
      "Epoch: 4006 - time: 0.0045 - loss_train: 0.8009023447482567 - loss_val: 0.9690759150049586\n",
      "Epoch: 4007 - time: 0.0044 - loss_train: 0.8008870625282637 - loss_val: 0.9690749873932287\n",
      "Epoch: 4008 - time: 0.0044 - loss_train: 0.8008717873777664 - loss_val: 0.9690740550456309\n",
      "Epoch: 4009 - time: 0.0045 - loss_train: 0.800856519290121 - loss_val: 0.9690731179601031\n",
      "Epoch: 4010 - time: 0.0044 - loss_train: 0.8008412582586935 - loss_val: 0.9690721761346033\n",
      "Epoch: 4011 - time: 0.0031 - loss_train: 0.80082600427686 - loss_val: 0.9690712295671082\n",
      "Epoch: 4012 - time: 0.0031 - loss_train: 0.800810757338005 - loss_val: 0.9690702782556169\n",
      "Epoch: 4013 - time: 0.0031 - loss_train: 0.800795517435523 - loss_val: 0.9690693221981456\n",
      "Epoch: 4014 - time: 0.0031 - loss_train: 0.8007802845628169 - loss_val: 0.9690683613927318\n",
      "Epoch: 4015 - time: 0.0031 - loss_train: 0.8007650587133001 - loss_val: 0.9690673958374302\n",
      "Epoch: 4016 - time: 0.0031 - loss_train: 0.8007498398803944 - loss_val: 0.9690664255303184\n",
      "Epoch: 4017 - time: 0.0031 - loss_train: 0.8007346280575314 - loss_val: 0.9690654504694908\n",
      "Epoch: 4018 - time: 0.0031 - loss_train: 0.8007194232381516 - loss_val: 0.9690644706530609\n",
      "Epoch: 4019 - time: 0.0031 - loss_train: 0.8007042254157059 - loss_val: 0.9690634860791645\n",
      "Epoch: 4020 - time: 0.0038 - loss_train: 0.8006890345836527 - loss_val: 0.9690624967459541\n",
      "Epoch: 4021 - time: 0.0032 - loss_train: 0.8006738507354609 - loss_val: 0.9690615026516032\n",
      "Epoch: 4022 - time: 0.0031 - loss_train: 0.8006586738646094 - loss_val: 0.9690605037943021\n",
      "Epoch: 4023 - time: 0.0031 - loss_train: 0.8006435039645841 - loss_val: 0.9690595001722635\n",
      "Epoch: 4024 - time: 0.0031 - loss_train: 0.8006283410288827 - loss_val: 0.9690584917837171\n",
      "Epoch: 4025 - time: 0.0031 - loss_train: 0.8006131850510098 - loss_val: 0.9690574786269128\n",
      "Epoch: 4026 - time: 0.0031 - loss_train: 0.8005980360244814 - loss_val: 0.9690564607001189\n",
      "Epoch: 4027 - time: 0.0031 - loss_train: 0.800582893942822 - loss_val: 0.9690554380016229\n",
      "Epoch: 4028 - time: 0.0031 - loss_train: 0.8005677587995647 - loss_val: 0.9690544105297332\n",
      "Epoch: 4029 - time: 0.0031 - loss_train: 0.8005526305882527 - loss_val: 0.9690533782827723\n",
      "Epoch: 4030 - time: 0.0031 - loss_train: 0.8005375093024377 - loss_val: 0.9690523412590882\n",
      "Epoch: 4031 - time: 0.0031 - loss_train: 0.8005223949356821 - loss_val: 0.9690512994570429\n",
      "Epoch: 4032 - time: 0.0031 - loss_train: 0.800507287481556 - loss_val: 0.9690502528750193\n",
      "Epoch: 4033 - time: 0.0031 - loss_train: 0.8004921869336388 - loss_val: 0.9690492015114185\n",
      "Epoch: 4034 - time: 0.0031 - loss_train: 0.8004770932855204 - loss_val: 0.9690481453646606\n",
      "Epoch: 4035 - time: 0.0031 - loss_train: 0.800462006530799 - loss_val: 0.9690470844331851\n",
      "Epoch: 4036 - time: 0.0031 - loss_train: 0.8004469266630819 - loss_val: 0.9690460187154492\n",
      "Epoch: 4037 - time: 0.0031 - loss_train: 0.8004318536759866 - loss_val: 0.9690449482099287\n",
      "Epoch: 4038 - time: 0.0031 - loss_train: 0.8004167875631383 - loss_val: 0.9690438729151192\n",
      "Epoch: 4039 - time: 0.0031 - loss_train: 0.8004017283181725 - loss_val: 0.9690427928295342\n",
      "Epoch: 4040 - time: 0.0031 - loss_train: 0.800386675934734 - loss_val: 0.9690417079517051\n",
      "Epoch: 4041 - time: 0.0031 - loss_train: 0.8003716304064766 - loss_val: 0.9690406182801844\n",
      "Epoch: 4042 - time: 0.0031 - loss_train: 0.8003565917270627 - loss_val: 0.9690395238135391\n",
      "Epoch: 4043 - time: 0.0031 - loss_train: 0.800341559890165 - loss_val: 0.969038424550358\n",
      "Epoch: 4044 - time: 0.0031 - loss_train: 0.8003265348894641 - loss_val: 0.9690373204892464\n",
      "Epoch: 4045 - time: 0.0031 - loss_train: 0.8003115167186509 - loss_val: 0.9690362116288297\n",
      "Epoch: 4046 - time: 0.0031 - loss_train: 0.8002965053714247 - loss_val: 0.9690350979677506\n",
      "Epoch: 4047 - time: 0.0031 - loss_train: 0.8002815008414944 - loss_val: 0.969033979504668\n",
      "Epoch: 4048 - time: 0.0031 - loss_train: 0.8002665031225783 - loss_val: 0.9690328562382633\n",
      "Epoch: 4049 - time: 0.0031 - loss_train: 0.8002515122084037 - loss_val: 0.9690317281672343\n",
      "Epoch: 4050 - time: 0.0031 - loss_train: 0.8002365280927062 - loss_val: 0.969030595290295\n",
      "Epoch: 4051 - time: 0.0031 - loss_train: 0.8002215507692318 - loss_val: 0.9690294576061803\n",
      "Epoch: 4052 - time: 0.0031 - loss_train: 0.8002065802317347 - loss_val: 0.9690283151136412\n",
      "Epoch: 4053 - time: 0.0031 - loss_train: 0.8001916164739792 - loss_val: 0.9690271678114498\n",
      "Epoch: 4054 - time: 0.0031 - loss_train: 0.8001766594897378 - loss_val: 0.9690260156983929\n",
      "Epoch: 4055 - time: 0.0031 - loss_train: 0.800161709272793 - loss_val: 0.9690248587732756\n",
      "Epoch: 4056 - time: 0.0031 - loss_train: 0.8001467658169351 - loss_val: 0.9690236970349231\n",
      "Epoch: 4057 - time: 0.0031 - loss_train: 0.8001318291159655 - loss_val: 0.9690225304821775\n",
      "Epoch: 4058 - time: 0.0035 - loss_train: 0.8001168991636926 - loss_val: 0.9690213591138976\n",
      "Epoch: 4059 - time: 0.0032 - loss_train: 0.800101975953936 - loss_val: 0.9690201829289623\n",
      "Epoch: 4060 - time: 0.0031 - loss_train: 0.8000870594805224 - loss_val: 0.9690190019262663\n",
      "Epoch: 4061 - time: 0.0031 - loss_train: 0.800072149737289 - loss_val: 0.9690178161047229\n",
      "Epoch: 4062 - time: 0.0031 - loss_train: 0.8000572467180819 - loss_val: 0.9690166254632635\n",
      "Epoch: 4063 - time: 0.0031 - loss_train: 0.8000423504167552 - loss_val: 0.9690154300008367\n",
      "Epoch: 4064 - time: 0.0031 - loss_train: 0.8000274608271737 - loss_val: 0.9690142297164085\n",
      "Epoch: 4065 - time: 0.0031 - loss_train: 0.8000125779432108 - loss_val: 0.9690130246089634\n",
      "Epoch: 4066 - time: 0.0031 - loss_train: 0.7999977017587477 - loss_val: 0.9690118146775026\n",
      "Epoch: 4067 - time: 0.0031 - loss_train: 0.7999828322676763 - loss_val: 0.9690105999210448\n",
      "Epoch: 4068 - time: 0.0031 - loss_train: 0.7999679694638971 - loss_val: 0.9690093803386278\n",
      "Epoch: 4069 - time: 0.0031 - loss_train: 0.7999531133413185 - loss_val: 0.9690081559293053\n",
      "Epoch: 4070 - time: 0.0031 - loss_train: 0.79993826389386 - loss_val: 0.9690069266921484\n",
      "Epoch: 4071 - time: 0.0031 - loss_train: 0.799923421115449 - loss_val: 0.9690056926262464\n",
      "Epoch: 4072 - time: 0.0031 - loss_train: 0.7999085850000219 - loss_val: 0.9690044537307051\n",
      "Epoch: 4073 - time: 0.0031 - loss_train: 0.799893755541524 - loss_val: 0.9690032100046494\n",
      "Epoch: 4074 - time: 0.0031 - loss_train: 0.7998789327339103 - loss_val: 0.9690019614472194\n",
      "Epoch: 4075 - time: 0.0031 - loss_train: 0.7998641165711444 - loss_val: 0.9690007080575725\n",
      "Epoch: 4076 - time: 0.0031 - loss_train: 0.7998493070471987 - loss_val: 0.9689994498348865\n",
      "Epoch: 4077 - time: 0.0031 - loss_train: 0.7998345041560557 - loss_val: 0.9689981867783529\n",
      "Epoch: 4078 - time: 0.0031 - loss_train: 0.7998197078917054 - loss_val: 0.9689969188871806\n",
      "Epoch: 4079 - time: 0.0044 - loss_train: 0.7998049182481475 - loss_val: 0.9689956461605969\n",
      "Epoch: 4080 - time: 0.0044 - loss_train: 0.799790135219391 - loss_val: 0.9689943685978472\n",
      "Epoch: 4081 - time: 0.0044 - loss_train: 0.7997753587994539 - loss_val: 0.9689930861981904\n",
      "Epoch: 4082 - time: 0.0044 - loss_train: 0.7997605889823624 - loss_val: 0.9689917989609055\n",
      "Epoch: 4083 - time: 0.0043 - loss_train: 0.7997458257621526 - loss_val: 0.9689905068852881\n",
      "Epoch: 4084 - time: 0.0038 - loss_train: 0.7997310691328685 - loss_val: 0.9689892099706496\n",
      "Epoch: 4085 - time: 0.0031 - loss_train: 0.7997163190885651 - loss_val: 0.9689879082163194\n",
      "Epoch: 4086 - time: 0.0031 - loss_train: 0.7997015756233035 - loss_val: 0.9689866016216423\n",
      "Epoch: 4087 - time: 0.0031 - loss_train: 0.7996868387311561 - loss_val: 0.9689852901859812\n",
      "Epoch: 4088 - time: 0.0031 - loss_train: 0.799672108406204 - loss_val: 0.9689839739087154\n",
      "Epoch: 4089 - time: 0.0031 - loss_train: 0.7996573846425358 - loss_val: 0.968982652789241\n",
      "Epoch: 4090 - time: 0.0032 - loss_train: 0.7996426674342503 - loss_val: 0.9689813268269718\n",
      "Epoch: 4091 - time: 0.0031 - loss_train: 0.7996279567754545 - loss_val: 0.9689799960213352\n",
      "Epoch: 4092 - time: 0.0031 - loss_train: 0.7996132526602655 - loss_val: 0.9689786603717796\n",
      "Epoch: 4093 - time: 0.0031 - loss_train: 0.799598555082808 - loss_val: 0.9689773198777667\n",
      "Epoch: 4094 - time: 0.0035 - loss_train: 0.7995838640372162 - loss_val: 0.9689759745387757\n",
      "Epoch: 4095 - time: 0.0032 - loss_train: 0.7995691795176335 - loss_val: 0.9689746243543036\n",
      "Epoch: 4096 - time: 0.0031 - loss_train: 0.7995545015182118 - loss_val: 0.9689732693238614\n",
      "Epoch: 4097 - time: 0.0031 - loss_train: 0.7995398300331119 - loss_val: 0.9689719094469794\n",
      "Epoch: 4098 - time: 0.0031 - loss_train: 0.7995251650565035 - loss_val: 0.9689705447232017\n",
      "Epoch: 4099 - time: 0.0031 - loss_train: 0.799510506582566 - loss_val: 0.9689691751520902\n",
      "Epoch: 4100 - time: 0.0031 - loss_train: 0.7994958546054862 - loss_val: 0.9689678007332242\n",
      "Epoch: 4101 - time: 0.0031 - loss_train: 0.7994812091194611 - loss_val: 0.9689664214661973\n",
      "Epoch: 4102 - time: 0.0031 - loss_train: 0.7994665701186953 - loss_val: 0.9689650373506201\n",
      "Epoch: 4103 - time: 0.0031 - loss_train: 0.799451937597404 - loss_val: 0.9689636483861206\n",
      "Epoch: 4104 - time: 0.0031 - loss_train: 0.7994373115498099 - loss_val: 0.9689622545723413\n",
      "Epoch: 4105 - time: 0.0031 - loss_train: 0.799422691970145 - loss_val: 0.9689608559089413\n",
      "Epoch: 4106 - time: 0.0031 - loss_train: 0.7994080788526496 - loss_val: 0.9689594523955981\n",
      "Epoch: 4107 - time: 0.0031 - loss_train: 0.7993934721915745 - loss_val: 0.9689580440320009\n",
      "Epoch: 4108 - time: 0.0031 - loss_train: 0.7993788719811771 - loss_val: 0.9689566308178595\n",
      "Epoch: 4109 - time: 0.0031 - loss_train: 0.7993642782157253 - loss_val: 0.9689552127528972\n",
      "Epoch: 4110 - time: 0.0031 - loss_train: 0.7993496908894955 - loss_val: 0.9689537898368547\n",
      "Epoch: 4111 - time: 0.0031 - loss_train: 0.7993351099967718 - loss_val: 0.968952362069487\n",
      "Epoch: 4112 - time: 0.0031 - loss_train: 0.7993205355318489 - loss_val: 0.9689509294505664\n",
      "Epoch: 4113 - time: 0.0031 - loss_train: 0.7993059674890287 - loss_val: 0.968949491979881\n",
      "Epoch: 4114 - time: 0.0031 - loss_train: 0.7992914058626231 - loss_val: 0.9689480496572341\n",
      "Epoch: 4115 - time: 0.0031 - loss_train: 0.7992768506469521 - loss_val: 0.9689466024824458\n",
      "Epoch: 4116 - time: 0.0031 - loss_train: 0.799262301836345 - loss_val: 0.9689451504553516\n",
      "Epoch: 4117 - time: 0.0031 - loss_train: 0.7992477594251391 - loss_val: 0.9689436935758032\n",
      "Epoch: 4118 - time: 0.0031 - loss_train: 0.7992332234076813 - loss_val: 0.9689422318436657\n",
      "Epoch: 4119 - time: 0.0031 - loss_train: 0.7992186937783271 - loss_val: 0.9689407652588238\n",
      "Epoch: 4120 - time: 0.0031 - loss_train: 0.7992041705314404 - loss_val: 0.9689392938211759\n",
      "Epoch: 4121 - time: 0.0031 - loss_train: 0.799189653661394 - loss_val: 0.9689378175306357\n",
      "Epoch: 4122 - time: 0.0031 - loss_train: 0.7991751431625694 - loss_val: 0.9689363363871318\n",
      "Epoch: 4123 - time: 0.0031 - loss_train: 0.799160639029358 - loss_val: 0.9689348503906118\n",
      "Epoch: 4124 - time: 0.0031 - loss_train: 0.7991461412561576 - loss_val: 0.9689333595410355\n",
      "Epoch: 4125 - time: 0.0031 - loss_train: 0.7991316498373766 - loss_val: 0.9689318638383784\n",
      "Epoch: 4126 - time: 0.0031 - loss_train: 0.799117164767432 - loss_val: 0.9689303632826345\n",
      "Epoch: 4127 - time: 0.0031 - loss_train: 0.7991026860407481 - loss_val: 0.9689288578738087\n",
      "Epoch: 4128 - time: 0.0031 - loss_train: 0.7990882136517604 - loss_val: 0.9689273476119257\n",
      "Epoch: 4129 - time: 0.0031 - loss_train: 0.7990737475949105 - loss_val: 0.968925832497023\n",
      "Epoch: 4130 - time: 0.0031 - loss_train: 0.7990592878646499 - loss_val: 0.9689243125291543\n",
      "Epoch: 4131 - time: 0.0031 - loss_train: 0.7990448344554393 - loss_val: 0.968922787708389\n",
      "Epoch: 4132 - time: 0.0031 - loss_train: 0.7990303873617475 - loss_val: 0.9689212580348106\n",
      "Epoch: 4133 - time: 0.0032 - loss_train: 0.7990159465780516 - loss_val: 0.9689197235085193\n",
      "Epoch: 4134 - time: 0.0031 - loss_train: 0.7990015120988376 - loss_val: 0.968918184129629\n",
      "Epoch: 4135 - time: 0.0031 - loss_train: 0.7989870839186014 - loss_val: 0.9689166398982697\n",
      "Epoch: 4136 - time: 0.0031 - loss_train: 0.798972662031846 - loss_val: 0.9689150908145867\n",
      "Epoch: 4137 - time: 0.0031 - loss_train: 0.7989582464330833 - loss_val: 0.9689135368787417\n",
      "Epoch: 4138 - time: 0.0031 - loss_train: 0.7989438371168346 - loss_val: 0.968911978090908\n",
      "Epoch: 4139 - time: 0.0031 - loss_train: 0.7989294340776294 - loss_val: 0.968910414451277\n",
      "Epoch: 4140 - time: 0.0031 - loss_train: 0.7989150373100056 - loss_val: 0.9689088459600532\n",
      "Epoch: 4141 - time: 0.0031 - loss_train: 0.7989006468085104 - loss_val: 0.968907272617458\n",
      "Epoch: 4142 - time: 0.0031 - loss_train: 0.7988862625676988 - loss_val: 0.9689056944237268\n",
      "Epoch: 4143 - time: 0.0031 - loss_train: 0.7988718845821351 - loss_val: 0.9689041113791103\n",
      "Epoch: 4144 - time: 0.0031 - loss_train: 0.7988575128463915 - loss_val: 0.9689025234838726\n",
      "Epoch: 4145 - time: 0.0031 - loss_train: 0.7988431473550499 - loss_val: 0.9689009307382946\n",
      "Epoch: 4146 - time: 0.0031 - loss_train: 0.7988287881026999 - loss_val: 0.9688993331426714\n",
      "Epoch: 4147 - time: 0.0031 - loss_train: 0.7988144350839398 - loss_val: 0.9688977306973134\n",
      "Epoch: 4148 - time: 0.0031 - loss_train: 0.7988000882933768 - loss_val: 0.968896123402544\n",
      "Epoch: 4149 - time: 0.0031 - loss_train: 0.7987857477256266 - loss_val: 0.9688945112587037\n",
      "Epoch: 4150 - time: 0.0045 - loss_train: 0.7987714133753134 - loss_val: 0.9688928942661467\n",
      "Epoch: 4151 - time: 0.0044 - loss_train: 0.7987570852370698 - loss_val: 0.9688912724252406\n",
      "Epoch: 4152 - time: 0.0045 - loss_train: 0.7987427633055375 - loss_val: 0.9688896457363698\n",
      "Epoch: 4153 - time: 0.0044 - loss_train: 0.7987284475753661 - loss_val: 0.9688880141999316\n",
      "Epoch: 4154 - time: 0.0044 - loss_train: 0.7987141380412138 - loss_val: 0.9688863778163397\n",
      "Epoch: 4155 - time: 0.0038 - loss_train: 0.7986998346977486 - loss_val: 0.9688847365860213\n",
      "Epoch: 4156 - time: 0.0031 - loss_train: 0.7986855375396451 - loss_val: 0.9688830905094173\n",
      "Epoch: 4157 - time: 0.0031 - loss_train: 0.7986712465615874 - loss_val: 0.968881439586985\n",
      "Epoch: 4158 - time: 0.0031 - loss_train: 0.798656961758268 - loss_val: 0.9688797838191947\n",
      "Epoch: 4159 - time: 0.0031 - loss_train: 0.7986426831243891 - loss_val: 0.968878123206532\n",
      "Epoch: 4160 - time: 0.0031 - loss_train: 0.7986284106546584 - loss_val: 0.9688764577494964\n",
      "Epoch: 4161 - time: 0.0031 - loss_train: 0.7986141443437957 - loss_val: 0.9688747874486012\n",
      "Epoch: 4162 - time: 0.0031 - loss_train: 0.798599884186527 - loss_val: 0.9688731123043749\n",
      "Epoch: 4163 - time: 0.0031 - loss_train: 0.7985856301775873 - loss_val: 0.968871432317362\n",
      "Epoch: 4164 - time: 0.0031 - loss_train: 0.79857138231172 - loss_val: 0.9688697474881177\n",
      "Epoch: 4165 - time: 0.0031 - loss_train: 0.7985571405836777 - loss_val: 0.9688680578172136\n",
      "Epoch: 4166 - time: 0.0031 - loss_train: 0.7985429049882204 - loss_val: 0.9688663633052358\n",
      "Epoch: 4167 - time: 0.0031 - loss_train: 0.7985286755201171 - loss_val: 0.9688646639527833\n",
      "Epoch: 4168 - time: 0.0035 - loss_train: 0.7985144521741454 - loss_val: 0.9688629597604707\n",
      "Epoch: 4169 - time: 0.0032 - loss_train: 0.7985002349450913 - loss_val: 0.9688612507289253\n",
      "Epoch: 4170 - time: 0.0031 - loss_train: 0.798486023827749 - loss_val: 0.9688595368587885\n",
      "Epoch: 4171 - time: 0.0031 - loss_train: 0.7984718188169213 - loss_val: 0.9688578181507185\n",
      "Epoch: 4172 - time: 0.0031 - loss_train: 0.798457619907419 - loss_val: 0.9688560946053841\n",
      "Epoch: 4173 - time: 0.0031 - loss_train: 0.7984434270940622 - loss_val: 0.9688543662234699\n",
      "Epoch: 4174 - time: 0.0031 - loss_train: 0.7984292403716786 - loss_val: 0.9688526330056737\n",
      "Epoch: 4175 - time: 0.0031 - loss_train: 0.7984150597351045 - loss_val: 0.9688508949527083\n",
      "Epoch: 4176 - time: 0.0031 - loss_train: 0.7984008851791855 - loss_val: 0.9688491520652994\n",
      "Epoch: 4177 - time: 0.0031 - loss_train: 0.7983867166987736 - loss_val: 0.9688474043441879\n",
      "Epoch: 4178 - time: 0.0031 - loss_train: 0.7983725542887314 - loss_val: 0.9688456517901268\n",
      "Epoch: 4179 - time: 0.0031 - loss_train: 0.7983583979439284 - loss_val: 0.968843894403884\n",
      "Epoch: 4180 - time: 0.0031 - loss_train: 0.7983442476592432 - loss_val: 0.9688421321862404\n",
      "Epoch: 4181 - time: 0.0031 - loss_train: 0.7983301034295617 - loss_val: 0.9688403651379928\n",
      "Epoch: 4182 - time: 0.0031 - loss_train: 0.7983159652497801 - loss_val: 0.9688385932599491\n",
      "Epoch: 4183 - time: 0.0031 - loss_train: 0.7983018331148012 - loss_val: 0.9688368165529325\n",
      "Epoch: 4184 - time: 0.0031 - loss_train: 0.7982877070195371 - loss_val: 0.9688350350177793\n",
      "Epoch: 4185 - time: 0.0031 - loss_train: 0.7982735869589074 - loss_val: 0.9688332486553398\n",
      "Epoch: 4186 - time: 0.0031 - loss_train: 0.7982594729278405 - loss_val: 0.9688314574664785\n",
      "Epoch: 4187 - time: 0.0031 - loss_train: 0.7982453649212736 - loss_val: 0.9688296614520708\n",
      "Epoch: 4188 - time: 0.0031 - loss_train: 0.7982312629341518 - loss_val: 0.9688278606130087\n",
      "Epoch: 4189 - time: 0.0031 - loss_train: 0.7982171669614279 - loss_val: 0.9688260549501984\n",
      "Epoch: 4190 - time: 0.0031 - loss_train: 0.7982030769980639 - loss_val: 0.9688242444645554\n",
      "Epoch: 4191 - time: 0.0031 - loss_train: 0.79818899303903 - loss_val: 0.9688224291570113\n",
      "Epoch: 4192 - time: 0.0031 - loss_train: 0.7981749150793039 - loss_val: 0.9688206090285129\n",
      "Epoch: 4193 - time: 0.0031 - loss_train: 0.7981608431138725 - loss_val: 0.9688187840800181\n",
      "Epoch: 4194 - time: 0.0033 - loss_train: 0.7981467771377302 - loss_val: 0.9688169543124975\n",
      "Epoch: 4195 - time: 0.0032 - loss_train: 0.7981327171458805 - loss_val: 0.9688151197269373\n",
      "Epoch: 4196 - time: 0.0031 - loss_train: 0.7981186631333343 - loss_val: 0.9688132803243358\n",
      "Epoch: 4197 - time: 0.0031 - loss_train: 0.798104615095112 - loss_val: 0.9688114361057035\n",
      "Epoch: 4198 - time: 0.0031 - loss_train: 0.7980905730262404 - loss_val: 0.9688095870720677\n",
      "Epoch: 4199 - time: 0.0031 - loss_train: 0.7980765369217561 - loss_val: 0.9688077332244653\n",
      "Epoch: 4200 - time: 0.0031 - loss_train: 0.7980625067767029 - loss_val: 0.9688058745639482\n",
      "Epoch: 4201 - time: 0.0031 - loss_train: 0.7980484825861341 - loss_val: 0.9688040110915814\n",
      "Epoch: 4202 - time: 0.0031 - loss_train: 0.7980344643451094 - loss_val: 0.9688021428084436\n",
      "Epoch: 4203 - time: 0.0031 - loss_train: 0.7980204520486982 - loss_val: 0.968800269715624\n",
      "Epoch: 4204 - time: 0.0031 - loss_train: 0.7980064456919781 - loss_val: 0.9687983918142286\n",
      "Epoch: 4205 - time: 0.0031 - loss_train: 0.7979924452700337 - loss_val: 0.9687965091053741\n",
      "Epoch: 4206 - time: 0.0034 - loss_train: 0.7979784507779583 - loss_val: 0.9687946215901901\n",
      "Epoch: 4207 - time: 0.0032 - loss_train: 0.7979644622108545 - loss_val: 0.9687927292698212\n",
      "Epoch: 4208 - time: 0.0031 - loss_train: 0.7979504795638312 - loss_val: 0.9687908321454236\n",
      "Epoch: 4209 - time: 0.0031 - loss_train: 0.7979365028320067 - loss_val: 0.9687889302181657\n",
      "Epoch: 4210 - time: 0.0031 - loss_train: 0.7979225320105076 - loss_val: 0.9687870234892305\n",
      "Epoch: 4211 - time: 0.0031 - loss_train: 0.7979085670944678 - loss_val: 0.9687851119598132\n",
      "Epoch: 4212 - time: 0.0031 - loss_train: 0.7978946080790292 - loss_val: 0.9687831956311227\n",
      "Epoch: 4213 - time: 0.0031 - loss_train: 0.7978806549593437 - loss_val: 0.9687812745043795\n",
      "Epoch: 4214 - time: 0.0031 - loss_train: 0.7978667077305688 - loss_val: 0.9687793485808163\n",
      "Epoch: 4215 - time: 0.0031 - loss_train: 0.7978527663878717 - loss_val: 0.9687774178616814\n",
      "Epoch: 4216 - time: 0.0031 - loss_train: 0.7978388309264274 - loss_val: 0.9687754823482332\n",
      "Epoch: 4217 - time: 0.0031 - loss_train: 0.797824901341419 - loss_val: 0.9687735420417444\n",
      "Epoch: 4218 - time: 0.0031 - loss_train: 0.7978109776280373 - loss_val: 0.9687715969434989\n",
      "Epoch: 4219 - time: 0.0031 - loss_train: 0.7977970597814819 - loss_val: 0.9687696470547965\n",
      "Epoch: 4220 - time: 0.0031 - loss_train: 0.7977831477969596 - loss_val: 0.9687676923769449\n",
      "Epoch: 4221 - time: 0.0031 - loss_train: 0.7977692416696859 - loss_val: 0.9687657329112692\n",
      "Epoch: 4222 - time: 0.0031 - loss_train: 0.7977553413948847 - loss_val: 0.9687637686591039\n",
      "Epoch: 4223 - time: 0.0031 - loss_train: 0.7977414469677871 - loss_val: 0.9687617996217968\n",
      "Epoch: 4224 - time: 0.0031 - loss_train: 0.7977275583836329 - loss_val: 0.9687598258007089\n",
      "Epoch: 4225 - time: 0.0031 - loss_train: 0.7977136756376692 - loss_val: 0.9687578471972143\n",
      "Epoch: 4226 - time: 0.0031 - loss_train: 0.7976997987251515 - loss_val: 0.9687558638126975\n",
      "Epoch: 4227 - time: 0.0031 - loss_train: 0.7976859276413443 - loss_val: 0.9687538756485568\n",
      "Epoch: 4228 - time: 0.0031 - loss_train: 0.7976720623815186 - loss_val: 0.9687518827062047\n",
      "Epoch: 4229 - time: 0.0031 - loss_train: 0.7976582029409545 - loss_val: 0.9687498849870615\n",
      "Epoch: 4230 - time: 0.0031 - loss_train: 0.7976443493149391 - loss_val: 0.9687478824925652\n",
      "Epoch: 4231 - time: 0.0031 - loss_train: 0.7976305014987684 - loss_val: 0.9687458752241621\n",
      "Epoch: 4232 - time: 0.0031 - loss_train: 0.7976166594877463 - loss_val: 0.9687438631833138\n",
      "Epoch: 4233 - time: 0.0031 - loss_train: 0.7976028232771839 - loss_val: 0.9687418463714909\n",
      "Epoch: 4234 - time: 0.0031 - loss_train: 0.7975889928624016 - loss_val: 0.9687398247901802\n",
      "Epoch: 4235 - time: 0.0031 - loss_train: 0.7975751682387261 - loss_val: 0.9687377984408775\n",
      "Epoch: 4236 - time: 0.0031 - loss_train: 0.7975613494014935 - loss_val: 0.9687357673250927\n",
      "Epoch: 4237 - time: 0.0031 - loss_train: 0.7975475363460472 - loss_val: 0.968733731444348\n",
      "Epoch: 4238 - time: 0.0031 - loss_train: 0.7975337290677386 - loss_val: 0.9687316908001757\n",
      "Epoch: 4239 - time: 0.0031 - loss_train: 0.7975199275619269 - loss_val: 0.9687296453941231\n",
      "Epoch: 4240 - time: 0.0031 - loss_train: 0.7975061318239796 - loss_val: 0.9687275952277475\n",
      "Epoch: 4241 - time: 0.0031 - loss_train: 0.7974923418492722 - loss_val: 0.9687255403026199\n",
      "Epoch: 4242 - time: 0.0031 - loss_train: 0.7974785576331873 - loss_val: 0.9687234806203212\n",
      "Epoch: 4243 - time: 0.0031 - loss_train: 0.7974647791711165 - loss_val: 0.9687214161824467\n",
      "Epoch: 4244 - time: 0.0031 - loss_train: 0.7974510064584583 - loss_val: 0.9687193469906019\n",
      "Epoch: 4245 - time: 0.0032 - loss_train: 0.7974372394906195 - loss_val: 0.9687172730464068\n",
      "Epoch: 4246 - time: 0.0031 - loss_train: 0.7974234782630153 - loss_val: 0.9687151943514902\n",
      "Epoch: 4247 - time: 0.0031 - loss_train: 0.7974097227710677 - loss_val: 0.968713110907495\n",
      "Epoch: 4248 - time: 0.0031 - loss_train: 0.7973959730102078 - loss_val: 0.9687110227160751\n",
      "Epoch: 4249 - time: 0.0031 - loss_train: 0.7973822289758732 - loss_val: 0.9687089297788973\n",
      "Epoch: 4250 - time: 0.0031 - loss_train: 0.7973684906635103 - loss_val: 0.9687068320976389\n",
      "Epoch: 4251 - time: 0.0031 - loss_train: 0.7973547580685736 - loss_val: 0.9687047296739899\n",
      "Epoch: 4252 - time: 0.0031 - loss_train: 0.7973410311865246 - loss_val: 0.968702622509652\n",
      "Epoch: 4253 - time: 0.0031 - loss_train: 0.7973273100128329 - loss_val: 0.968700510606339\n",
      "Epoch: 4254 - time: 0.0031 - loss_train: 0.7973135945429759 - loss_val: 0.9686983939657756\n",
      "Epoch: 4255 - time: 0.0031 - loss_train: 0.797299884772439 - loss_val: 0.9686962725896996\n",
      "Epoch: 4256 - time: 0.0031 - loss_train: 0.7972861806967153 - loss_val: 0.9686941464798586\n",
      "Epoch: 4257 - time: 0.0031 - loss_train: 0.7972724823113058 - loss_val: 0.9686920156380138\n",
      "Epoch: 4258 - time: 0.0031 - loss_train: 0.7972587896117189 - loss_val: 0.9686898800659369\n",
      "Epoch: 4259 - time: 0.0031 - loss_train: 0.7972451025934718 - loss_val: 0.9686877397654127\n",
      "Epoch: 4260 - time: 0.0031 - loss_train: 0.797231421252088 - loss_val: 0.9686855947382351\n",
      "Epoch: 4261 - time: 0.0031 - loss_train: 0.7972177455830993 - loss_val: 0.9686834449862115\n",
      "Epoch: 4262 - time: 0.0031 - loss_train: 0.7972040755820463 - loss_val: 0.9686812905111604\n",
      "Epoch: 4263 - time: 0.0031 - loss_train: 0.7971904112444764 - loss_val: 0.9686791313149127\n",
      "Epoch: 4264 - time: 0.0031 - loss_train: 0.7971767525659443 - loss_val: 0.9686769673993088\n",
      "Epoch: 4265 - time: 0.0031 - loss_train: 0.7971630995420128 - loss_val: 0.9686747987662024\n",
      "Epoch: 4266 - time: 0.0031 - loss_train: 0.7971494521682537 - loss_val: 0.9686726254174577\n",
      "Epoch: 4267 - time: 0.0031 - loss_train: 0.7971358104402442 - loss_val: 0.9686704473549517\n",
      "Epoch: 4268 - time: 0.0031 - loss_train: 0.7971221743535711 - loss_val: 0.9686682645805708\n",
      "Epoch: 4269 - time: 0.0031 - loss_train: 0.7971085439038282 - loss_val: 0.9686660770962142\n",
      "Epoch: 4270 - time: 0.0031 - loss_train: 0.7970949190866173 - loss_val: 0.968663884903792\n",
      "Epoch: 4271 - time: 0.0031 - loss_train: 0.7970812998975467 - loss_val: 0.968661688005226\n",
      "Epoch: 4272 - time: 0.0031 - loss_train: 0.797067686332234 - loss_val: 0.9686594864024493\n",
      "Epoch: 4273 - time: 0.0031 - loss_train: 0.7970540783863035 - loss_val: 0.9686572800974043\n",
      "Epoch: 4274 - time: 0.0031 - loss_train: 0.7970404760553879 - loss_val: 0.968655069092049\n",
      "Epoch: 4275 - time: 0.0031 - loss_train: 0.7970268793351262 - loss_val: 0.968652853388348\n",
      "Epoch: 4276 - time: 0.0031 - loss_train: 0.7970132882211667 - loss_val: 0.9686506329882814\n",
      "Epoch: 4277 - time: 0.0035 - loss_train: 0.796999702709164 - loss_val: 0.968648407893836\n",
      "Epoch: 4278 - time: 0.0036 - loss_train: 0.7969861227947812 - loss_val: 0.9686461781070136\n",
      "Epoch: 4279 - time: 0.0035 - loss_train: 0.7969725484736883 - loss_val: 0.9686439436298246\n",
      "Epoch: 4280 - time: 0.0032 - loss_train: 0.796958979741564 - loss_val: 0.9686417044642924\n",
      "Epoch: 4281 - time: 0.0031 - loss_train: 0.7969454165940931 - loss_val: 0.9686394606124509\n",
      "Epoch: 4282 - time: 0.0037 - loss_train: 0.7969318590269693 - loss_val: 0.9686372120763426\n",
      "Epoch: 4283 - time: 0.0032 - loss_train: 0.7969183070358934 - loss_val: 0.9686349588580261\n",
      "Epoch: 4284 - time: 0.0031 - loss_train: 0.7969047606165734 - loss_val: 0.9686327009595675\n",
      "Epoch: 4285 - time: 0.0031 - loss_train: 0.7968912197647255 - loss_val: 0.9686304383830441\n",
      "Epoch: 4286 - time: 0.0031 - loss_train: 0.7968776844760734 - loss_val: 0.9686281711305449\n",
      "Epoch: 4287 - time: 0.0031 - loss_train: 0.7968641547463479 - loss_val: 0.9686258992041687\n",
      "Epoch: 4288 - time: 0.0031 - loss_train: 0.7968506305712877 - loss_val: 0.9686236226060289\n",
      "Epoch: 4289 - time: 0.0031 - loss_train: 0.796837111946639 - loss_val: 0.9686213413382442\n",
      "Epoch: 4290 - time: 0.0031 - loss_train: 0.7968235988681551 - loss_val: 0.968619055402949\n",
      "Epoch: 4291 - time: 0.0031 - loss_train: 0.7968100913315975 - loss_val: 0.968616764802286\n",
      "Epoch: 4292 - time: 0.0031 - loss_train: 0.7967965893327348 - loss_val: 0.9686144695384088\n",
      "Epoch: 4293 - time: 0.0031 - loss_train: 0.7967830928673436 - loss_val: 0.9686121696134828\n",
      "Epoch: 4294 - time: 0.0031 - loss_train: 0.7967696019312073 - loss_val: 0.9686098650296854\n",
      "Epoch: 4295 - time: 0.0031 - loss_train: 0.7967561165201168 - loss_val: 0.9686075557892007\n",
      "Epoch: 4296 - time: 0.0031 - loss_train: 0.7967426366298714 - loss_val: 0.9686052418942275\n",
      "Epoch: 4297 - time: 0.0031 - loss_train: 0.796729162256277 - loss_val: 0.9686029233469741\n",
      "Epoch: 4298 - time: 0.0031 - loss_train: 0.7967156933951467 - loss_val: 0.9686006001496574\n",
      "Epoch: 4299 - time: 0.0031 - loss_train: 0.7967022300423026 - loss_val: 0.9685982723045097\n",
      "Epoch: 4300 - time: 0.0031 - loss_train: 0.796688772193572 - loss_val: 0.9685959398137678\n",
      "Epoch: 4301 - time: 0.0031 - loss_train: 0.796675319844792 - loss_val: 0.9685936026796848\n",
      "Epoch: 4302 - time: 0.0031 - loss_train: 0.7966618729918055 - loss_val: 0.9685912609045217\n",
      "Epoch: 4303 - time: 0.0031 - loss_train: 0.7966484316304632 - loss_val: 0.9685889144905494\n",
      "Epoch: 4304 - time: 0.0031 - loss_train: 0.7966349957566238 - loss_val: 0.9685865634400511\n",
      "Epoch: 4305 - time: 0.0031 - loss_train: 0.7966215653661525 - loss_val: 0.9685842077553195\n",
      "Epoch: 4306 - time: 0.0031 - loss_train: 0.7966081404549221 - loss_val: 0.9685818474386587\n",
      "Epoch: 4307 - time: 0.0031 - loss_train: 0.7965947210188137 - loss_val: 0.9685794824923812\n",
      "Epoch: 4308 - time: 0.0031 - loss_train: 0.7965813070537147 - loss_val: 0.9685771129188133\n",
      "Epoch: 4309 - time: 0.0031 - loss_train: 0.7965678985555205 - loss_val: 0.9685747387202875\n",
      "Epoch: 4310 - time: 0.0031 - loss_train: 0.7965544955201331 - loss_val: 0.9685723598991521\n",
      "Epoch: 4311 - time: 0.0031 - loss_train: 0.7965410979434635 - loss_val: 0.9685699764577606\n",
      "Epoch: 4312 - time: 0.0031 - loss_train: 0.7965277058214277 - loss_val: 0.9685675883984789\n",
      "Epoch: 4313 - time: 0.0031 - loss_train: 0.7965143191499506 - loss_val: 0.9685651957236853\n",
      "Epoch: 4314 - time: 0.0031 - loss_train: 0.796500937924965 - loss_val: 0.9685627984357644\n",
      "Epoch: 4315 - time: 0.0031 - loss_train: 0.7964875621424092 - loss_val: 0.9685603965371157\n",
      "Epoch: 4316 - time: 0.0031 - loss_train: 0.7964741917982301 - loss_val: 0.9685579900301444\n",
      "Epoch: 4317 - time: 0.0035 - loss_train: 0.7964608268883818 - loss_val: 0.9685555789172691\n",
      "Epoch: 4318 - time: 0.0043 - loss_train: 0.7964474674088248 - loss_val: 0.9685531632009176\n",
      "Epoch: 4319 - time: 0.0047 - loss_train: 0.7964341133555284 - loss_val: 0.9685507428835272\n",
      "Epoch: 4320 - time: 0.0046 - loss_train: 0.7964207647244675 - loss_val: 0.9685483179675465\n",
      "Epoch: 4321 - time: 0.0045 - loss_train: 0.7964074215116257 - loss_val: 0.9685458884554339\n",
      "Epoch: 4322 - time: 0.0045 - loss_train: 0.7963940837129928 - loss_val: 0.9685434543496578\n",
      "Epoch: 4323 - time: 0.0045 - loss_train: 0.7963807513245668 - loss_val: 0.9685410156526985\n",
      "Epoch: 4324 - time: 0.0046 - loss_train: 0.7963674243423523 - loss_val: 0.9685385723670416\n",
      "Epoch: 4325 - time: 0.0046 - loss_train: 0.796354102762361 - loss_val: 0.9685361244951887\n",
      "Epoch: 4326 - time: 0.0037 - loss_train: 0.7963407865806122 - loss_val: 0.9685336720396481\n",
      "Epoch: 4327 - time: 0.0035 - loss_train: 0.7963274757931329 - loss_val: 0.9685312150029382\n",
      "Epoch: 4328 - time: 0.0035 - loss_train: 0.796314170395956 - loss_val: 0.9685287533875879\n",
      "Epoch: 4329 - time: 0.0035 - loss_train: 0.7963008703851231 - loss_val: 0.9685262871961369\n",
      "Epoch: 4330 - time: 0.0035 - loss_train: 0.7962875757566823 - loss_val: 0.9685238164311327\n",
      "Epoch: 4331 - time: 0.0036 - loss_train: 0.7962742865066877 - loss_val: 0.9685213410951357\n",
      "Epoch: 4332 - time: 0.0035 - loss_train: 0.7962610026312028 - loss_val: 0.968518861190714\n",
      "Epoch: 4333 - time: 0.0035 - loss_train: 0.7962477241262973 - loss_val: 0.9685163767204457\n",
      "Epoch: 4334 - time: 0.0035 - loss_train: 0.7962344509880472 - loss_val: 0.9685138876869207\n",
      "Epoch: 4335 - time: 0.0036 - loss_train: 0.7962211832125368 - loss_val: 0.9685113940927363\n",
      "Epoch: 4336 - time: 0.0036 - loss_train: 0.7962079207958574 - loss_val: 0.9685088959405014\n",
      "Epoch: 4337 - time: 0.0043 - loss_train: 0.7961946637341069 - loss_val: 0.9685063932328335\n",
      "Epoch: 4338 - time: 0.0043 - loss_train: 0.7961814120233909 - loss_val: 0.9685038859723613\n",
      "Epoch: 4339 - time: 0.0045 - loss_train: 0.7961681656598211 - loss_val: 0.9685013741617212\n",
      "Epoch: 4340 - time: 0.0046 - loss_train: 0.7961549246395182 - loss_val: 0.9684988578035616\n",
      "Epoch: 4341 - time: 0.0046 - loss_train: 0.7961416889586082 - loss_val: 0.968496336900539\n",
      "Epoch: 4342 - time: 0.0045 - loss_train: 0.7961284586132246 - loss_val: 0.9684938114553215\n",
      "Epoch: 4343 - time: 0.0046 - loss_train: 0.7961152335995084 - loss_val: 0.9684912814705829\n",
      "Epoch: 4344 - time: 0.0043 - loss_train: 0.7961020139136082 - loss_val: 0.968488746949012\n",
      "Epoch: 4345 - time: 0.0043 - loss_train: 0.7960887995516784 - loss_val: 0.9684862078933035\n",
      "Epoch: 4346 - time: 0.0043 - loss_train: 0.7960755905098809 - loss_val: 0.9684836643061631\n",
      "Epoch: 4347 - time: 0.0043 - loss_train: 0.7960623867843848 - loss_val: 0.9684811161903056\n",
      "Epoch: 4348 - time: 0.0039 - loss_train: 0.7960491883713665 - loss_val: 0.9684785635484551\n",
      "Epoch: 4349 - time: 0.0045 - loss_train: 0.7960359952670092 - loss_val: 0.9684760063833467\n",
      "Epoch: 4350 - time: 0.0038 - loss_train: 0.7960228074675026 - loss_val: 0.9684734446977236\n",
      "Epoch: 4351 - time: 0.0038 - loss_train: 0.7960096249690448 - loss_val: 0.9684708784943384\n",
      "Epoch: 4352 - time: 0.0038 - loss_train: 0.7959964477678388 - loss_val: 0.9684683077759553\n",
      "Epoch: 4353 - time: 0.0038 - loss_train: 0.7959832758600969 - loss_val: 0.9684657325453447\n",
      "Epoch: 4354 - time: 0.0038 - loss_train: 0.7959701092420366 - loss_val: 0.9684631528052894\n",
      "Epoch: 4355 - time: 0.0038 - loss_train: 0.7959569479098831 - loss_val: 0.9684605685585796\n",
      "Epoch: 4356 - time: 0.0038 - loss_train: 0.7959437918598692 - loss_val: 0.9684579798080161\n",
      "Epoch: 4357 - time: 0.0038 - loss_train: 0.7959306410882333 - loss_val: 0.9684553865564092\n",
      "Epoch: 4358 - time: 0.0043 - loss_train: 0.7959174955912219 - loss_val: 0.9684527888065771\n",
      "Epoch: 4359 - time: 0.0044 - loss_train: 0.7959043553650876 - loss_val: 0.9684501865613488\n",
      "Epoch: 4360 - time: 0.0043 - loss_train: 0.795891220406091 - loss_val: 0.9684475798235623\n",
      "Epoch: 4361 - time: 0.0044 - loss_train: 0.7958780907104978 - loss_val: 0.9684449685960635\n",
      "Epoch: 4362 - time: 0.0043 - loss_train: 0.7958649662745827 - loss_val: 0.9684423528817111\n",
      "Epoch: 4363 - time: 0.0045 - loss_train: 0.7958518470946263 - loss_val: 0.9684397326833694\n",
      "Epoch: 4364 - time: 0.0043 - loss_train: 0.7958387331669163 - loss_val: 0.9684371080039119\n",
      "Epoch: 4365 - time: 0.0044 - loss_train: 0.795825624487747 - loss_val: 0.9684344788462254\n",
      "Epoch: 4366 - time: 0.0044 - loss_train: 0.7958125210534197 - loss_val: 0.9684318452132008\n",
      "Epoch: 4367 - time: 0.0045 - loss_train: 0.7957994228602424 - loss_val: 0.9684292071077428\n",
      "Epoch: 4368 - time: 0.0044 - loss_train: 0.7957863299045314 - loss_val: 0.968426564532761\n",
      "Epoch: 4369 - time: 0.0044 - loss_train: 0.7957732421826071 - loss_val: 0.9684239174911774\n",
      "Epoch: 4370 - time: 0.0044 - loss_train: 0.7957601596907997 - loss_val: 0.968421265985921\n",
      "Epoch: 4371 - time: 0.0045 - loss_train: 0.7957470824254438 - loss_val: 0.9684186100199321\n",
      "Epoch: 4372 - time: 0.0044 - loss_train: 0.7957340103828824 - loss_val: 0.9684159495961578\n",
      "Epoch: 4373 - time: 0.0044 - loss_train: 0.7957209435594651 - loss_val: 0.9684132847175556\n",
      "Epoch: 4374 - time: 0.0044 - loss_train: 0.7957078819515475 - loss_val: 0.9684106153870907\n",
      "Epoch: 4375 - time: 0.0044 - loss_train: 0.7956948255554928 - loss_val: 0.9684079416077391\n",
      "Epoch: 4376 - time: 0.0044 - loss_train: 0.7956817743676704 - loss_val: 0.9684052633824844\n",
      "Epoch: 4377 - time: 0.0046 - loss_train: 0.7956687283844576 - loss_val: 0.9684025807143193\n",
      "Epoch: 4378 - time: 0.0044 - loss_train: 0.7956556876022369 - loss_val: 0.9683998936062476\n",
      "Epoch: 4379 - time: 0.0034 - loss_train: 0.7956426520173988 - loss_val: 0.9683972020612778\n",
      "Epoch: 4380 - time: 0.0031 - loss_train: 0.7956296216263405 - loss_val: 0.9683945060824319\n",
      "Epoch: 4381 - time: 0.0031 - loss_train: 0.7956165964254647 - loss_val: 0.9683918056727371\n",
      "Epoch: 4382 - time: 0.0031 - loss_train: 0.7956035764111821 - loss_val: 0.9683891008352318\n",
      "Epoch: 4383 - time: 0.0031 - loss_train: 0.7955905615799101 - loss_val: 0.9683863915729626\n",
      "Epoch: 4384 - time: 0.0031 - loss_train: 0.795577551928072 - loss_val: 0.9683836778889836\n",
      "Epoch: 4385 - time: 0.0031 - loss_train: 0.7955645474520991 - loss_val: 0.9683809597863612\n",
      "Epoch: 4386 - time: 0.0031 - loss_train: 0.7955515481484275 - loss_val: 0.9683782372681651\n",
      "Epoch: 4387 - time: 0.0031 - loss_train: 0.7955385540135016 - loss_val: 0.9683755103374789\n",
      "Epoch: 4388 - time: 0.0031 - loss_train: 0.7955255650437725 - loss_val: 0.9683727789973932\n",
      "Epoch: 4389 - time: 0.0031 - loss_train: 0.7955125812356969 - loss_val: 0.9683700432510058\n",
      "Epoch: 4390 - time: 0.0031 - loss_train: 0.7954996025857389 - loss_val: 0.9683673031014259\n",
      "Epoch: 4391 - time: 0.0031 - loss_train: 0.795486629090369 - loss_val: 0.9683645585517686\n",
      "Epoch: 4392 - time: 0.0031 - loss_train: 0.7954736607460647 - loss_val: 0.9683618096051598\n",
      "Epoch: 4393 - time: 0.0031 - loss_train: 0.7954606975493103 - loss_val: 0.9683590562647333\n",
      "Epoch: 4394 - time: 0.0031 - loss_train: 0.7954477394965954 - loss_val: 0.9683562985336314\n",
      "Epoch: 4395 - time: 0.0031 - loss_train: 0.7954347865844181 - loss_val: 0.9683535364150049\n",
      "Epoch: 4396 - time: 0.0031 - loss_train: 0.7954218388092815 - loss_val: 0.9683507699120139\n",
      "Epoch: 4397 - time: 0.0031 - loss_train: 0.7954088961676962 - loss_val: 0.9683479990278259\n",
      "Epoch: 4398 - time: 0.0031 - loss_train: 0.7953959586561797 - loss_val: 0.9683452237656179\n",
      "Epoch: 4399 - time: 0.0031 - loss_train: 0.7953830262712551 - loss_val: 0.9683424441285751\n",
      "Epoch: 4400 - time: 0.0031 - loss_train: 0.7953700990094528 - loss_val: 0.968339660119891\n",
      "Epoch: 4401 - time: 0.0031 - loss_train: 0.7953571768673093 - loss_val: 0.9683368717427686\n",
      "Epoch: 4402 - time: 0.0031 - loss_train: 0.7953442598413683 - loss_val: 0.9683340790004176\n",
      "Epoch: 4403 - time: 0.0031 - loss_train: 0.7953313479281794 - loss_val: 0.9683312818960578\n",
      "Epoch: 4404 - time: 0.0031 - loss_train: 0.7953184411242994 - loss_val: 0.9683284804329167\n",
      "Epoch: 4405 - time: 0.0031 - loss_train: 0.7953055394262908 - loss_val: 0.9683256746142294\n",
      "Epoch: 4406 - time: 0.0031 - loss_train: 0.7952926428307232 - loss_val: 0.9683228644432404\n",
      "Epoch: 4407 - time: 0.0031 - loss_train: 0.7952797513341732 - loss_val: 0.9683200499232044\n",
      "Epoch: 4408 - time: 0.0031 - loss_train: 0.7952668649332224 - loss_val: 0.9683172310573795\n",
      "Epoch: 4409 - time: 0.0031 - loss_train: 0.7952539836244606 - loss_val: 0.9683144078490374\n",
      "Epoch: 4410 - time: 0.0031 - loss_train: 0.7952411074044828 - loss_val: 0.9683115803014539\n",
      "Epoch: 4411 - time: 0.0031 - loss_train: 0.7952282362698914 - loss_val: 0.968308748417917\n",
      "Epoch: 4412 - time: 0.0031 - loss_train: 0.7952153702172948 - loss_val: 0.968305912201719\n",
      "Epoch: 4413 - time: 0.0031 - loss_train: 0.7952025092433077 - loss_val: 0.9683030716561647\n",
      "Epoch: 4414 - time: 0.0031 - loss_train: 0.7951896533445519 - loss_val: 0.9683002267845624\n",
      "Epoch: 4415 - time: 0.0031 - loss_train: 0.7951768025176547 - loss_val: 0.9682973775902322\n",
      "Epoch: 4416 - time: 0.0031 - loss_train: 0.7951639567592508 - loss_val: 0.9682945240765009\n",
      "Epoch: 4417 - time: 0.0031 - loss_train: 0.7951511160659812 - loss_val: 0.9682916662467036\n",
      "Epoch: 4418 - time: 0.0031 - loss_train: 0.7951382804344926 - loss_val: 0.9682888041041845\n",
      "Epoch: 4419 - time: 0.0031 - loss_train: 0.7951254498614386 - loss_val: 0.9682859376522943\n",
      "Epoch: 4420 - time: 0.0031 - loss_train: 0.795112624343479 - loss_val: 0.9682830668943934\n",
      "Epoch: 4421 - time: 0.0031 - loss_train: 0.7950998038772807 - loss_val: 0.96828019183385\n",
      "Epoch: 4422 - time: 0.0031 - loss_train: 0.795086988459516 - loss_val: 0.9682773124740385\n",
      "Epoch: 4423 - time: 0.0031 - loss_train: 0.795074178086864 - loss_val: 0.9682744288183437\n",
      "Epoch: 4424 - time: 0.0031 - loss_train: 0.7950613727560106 - loss_val: 0.9682715408701581\n",
      "Epoch: 4425 - time: 0.0031 - loss_train: 0.7950485724636471 - loss_val: 0.9682686486328804\n",
      "Epoch: 4426 - time: 0.0031 - loss_train: 0.7950357772064726 - loss_val: 0.9682657521099198\n",
      "Epoch: 4427 - time: 0.0031 - loss_train: 0.7950229869811899 - loss_val: 0.9682628513046916\n",
      "Epoch: 4428 - time: 0.0031 - loss_train: 0.795010201784512 - loss_val: 0.9682599462206196\n",
      "Epoch: 4429 - time: 0.0031 - loss_train: 0.7949974216131546 - loss_val: 0.9682570368611364\n",
      "Epoch: 4430 - time: 0.0031 - loss_train: 0.794984646463841 - loss_val: 0.9682541232296804\n",
      "Epoch: 4431 - time: 0.0031 - loss_train: 0.7949718763333022 - loss_val: 0.968251205329701\n",
      "Epoch: 4432 - time: 0.0031 - loss_train: 0.7949591112182739 - loss_val: 0.9682482831646525\n",
      "Epoch: 4433 - time: 0.0031 - loss_train: 0.794946351115498 - loss_val: 0.9682453567379987\n",
      "Epoch: 4434 - time: 0.0031 - loss_train: 0.7949335960217236 - loss_val: 0.9682424260532119\n",
      "Epoch: 4435 - time: 0.0031 - loss_train: 0.7949208459337049 - loss_val: 0.9682394911137693\n",
      "Epoch: 4436 - time: 0.0031 - loss_train: 0.794908100848204 - loss_val: 0.9682365519231589\n",
      "Epoch: 4437 - time: 0.0031 - loss_train: 0.794895360761988 - loss_val: 0.968233608484875\n",
      "Epoch: 4438 - time: 0.0031 - loss_train: 0.7948826256718304 - loss_val: 0.9682306608024218\n",
      "Epoch: 4439 - time: 0.0031 - loss_train: 0.7948698955745113 - loss_val: 0.9682277088793073\n",
      "Epoch: 4440 - time: 0.0031 - loss_train: 0.7948571704668167 - loss_val: 0.9682247527190513\n",
      "Epoch: 4441 - time: 0.0031 - loss_train: 0.7948444503455384 - loss_val: 0.9682217923251778\n",
      "Epoch: 4442 - time: 0.0031 - loss_train: 0.794831735207476 - loss_val: 0.9682188277012208\n",
      "Epoch: 4443 - time: 0.0031 - loss_train: 0.7948190250494336 - loss_val: 0.9682158588507221\n",
      "Epoch: 4444 - time: 0.0031 - loss_train: 0.7948063198682219 - loss_val: 0.96821288577723\n",
      "Epoch: 4445 - time: 0.0031 - loss_train: 0.7947936196606585 - loss_val: 0.9682099084843006\n",
      "Epoch: 4446 - time: 0.0031 - loss_train: 0.7947809244235662 - loss_val: 0.9682069269754985\n",
      "Epoch: 4447 - time: 0.0031 - loss_train: 0.794768234153775 - loss_val: 0.968203941254394\n",
      "Epoch: 4448 - time: 0.0031 - loss_train: 0.7947555488481197 - loss_val: 0.9682009513245681\n",
      "Epoch: 4449 - time: 0.0031 - loss_train: 0.7947428685034426 - loss_val: 0.9681979571896066\n",
      "Epoch: 4450 - time: 0.0031 - loss_train: 0.794730193116591 - loss_val: 0.9681949588531035\n",
      "Epoch: 4451 - time: 0.0034 - loss_train: 0.7947175226844192 - loss_val: 0.968191956318662\n",
      "Epoch: 4452 - time: 0.0032 - loss_train: 0.7947048572037875 - loss_val: 0.9681889495898891\n",
      "Epoch: 4453 - time: 0.0031 - loss_train: 0.7946921966715613 - loss_val: 0.9681859386704036\n",
      "Epoch: 4454 - time: 0.0031 - loss_train: 0.7946795410846137 - loss_val: 0.9681829235638298\n",
      "Epoch: 4455 - time: 0.0031 - loss_train: 0.7946668904398223 - loss_val: 0.9681799042737986\n",
      "Epoch: 4456 - time: 0.0031 - loss_train: 0.7946542447340721 - loss_val: 0.9681768808039499\n",
      "Epoch: 4457 - time: 0.0031 - loss_train: 0.7946416039642531 - loss_val: 0.9681738531579298\n",
      "Epoch: 4458 - time: 0.0031 - loss_train: 0.7946289681272624 - loss_val: 0.9681708213393931\n",
      "Epoch: 4459 - time: 0.0031 - loss_train: 0.7946163372200015 - loss_val: 0.9681677853520001\n",
      "Epoch: 4460 - time: 0.0031 - loss_train: 0.7946037112393803 - loss_val: 0.9681647451994203\n",
      "Epoch: 4461 - time: 0.0031 - loss_train: 0.7945910901823124 - loss_val: 0.9681617008853302\n",
      "Epoch: 4462 - time: 0.0031 - loss_train: 0.7945784740457196 - loss_val: 0.9681586524134128\n",
      "Epoch: 4463 - time: 0.0031 - loss_train: 0.7945658628265275 - loss_val: 0.9681555997873594\n",
      "Epoch: 4464 - time: 0.0031 - loss_train: 0.7945532565216691 - loss_val: 0.9681525430108666\n",
      "Epoch: 4465 - time: 0.0031 - loss_train: 0.7945406551280835 - loss_val: 0.9681494820876417\n",
      "Epoch: 4466 - time: 0.0031 - loss_train: 0.7945280586427149 - loss_val: 0.9681464170213957\n",
      "Epoch: 4467 - time: 0.0031 - loss_train: 0.7945154670625137 - loss_val: 0.9681433478158497\n",
      "Epoch: 4468 - time: 0.0031 - loss_train: 0.7945028803844375 - loss_val: 0.9681402744747297\n",
      "Epoch: 4469 - time: 0.0031 - loss_train: 0.7944902986054477 - loss_val: 0.9681371970017715\n",
      "Epoch: 4470 - time: 0.0031 - loss_train: 0.7944777217225135 - loss_val: 0.9681341154007157\n",
      "Epoch: 4471 - time: 0.0031 - loss_train: 0.794465149732609 - loss_val: 0.9681310296753098\n",
      "Epoch: 4472 - time: 0.0031 - loss_train: 0.7944525826327149 - loss_val: 0.9681279398293112\n",
      "Epoch: 4473 - time: 0.0031 - loss_train: 0.7944400204198168 - loss_val: 0.9681248458664827\n",
      "Epoch: 4474 - time: 0.0031 - loss_train: 0.7944274630909074 - loss_val: 0.9681217477905939\n",
      "Epoch: 4475 - time: 0.0031 - loss_train: 0.7944149106429852 - loss_val: 0.9681186456054216\n",
      "Epoch: 4476 - time: 0.0031 - loss_train: 0.7944023630730532 - loss_val: 0.9681155393147496\n",
      "Epoch: 4477 - time: 0.0031 - loss_train: 0.794389820378122 - loss_val: 0.9681124289223708\n",
      "Epoch: 4478 - time: 0.0031 - loss_train: 0.794377282555207 - loss_val: 0.9681093144320825\n",
      "Epoch: 4479 - time: 0.0031 - loss_train: 0.7943647496013302 - loss_val: 0.9681061958476905\n",
      "Epoch: 4480 - time: 0.0031 - loss_train: 0.7943522215135183 - loss_val: 0.9681030731730059\n",
      "Epoch: 4481 - time: 0.0031 - loss_train: 0.7943396982888052 - loss_val: 0.9680999464118484\n",
      "Epoch: 4482 - time: 0.0031 - loss_train: 0.7943271799242295 - loss_val: 0.968096815568046\n",
      "Epoch: 4483 - time: 0.0031 - loss_train: 0.794314666416837 - loss_val: 0.9680936806454301\n",
      "Epoch: 4484 - time: 0.0031 - loss_train: 0.7943021577636775 - loss_val: 0.9680905416478417\n",
      "Epoch: 4485 - time: 0.0031 - loss_train: 0.7942896539618086 - loss_val: 0.9680873985791275\n",
      "Epoch: 4486 - time: 0.0031 - loss_train: 0.794277155008292 - loss_val: 0.9680842514431416\n",
      "Epoch: 4487 - time: 0.0031 - loss_train: 0.794264660900196 - loss_val: 0.9680811002437447\n",
      "Epoch: 4488 - time: 0.0031 - loss_train: 0.7942521716345944 - loss_val: 0.9680779449848057\n",
      "Epoch: 4489 - time: 0.0031 - loss_train: 0.7942396872085674 - loss_val: 0.9680747856701984\n",
      "Epoch: 4490 - time: 0.0032 - loss_train: 0.7942272076191998 - loss_val: 0.9680716223038032\n",
      "Epoch: 4491 - time: 0.0031 - loss_train: 0.7942147328635834 - loss_val: 0.9680684548895097\n",
      "Epoch: 4492 - time: 0.0031 - loss_train: 0.7942022629388152 - loss_val: 0.9680652834312116\n",
      "Epoch: 4493 - time: 0.0031 - loss_train: 0.7941897978419973 - loss_val: 0.9680621079328128\n",
      "Epoch: 4494 - time: 0.0031 - loss_train: 0.7941773375702389 - loss_val: 0.9680589283982203\n",
      "Epoch: 4495 - time: 0.0031 - loss_train: 0.7941648821206536 - loss_val: 0.9680557448313494\n",
      "Epoch: 4496 - time: 0.0031 - loss_train: 0.7941524314903615 - loss_val: 0.9680525572361222\n",
      "Epoch: 4497 - time: 0.0031 - loss_train: 0.7941399856764881 - loss_val: 0.9680493656164688\n",
      "Epoch: 4498 - time: 0.0031 - loss_train: 0.7941275446761646 - loss_val: 0.968046169976323\n",
      "Epoch: 4499 - time: 0.0031 - loss_train: 0.794115108486528 - loss_val: 0.9680429703196266\n",
      "Epoch: 4500 - time: 0.0031 - loss_train: 0.7941026771047214 - loss_val: 0.9680397666503306\n",
      "Epoch: 4501 - time: 0.0031 - loss_train: 0.7940902505278918 - loss_val: 0.9680365589723875\n",
      "Epoch: 4502 - time: 0.0031 - loss_train: 0.7940778287531943 - loss_val: 0.968033347289762\n",
      "Epoch: 4503 - time: 0.0031 - loss_train: 0.794065411777788 - loss_val: 0.9680301316064214\n",
      "Epoch: 4504 - time: 0.0031 - loss_train: 0.7940529995988379 - loss_val: 0.9680269119263405\n",
      "Epoch: 4505 - time: 0.0031 - loss_train: 0.7940405922135149 - loss_val: 0.9680236882535014\n",
      "Epoch: 4506 - time: 0.0031 - loss_train: 0.7940281896189957 - loss_val: 0.9680204605918936\n",
      "Epoch: 4507 - time: 0.0031 - loss_train: 0.7940157918124622 - loss_val: 0.9680172289455093\n",
      "Epoch: 4508 - time: 0.0031 - loss_train: 0.7940033987911019 - loss_val: 0.9680139933183527\n",
      "Epoch: 4509 - time: 0.0031 - loss_train: 0.7939910105521079 - loss_val: 0.9680107537144298\n",
      "Epoch: 4510 - time: 0.0031 - loss_train: 0.7939786270926793 - loss_val: 0.9680075101377562\n",
      "Epoch: 4511 - time: 0.0031 - loss_train: 0.7939662484100202 - loss_val: 0.9680042625923521\n",
      "Epoch: 4512 - time: 0.0031 - loss_train: 0.7939538745013404 - loss_val: 0.9680010110822446\n",
      "Epoch: 4513 - time: 0.0031 - loss_train: 0.7939415053638558 - loss_val: 0.9679977556114673\n",
      "Epoch: 4514 - time: 0.0031 - loss_train: 0.7939291409947868 - loss_val: 0.9679944961840612\n",
      "Epoch: 4515 - time: 0.0031 - loss_train: 0.7939167813913609 - loss_val: 0.9679912328040717\n",
      "Epoch: 4516 - time: 0.0031 - loss_train: 0.7939044265508094 - loss_val: 0.9679879654755521\n",
      "Epoch: 4517 - time: 0.0031 - loss_train: 0.7938920764703696 - loss_val: 0.9679846942025621\n",
      "Epoch: 4518 - time: 0.0031 - loss_train: 0.7938797311472853 - loss_val: 0.9679814189891662\n",
      "Epoch: 4519 - time: 0.0031 - loss_train: 0.7938673905788046 - loss_val: 0.9679781398394373\n",
      "Epoch: 4520 - time: 0.0031 - loss_train: 0.7938550547621817 - loss_val: 0.9679748567574531\n",
      "Epoch: 4521 - time: 0.0031 - loss_train: 0.793842723694676 - loss_val: 0.9679715697472981\n",
      "Epoch: 4522 - time: 0.0031 - loss_train: 0.7938303973735527 - loss_val: 0.9679682788130644\n",
      "Epoch: 4523 - time: 0.0031 - loss_train: 0.7938180757960818 - loss_val: 0.9679649839588464\n",
      "Epoch: 4524 - time: 0.0031 - loss_train: 0.7938057589595396 - loss_val: 0.9679616851887499\n",
      "Epoch: 4525 - time: 0.0031 - loss_train: 0.7937934468612073 - loss_val: 0.9679583825068834\n",
      "Epoch: 4526 - time: 0.0031 - loss_train: 0.7937811394983719 - loss_val: 0.9679550759173623\n",
      "Epoch: 4527 - time: 0.0031 - loss_train: 0.7937688368683253 - loss_val: 0.9679517654243098\n",
      "Epoch: 4528 - time: 0.0032 - loss_train: 0.7937565389683653 - loss_val: 0.9679484510318521\n",
      "Epoch: 4529 - time: 0.0031 - loss_train: 0.7937442457957946 - loss_val: 0.9679451327441245\n",
      "Epoch: 4530 - time: 0.0031 - loss_train: 0.7937319573479215 - loss_val: 0.9679418105652677\n",
      "Epoch: 4531 - time: 0.0031 - loss_train: 0.7937196736220604 - loss_val: 0.9679384844994279\n",
      "Epoch: 4532 - time: 0.0031 - loss_train: 0.7937073946155301 - loss_val: 0.967935154550758\n",
      "Epoch: 4533 - time: 0.0031 - loss_train: 0.7936951203256549 - loss_val: 0.9679318207234155\n",
      "Epoch: 4534 - time: 0.0031 - loss_train: 0.7936828507497646 - loss_val: 0.9679284830215668\n",
      "Epoch: 4535 - time: 0.0031 - loss_train: 0.7936705858851945 - loss_val: 0.9679251414493816\n",
      "Epoch: 4536 - time: 0.0031 - loss_train: 0.7936583257292855 - loss_val: 0.9679217960110373\n",
      "Epoch: 4537 - time: 0.0032 - loss_train: 0.7936460702793833 - loss_val: 0.9679184467107164\n",
      "Epoch: 4538 - time: 0.0043 - loss_train: 0.7936338195328387 - loss_val: 0.9679150935526097\n",
      "Epoch: 4539 - time: 0.0036 - loss_train: 0.7936215734870087 - loss_val: 0.9679117365409092\n",
      "Epoch: 4540 - time: 0.0031 - loss_train: 0.7936093321392549 - loss_val: 0.9679083756798171\n",
      "Epoch: 4541 - time: 0.0031 - loss_train: 0.7935970954869442 - loss_val: 0.9679050109735411\n",
      "Epoch: 4542 - time: 0.0031 - loss_train: 0.7935848635274494 - loss_val: 0.9679016424262934\n",
      "Epoch: 4543 - time: 0.0031 - loss_train: 0.7935726362581474 - loss_val: 0.9678982700422918\n",
      "Epoch: 4544 - time: 0.0031 - loss_train: 0.7935604136764222 - loss_val: 0.9678948938257618\n",
      "Epoch: 4545 - time: 0.0031 - loss_train: 0.7935481957796611 - loss_val: 0.9678915137809343\n",
      "Epoch: 4546 - time: 0.0031 - loss_train: 0.7935359825652578 - loss_val: 0.9678881299120441\n",
      "Epoch: 4547 - time: 0.0031 - loss_train: 0.7935237740306108 - loss_val: 0.9678847422233346\n",
      "Epoch: 4548 - time: 0.0031 - loss_train: 0.7935115701731241 - loss_val: 0.9678813507190543\n",
      "Epoch: 4549 - time: 0.0031 - loss_train: 0.7934993709902064 - loss_val: 0.967877955403456\n",
      "Epoch: 4550 - time: 0.0031 - loss_train: 0.7934871764792729 - loss_val: 0.9678745562808007\n",
      "Epoch: 4551 - time: 0.0031 - loss_train: 0.7934749866377422 - loss_val: 0.9678711533553523\n",
      "Epoch: 4552 - time: 0.0031 - loss_train: 0.7934628014630393 - loss_val: 0.9678677466313832\n",
      "Epoch: 4553 - time: 0.0031 - loss_train: 0.7934506209525937 - loss_val: 0.9678643361131706\n",
      "Epoch: 4554 - time: 0.0031 - loss_train: 0.7934384451038407 - loss_val: 0.9678609218049968\n",
      "Epoch: 4555 - time: 0.0031 - loss_train: 0.7934262739142209 - loss_val: 0.9678575037111494\n",
      "Epoch: 4556 - time: 0.0031 - loss_train: 0.7934141073811793 - loss_val: 0.9678540818359245\n",
      "Epoch: 4557 - time: 0.0031 - loss_train: 0.7934019455021664 - loss_val: 0.9678506561836209\n",
      "Epoch: 4558 - time: 0.0031 - loss_train: 0.7933897882746374 - loss_val: 0.9678472267585442\n",
      "Epoch: 4559 - time: 0.0031 - loss_train: 0.7933776356960534 - loss_val: 0.9678437935650056\n",
      "Epoch: 4560 - time: 0.0031 - loss_train: 0.7933654877638805 - loss_val: 0.9678403566073223\n",
      "Epoch: 4561 - time: 0.0031 - loss_train: 0.7933533444755893 - loss_val: 0.9678369158898165\n",
      "Epoch: 4562 - time: 0.0031 - loss_train: 0.7933412058286557 - loss_val: 0.9678334714168165\n",
      "Epoch: 4563 - time: 0.0031 - loss_train: 0.7933290718205611 - loss_val: 0.9678300231926569\n",
      "Epoch: 4564 - time: 0.0031 - loss_train: 0.7933169424487923 - loss_val: 0.9678265712216756\n",
      "Epoch: 4565 - time: 0.0033 - loss_train: 0.7933048177108394 - loss_val: 0.9678231155082169\n",
      "Epoch: 4566 - time: 0.0031 - loss_train: 0.7932926976041997 - loss_val: 0.9678196560566339\n",
      "Epoch: 4567 - time: 0.0031 - loss_train: 0.7932805821263744 - loss_val: 0.9678161928712807\n",
      "Epoch: 4568 - time: 0.0031 - loss_train: 0.7932684712748694 - loss_val: 0.9678127259565185\n",
      "Epoch: 4569 - time: 0.0031 - loss_train: 0.7932563650471971 - loss_val: 0.9678092553167142\n",
      "Epoch: 4570 - time: 0.0031 - loss_train: 0.7932442634408731 - loss_val: 0.967805780956242\n",
      "Epoch: 4571 - time: 0.0031 - loss_train: 0.7932321664534195 - loss_val: 0.9678023028794775\n",
      "Epoch: 4572 - time: 0.0031 - loss_train: 0.7932200740823622 - loss_val: 0.9677988210908065\n",
      "Epoch: 4573 - time: 0.0031 - loss_train: 0.7932079863252336 - loss_val: 0.9677953355946147\n",
      "Epoch: 4574 - time: 0.0031 - loss_train: 0.7931959031795696 - loss_val: 0.9677918463952984\n",
      "Epoch: 4575 - time: 0.0031 - loss_train: 0.7931838246429119 - loss_val: 0.967788353497257\n",
      "Epoch: 4576 - time: 0.0031 - loss_train: 0.7931717507128064 - loss_val: 0.9677848569048947\n",
      "Epoch: 4577 - time: 0.0031 - loss_train: 0.7931596813868057 - loss_val: 0.9677813566226231\n",
      "Epoch: 4578 - time: 0.0031 - loss_train: 0.7931476166624648 - loss_val: 0.9677778526548572\n",
      "Epoch: 4579 - time: 0.0031 - loss_train: 0.7931355565373456 - loss_val: 0.9677743450060169\n",
      "Epoch: 4580 - time: 0.0031 - loss_train: 0.793123501009015 - loss_val: 0.9677708336805306\n",
      "Epoch: 4581 - time: 0.0031 - loss_train: 0.7931114500750429 - loss_val: 0.9677673186828285\n",
      "Epoch: 4582 - time: 0.0032 - loss_train: 0.7930994037330062 - loss_val: 0.9677638000173486\n",
      "Epoch: 4583 - time: 0.0031 - loss_train: 0.7930873619804857 - loss_val: 0.9677602776885318\n",
      "Epoch: 4584 - time: 0.0031 - loss_train: 0.793075324815067 - loss_val: 0.9677567517008268\n",
      "Epoch: 4585 - time: 0.0031 - loss_train: 0.7930632922343409 - loss_val: 0.9677532220586859\n",
      "Epoch: 4586 - time: 0.0031 - loss_train: 0.7930512642359037 - loss_val: 0.9677496887665664\n",
      "Epoch: 4587 - time: 0.0031 - loss_train: 0.7930392408173548 - loss_val: 0.9677461518289324\n",
      "Epoch: 4588 - time: 0.0031 - loss_train: 0.7930272219763004 - loss_val: 0.9677426112502511\n",
      "Epoch: 4589 - time: 0.0031 - loss_train: 0.7930152077103504 - loss_val: 0.9677390670349971\n",
      "Epoch: 4590 - time: 0.0031 - loss_train: 0.7930031980171196 - loss_val: 0.9677355191876496\n",
      "Epoch: 4591 - time: 0.0031 - loss_train: 0.7929911928942284 - loss_val: 0.9677319677126907\n",
      "Epoch: 4592 - time: 0.0031 - loss_train: 0.7929791923393014 - loss_val: 0.9677284126146098\n",
      "Epoch: 4593 - time: 0.0031 - loss_train: 0.792967196349967 - loss_val: 0.9677248538979012\n",
      "Epoch: 4594 - time: 0.0031 - loss_train: 0.7929552049238612 - loss_val: 0.9677212915670653\n",
      "Epoch: 4595 - time: 0.0031 - loss_train: 0.792943218058622 - loss_val: 0.9677177256266046\n",
      "Epoch: 4596 - time: 0.0031 - loss_train: 0.7929312357518942 - loss_val: 0.9677141560810281\n",
      "Epoch: 4597 - time: 0.0031 - loss_train: 0.7929192580013251 - loss_val: 0.967710582934852\n",
      "Epoch: 4598 - time: 0.0031 - loss_train: 0.7929072848045691 - loss_val: 0.9677070061925942\n",
      "Epoch: 4599 - time: 0.0031 - loss_train: 0.7928953161592844 - loss_val: 0.9677034258587798\n",
      "Epoch: 4600 - time: 0.0031 - loss_train: 0.7928833520631335 - loss_val: 0.9676998419379377\n",
      "Epoch: 4601 - time: 0.0031 - loss_train: 0.7928713925137845 - loss_val: 0.9676962544346038\n",
      "Epoch: 4602 - time: 0.0031 - loss_train: 0.7928594375089096 - loss_val: 0.9676926633533145\n",
      "Epoch: 4603 - time: 0.0032 - loss_train: 0.7928474870461861 - loss_val: 0.9676890686986168\n",
      "Epoch: 4604 - time: 0.0031 - loss_train: 0.7928355411232955 - loss_val: 0.9676854704750584\n",
      "Epoch: 4605 - time: 0.0031 - loss_train: 0.7928235997379243 - loss_val: 0.9676818686871945\n",
      "Epoch: 4606 - time: 0.0032 - loss_train: 0.7928116628877642 - loss_val: 0.9676782633395834\n",
      "Epoch: 4607 - time: 0.0031 - loss_train: 0.792799730570511 - loss_val: 0.9676746544367895\n",
      "Epoch: 4608 - time: 0.0031 - loss_train: 0.7927878027838648 - loss_val: 0.9676710419833807\n",
      "Epoch: 4609 - time: 0.0032 - loss_train: 0.7927758795255315 - loss_val: 0.9676674259839327\n",
      "Epoch: 4610 - time: 0.0031 - loss_train: 0.7927639607932209 - loss_val: 0.967663806443022\n",
      "Epoch: 4611 - time: 0.0031 - loss_train: 0.7927520465846475 - loss_val: 0.9676601833652335\n",
      "Epoch: 4612 - time: 0.0031 - loss_train: 0.7927401368975303 - loss_val: 0.967656556755154\n",
      "Epoch: 4613 - time: 0.0031 - loss_train: 0.7927282317295933 - loss_val: 0.9676529266173779\n",
      "Epoch: 4614 - time: 0.0031 - loss_train: 0.7927163310785654 - loss_val: 0.9676492929565023\n",
      "Epoch: 4615 - time: 0.0031 - loss_train: 0.7927044349421788 - loss_val: 0.9676456557771291\n",
      "Epoch: 4616 - time: 0.0031 - loss_train: 0.7926925433181717 - loss_val: 0.9676420150838667\n",
      "Epoch: 4617 - time: 0.0031 - loss_train: 0.7926806562042864 - loss_val: 0.9676383708813263\n",
      "Epoch: 4618 - time: 0.0031 - loss_train: 0.7926687735982696 - loss_val: 0.967634723174125\n",
      "Epoch: 4619 - time: 0.0031 - loss_train: 0.7926568954978732 - loss_val: 0.9676310719668845\n",
      "Epoch: 4620 - time: 0.0031 - loss_train: 0.7926450219008524 - loss_val: 0.9676274172642306\n",
      "Epoch: 4621 - time: 0.0031 - loss_train: 0.7926331528049684 - loss_val: 0.967623759070794\n",
      "Epoch: 4622 - time: 0.0031 - loss_train: 0.792621288207986 - loss_val: 0.9676200973912101\n",
      "Epoch: 4623 - time: 0.0031 - loss_train: 0.7926094281076753 - loss_val: 0.9676164322301195\n",
      "Epoch: 4624 - time: 0.0031 - loss_train: 0.7925975725018097 - loss_val: 0.9676127635921675\n",
      "Epoch: 4625 - time: 0.0031 - loss_train: 0.7925857213881686 - loss_val: 0.967609091482002\n",
      "Epoch: 4626 - time: 0.0031 - loss_train: 0.7925738747645352 - loss_val: 0.9676054159042778\n",
      "Epoch: 4627 - time: 0.0031 - loss_train: 0.7925620326286966 - loss_val: 0.9676017368636528\n",
      "Epoch: 4628 - time: 0.0031 - loss_train: 0.7925501949784457 - loss_val: 0.9675980543647904\n",
      "Epoch: 4629 - time: 0.0031 - loss_train: 0.792538361811579 - loss_val: 0.9675943684123595\n",
      "Epoch: 4630 - time: 0.0031 - loss_train: 0.7925265331258975 - loss_val: 0.9675906790110299\n",
      "Epoch: 4631 - time: 0.0035 - loss_train: 0.7925147089192073 - loss_val: 0.9675869861654799\n",
      "Epoch: 4632 - time: 0.0032 - loss_train: 0.7925028891893178 - loss_val: 0.967583289880391\n",
      "Epoch: 4633 - time: 0.0031 - loss_train: 0.7924910739340439 - loss_val: 0.9675795901604476\n",
      "Epoch: 4634 - time: 0.0031 - loss_train: 0.792479263151205 - loss_val: 0.967575887010341\n",
      "Epoch: 4635 - time: 0.0031 - loss_train: 0.792467456838624 - loss_val: 0.9675721804347647\n",
      "Epoch: 4636 - time: 0.0031 - loss_train: 0.792455654994129 - loss_val: 0.9675684704384189\n",
      "Epoch: 4637 - time: 0.0031 - loss_train: 0.7924438576155519 - loss_val: 0.9675647570260069\n",
      "Epoch: 4638 - time: 0.0031 - loss_train: 0.7924320647007302 - loss_val: 0.9675610402022355\n",
      "Epoch: 4639 - time: 0.0031 - loss_train: 0.7924202762475043 - loss_val: 0.9675573199718179\n",
      "Epoch: 4640 - time: 0.0034 - loss_train: 0.7924084922537201 - loss_val: 0.9675535963394719\n",
      "Epoch: 4641 - time: 0.0032 - loss_train: 0.792396712717227 - loss_val: 0.9675498693099162\n",
      "Epoch: 4642 - time: 0.0031 - loss_train: 0.7923849376358791 - loss_val: 0.9675461388878773\n",
      "Epoch: 4643 - time: 0.0031 - loss_train: 0.7923731670075355 - loss_val: 0.9675424050780854\n",
      "Epoch: 4644 - time: 0.0031 - loss_train: 0.7923614008300593 - loss_val: 0.9675386678852742\n",
      "Epoch: 4645 - time: 0.0031 - loss_train: 0.7923496391013171 - loss_val: 0.967534927314182\n",
      "Epoch: 4646 - time: 0.0031 - loss_train: 0.7923378818191809 - loss_val: 0.9675311833695514\n",
      "Epoch: 4647 - time: 0.0031 - loss_train: 0.7923261289815264 - loss_val: 0.96752743605613\n",
      "Epoch: 4648 - time: 0.0031 - loss_train: 0.7923143805862338 - loss_val: 0.967523685378668\n",
      "Epoch: 4649 - time: 0.0031 - loss_train: 0.7923026366311883 - loss_val: 0.9675199313419214\n",
      "Epoch: 4650 - time: 0.0031 - loss_train: 0.7922908971142778 - loss_val: 0.967516173950649\n",
      "Epoch: 4651 - time: 0.0031 - loss_train: 0.7922791620333959 - loss_val: 0.9675124132096166\n",
      "Epoch: 4652 - time: 0.0031 - loss_train: 0.7922674313864402 - loss_val: 0.9675086491235906\n",
      "Epoch: 4653 - time: 0.0031 - loss_train: 0.792255705171312 - loss_val: 0.9675048816973433\n",
      "Epoch: 4654 - time: 0.0031 - loss_train: 0.7922439833859178 - loss_val: 0.9675011109356518\n",
      "Epoch: 4655 - time: 0.0031 - loss_train: 0.7922322660281672 - loss_val: 0.967497336843297\n",
      "Epoch: 4656 - time: 0.0031 - loss_train: 0.7922205530959749 - loss_val: 0.9674935594250627\n",
      "Epoch: 4657 - time: 0.0031 - loss_train: 0.79220884458726 - loss_val: 0.9674897786857379\n",
      "Epoch: 4658 - time: 0.0031 - loss_train: 0.7921971404999446 - loss_val: 0.9674859946301164\n",
      "Epoch: 4659 - time: 0.0031 - loss_train: 0.7921854408319567 - loss_val: 0.9674822072629946\n",
      "Epoch: 4660 - time: 0.0031 - loss_train: 0.792173745581227 - loss_val: 0.9674784165891738\n",
      "Epoch: 4661 - time: 0.0031 - loss_train: 0.792162054745691 - loss_val: 0.9674746226134595\n",
      "Epoch: 4662 - time: 0.0031 - loss_train: 0.7921503683232889 - loss_val: 0.9674708253406605\n",
      "Epoch: 4663 - time: 0.0031 - loss_train: 0.7921386863119647 - loss_val: 0.9674670247755899\n",
      "Epoch: 4664 - time: 0.0031 - loss_train: 0.7921270087096659 - loss_val: 0.9674632209230662\n",
      "Epoch: 4665 - time: 0.0031 - loss_train: 0.7921153355143451 - loss_val: 0.9674594137879087\n",
      "Epoch: 4666 - time: 0.0031 - loss_train: 0.7921036667239589 - loss_val: 0.967455603374945\n",
      "Epoch: 4667 - time: 0.0031 - loss_train: 0.7920920023364671 - loss_val: 0.9674517896890018\n",
      "Epoch: 4668 - time: 0.0031 - loss_train: 0.7920803423498357 - loss_val: 0.9674479727349143\n",
      "Epoch: 4669 - time: 0.0031 - loss_train: 0.7920686867620328 - loss_val: 0.9674441525175199\n",
      "Epoch: 4670 - time: 0.0031 - loss_train: 0.7920570355710308 - loss_val: 0.9674403290416582\n",
      "Epoch: 4671 - time: 0.0031 - loss_train: 0.792045388774808 - loss_val: 0.9674365023121757\n",
      "Epoch: 4672 - time: 0.0031 - loss_train: 0.7920337463713443 - loss_val: 0.9674326723339199\n",
      "Epoch: 4673 - time: 0.0031 - loss_train: 0.792022108358626 - loss_val: 0.9674288391117447\n",
      "Epoch: 4674 - time: 0.0031 - loss_train: 0.7920104747346416 - loss_val: 0.9674250026505062\n",
      "Epoch: 4675 - time: 0.0031 - loss_train: 0.7919988454973852 - loss_val: 0.9674211629550662\n",
      "Epoch: 4676 - time: 0.0031 - loss_train: 0.7919872206448543 - loss_val: 0.9674173200302874\n",
      "Epoch: 4677 - time: 0.0031 - loss_train: 0.7919756001750496 - loss_val: 0.9674134738810379\n",
      "Epoch: 4678 - time: 0.0031 - loss_train: 0.7919639840859779 - loss_val: 0.9674096245121911\n",
      "Epoch: 4679 - time: 0.0032 - loss_train: 0.7919523723756479 - loss_val: 0.9674057719286222\n",
      "Epoch: 4680 - time: 0.0031 - loss_train: 0.7919407650420743 - loss_val: 0.9674019161352113\n",
      "Epoch: 4681 - time: 0.0031 - loss_train: 0.7919291620832736 - loss_val: 0.9673980571368413\n",
      "Epoch: 4682 - time: 0.0031 - loss_train: 0.7919175634972683 - loss_val: 0.9673941949383991\n",
      "Epoch: 4683 - time: 0.0031 - loss_train: 0.791905969282084 - loss_val: 0.9673903295447754\n",
      "Epoch: 4684 - time: 0.0031 - loss_train: 0.7918943794357505 - loss_val: 0.9673864609608659\n",
      "Epoch: 4685 - time: 0.0031 - loss_train: 0.791882793956301 - loss_val: 0.9673825891915667\n",
      "Epoch: 4686 - time: 0.0031 - loss_train: 0.7918712128417742 - loss_val: 0.9673787142417826\n",
      "Epoch: 4687 - time: 0.0031 - loss_train: 0.791859636090211 - loss_val: 0.9673748361164175\n",
      "Epoch: 4688 - time: 0.0031 - loss_train: 0.7918480636996571 - loss_val: 0.9673709548203808\n",
      "Epoch: 4689 - time: 0.0031 - loss_train: 0.7918364956681627 - loss_val: 0.9673670703585865\n",
      "Epoch: 4690 - time: 0.0031 - loss_train: 0.7918249319937805 - loss_val: 0.9673631827359502\n",
      "Epoch: 4691 - time: 0.0031 - loss_train: 0.7918133726745684 - loss_val: 0.9673592919573932\n",
      "Epoch: 4692 - time: 0.0031 - loss_train: 0.7918018177085877 - loss_val: 0.9673553980278373\n",
      "Epoch: 4693 - time: 0.0031 - loss_train: 0.7917902670939043 - loss_val: 0.9673515009522117\n",
      "Epoch: 4694 - time: 0.0031 - loss_train: 0.7917787208285868 - loss_val: 0.967347600735447\n",
      "Epoch: 4695 - time: 0.0031 - loss_train: 0.7917671789107082 - loss_val: 0.9673436973824774\n",
      "Epoch: 4696 - time: 0.0031 - loss_train: 0.7917556413383461 - loss_val: 0.9673397908982422\n",
      "Epoch: 4697 - time: 0.0031 - loss_train: 0.7917441081095811 - loss_val: 0.9673358812876817\n",
      "Epoch: 4698 - time: 0.0031 - loss_train: 0.7917325792224985 - loss_val: 0.9673319685557412\n",
      "Epoch: 4699 - time: 0.0031 - loss_train: 0.7917210546751865 - loss_val: 0.9673280527073695\n",
      "Epoch: 4700 - time: 0.0031 - loss_train: 0.7917095344657374 - loss_val: 0.96732413374752\n",
      "Epoch: 4701 - time: 0.0031 - loss_train: 0.7916980185922479 - loss_val: 0.9673202116811463\n",
      "Epoch: 4702 - time: 0.0031 - loss_train: 0.7916865070528187 - loss_val: 0.9673162865132094\n",
      "Epoch: 4703 - time: 0.0031 - loss_train: 0.791674999845553 - loss_val: 0.96731235824867\n",
      "Epoch: 4704 - time: 0.0031 - loss_train: 0.7916634969685592 - loss_val: 0.9673084268924952\n",
      "Epoch: 4705 - time: 0.0031 - loss_train: 0.791651998419949 - loss_val: 0.9673044924496541\n",
      "Epoch: 4706 - time: 0.0031 - loss_train: 0.7916405041978376 - loss_val: 0.96730055492512\n",
      "Epoch: 4707 - time: 0.0031 - loss_train: 0.791629014300345 - loss_val: 0.967296614323869\n",
      "Epoch: 4708 - time: 0.0031 - loss_train: 0.7916175287255933 - loss_val: 0.9672926706508794\n",
      "Epoch: 4709 - time: 0.0031 - loss_train: 0.7916060474717102 - loss_val: 0.9672887239111362\n",
      "Epoch: 4710 - time: 0.0031 - loss_train: 0.7915945705368262 - loss_val: 0.9672847741096234\n",
      "Epoch: 4711 - time: 0.0031 - loss_train: 0.7915830979190756 - loss_val: 0.9672808212513323\n",
      "Epoch: 4712 - time: 0.0044 - loss_train: 0.7915716296165963 - loss_val: 0.9672768653412546\n",
      "Epoch: 4713 - time: 0.0043 - loss_train: 0.7915601656275311 - loss_val: 0.9672729063843871\n",
      "Epoch: 4714 - time: 0.0044 - loss_train: 0.7915487059500245 - loss_val: 0.9672689443857295\n",
      "Epoch: 4715 - time: 0.0048 - loss_train: 0.7915372505822268 - loss_val: 0.967264979350284\n",
      "Epoch: 4716 - time: 0.0044 - loss_train: 0.7915257995222907 - loss_val: 0.9672610112830571\n",
      "Epoch: 4717 - time: 0.0043 - loss_train: 0.7915143527683733 - loss_val: 0.9672570401890572\n",
      "Epoch: 4718 - time: 0.0045 - loss_train: 0.7915029103186353 - loss_val: 0.9672530660732984\n",
      "Epoch: 4719 - time: 0.0045 - loss_train: 0.7914914721712403 - loss_val: 0.9672490889407956\n",
      "Epoch: 4720 - time: 0.0045 - loss_train: 0.7914800383243566 - loss_val: 0.9672451087965669\n",
      "Epoch: 4721 - time: 0.0045 - loss_train: 0.7914686087761559 - loss_val: 0.9672411256456352\n",
      "Epoch: 4722 - time: 0.0045 - loss_train: 0.7914571835248134 - loss_val: 0.967237139493026\n",
      "Epoch: 4723 - time: 0.0044 - loss_train: 0.7914457625685078 - loss_val: 0.9672331503437663\n",
      "Epoch: 4724 - time: 0.0043 - loss_train: 0.7914343459054226 - loss_val: 0.9672291582028895\n",
      "Epoch: 4725 - time: 0.0037 - loss_train: 0.7914229335337427 - loss_val: 0.9672251630754298\n",
      "Epoch: 4726 - time: 0.0038 - loss_train: 0.7914115254516588 - loss_val: 0.9672211649664244\n",
      "Epoch: 4727 - time: 0.0038 - loss_train: 0.7914001216573647 - loss_val: 0.9672171638809139\n",
      "Epoch: 4728 - time: 0.0038 - loss_train: 0.7913887221490568 - loss_val: 0.9672131598239427\n",
      "Epoch: 4729 - time: 0.0038 - loss_train: 0.7913773269249363 - loss_val: 0.9672091528005586\n",
      "Epoch: 4730 - time: 0.0038 - loss_train: 0.7913659359832074 - loss_val: 0.9672051428158116\n",
      "Epoch: 4731 - time: 0.0038 - loss_train: 0.7913545493220779 - loss_val: 0.967201129874754\n",
      "Epoch: 4732 - time: 0.0038 - loss_train: 0.7913431669397599 - loss_val: 0.9671971139824417\n",
      "Epoch: 4733 - time: 0.0038 - loss_train: 0.7913317888344674 - loss_val: 0.9671930951439357\n",
      "Epoch: 4734 - time: 0.0038 - loss_train: 0.7913204150044204 - loss_val: 0.9671890733642974\n",
      "Epoch: 4735 - time: 0.0041 - loss_train: 0.7913090454478405 - loss_val: 0.9671850486485899\n",
      "Epoch: 4736 - time: 0.0035 - loss_train: 0.7912976801629533 - loss_val: 0.9671810210018856\n",
      "Epoch: 4737 - time: 0.0035 - loss_train: 0.7912863191479886 - loss_val: 0.9671769904292511\n",
      "Epoch: 4738 - time: 0.0035 - loss_train: 0.7912749624011788 - loss_val: 0.9671729569357636\n",
      "Epoch: 4739 - time: 0.0038 - loss_train: 0.7912636099207606 - loss_val: 0.9671689205264994\n",
      "Epoch: 4740 - time: 0.0039 - loss_train: 0.791252261704974 - loss_val: 0.9671648812065377\n",
      "Epoch: 4741 - time: 0.0039 - loss_train: 0.7912409177520622 - loss_val: 0.9671608389809612\n",
      "Epoch: 4742 - time: 0.0038 - loss_train: 0.791229578060272 - loss_val: 0.9671567938548568\n",
      "Epoch: 4743 - time: 0.0031 - loss_train: 0.7912182426278541 - loss_val: 0.9671527458333119\n",
      "Epoch: 4744 - time: 0.0031 - loss_train: 0.7912069114530627 - loss_val: 0.9671486949214188\n",
      "Epoch: 4745 - time: 0.0031 - loss_train: 0.7911955845341548 - loss_val: 0.9671446411242718\n",
      "Epoch: 4746 - time: 0.0033 - loss_train: 0.7911842618693913 - loss_val: 0.9671405844469677\n",
      "Epoch: 4747 - time: 0.0031 - loss_train: 0.7911729434570363 - loss_val: 0.9671365248946056\n",
      "Epoch: 4748 - time: 0.0031 - loss_train: 0.791161629295358 - loss_val: 0.9671324624722892\n",
      "Epoch: 4749 - time: 0.0031 - loss_train: 0.7911503193826277 - loss_val: 0.9671283971851237\n",
      "Epoch: 4750 - time: 0.0031 - loss_train: 0.7911390137171195 - loss_val: 0.967124329038218\n",
      "Epoch: 4751 - time: 0.0031 - loss_train: 0.7911277122971119 - loss_val: 0.9671202580366823\n",
      "Epoch: 4752 - time: 0.0031 - loss_train: 0.7911164151208863 - loss_val: 0.9671161841856304\n",
      "Epoch: 4753 - time: 0.0031 - loss_train: 0.7911051221867273 - loss_val: 0.9671121074901797\n",
      "Epoch: 4754 - time: 0.0031 - loss_train: 0.7910938334929238 - loss_val: 0.9671080279554495\n",
      "Epoch: 4755 - time: 0.0031 - loss_train: 0.7910825490377671 - loss_val: 0.9671039455865602\n",
      "Epoch: 4756 - time: 0.0031 - loss_train: 0.7910712688195527 - loss_val: 0.9670998603886378\n",
      "Epoch: 4757 - time: 0.0031 - loss_train: 0.7910599928365784 - loss_val: 0.9670957723668089\n",
      "Epoch: 4758 - time: 0.0031 - loss_train: 0.7910487210871467 - loss_val: 0.9670916815262044\n",
      "Epoch: 4759 - time: 0.0031 - loss_train: 0.7910374535695626 - loss_val: 0.9670875878719568\n",
      "Epoch: 4760 - time: 0.0031 - loss_train: 0.7910261902821342 - loss_val: 0.9670834914092009\n",
      "Epoch: 4761 - time: 0.0031 - loss_train: 0.791014931223174 - loss_val: 0.9670793921430735\n",
      "Epoch: 4762 - time: 0.0031 - loss_train: 0.7910036763909968 - loss_val: 0.9670752900787174\n",
      "Epoch: 4763 - time: 0.0031 - loss_train: 0.7909924257839215 - loss_val: 0.9670711852212746\n",
      "Epoch: 4764 - time: 0.0031 - loss_train: 0.7909811794002701 - loss_val: 0.9670670775758904\n",
      "Epoch: 4765 - time: 0.0031 - loss_train: 0.7909699372383672 - loss_val: 0.9670629671477133\n",
      "Epoch: 4766 - time: 0.0031 - loss_train: 0.7909586992965415 - loss_val: 0.9670588539418943\n",
      "Epoch: 4767 - time: 0.0031 - loss_train: 0.7909474655731255 - loss_val: 0.9670547379635869\n",
      "Epoch: 4768 - time: 0.0031 - loss_train: 0.7909362360664535 - loss_val: 0.9670506192179461\n",
      "Epoch: 4769 - time: 0.0031 - loss_train: 0.7909250107748635 - loss_val: 0.9670464977101315\n",
      "Epoch: 4770 - time: 0.0031 - loss_train: 0.7909137896966983 - loss_val: 0.9670423734453035\n",
      "Epoch: 4771 - time: 0.0031 - loss_train: 0.790902572830302 - loss_val: 0.9670382464286241\n",
      "Epoch: 4772 - time: 0.0031 - loss_train: 0.790891360174023 - loss_val: 0.9670341166652604\n",
      "Epoch: 4773 - time: 0.0031 - loss_train: 0.7908801517262123 - loss_val: 0.9670299841603808\n",
      "Epoch: 4774 - time: 0.0031 - loss_train: 0.790868947485225 - loss_val: 0.9670258489191552\n",
      "Epoch: 4775 - time: 0.0031 - loss_train: 0.7908577474494185 - loss_val: 0.9670217109467577\n",
      "Epoch: 4776 - time: 0.0031 - loss_train: 0.7908465516171543 - loss_val: 0.967017570248363\n",
      "Epoch: 4777 - time: 0.0031 - loss_train: 0.7908353599867963 - loss_val: 0.9670134268291493\n",
      "Epoch: 4778 - time: 0.0031 - loss_train: 0.7908241725567127 - loss_val: 0.9670092806942978\n",
      "Epoch: 4779 - time: 0.0031 - loss_train: 0.7908129893252734 - loss_val: 0.9670051318489891\n",
      "Epoch: 4780 - time: 0.0031 - loss_train: 0.7908018102908525 - loss_val: 0.9670009802984098\n",
      "Epoch: 4781 - time: 0.0031 - loss_train: 0.7907906354518269 - loss_val: 0.9669968260477474\n",
      "Epoch: 4782 - time: 0.0031 - loss_train: 0.7907794648065771 - loss_val: 0.9669926691021911\n",
      "Epoch: 4783 - time: 0.0035 - loss_train: 0.7907682983534869 - loss_val: 0.9669885094669326\n",
      "Epoch: 4784 - time: 0.0032 - loss_train: 0.7907571360909419 - loss_val: 0.9669843471471667\n",
      "Epoch: 4785 - time: 0.0031 - loss_train: 0.790745978017332 - loss_val: 0.9669801821480903\n",
      "Epoch: 4786 - time: 0.0031 - loss_train: 0.7907348241310507 - loss_val: 0.9669760144749021\n",
      "Epoch: 4787 - time: 0.0031 - loss_train: 0.7907236744304931 - loss_val: 0.9669718441328028\n",
      "Epoch: 4788 - time: 0.0031 - loss_train: 0.7907125289140591 - loss_val: 0.9669676711269959\n",
      "Epoch: 4789 - time: 0.0031 - loss_train: 0.79070138758015 - loss_val: 0.9669634954626875\n",
      "Epoch: 4790 - time: 0.0031 - loss_train: 0.7906902504271718 - loss_val: 0.9669593171450853\n",
      "Epoch: 4791 - time: 0.0031 - loss_train: 0.7906791174535327 - loss_val: 0.9669551361793988\n",
      "Epoch: 4792 - time: 0.0031 - loss_train: 0.7906679886576444 - loss_val: 0.9669509525708413\n",
      "Epoch: 4793 - time: 0.0031 - loss_train: 0.7906568640379208 - loss_val: 0.9669467663246267\n",
      "Epoch: 4794 - time: 0.0031 - loss_train: 0.7906457435927798 - loss_val: 0.9669425774459711\n",
      "Epoch: 4795 - time: 0.0031 - loss_train: 0.7906346273206427 - loss_val: 0.9669383859400946\n",
      "Epoch: 4796 - time: 0.0031 - loss_train: 0.7906235152199329 - loss_val: 0.9669341918122171\n",
      "Epoch: 4797 - time: 0.0031 - loss_train: 0.7906124072890768 - loss_val: 0.9669299950675604\n",
      "Epoch: 4798 - time: 0.0031 - loss_train: 0.7906013035265046 - loss_val: 0.9669257957113515\n",
      "Epoch: 4799 - time: 0.0031 - loss_train: 0.7905902039306496 - loss_val: 0.9669215937488171\n",
      "Epoch: 4800 - time: 0.0031 - loss_train: 0.7905791084999472 - loss_val: 0.9669173891851867\n",
      "Epoch: 4801 - time: 0.0031 - loss_train: 0.7905680172328364 - loss_val: 0.9669131820256914\n",
      "Epoch: 4802 - time: 0.0031 - loss_train: 0.7905569301277589 - loss_val: 0.966908972275564\n",
      "Epoch: 4803 - time: 0.0031 - loss_train: 0.7905458471831602 - loss_val: 0.9669047599400412\n",
      "Epoch: 4804 - time: 0.0031 - loss_train: 0.7905347683974878 - loss_val: 0.9669005450243596\n",
      "Epoch: 4805 - time: 0.0031 - loss_train: 0.790523693769193 - loss_val: 0.9668963275337583\n",
      "Epoch: 4806 - time: 0.0031 - loss_train: 0.7905126232967293 - loss_val: 0.9668921074734799\n",
      "Epoch: 4807 - time: 0.0031 - loss_train: 0.790501556978554 - loss_val: 0.9668878848487672\n",
      "Epoch: 4808 - time: 0.0031 - loss_train: 0.7904904948131263 - loss_val: 0.9668836596648669\n",
      "Epoch: 4809 - time: 0.0031 - loss_train: 0.7904794367989095 - loss_val: 0.9668794319270244\n",
      "Epoch: 4810 - time: 0.0035 - loss_train: 0.7904683829343694 - loss_val: 0.9668752016404899\n",
      "Epoch: 4811 - time: 0.0035 - loss_train: 0.7904573332179741 - loss_val: 0.966870968810515\n",
      "Epoch: 4812 - time: 0.0031 - loss_train: 0.7904462876481957 - loss_val: 0.9668667334423529\n",
      "Epoch: 4813 - time: 0.0031 - loss_train: 0.7904352462235088 - loss_val: 0.9668624955412588\n",
      "Epoch: 4814 - time: 0.0031 - loss_train: 0.79042420894239 - loss_val: 0.9668582551124894\n",
      "Epoch: 4815 - time: 0.0031 - loss_train: 0.7904131758033204 - loss_val: 0.9668540121613036\n",
      "Epoch: 4816 - time: 0.0031 - loss_train: 0.7904021468047833 - loss_val: 0.9668497666929623\n",
      "Epoch: 4817 - time: 0.0031 - loss_train: 0.7903911219452638 - loss_val: 0.9668455187127278\n",
      "Epoch: 4818 - time: 0.0031 - loss_train: 0.7903801012232524 - loss_val: 0.9668412682258646\n",
      "Epoch: 4819 - time: 0.0031 - loss_train: 0.7903690846372399 - loss_val: 0.966837015237639\n",
      "Epoch: 4820 - time: 0.0031 - loss_train: 0.7903580721857211 - loss_val: 0.9668327597533195\n",
      "Epoch: 4821 - time: 0.0036 - loss_train: 0.7903470638671938 - loss_val: 0.966828501778176\n",
      "Epoch: 4822 - time: 0.0032 - loss_train: 0.7903360596801585 - loss_val: 0.9668242413174799\n",
      "Epoch: 4823 - time: 0.0031 - loss_train: 0.7903250596231184 - loss_val: 0.9668199783765035\n",
      "Epoch: 4824 - time: 0.0031 - loss_train: 0.7903140636945798 - loss_val: 0.9668157129605235\n",
      "Epoch: 4825 - time: 0.0031 - loss_train: 0.790303071893051 - loss_val: 0.9668114450748166\n",
      "Epoch: 4826 - time: 0.0031 - loss_train: 0.7902920842170442 - loss_val: 0.9668071747246607\n",
      "Epoch: 4827 - time: 0.0031 - loss_train: 0.7902811006650741 - loss_val: 0.9668029019153369\n",
      "Epoch: 4828 - time: 0.0031 - loss_train: 0.7902701212356579 - loss_val: 0.9667986266521268\n",
      "Epoch: 4829 - time: 0.0031 - loss_train: 0.7902591459273157 - loss_val: 0.966794348940314\n",
      "Epoch: 4830 - time: 0.0031 - loss_train: 0.7902481747385703 - loss_val: 0.9667900687851848\n",
      "Epoch: 4831 - time: 0.0031 - loss_train: 0.7902372076679479 - loss_val: 0.9667857861920254\n",
      "Epoch: 4832 - time: 0.0031 - loss_train: 0.7902262447139765 - loss_val: 0.9667815011661242\n",
      "Epoch: 4833 - time: 0.0031 - loss_train: 0.7902152858751874 - loss_val: 0.9667772137127727\n",
      "Epoch: 4834 - time: 0.0031 - loss_train: 0.7902043311501147 - loss_val: 0.9667729238372629\n",
      "Epoch: 4835 - time: 0.0031 - loss_train: 0.7901933805372952 - loss_val: 0.9667686315448866\n",
      "Epoch: 4836 - time: 0.0031 - loss_train: 0.7901824340352681 - loss_val: 0.9667643368409414\n",
      "Epoch: 4837 - time: 0.0031 - loss_train: 0.7901714916425763 - loss_val: 0.9667600397307223\n",
      "Epoch: 4838 - time: 0.0031 - loss_train: 0.7901605533577637 - loss_val: 0.9667557402195285\n",
      "Epoch: 4839 - time: 0.0031 - loss_train: 0.7901496191793788 - loss_val: 0.9667514383126594\n",
      "Epoch: 4840 - time: 0.0031 - loss_train: 0.7901386891059715 - loss_val: 0.9667471340154172\n",
      "Epoch: 4841 - time: 0.0031 - loss_train: 0.7901277631360949 - loss_val: 0.9667428273331033\n",
      "Epoch: 4842 - time: 0.0031 - loss_train: 0.7901168412683048 - loss_val: 0.966738518271024\n",
      "Epoch: 4843 - time: 0.0031 - loss_train: 0.7901059235011596 - loss_val: 0.9667342068344835\n",
      "Epoch: 4844 - time: 0.0031 - loss_train: 0.7900950098332205 - loss_val: 0.9667298930287902\n",
      "Epoch: 4845 - time: 0.0031 - loss_train: 0.7900841002630509 - loss_val: 0.9667255768592535\n",
      "Epoch: 4846 - time: 0.0031 - loss_train: 0.7900731947892177 - loss_val: 0.9667212583311822\n",
      "Epoch: 4847 - time: 0.0031 - loss_train: 0.7900622934102897 - loss_val: 0.9667169374498901\n",
      "Epoch: 4848 - time: 0.0031 - loss_train: 0.7900513961248383 - loss_val: 0.9667126142206884\n",
      "Epoch: 4849 - time: 0.0031 - loss_train: 0.7900405029314383 - loss_val: 0.9667082886488934\n",
      "Epoch: 4850 - time: 0.0031 - loss_train: 0.7900296138286664 - loss_val: 0.9667039607398201\n",
      "Epoch: 4851 - time: 0.0031 - loss_train: 0.7900187288151028 - loss_val: 0.9666996304987867\n",
      "Epoch: 4852 - time: 0.0031 - loss_train: 0.7900078478893288 - loss_val: 0.9666952979311119\n",
      "Epoch: 4853 - time: 0.0031 - loss_train: 0.7899969710499297 - loss_val: 0.9666909630421153\n",
      "Epoch: 4854 - time: 0.0031 - loss_train: 0.7899860982954922 - loss_val: 0.9666866258371192\n",
      "Epoch: 4855 - time: 0.0031 - loss_train: 0.7899752296246074 - loss_val: 0.9666822863214452\n",
      "Epoch: 4856 - time: 0.0031 - loss_train: 0.7899643650358672 - loss_val: 0.9666779445004193\n",
      "Epoch: 4857 - time: 0.0031 - loss_train: 0.7899535045278667 - loss_val: 0.9666736003793658\n",
      "Epoch: 4858 - time: 0.0031 - loss_train: 0.7899426480992041 - loss_val: 0.9666692539636119\n",
      "Epoch: 4859 - time: 0.0031 - loss_train: 0.7899317957484788 - loss_val: 0.9666649052584859\n",
      "Epoch: 4860 - time: 0.0032 - loss_train: 0.7899209474742941 - loss_val: 0.9666605542693165\n",
      "Epoch: 4861 - time: 0.0031 - loss_train: 0.7899101032752558 - loss_val: 0.9666562010014349\n",
      "Epoch: 4862 - time: 0.0031 - loss_train: 0.7898992631499705 - loss_val: 0.9666518454601721\n",
      "Epoch: 4863 - time: 0.0031 - loss_train: 0.78988842709705 - loss_val: 0.9666474876508626\n",
      "Epoch: 4864 - time: 0.0031 - loss_train: 0.789877595115106 - loss_val: 0.9666431275788394\n",
      "Epoch: 4865 - time: 0.0031 - loss_train: 0.7898667672027546 - loss_val: 0.9666387652494389\n",
      "Epoch: 4866 - time: 0.0031 - loss_train: 0.7898559433586135 - loss_val: 0.9666344006679968\n",
      "Epoch: 4867 - time: 0.0031 - loss_train: 0.7898451235813034 - loss_val: 0.9666300338398521\n",
      "Epoch: 4868 - time: 0.0031 - loss_train: 0.7898343078694469 - loss_val: 0.9666256647703437\n",
      "Epoch: 4869 - time: 0.0032 - loss_train: 0.7898234962216698 - loss_val: 0.9666212934648108\n",
      "Epoch: 4870 - time: 0.0031 - loss_train: 0.7898126886365985 - loss_val: 0.9666169199285956\n",
      "Epoch: 4871 - time: 0.0031 - loss_train: 0.7898018851128652 - loss_val: 0.96661254416704\n",
      "Epoch: 4872 - time: 0.0031 - loss_train: 0.7897910856491016 - loss_val: 0.966608166185488\n",
      "Epoch: 4873 - time: 0.0031 - loss_train: 0.7897802902439428 - loss_val: 0.9666037859892833\n",
      "Epoch: 4874 - time: 0.0031 - loss_train: 0.7897694988960274 - loss_val: 0.9665994035837725\n",
      "Epoch: 4875 - time: 0.0031 - loss_train: 0.7897587116039942 - loss_val: 0.966595018974303\n",
      "Epoch: 4876 - time: 0.0031 - loss_train: 0.7897479283664866 - loss_val: 0.9665906321662219\n",
      "Epoch: 4877 - time: 0.0031 - loss_train: 0.7897371491821491 - loss_val: 0.9665862431648768\n",
      "Epoch: 4878 - time: 0.0031 - loss_train: 0.7897263740496292 - loss_val: 0.96658185197562\n",
      "Epoch: 4879 - time: 0.0031 - loss_train: 0.7897156029675764 - loss_val: 0.9665774586038005\n",
      "Epoch: 4880 - time: 0.0031 - loss_train: 0.7897048359346428 - loss_val: 0.9665730630547719\n",
      "Epoch: 4881 - time: 0.0031 - loss_train: 0.7896940729494831 - loss_val: 0.9665686653338842\n",
      "Epoch: 4882 - time: 0.0031 - loss_train: 0.7896833140107538 - loss_val: 0.9665642654464948\n",
      "Epoch: 4883 - time: 0.0031 - loss_train: 0.7896725591171149 - loss_val: 0.9665598633979567\n",
      "Epoch: 4884 - time: 0.0031 - loss_train: 0.7896618082672271 - loss_val: 0.9665554591936258\n",
      "Epoch: 4885 - time: 0.0031 - loss_train: 0.7896510614597545 - loss_val: 0.9665510528388583\n",
      "Epoch: 4886 - time: 0.0031 - loss_train: 0.7896403186933635 - loss_val: 0.966546644339013\n",
      "Epoch: 4887 - time: 0.0031 - loss_train: 0.7896295799667232 - loss_val: 0.9665422336994481\n",
      "Epoch: 4888 - time: 0.0031 - loss_train: 0.7896188452785038 - loss_val: 0.9665378209255223\n",
      "Epoch: 4889 - time: 0.0031 - loss_train: 0.7896081146273787 - loss_val: 0.9665334060225969\n",
      "Epoch: 4890 - time: 0.0031 - loss_train: 0.7895973880120241 - loss_val: 0.9665289889960325\n",
      "Epoch: 4891 - time: 0.0031 - loss_train: 0.7895866654311171 - loss_val: 0.9665245698511906\n",
      "Epoch: 4892 - time: 0.0031 - loss_train: 0.7895759468833383 - loss_val: 0.9665201485934356\n",
      "Epoch: 4893 - time: 0.0031 - loss_train: 0.7895652323673701 - loss_val: 0.9665157252281297\n",
      "Epoch: 4894 - time: 0.0031 - loss_train: 0.7895545218818968 - loss_val: 0.9665112997606383\n",
      "Epoch: 4895 - time: 0.0031 - loss_train: 0.7895438154256063 - loss_val: 0.966506872196326\n",
      "Epoch: 4896 - time: 0.0031 - loss_train: 0.7895331129971872 - loss_val: 0.9665024425405594\n",
      "Epoch: 4897 - time: 0.0031 - loss_train: 0.7895224145953312 - loss_val: 0.9664980107987051\n",
      "Epoch: 4898 - time: 0.0032 - loss_train: 0.7895117202187322 - loss_val: 0.9664935769761311\n",
      "Epoch: 4899 - time: 0.0031 - loss_train: 0.7895010298660863 - loss_val: 0.9664891410782052\n",
      "Epoch: 4900 - time: 0.0031 - loss_train: 0.7894903435360915 - loss_val: 0.9664847031102964\n",
      "Epoch: 4901 - time: 0.0031 - loss_train: 0.7894796612274483 - loss_val: 0.9664802630777751\n",
      "Epoch: 4902 - time: 0.0031 - loss_train: 0.7894689829388598 - loss_val: 0.9664758209860109\n",
      "Epoch: 4903 - time: 0.0031 - loss_train: 0.7894583086690309 - loss_val: 0.9664713768403768\n",
      "Epoch: 4904 - time: 0.0031 - loss_train: 0.7894476384166682 - loss_val: 0.9664669306462429\n",
      "Epoch: 4905 - time: 0.0031 - loss_train: 0.7894369721804813 - loss_val: 0.9664624824089821\n",
      "Epoch: 4906 - time: 0.0031 - loss_train: 0.789426309959182 - loss_val: 0.9664580321339681\n",
      "Epoch: 4907 - time: 0.0031 - loss_train: 0.7894156517514838 - loss_val: 0.9664535798265742\n",
      "Epoch: 4908 - time: 0.0031 - loss_train: 0.7894049975561022 - loss_val: 0.9664491254921754\n",
      "Epoch: 4909 - time: 0.0031 - loss_train: 0.7893943473717556 - loss_val: 0.9664446691361457\n",
      "Epoch: 4910 - time: 0.0031 - loss_train: 0.7893837011971643 - loss_val: 0.966440210763862\n",
      "Epoch: 4911 - time: 0.0031 - loss_train: 0.7893730590310506 - loss_val: 0.9664357503806991\n",
      "Epoch: 4912 - time: 0.0031 - loss_train: 0.7893624208721387 - loss_val: 0.9664312879920354\n",
      "Epoch: 4913 - time: 0.0031 - loss_train: 0.7893517867191556 - loss_val: 0.9664268236032472\n",
      "Epoch: 4914 - time: 0.0031 - loss_train: 0.7893411565708296 - loss_val: 0.966422357219713\n",
      "Epoch: 4915 - time: 0.0031 - loss_train: 0.789330530425892 - loss_val: 0.9664178888468105\n",
      "Epoch: 4916 - time: 0.0031 - loss_train: 0.7893199082830755 - loss_val: 0.9664134184899187\n",
      "Epoch: 4917 - time: 0.0031 - loss_train: 0.7893092901411146 - loss_val: 0.9664089461544174\n",
      "Epoch: 4918 - time: 0.0031 - loss_train: 0.7892986759987478 - loss_val: 0.9664044718456862\n",
      "Epoch: 4919 - time: 0.0031 - loss_train: 0.7892880658547131 - loss_val: 0.9663999955691057\n",
      "Epoch: 4920 - time: 0.0031 - loss_train: 0.7892774597077525 - loss_val: 0.9663955173300571\n",
      "Epoch: 4921 - time: 0.0031 - loss_train: 0.7892668575566092 - loss_val: 0.9663910371339213\n",
      "Epoch: 4922 - time: 0.0031 - loss_train: 0.789256259400029 - loss_val: 0.9663865549860795\n",
      "Epoch: 4923 - time: 0.0031 - loss_train: 0.7892456652367589 - loss_val: 0.9663820708919146\n",
      "Epoch: 4924 - time: 0.0031 - loss_train: 0.7892350750655486 - loss_val: 0.9663775848568096\n",
      "Epoch: 4925 - time: 0.0031 - loss_train: 0.78922448888515 - loss_val: 0.9663730968861455\n",
      "Epoch: 4926 - time: 0.0031 - loss_train: 0.7892139066943163 - loss_val: 0.9663686069853072\n",
      "Epoch: 4927 - time: 0.0031 - loss_train: 0.7892033284918032 - loss_val: 0.9663641151596785\n",
      "Epoch: 4928 - time: 0.0031 - loss_train: 0.789192754276369 - loss_val: 0.9663596214146424\n",
      "Epoch: 4929 - time: 0.0031 - loss_train: 0.7891821840467724 - loss_val: 0.9663551257555842\n",
      "Epoch: 4930 - time: 0.0031 - loss_train: 0.7891716178017759 - loss_val: 0.9663506281878874\n",
      "Epoch: 4931 - time: 0.0031 - loss_train: 0.789161055540143 - loss_val: 0.9663461287169387\n",
      "Epoch: 4932 - time: 0.0031 - loss_train: 0.7891504972606391 - loss_val: 0.9663416273481221\n",
      "Epoch: 4933 - time: 0.0031 - loss_train: 0.7891399429620318 - loss_val: 0.966337124086823\n",
      "Epoch: 4934 - time: 0.0031 - loss_train: 0.7891293926430908 - loss_val: 0.9663326189384284\n",
      "Epoch: 4935 - time: 0.0031 - loss_train: 0.7891188463025878 - loss_val: 0.9663281119083234\n",
      "Epoch: 4936 - time: 0.0032 - loss_train: 0.7891083039392963 - loss_val: 0.9663236030018948\n",
      "Epoch: 4937 - time: 0.0031 - loss_train: 0.7890977655519924 - loss_val: 0.9663190922245292\n",
      "Epoch: 4938 - time: 0.0031 - loss_train: 0.7890872311394527 - loss_val: 0.9663145795816128\n",
      "Epoch: 4939 - time: 0.0031 - loss_train: 0.7890767007004561 - loss_val: 0.9663100650785339\n",
      "Epoch: 4940 - time: 0.0031 - loss_train: 0.7890661742337847 - loss_val: 0.9663055487206771\n",
      "Epoch: 4941 - time: 0.0031 - loss_train: 0.7890556517382215 - loss_val: 0.9663010305134323\n",
      "Epoch: 4942 - time: 0.0031 - loss_train: 0.7890451332125512 - loss_val: 0.9662965104621851\n",
      "Epoch: 4943 - time: 0.0031 - loss_train: 0.7890346186555615 - loss_val: 0.9662919885723257\n",
      "Epoch: 4944 - time: 0.0031 - loss_train: 0.7890241080660407 - loss_val: 0.9662874648492396\n",
      "Epoch: 4945 - time: 0.0031 - loss_train: 0.7890136014427797 - loss_val: 0.9662829392983152\n",
      "Epoch: 4946 - time: 0.0031 - loss_train: 0.7890030987845712 - loss_val: 0.9662784119249412\n",
      "Epoch: 4947 - time: 0.0031 - loss_train: 0.7889926000902099 - loss_val: 0.9662738827345042\n",
      "Epoch: 4948 - time: 0.0031 - loss_train: 0.7889821053584913 - loss_val: 0.9662693517323935\n",
      "Epoch: 4949 - time: 0.0031 - loss_train: 0.7889716145882151 - loss_val: 0.966264818923997\n",
      "Epoch: 4950 - time: 0.0031 - loss_train: 0.7889611277781798 - loss_val: 0.9662602843147031\n",
      "Epoch: 4951 - time: 0.0031 - loss_train: 0.7889506449271881 - loss_val: 0.9662557479098995\n",
      "Epoch: 4952 - time: 0.0031 - loss_train: 0.7889401660340438 - loss_val: 0.966251209714976\n",
      "Epoch: 4953 - time: 0.0031 - loss_train: 0.788929691097552 - loss_val: 0.9662466697353198\n",
      "Epoch: 4954 - time: 0.0031 - loss_train: 0.7889192201165204 - loss_val: 0.9662421279763183\n",
      "Epoch: 4955 - time: 0.0031 - loss_train: 0.7889087530897583 - loss_val: 0.966237584443362\n",
      "Epoch: 4956 - time: 0.0031 - loss_train: 0.7888982900160759 - loss_val: 0.9662330391418377\n",
      "Epoch: 4957 - time: 0.0031 - loss_train: 0.7888878308942867 - loss_val: 0.966228492077134\n",
      "Epoch: 4958 - time: 0.0031 - loss_train: 0.7888773757232049 - loss_val: 0.9662239432546385\n",
      "Epoch: 4959 - time: 0.0031 - loss_train: 0.7888669245016472 - loss_val: 0.9662193926797399\n",
      "Epoch: 4960 - time: 0.0031 - loss_train: 0.7888564772284312 - loss_val: 0.9662148403578268\n",
      "Epoch: 4961 - time: 0.0031 - loss_train: 0.7888460339023771 - loss_val: 0.9662102862942853\n",
      "Epoch: 4962 - time: 0.0031 - loss_train: 0.7888355945223059 - loss_val: 0.9662057304945046\n",
      "Epoch: 4963 - time: 0.0031 - loss_train: 0.7888251590870413 - loss_val: 0.9662011729638718\n",
      "Epoch: 4964 - time: 0.0031 - loss_train: 0.7888147275954084 - loss_val: 0.9661966137077745\n",
      "Epoch: 4965 - time: 0.0031 - loss_train: 0.7888043000462339 - loss_val: 0.9661920527315999\n",
      "Epoch: 4966 - time: 0.0031 - loss_train: 0.7887938764383464 - loss_val: 0.9661874900407355\n",
      "Epoch: 4967 - time: 0.0031 - loss_train: 0.7887834567705764 - loss_val: 0.966182925640568\n",
      "Epoch: 4968 - time: 0.0031 - loss_train: 0.7887730410417548 - loss_val: 0.9661783595364833\n",
      "Epoch: 4969 - time: 0.0031 - loss_train: 0.7887626292507159 - loss_val: 0.9661737917338702\n",
      "Epoch: 4970 - time: 0.0031 - loss_train: 0.7887522213962952 - loss_val: 0.966169222238113\n",
      "Epoch: 4971 - time: 0.0031 - loss_train: 0.7887418174773295 - loss_val: 0.9661646510545989\n",
      "Epoch: 4972 - time: 0.0031 - loss_train: 0.7887314174926573 - loss_val: 0.9661600781887125\n",
      "Epoch: 4973 - time: 0.0031 - loss_train: 0.7887210214411189 - loss_val: 0.9661555036458399\n",
      "Epoch: 4974 - time: 0.0032 - loss_train: 0.7887106293215566 - loss_val: 0.9661509274313669\n",
      "Epoch: 4975 - time: 0.0031 - loss_train: 0.7887002411328133 - loss_val: 0.9661463495506781\n",
      "Epoch: 4976 - time: 0.0031 - loss_train: 0.7886898568737349 - loss_val: 0.9661417700091587\n",
      "Epoch: 4977 - time: 0.0031 - loss_train: 0.7886794765431682 - loss_val: 0.966137188812191\n",
      "Epoch: 4978 - time: 0.0031 - loss_train: 0.7886691001399615 - loss_val: 0.9661326059651614\n",
      "Epoch: 4979 - time: 0.0031 - loss_train: 0.7886587276629649 - loss_val: 0.966128021473452\n",
      "Epoch: 4980 - time: 0.0031 - loss_train: 0.7886483591110307 - loss_val: 0.966123435342447\n",
      "Epoch: 4981 - time: 0.0031 - loss_train: 0.7886379944830113 - loss_val: 0.9661188475775283\n",
      "Epoch: 4982 - time: 0.0031 - loss_train: 0.7886276337777625 - loss_val: 0.966114258184079\n",
      "Epoch: 4983 - time: 0.0031 - loss_train: 0.7886172769941404 - loss_val: 0.9661096671674814\n",
      "Epoch: 4984 - time: 0.0031 - loss_train: 0.7886069241310031 - loss_val: 0.9661050745331163\n",
      "Epoch: 4985 - time: 0.0031 - loss_train: 0.7885965751872102 - loss_val: 0.9661004802863651\n",
      "Epoch: 4986 - time: 0.0031 - loss_train: 0.7885862301616229 - loss_val: 0.9660958844326093\n",
      "Epoch: 4987 - time: 0.0031 - loss_train: 0.788575889053104 - loss_val: 0.9660912869772286\n",
      "Epoch: 4988 - time: 0.0031 - loss_train: 0.7885655518605186 - loss_val: 0.9660866879256023\n",
      "Epoch: 4989 - time: 0.0031 - loss_train: 0.788555218582731 - loss_val: 0.9660820872831105\n",
      "Epoch: 4990 - time: 0.0031 - loss_train: 0.7885448892186101 - loss_val: 0.9660774850551309\n",
      "Epoch: 4991 - time: 0.0031 - loss_train: 0.7885345637670239 - loss_val: 0.9660728812470425\n",
      "Epoch: 4992 - time: 0.0031 - loss_train: 0.7885242422268431 - loss_val: 0.9660682758642235\n",
      "Epoch: 4993 - time: 0.0031 - loss_train: 0.7885139245969394 - loss_val: 0.9660636689120502\n",
      "Epoch: 4994 - time: 0.0031 - loss_train: 0.7885036108761865 - loss_val: 0.9660590603958995\n",
      "Epoch: 4995 - time: 0.0035 - loss_train: 0.7884933010634595 - loss_val: 0.9660544503211463\n",
      "Epoch: 4996 - time: 0.0032 - loss_train: 0.7884829951576345 - loss_val: 0.9660498386931686\n",
      "Epoch: 4997 - time: 0.0031 - loss_train: 0.7884726931575889 - loss_val: 0.9660452255173388\n",
      "Epoch: 4998 - time: 0.0031 - loss_train: 0.7884623950622028 - loss_val: 0.9660406107990315\n",
      "Epoch: 4999 - time: 0.0031 - loss_train: 0.7884521008703569 - loss_val: 0.9660359945436214\n",
      "Epoch: 5000 - time: 0.0031 - loss_train: 0.788441810580933 - loss_val: 0.9660313767564794\n",
      "Epoch: 5001 - time: 0.0031 - loss_train: 0.7884315241928149 - loss_val: 0.9660267574429799\n",
      "Epoch: 5002 - time: 0.0031 - loss_train: 0.7884212417048879 - loss_val: 0.9660221366084916\n",
      "Epoch: 5003 - time: 0.0031 - loss_train: 0.7884109631160389 - loss_val: 0.9660175142583883\n",
      "Epoch: 5004 - time: 0.0031 - loss_train: 0.7884006884251549 - loss_val: 0.9660128903980375\n",
      "Epoch: 5005 - time: 0.0031 - loss_train: 0.7883904176311259 - loss_val: 0.9660082650328108\n",
      "Epoch: 5006 - time: 0.0031 - loss_train: 0.7883801507328428 - loss_val: 0.9660036381680756\n",
      "Epoch: 5007 - time: 0.0031 - loss_train: 0.7883698877291972 - loss_val: 0.9659990098092\n",
      "Epoch: 5008 - time: 0.0031 - loss_train: 0.7883596286190834 - loss_val: 0.9659943799615511\n",
      "Epoch: 5009 - time: 0.0031 - loss_train: 0.7883493734013958 - loss_val: 0.9659897486304951\n",
      "Epoch: 5010 - time: 0.0031 - loss_train: 0.7883391220750309 - loss_val: 0.9659851158213976\n",
      "Epoch: 5011 - time: 0.0036 - loss_train: 0.7883288746388861 - loss_val: 0.9659804815396222\n",
      "Epoch: 5012 - time: 0.0032 - loss_train: 0.7883186310918605 - loss_val: 0.9659758457905345\n",
      "Epoch: 5013 - time: 0.0031 - loss_train: 0.7883083914328547 - loss_val: 0.9659712085794975\n",
      "Epoch: 5014 - time: 0.0031 - loss_train: 0.7882981556607701 - loss_val: 0.9659665699118718\n",
      "Epoch: 5015 - time: 0.0031 - loss_train: 0.7882879237745102 - loss_val: 0.96596192979302\n",
      "Epoch: 5016 - time: 0.0031 - loss_train: 0.7882776957729787 - loss_val: 0.965957288228302\n",
      "Epoch: 5017 - time: 0.0031 - loss_train: 0.7882674716550816 - loss_val: 0.9659526452230776\n",
      "Epoch: 5018 - time: 0.0031 - loss_train: 0.7882572514197257 - loss_val: 0.9659480007827045\n",
      "Epoch: 5019 - time: 0.0031 - loss_train: 0.7882470350658197 - loss_val: 0.9659433549125417\n",
      "Epoch: 5020 - time: 0.0031 - loss_train: 0.7882368225922728 - loss_val: 0.9659387076179443\n",
      "Epoch: 5021 - time: 0.0031 - loss_train: 0.7882266139979957 - loss_val: 0.9659340589042693\n",
      "Epoch: 5022 - time: 0.0031 - loss_train: 0.7882164092819012 - loss_val: 0.9659294087768715\n",
      "Epoch: 5023 - time: 0.0031 - loss_train: 0.7882062084429018 - loss_val: 0.965924757241104\n",
      "Epoch: 5024 - time: 0.0031 - loss_train: 0.7881960114799126 - loss_val: 0.9659201043023196\n",
      "Epoch: 5025 - time: 0.0031 - loss_train: 0.7881858183918489 - loss_val: 0.9659154499658704\n",
      "Epoch: 5026 - time: 0.0031 - loss_train: 0.788175629177629 - loss_val: 0.9659107942371075\n",
      "Epoch: 5027 - time: 0.0031 - loss_train: 0.7881654438361702 - loss_val: 0.9659061371213795\n",
      "Epoch: 5028 - time: 0.0031 - loss_train: 0.7881552623663927 - loss_val: 0.9659014786240354\n",
      "Epoch: 5029 - time: 0.0031 - loss_train: 0.788145084767217 - loss_val: 0.9658968187504231\n",
      "Epoch: 5030 - time: 0.0031 - loss_train: 0.7881349110375647 - loss_val: 0.9658921575058901\n",
      "Epoch: 5031 - time: 0.0031 - loss_train: 0.7881247411763602 - loss_val: 0.9658874948957792\n",
      "Epoch: 5032 - time: 0.0031 - loss_train: 0.7881145751825267 - loss_val: 0.9658828309254359\n",
      "Epoch: 5033 - time: 0.0031 - loss_train: 0.7881044130549903 - loss_val: 0.9658781656002038\n",
      "Epoch: 5034 - time: 0.0031 - loss_train: 0.7880942547926779 - loss_val: 0.9658734989254238\n",
      "Epoch: 5035 - time: 0.0031 - loss_train: 0.7880841003945172 - loss_val: 0.9658688309064378\n",
      "Epoch: 5036 - time: 0.0031 - loss_train: 0.7880739498594372 - loss_val: 0.9658641615485839\n",
      "Epoch: 5037 - time: 0.0031 - loss_train: 0.788063803186368 - loss_val: 0.9658594908572015\n",
      "Epoch: 5038 - time: 0.0031 - loss_train: 0.7880536603742414 - loss_val: 0.9658548188376271\n",
      "Epoch: 5039 - time: 0.0031 - loss_train: 0.7880435214219902 - loss_val: 0.9658501454951972\n",
      "Epoch: 5040 - time: 0.0031 - loss_train: 0.7880333863285472 - loss_val: 0.965845470835247\n",
      "Epoch: 5041 - time: 0.0031 - loss_train: 0.7880232550928479 - loss_val: 0.9658407948631087\n",
      "Epoch: 5042 - time: 0.0031 - loss_train: 0.7880131277138276 - loss_val: 0.9658361175841149\n",
      "Epoch: 5043 - time: 0.0031 - loss_train: 0.7880030041904236 - loss_val: 0.9658314390035961\n",
      "Epoch: 5044 - time: 0.0031 - loss_train: 0.7879928845215741 - loss_val: 0.9658267591268835\n",
      "Epoch: 5045 - time: 0.0031 - loss_train: 0.7879827687062178 - loss_val: 0.9658220779593026\n",
      "Epoch: 5046 - time: 0.0031 - loss_train: 0.7879726567432956 - loss_val: 0.9658173955061823\n",
      "Epoch: 5047 - time: 0.0031 - loss_train: 0.7879625486317484 - loss_val: 0.9658127117728488\n",
      "Epoch: 5048 - time: 0.0031 - loss_train: 0.7879524443705183 - loss_val: 0.9658080267646244\n",
      "Epoch: 5049 - time: 0.0031 - loss_train: 0.7879423439585495 - loss_val: 0.9658033404868331\n",
      "Epoch: 5050 - time: 0.0032 - loss_train: 0.7879322473947853 - loss_val: 0.9657986529447953\n",
      "Epoch: 5051 - time: 0.0031 - loss_train: 0.7879221546781727 - loss_val: 0.9657939641438316\n",
      "Epoch: 5052 - time: 0.0031 - loss_train: 0.787912065807657 - loss_val: 0.965789274089261\n",
      "Epoch: 5053 - time: 0.0031 - loss_train: 0.7879019807821868 - loss_val: 0.9657845827864002\n",
      "Epoch: 5054 - time: 0.0031 - loss_train: 0.7878918996007102 - loss_val: 0.9657798902405654\n",
      "Epoch: 5055 - time: 0.0031 - loss_train: 0.7878818222621763 - loss_val: 0.9657751964570707\n",
      "Epoch: 5056 - time: 0.0031 - loss_train: 0.7878717487655363 - loss_val: 0.965770501441228\n",
      "Epoch: 5057 - time: 0.0031 - loss_train: 0.7878616791097418 - loss_val: 0.965765805198349\n",
      "Epoch: 5058 - time: 0.0031 - loss_train: 0.787851613293745 - loss_val: 0.9657611077337436\n",
      "Epoch: 5059 - time: 0.0031 - loss_train: 0.7878415513164995 - loss_val: 0.9657564090527206\n",
      "Epoch: 5060 - time: 0.0031 - loss_train: 0.7878314931769601 - loss_val: 0.9657517091605854\n",
      "Epoch: 5061 - time: 0.0031 - loss_train: 0.7878214388740818 - loss_val: 0.9657470080626437\n",
      "Epoch: 5062 - time: 0.0031 - loss_train: 0.7878113884068213 - loss_val: 0.965742305764199\n",
      "Epoch: 5063 - time: 0.0031 - loss_train: 0.7878013417741361 - loss_val: 0.9657376022705532\n",
      "Epoch: 5064 - time: 0.0031 - loss_train: 0.7877912989749837 - loss_val: 0.965732897587008\n",
      "Epoch: 5065 - time: 0.0031 - loss_train: 0.7877812600083239 - loss_val: 0.9657281917188587\n",
      "Epoch: 5066 - time: 0.0031 - loss_train: 0.7877712248731172 - loss_val: 0.9657234846714066\n",
      "Epoch: 5067 - time: 0.0031 - loss_train: 0.787761193568324 - loss_val: 0.9657187764499433\n",
      "Epoch: 5068 - time: 0.0031 - loss_train: 0.787751166092906 - loss_val: 0.9657140670597641\n",
      "Epoch: 5069 - time: 0.0031 - loss_train: 0.7877411424458264 - loss_val: 0.9657093565061617\n",
      "Epoch: 5070 - time: 0.0031 - loss_train: 0.7877311226260487 - loss_val: 0.9657046447944254\n",
      "Epoch: 5071 - time: 0.0031 - loss_train: 0.7877211066325378 - loss_val: 0.9656999319298449\n",
      "Epoch: 5072 - time: 0.0031 - loss_train: 0.7877110944642589 - loss_val: 0.965695217917706\n",
      "Epoch: 5073 - time: 0.0031 - loss_train: 0.7877010861201782 - loss_val: 0.9656905027632939\n",
      "Epoch: 5074 - time: 0.0031 - loss_train: 0.7876910815992629 - loss_val: 0.9656857864718936\n",
      "Epoch: 5075 - time: 0.0031 - loss_train: 0.7876810809004808 - loss_val: 0.965681069048785\n",
      "Epoch: 5076 - time: 0.0031 - loss_train: 0.7876710840228013 - loss_val: 0.9656763504992482\n",
      "Epoch: 5077 - time: 0.0031 - loss_train: 0.7876610909651931 - loss_val: 0.9656716308285616\n",
      "Epoch: 5078 - time: 0.0031 - loss_train: 0.7876511017266272 - loss_val: 0.9656669100420013\n",
      "Epoch: 5079 - time: 0.0031 - loss_train: 0.7876411163060751 - loss_val: 0.965662188144841\n",
      "Epoch: 5080 - time: 0.0031 - loss_train: 0.7876311347025081 - loss_val: 0.965657465142354\n",
      "Epoch: 5081 - time: 0.0031 - loss_train: 0.7876211569148994 - loss_val: 0.9656527410398108\n",
      "Epoch: 5082 - time: 0.0031 - loss_train: 0.7876111829422229 - loss_val: 0.96564801584248\n",
      "Epoch: 5083 - time: 0.0031 - loss_train: 0.7876012127834526 - loss_val: 0.9656432895556283\n",
      "Epoch: 5084 - time: 0.0031 - loss_train: 0.7875912464375637 - loss_val: 0.9656385621845207\n",
      "Epoch: 5085 - time: 0.0031 - loss_train: 0.7875812839035323 - loss_val: 0.9656338337344205\n",
      "Epoch: 5086 - time: 0.0032 - loss_train: 0.7875713251803347 - loss_val: 0.9656291042105876\n",
      "Epoch: 5087 - time: 0.0031 - loss_train: 0.7875613702669495 - loss_val: 0.9656243736182826\n",
      "Epoch: 5088 - time: 0.0032 - loss_train: 0.7875514191623534 - loss_val: 0.9656196419627613\n",
      "Epoch: 5089 - time: 0.0032 - loss_train: 0.7875414718655254 - loss_val: 0.9656149092492791\n",
      "Epoch: 5090 - time: 0.0031 - loss_train: 0.7875315283754463 - loss_val: 0.9656101754830895\n",
      "Epoch: 5091 - time: 0.0033 - loss_train: 0.7875215886910949 - loss_val: 0.9656054406694434\n",
      "Epoch: 5092 - time: 0.0035 - loss_train: 0.7875116528114529 - loss_val: 0.9656007048135884\n",
      "Epoch: 5093 - time: 0.0032 - loss_train: 0.7875017207355017 - loss_val: 0.9655959679207734\n",
      "Epoch: 5094 - time: 0.0031 - loss_train: 0.7874917924622243 - loss_val: 0.9655912299962434\n",
      "Epoch: 5095 - time: 0.0032 - loss_train: 0.7874818679906033 - loss_val: 0.9655864910452387\n",
      "Epoch: 5096 - time: 0.0031 - loss_train: 0.7874719473196219 - loss_val: 0.9655817510730015\n",
      "Epoch: 5097 - time: 0.0031 - loss_train: 0.7874620304482656 - loss_val: 0.9655770100847698\n",
      "Epoch: 5098 - time: 0.0031 - loss_train: 0.7874521173755185 - loss_val: 0.965572268085782\n",
      "Epoch: 5099 - time: 0.0031 - loss_train: 0.7874422081003666 - loss_val: 0.9655675250812693\n",
      "Epoch: 5100 - time: 0.0031 - loss_train: 0.7874323026217956 - loss_val: 0.9655627810764646\n",
      "Epoch: 5101 - time: 0.0031 - loss_train: 0.7874224009387933 - loss_val: 0.9655580360765988\n",
      "Epoch: 5102 - time: 0.0031 - loss_train: 0.7874125030503467 - loss_val: 0.9655532900868988\n",
      "Epoch: 5103 - time: 0.0031 - loss_train: 0.7874026089554441 - loss_val: 0.9655485431125895\n",
      "Epoch: 5104 - time: 0.0031 - loss_train: 0.7873927186530741 - loss_val: 0.9655437951588954\n",
      "Epoch: 5105 - time: 0.0031 - loss_train: 0.7873828321422263 - loss_val: 0.9655390462310366\n",
      "Epoch: 5106 - time: 0.0031 - loss_train: 0.7873729494218901 - loss_val: 0.9655342963342318\n",
      "Epoch: 5107 - time: 0.0031 - loss_train: 0.787363070491056 - loss_val: 0.9655295454736968\n",
      "Epoch: 5108 - time: 0.0031 - loss_train: 0.7873531953487154 - loss_val: 0.9655247936546463\n",
      "Epoch: 5109 - time: 0.0031 - loss_train: 0.7873433239938602 - loss_val: 0.965520040882292\n",
      "Epoch: 5110 - time: 0.0031 - loss_train: 0.7873334564254814 - loss_val: 0.9655152871618432\n",
      "Epoch: 5111 - time: 0.0031 - loss_train: 0.7873235926425728 - loss_val: 0.965510532498507\n",
      "Epoch: 5112 - time: 0.0031 - loss_train: 0.787313732644127 - loss_val: 0.9655057768974873\n",
      "Epoch: 5113 - time: 0.0036 - loss_train: 0.787303876429138 - loss_val: 0.9655010203639875\n",
      "Epoch: 5114 - time: 0.0043 - loss_train: 0.7872940239966001 - loss_val: 0.9654962629032077\n",
      "Epoch: 5115 - time: 0.0043 - loss_train: 0.787284175345508 - loss_val: 0.9654915045203439\n",
      "Epoch: 5116 - time: 0.0043 - loss_train: 0.7872743304748563 - loss_val: 0.9654867452205923\n",
      "Epoch: 5117 - time: 0.0043 - loss_train: 0.7872644893836418 - loss_val: 0.9654819850091448\n",
      "Epoch: 5118 - time: 0.0043 - loss_train: 0.7872546520708602 - loss_val: 0.9654772238911913\n",
      "Epoch: 5119 - time: 0.0043 - loss_train: 0.7872448185355077 - loss_val: 0.9654724618719208\n",
      "Epoch: 5120 - time: 0.0043 - loss_train: 0.7872349887765829 - loss_val: 0.9654676989565169\n",
      "Epoch: 5121 - time: 0.0043 - loss_train: 0.7872251627930819 - loss_val: 0.965462935150163\n",
      "Epoch: 5122 - time: 0.0039 - loss_train: 0.7872153405840037 - loss_val: 0.9654581704580388\n",
      "Epoch: 5123 - time: 0.0036 - loss_train: 0.787205522148346 - loss_val: 0.9654534048853223\n",
      "Epoch: 5124 - time: 0.0036 - loss_train: 0.7871957074851086 - loss_val: 0.9654486384371881\n",
      "Epoch: 5125 - time: 0.0036 - loss_train: 0.7871858965932904 - loss_val: 0.9654438711188089\n",
      "Epoch: 5126 - time: 0.0036 - loss_train: 0.7871760894718912 - loss_val: 0.9654391029353542\n",
      "Epoch: 5127 - time: 0.0036 - loss_train: 0.7871662861199114 - loss_val: 0.9654343338919905\n",
      "Epoch: 5128 - time: 0.0036 - loss_train: 0.7871564865363508 - loss_val: 0.9654295639938832\n",
      "Epoch: 5129 - time: 0.0036 - loss_train: 0.7871466907202116 - loss_val: 0.9654247932461948\n",
      "Epoch: 5130 - time: 0.0036 - loss_train: 0.787136898670494 - loss_val: 0.9654200216540835\n",
      "Epoch: 5131 - time: 0.0039 - loss_train: 0.7871271103862005 - loss_val: 0.9654152492227053\n",
      "Epoch: 5132 - time: 0.0043 - loss_train: 0.7871173258663329 - loss_val: 0.9654104759572155\n",
      "Epoch: 5133 - time: 0.0036 - loss_train: 0.7871075451098934 - loss_val: 0.9654057018627642\n",
      "Epoch: 5134 - time: 0.0036 - loss_train: 0.7870977681158853 - loss_val: 0.9654009269445002\n",
      "Epoch: 5135 - time: 0.0036 - loss_train: 0.787087994883311 - loss_val: 0.9653961512075692\n",
      "Epoch: 5136 - time: 0.0036 - loss_train: 0.7870782254111744 - loss_val: 0.9653913746571136\n",
      "Epoch: 5137 - time: 0.0038 - loss_train: 0.7870684596984793 - loss_val: 0.9653865972982739\n",
      "Epoch: 5138 - time: 0.0045 - loss_train: 0.7870586977442297 - loss_val: 0.9653818191361873\n",
      "Epoch: 5139 - time: 0.0045 - loss_train: 0.7870489395474298 - loss_val: 0.9653770401759884\n",
      "Epoch: 5140 - time: 0.0045 - loss_train: 0.7870391851070838 - loss_val: 0.9653722604228083\n",
      "Epoch: 5141 - time: 0.0038 - loss_train: 0.7870294344221981 - loss_val: 0.9653674798817763\n",
      "Epoch: 5142 - time: 0.0038 - loss_train: 0.787019687491777 - loss_val: 0.9653626985580186\n",
      "Epoch: 5143 - time: 0.0038 - loss_train: 0.7870099443148258 - loss_val: 0.9653579164566586\n",
      "Epoch: 5144 - time: 0.0035 - loss_train: 0.7870002048903507 - loss_val: 0.9653531335828142\n",
      "Epoch: 5145 - time: 0.0035 - loss_train: 0.7869904692173575 - loss_val: 0.9653483499416045\n",
      "Epoch: 5146 - time: 0.0035 - loss_train: 0.7869807372948529 - loss_val: 0.9653435655381438\n",
      "Epoch: 5147 - time: 0.0035 - loss_train: 0.7869710091218425 - loss_val: 0.9653387803775434\n",
      "Epoch: 5148 - time: 0.0038 - loss_train: 0.7869612846973338 - loss_val: 0.9653339944649105\n",
      "Epoch: 5149 - time: 0.0042 - loss_train: 0.7869515640203336 - loss_val: 0.9653292078053525\n",
      "Epoch: 5150 - time: 0.0038 - loss_train: 0.7869418470898487 - loss_val: 0.9653244204039704\n",
      "Epoch: 5151 - time: 0.0038 - loss_train: 0.7869321339048873 - loss_val: 0.9653196322658627\n",
      "Epoch: 5152 - time: 0.0038 - loss_train: 0.7869224244644558 - loss_val: 0.9653148433961287\n",
      "Epoch: 5153 - time: 0.0039 - loss_train: 0.7869127187675626 - loss_val: 0.9653100537998583\n",
      "Epoch: 5154 - time: 0.0031 - loss_train: 0.7869030168132161 - loss_val: 0.9653052634821441\n",
      "Epoch: 5155 - time: 0.0031 - loss_train: 0.7868933186004229 - loss_val: 0.965300472448072\n",
      "Epoch: 5156 - time: 0.0031 - loss_train: 0.7868836241281927 - loss_val: 0.965295680702727\n",
      "Epoch: 5157 - time: 0.0031 - loss_train: 0.7868739333955335 - loss_val: 0.965290888251189\n",
      "Epoch: 5158 - time: 0.0031 - loss_train: 0.7868642464014534 - loss_val: 0.9652860950985362\n",
      "Epoch: 5159 - time: 0.0031 - loss_train: 0.7868545631449614 - loss_val: 0.965281301249844\n",
      "Epoch: 5160 - time: 0.0031 - loss_train: 0.7868448836250662 - loss_val: 0.9652765067101827\n",
      "Epoch: 5161 - time: 0.0031 - loss_train: 0.7868352078407765 - loss_val: 0.9652717114846219\n",
      "Epoch: 5162 - time: 0.0031 - loss_train: 0.786825535791102 - loss_val: 0.9652669155782246\n",
      "Epoch: 5163 - time: 0.0031 - loss_train: 0.7868158674750514 - loss_val: 0.9652621189960539\n",
      "Epoch: 5164 - time: 0.0031 - loss_train: 0.7868062028916339 - loss_val: 0.9652573217431686\n",
      "Epoch: 5165 - time: 0.0031 - loss_train: 0.7867965420398586 - loss_val: 0.9652525238246239\n",
      "Epoch: 5166 - time: 0.0031 - loss_train: 0.7867868849187349 - loss_val: 0.9652477252454712\n",
      "Epoch: 5167 - time: 0.0031 - loss_train: 0.786777231527273 - loss_val: 0.96524292601076\n",
      "Epoch: 5168 - time: 0.0031 - loss_train: 0.7867675818644814 - loss_val: 0.9652381261255355\n",
      "Epoch: 5169 - time: 0.0031 - loss_train: 0.78675793592937 - loss_val: 0.9652333255948404\n",
      "Epoch: 5170 - time: 0.0031 - loss_train: 0.7867482937209483 - loss_val: 0.9652285244237123\n",
      "Epoch: 5171 - time: 0.0031 - loss_train: 0.7867386552382263 - loss_val: 0.9652237226171874\n",
      "Epoch: 5172 - time: 0.0031 - loss_train: 0.7867290204802132 - loss_val: 0.9652189201802975\n",
      "Epoch: 5173 - time: 0.0031 - loss_train: 0.7867193894459191 - loss_val: 0.9652141171180726\n",
      "Epoch: 5174 - time: 0.0031 - loss_train: 0.7867097621343528 - loss_val: 0.9652093134355351\n",
      "Epoch: 5175 - time: 0.0031 - loss_train: 0.7867001385445253 - loss_val: 0.9652045091377096\n",
      "Epoch: 5176 - time: 0.0031 - loss_train: 0.786690518675445 - loss_val: 0.9651997042296129\n",
      "Epoch: 5177 - time: 0.0031 - loss_train: 0.7866809025261223 - loss_val: 0.9651948987162611\n",
      "Epoch: 5178 - time: 0.0031 - loss_train: 0.7866712900955662 - loss_val: 0.9651900926026639\n",
      "Epoch: 5179 - time: 0.0031 - loss_train: 0.786661681382787 - loss_val: 0.965185285893831\n",
      "Epoch: 5180 - time: 0.0031 - loss_train: 0.7866520763867934 - loss_val: 0.9651804785947663\n",
      "Epoch: 5181 - time: 0.0031 - loss_train: 0.7866424751065956 - loss_val: 0.9651756707104708\n",
      "Epoch: 5182 - time: 0.0031 - loss_train: 0.7866328775412026 - loss_val: 0.9651708622459401\n",
      "Epoch: 5183 - time: 0.0031 - loss_train: 0.7866232836896238 - loss_val: 0.96516605320617\n",
      "Epoch: 5184 - time: 0.0031 - loss_train: 0.7866136935508685 - loss_val: 0.9651612435961513\n",
      "Epoch: 5185 - time: 0.0031 - loss_train: 0.7866041071239459 - loss_val: 0.9651564334208683\n",
      "Epoch: 5186 - time: 0.0031 - loss_train: 0.7865945244078653 - loss_val: 0.9651516226853045\n",
      "Epoch: 5187 - time: 0.0031 - loss_train: 0.7865849454016347 - loss_val: 0.9651468113944406\n",
      "Epoch: 5188 - time: 0.0031 - loss_train: 0.7865753701042641 - loss_val: 0.9651419995532516\n",
      "Epoch: 5189 - time: 0.0031 - loss_train: 0.7865657985147623 - loss_val: 0.9651371871667082\n",
      "Epoch: 5190 - time: 0.0031 - loss_train: 0.786556230632137 - loss_val: 0.9651323742397807\n",
      "Epoch: 5191 - time: 0.0032 - loss_train: 0.7865466664553974 - loss_val: 0.965127560777433\n",
      "Epoch: 5192 - time: 0.0031 - loss_train: 0.7865371059835515 - loss_val: 0.9651227467846247\n",
      "Epoch: 5193 - time: 0.0031 - loss_train: 0.7865275492156073 - loss_val: 0.965117932266315\n",
      "Epoch: 5194 - time: 0.0031 - loss_train: 0.7865179961505735 - loss_val: 0.9651131172274561\n",
      "Epoch: 5195 - time: 0.0031 - loss_train: 0.7865084467874571 - loss_val: 0.9651083016729979\n",
      "Epoch: 5196 - time: 0.0031 - loss_train: 0.7864989011252669 - loss_val: 0.9651034856078858\n",
      "Epoch: 5197 - time: 0.0031 - loss_train: 0.7864893591630093 - loss_val: 0.9650986690370623\n",
      "Epoch: 5198 - time: 0.0031 - loss_train: 0.786479820899692 - loss_val: 0.965093851965465\n",
      "Epoch: 5199 - time: 0.0031 - loss_train: 0.7864702863343221 - loss_val: 0.9650890343980288\n",
      "Epoch: 5200 - time: 0.0031 - loss_train: 0.7864607554659064 - loss_val: 0.9650842163396839\n",
      "Epoch: 5201 - time: 0.0031 - loss_train: 0.786451228293452 - loss_val: 0.9650793977953571\n",
      "Epoch: 5202 - time: 0.0031 - loss_train: 0.7864417048159644 - loss_val: 0.9650745787699707\n",
      "Epoch: 5203 - time: 0.0031 - loss_train: 0.7864321850324504 - loss_val: 0.9650697592684427\n",
      "Epoch: 5204 - time: 0.0031 - loss_train: 0.786422668941916 - loss_val: 0.9650649392956904\n",
      "Epoch: 5205 - time: 0.0031 - loss_train: 0.7864131565433667 - loss_val: 0.9650601188566226\n",
      "Epoch: 5206 - time: 0.0031 - loss_train: 0.7864036478358077 - loss_val: 0.9650552979561458\n",
      "Epoch: 5207 - time: 0.0031 - loss_train: 0.7863941428182447 - loss_val: 0.9650504765991648\n",
      "Epoch: 5208 - time: 0.0031 - loss_train: 0.786384641489682 - loss_val: 0.9650456547905768\n",
      "Epoch: 5209 - time: 0.0031 - loss_train: 0.7863751438491244 - loss_val: 0.9650408325352775\n",
      "Epoch: 5210 - time: 0.0031 - loss_train: 0.7863656498955766 - loss_val: 0.9650360098381571\n",
      "Epoch: 5211 - time: 0.0031 - loss_train: 0.7863561596280421 - loss_val: 0.9650311867041041\n",
      "Epoch: 5212 - time: 0.0031 - loss_train: 0.7863466730455241 - loss_val: 0.9650263631379992\n",
      "Epoch: 5213 - time: 0.0031 - loss_train: 0.7863371901470271 - loss_val: 0.9650215391447212\n",
      "Epoch: 5214 - time: 0.0031 - loss_train: 0.786327710931553 - loss_val: 0.9650167147291461\n",
      "Epoch: 5215 - time: 0.0031 - loss_train: 0.7863182353981053 - loss_val: 0.9650118898961423\n",
      "Epoch: 5216 - time: 0.0031 - loss_train: 0.7863087635456859 - loss_val: 0.9650070646505777\n",
      "Epoch: 5217 - time: 0.0031 - loss_train: 0.7862992953732969 - loss_val: 0.9650022389973136\n",
      "Epoch: 5218 - time: 0.0031 - loss_train: 0.7862898308799398 - loss_val: 0.9649974129412082\n",
      "Epoch: 5219 - time: 0.0031 - loss_train: 0.7862803700646162 - loss_val: 0.9649925864871142\n",
      "Epoch: 5220 - time: 0.0031 - loss_train: 0.7862709129263262 - loss_val: 0.9649877596398829\n",
      "Epoch: 5221 - time: 0.0031 - loss_train: 0.7862614594640713 - loss_val: 0.9649829324043567\n",
      "Epoch: 5222 - time: 0.0031 - loss_train: 0.7862520096768508 - loss_val: 0.9649781047853795\n",
      "Epoch: 5223 - time: 0.0031 - loss_train: 0.7862425635636644 - loss_val: 0.9649732767877867\n",
      "Epoch: 5224 - time: 0.0031 - loss_train: 0.7862331211235115 - loss_val: 0.9649684484164104\n",
      "Epoch: 5225 - time: 0.0031 - loss_train: 0.7862236823553912 - loss_val: 0.9649636196760795\n",
      "Epoch: 5226 - time: 0.0031 - loss_train: 0.7862142472583018 - loss_val: 0.9649587905716162\n",
      "Epoch: 5227 - time: 0.0031 - loss_train: 0.786204815831241 - loss_val: 0.9649539611078429\n",
      "Epoch: 5228 - time: 0.0031 - loss_train: 0.7861953880732063 - loss_val: 0.9649491312895713\n",
      "Epoch: 5229 - time: 0.0032 - loss_train: 0.7861859639831954 - loss_val: 0.9649443011216143\n",
      "Epoch: 5230 - time: 0.0031 - loss_train: 0.7861765435602039 - loss_val: 0.9649394706087778\n",
      "Epoch: 5231 - time: 0.0031 - loss_train: 0.786167126803229 - loss_val: 0.964934639755863\n",
      "Epoch: 5232 - time: 0.0031 - loss_train: 0.7861577137112652 - loss_val: 0.9649298085676672\n",
      "Epoch: 5233 - time: 0.0031 - loss_train: 0.7861483042833085 - loss_val: 0.9649249770489855\n",
      "Epoch: 5234 - time: 0.0031 - loss_train: 0.7861388985183537 - loss_val: 0.9649201452046046\n",
      "Epoch: 5235 - time: 0.0031 - loss_train: 0.7861294964153944 - loss_val: 0.9649153130393083\n",
      "Epoch: 5236 - time: 0.0031 - loss_train: 0.7861200979734245 - loss_val: 0.9649104805578773\n",
      "Epoch: 5237 - time: 0.0031 - loss_train: 0.7861107031914369 - loss_val: 0.9649056477650865\n",
      "Epoch: 5238 - time: 0.0031 - loss_train: 0.7861013120684247 - loss_val: 0.9649008146657054\n",
      "Epoch: 5239 - time: 0.0031 - loss_train: 0.7860919246033795 - loss_val: 0.9648959812645019\n",
      "Epoch: 5240 - time: 0.0031 - loss_train: 0.7860825407952932 - loss_val: 0.964891147566235\n",
      "Epoch: 5241 - time: 0.0031 - loss_train: 0.7860731606431564 - loss_val: 0.9648863135756625\n",
      "Epoch: 5242 - time: 0.0031 - loss_train: 0.7860637841459596 - loss_val: 0.9648814792975372\n",
      "Epoch: 5243 - time: 0.0031 - loss_train: 0.7860544113026927 - loss_val: 0.9648766447366064\n",
      "Epoch: 5244 - time: 0.0031 - loss_train: 0.7860450421123453 - loss_val: 0.9648718098976123\n",
      "Epoch: 5245 - time: 0.0031 - loss_train: 0.7860356765739056 - loss_val: 0.9648669747852945\n",
      "Epoch: 5246 - time: 0.0031 - loss_train: 0.786026314686362 - loss_val: 0.9648621394043848\n",
      "Epoch: 5247 - time: 0.0031 - loss_train: 0.7860169564487016 - loss_val: 0.9648573037596134\n",
      "Epoch: 5248 - time: 0.0031 - loss_train: 0.7860076018599118 - loss_val: 0.9648524678557049\n",
      "Epoch: 5249 - time: 0.0031 - loss_train: 0.7859982509189783 - loss_val: 0.9648476316973774\n",
      "Epoch: 5250 - time: 0.0031 - loss_train: 0.7859889036248869 - loss_val: 0.9648427952893466\n",
      "Epoch: 5251 - time: 0.0031 - loss_train: 0.785979559976623 - loss_val: 0.9648379586363217\n",
      "Epoch: 5252 - time: 0.0031 - loss_train: 0.7859702199731703 - loss_val: 0.9648331217430081\n",
      "Epoch: 5253 - time: 0.0031 - loss_train: 0.7859608836135132 - loss_val: 0.9648282846141071\n",
      "Epoch: 5254 - time: 0.0031 - loss_train: 0.785951550896634 - loss_val: 0.9648234472543122\n",
      "Epoch: 5255 - time: 0.0031 - loss_train: 0.7859422218215161 - loss_val: 0.964818609668315\n",
      "Epoch: 5256 - time: 0.0031 - loss_train: 0.7859328963871404 - loss_val: 0.9648137718608021\n",
      "Epoch: 5257 - time: 0.0031 - loss_train: 0.7859235745924877 - loss_val: 0.9648089338364543\n",
      "Epoch: 5258 - time: 0.0031 - loss_train: 0.7859142564365387 - loss_val: 0.9648040955999467\n",
      "Epoch: 5259 - time: 0.0031 - loss_train: 0.7859049419182736 - loss_val: 0.964799257155951\n",
      "Epoch: 5260 - time: 0.0031 - loss_train: 0.7858956310366706 - loss_val: 0.964794418509134\n",
      "Epoch: 5261 - time: 0.0031 - loss_train: 0.7858863237907079 - loss_val: 0.9647895796641559\n",
      "Epoch: 5262 - time: 0.0031 - loss_train: 0.7858770201793635 - loss_val: 0.9647847406256737\n",
      "Epoch: 5263 - time: 0.0031 - loss_train: 0.7858677202016134 - loss_val: 0.964779901398339\n",
      "Epoch: 5264 - time: 0.0031 - loss_train: 0.7858584238564345 - loss_val: 0.9647750619867973\n",
      "Epoch: 5265 - time: 0.0031 - loss_train: 0.7858491311428015 - loss_val: 0.9647702223956912\n",
      "Epoch: 5266 - time: 0.0031 - loss_train: 0.7858398420596893 - loss_val: 0.9647653826296566\n",
      "Epoch: 5267 - time: 0.0033 - loss_train: 0.7858305566060712 - loss_val: 0.9647605426933221\n",
      "Epoch: 5268 - time: 0.0031 - loss_train: 0.7858212747809206 - loss_val: 0.9647557025913184\n",
      "Epoch: 5269 - time: 0.0031 - loss_train: 0.7858119965832093 - loss_val: 0.964750862328263\n",
      "Epoch: 5270 - time: 0.0031 - loss_train: 0.7858027220119091 - loss_val: 0.9647460219087747\n",
      "Epoch: 5271 - time: 0.0031 - loss_train: 0.7857934510659909 - loss_val: 0.9647411813374616\n",
      "Epoch: 5272 - time: 0.0031 - loss_train: 0.7857841837444239 - loss_val: 0.9647363406189315\n",
      "Epoch: 5273 - time: 0.0031 - loss_train: 0.7857749200461774 - loss_val: 0.9647314997577835\n",
      "Epoch: 5274 - time: 0.0031 - loss_train: 0.7857656599702196 - loss_val: 0.9647266587586146\n",
      "Epoch: 5275 - time: 0.0044 - loss_train: 0.7857564035155177 - loss_val: 0.9647218176260143\n",
      "Epoch: 5276 - time: 0.0044 - loss_train: 0.7857471506810386 - loss_val: 0.9647169763645668\n",
      "Epoch: 5277 - time: 0.0044 - loss_train: 0.7857379014657476 - loss_val: 0.9647121349788521\n",
      "Epoch: 5278 - time: 0.0045 - loss_train: 0.7857286558686103 - loss_val: 0.9647072934734465\n",
      "Epoch: 5279 - time: 0.0044 - loss_train: 0.7857194138885902 - loss_val: 0.9647024518529179\n",
      "Epoch: 5280 - time: 0.0044 - loss_train: 0.7857101755246504 - loss_val: 0.9646976101218302\n",
      "Epoch: 5281 - time: 0.0044 - loss_train: 0.785700940775753 - loss_val: 0.9646927682847415\n",
      "Epoch: 5282 - time: 0.0044 - loss_train: 0.7856917096408597 - loss_val: 0.9646879263462076\n",
      "Epoch: 5283 - time: 0.0044 - loss_train: 0.7856824821189307 - loss_val: 0.9646830843107741\n",
      "Epoch: 5284 - time: 0.0044 - loss_train: 0.7856732582089264 - loss_val: 0.9646782421829849\n",
      "Epoch: 5285 - time: 0.0044 - loss_train: 0.7856640379098049 - loss_val: 0.9646733999673771\n",
      "Epoch: 5286 - time: 0.0044 - loss_train: 0.7856548212205239 - loss_val: 0.9646685576684818\n",
      "Epoch: 5287 - time: 0.0044 - loss_train: 0.7856456081400408 - loss_val: 0.9646637152908267\n",
      "Epoch: 5288 - time: 0.0044 - loss_train: 0.7856363986673108 - loss_val: 0.9646588728389338\n",
      "Epoch: 5289 - time: 0.0044 - loss_train: 0.7856271928012893 - loss_val: 0.9646540303173167\n",
      "Epoch: 5290 - time: 0.0044 - loss_train: 0.785617990540931 - loss_val: 0.9646491877304868\n",
      "Epoch: 5291 - time: 0.0044 - loss_train: 0.7856087918851881 - loss_val: 0.9646443450829485\n",
      "Epoch: 5292 - time: 0.0044 - loss_train: 0.7855995968330133 - loss_val: 0.9646395023792017\n",
      "Epoch: 5293 - time: 0.0044 - loss_train: 0.7855904053833581 - loss_val: 0.9646346596237391\n",
      "Epoch: 5294 - time: 0.0044 - loss_train: 0.7855812175351715 - loss_val: 0.96462981682105\n",
      "Epoch: 5295 - time: 0.0044 - loss_train: 0.7855720332874042 - loss_val: 0.9646249739756166\n",
      "Epoch: 5296 - time: 0.0045 - loss_train: 0.7855628526390038 - loss_val: 0.9646201310919158\n",
      "Epoch: 5297 - time: 0.0044 - loss_train: 0.785553675588918 - loss_val: 0.9646152881744203\n",
      "Epoch: 5298 - time: 0.0044 - loss_train: 0.7855445021360925 - loss_val: 0.9646104452275952\n",
      "Epoch: 5299 - time: 0.0044 - loss_train: 0.7855353322794731 - loss_val: 0.9646056022559013\n",
      "Epoch: 5300 - time: 0.0044 - loss_train: 0.7855261660180038 - loss_val: 0.9646007592637932\n",
      "Epoch: 5301 - time: 0.0044 - loss_train: 0.7855170033506277 - loss_val: 0.96459591625572\n",
      "Epoch: 5302 - time: 0.0044 - loss_train: 0.7855078442762875 - loss_val: 0.964591073236125\n",
      "Epoch: 5303 - time: 0.0044 - loss_train: 0.7854986887939244 - loss_val: 0.964586230209446\n",
      "Epoch: 5304 - time: 0.0044 - loss_train: 0.785489536902478 - loss_val: 0.9645813871801149\n",
      "Epoch: 5305 - time: 0.0045 - loss_train: 0.7854803886008879 - loss_val: 0.9645765441525593\n",
      "Epoch: 5306 - time: 0.0044 - loss_train: 0.7854712438880913 - loss_val: 0.9645717011311983\n",
      "Epoch: 5307 - time: 0.0044 - loss_train: 0.7854621027630264 - loss_val: 0.9645668581204473\n",
      "Epoch: 5308 - time: 0.0044 - loss_train: 0.7854529652246283 - loss_val: 0.9645620151247156\n",
      "Epoch: 5309 - time: 0.0044 - loss_train: 0.7854438312718316 - loss_val: 0.9645571721484065\n",
      "Epoch: 5310 - time: 0.0044 - loss_train: 0.7854347009035705 - loss_val: 0.964552329195918\n",
      "Epoch: 5311 - time: 0.0044 - loss_train: 0.7854255741187778 - loss_val: 0.9645474862716403\n",
      "Epoch: 5312 - time: 0.0044 - loss_train: 0.7854164509163846 - loss_val: 0.9645426433799608\n",
      "Epoch: 5313 - time: 0.0044 - loss_train: 0.7854073312953213 - loss_val: 0.9645378005252597\n",
      "Epoch: 5314 - time: 0.0044 - loss_train: 0.785398215254517 - loss_val: 0.9645329577119103\n",
      "Epoch: 5315 - time: 0.0044 - loss_train: 0.7853891027929004 - loss_val: 0.9645281149442807\n",
      "Epoch: 5316 - time: 0.0044 - loss_train: 0.7853799939093985 - loss_val: 0.9645232722267332\n",
      "Epoch: 5317 - time: 0.0044 - loss_train: 0.7853708886029365 - loss_val: 0.9645184295636257\n",
      "Epoch: 5318 - time: 0.0044 - loss_train: 0.7853617868724397 - loss_val: 0.9645135869593073\n",
      "Epoch: 5319 - time: 0.0044 - loss_train: 0.7853526887168318 - loss_val: 0.964508744418124\n",
      "Epoch: 5320 - time: 0.0044 - loss_train: 0.7853435941350351 - loss_val: 0.9645039019444138\n",
      "Epoch: 5321 - time: 0.0044 - loss_train: 0.7853345031259705 - loss_val: 0.9644990595425079\n",
      "Epoch: 5322 - time: 0.0047 - loss_train: 0.7853254156885582 - loss_val: 0.9644942172167343\n",
      "Epoch: 5323 - time: 0.0045 - loss_train: 0.7853163318217176 - loss_val: 0.9644893749714133\n",
      "Epoch: 5324 - time: 0.0045 - loss_train: 0.785307251524366 - loss_val: 0.9644845328108596\n",
      "Epoch: 5325 - time: 0.0044 - loss_train: 0.7852981747954197 - loss_val: 0.964479690739382\n",
      "Epoch: 5326 - time: 0.0044 - loss_train: 0.7852891016337944 - loss_val: 0.9644748487612824\n",
      "Epoch: 5327 - time: 0.0044 - loss_train: 0.7852800320384045 - loss_val: 0.964470006880857\n",
      "Epoch: 5328 - time: 0.0044 - loss_train: 0.7852709660081622 - loss_val: 0.9644651651023971\n",
      "Epoch: 5329 - time: 0.0044 - loss_train: 0.7852619035419793 - loss_val: 0.9644603234301862\n",
      "Epoch: 5330 - time: 0.0044 - loss_train: 0.7852528446387664 - loss_val: 0.9644554818685022\n",
      "Epoch: 5331 - time: 0.0044 - loss_train: 0.7852437892974328 - loss_val: 0.9644506404216163\n",
      "Epoch: 5332 - time: 0.0045 - loss_train: 0.7852347375168859 - loss_val: 0.9644457990937949\n",
      "Epoch: 5333 - time: 0.0045 - loss_train: 0.7852256892960335 - loss_val: 0.9644409578892983\n",
      "Epoch: 5334 - time: 0.0053 - loss_train: 0.7852166446337797 - loss_val: 0.9644361168123782\n",
      "Epoch: 5335 - time: 0.0050 - loss_train: 0.7852076035290293 - loss_val: 0.964431275867282\n",
      "Epoch: 5336 - time: 0.0045 - loss_train: 0.7851985659806853 - loss_val: 0.9644264350582511\n",
      "Epoch: 5337 - time: 0.0046 - loss_train: 0.7851895319876494 - loss_val: 0.96442159438952\n",
      "Epoch: 5338 - time: 0.0046 - loss_train: 0.7851805015488216 - loss_val: 0.9644167538653167\n",
      "Epoch: 5339 - time: 0.0044 - loss_train: 0.785171474663101 - loss_val: 0.9644119134898638\n",
      "Epoch: 5340 - time: 0.0043 - loss_train: 0.7851624513293857 - loss_val: 0.9644070732673767\n",
      "Epoch: 5341 - time: 0.0045 - loss_train: 0.7851534315465715 - loss_val: 0.9644022332020635\n",
      "Epoch: 5342 - time: 0.0043 - loss_train: 0.785144415313554 - loss_val: 0.9643973932981287\n",
      "Epoch: 5343 - time: 0.0043 - loss_train: 0.7851354026292267 - loss_val: 0.964392553559769\n",
      "Epoch: 5344 - time: 0.0042 - loss_train: 0.7851263934924821 - loss_val: 0.9643877139911741\n",
      "Epoch: 5345 - time: 0.0043 - loss_train: 0.7851173879022117 - loss_val: 0.9643828745965284\n",
      "Epoch: 5346 - time: 0.0042 - loss_train: 0.7851083858573048 - loss_val: 0.9643780353800088\n",
      "Epoch: 5347 - time: 0.0043 - loss_train: 0.7850993873566509 - loss_val: 0.9643731963457871\n",
      "Epoch: 5348 - time: 0.0042 - loss_train: 0.7850903923991354 - loss_val: 0.9643683574980285\n",
      "Epoch: 5349 - time: 0.0045 - loss_train: 0.7850814009836452 - loss_val: 0.9643635188408896\n",
      "Epoch: 5350 - time: 0.0044 - loss_train: 0.7850724131090646 - loss_val: 0.9643586803785233\n",
      "Epoch: 5351 - time: 0.0043 - loss_train: 0.7850634287742764 - loss_val: 0.9643538421150742\n",
      "Epoch: 5352 - time: 0.0042 - loss_train: 0.7850544479781622 - loss_val: 0.9643490040546826\n",
      "Epoch: 5353 - time: 0.0042 - loss_train: 0.785045470719602 - loss_val: 0.9643441662014787\n",
      "Epoch: 5354 - time: 0.0042 - loss_train: 0.785036496997475 - loss_val: 0.9643393285595894\n",
      "Epoch: 5355 - time: 0.0044 - loss_train: 0.7850275268106589 - loss_val: 0.964334491133134\n",
      "Epoch: 5356 - time: 0.0043 - loss_train: 0.7850185601580295 - loss_val: 0.9643296539262242\n",
      "Epoch: 5357 - time: 0.0043 - loss_train: 0.7850095970384607 - loss_val: 0.9643248169429677\n",
      "Epoch: 5358 - time: 0.0043 - loss_train: 0.7850006374508266 - loss_val: 0.9643199801874621\n",
      "Epoch: 5359 - time: 0.0043 - loss_train: 0.7849916813939992 - loss_val: 0.9643151436638017\n",
      "Epoch: 5360 - time: 0.0043 - loss_train: 0.784982728866848 - loss_val: 0.9643103073760725\n",
      "Epoch: 5361 - time: 0.0044 - loss_train: 0.7849737798682425 - loss_val: 0.9643054713283533\n",
      "Epoch: 5362 - time: 0.0044 - loss_train: 0.7849648343970496 - loss_val: 0.9643006355247172\n",
      "Epoch: 5363 - time: 0.0043 - loss_train: 0.7849558924521362 - loss_val: 0.9642957999692308\n",
      "Epoch: 5364 - time: 0.0043 - loss_train: 0.784946954032366 - loss_val: 0.9642909646659535\n",
      "Epoch: 5365 - time: 0.0043 - loss_train: 0.7849380191366029 - loss_val: 0.964286129618938\n",
      "Epoch: 5366 - time: 0.0043 - loss_train: 0.7849290877637078 - loss_val: 0.9642812948322317\n",
      "Epoch: 5367 - time: 0.0042 - loss_train: 0.7849201599125413 - loss_val: 0.9642764603098722\n",
      "Epoch: 5368 - time: 0.0043 - loss_train: 0.7849112355819623 - loss_val: 0.9642716260558928\n",
      "Epoch: 5369 - time: 0.0043 - loss_train: 0.7849023147708274 - loss_val: 0.9642667920743198\n",
      "Epoch: 5370 - time: 0.0044 - loss_train: 0.7848933974779927 - loss_val: 0.9642619583691717\n",
      "Epoch: 5371 - time: 0.0044 - loss_train: 0.7848844837023126 - loss_val: 0.9642571249444617\n",
      "Epoch: 5372 - time: 0.0043 - loss_train: 0.7848755734426393 - loss_val: 0.9642522918041935\n",
      "Epoch: 5373 - time: 0.0043 - loss_train: 0.7848666666978245 - loss_val: 0.9642474589523674\n",
      "Epoch: 5374 - time: 0.0043 - loss_train: 0.7848577634667173 - loss_val: 0.964242626392975\n",
      "Epoch: 5375 - time: 0.0043 - loss_train: 0.7848488637481664 - loss_val: 0.9642377941300008\n",
      "Epoch: 5376 - time: 0.0044 - loss_train: 0.7848399675410183 - loss_val: 0.964232962167423\n",
      "Epoch: 5377 - time: 0.0044 - loss_train: 0.7848310748441178 - loss_val: 0.9642281305092126\n",
      "Epoch: 5378 - time: 0.0043 - loss_train: 0.7848221856563089 - loss_val: 0.9642232991593339\n",
      "Epoch: 5379 - time: 0.0043 - loss_train: 0.7848132999764332 - loss_val: 0.964218468121745\n",
      "Epoch: 5380 - time: 0.0039 - loss_train: 0.7848044178033313 - loss_val: 0.9642136374003951\n",
      "Epoch: 5381 - time: 0.0031 - loss_train: 0.7847955391358423 - loss_val: 0.9642088069992285\n",
      "Epoch: 5382 - time: 0.0031 - loss_train: 0.7847866639728034 - loss_val: 0.9642039769221816\n",
      "Epoch: 5383 - time: 0.0031 - loss_train: 0.7847777923130503 - loss_val: 0.9641991471731841\n",
      "Epoch: 5384 - time: 0.0031 - loss_train: 0.7847689241554171 - loss_val: 0.9641943177561579\n",
      "Epoch: 5385 - time: 0.0031 - loss_train: 0.7847600594987366 - loss_val: 0.9641894886750191\n",
      "Epoch: 5386 - time: 0.0031 - loss_train: 0.7847511983418399 - loss_val: 0.9641846599336745\n",
      "Epoch: 5387 - time: 0.0031 - loss_train: 0.7847423406835562 - loss_val: 0.9641798315360285\n",
      "Epoch: 5388 - time: 0.0031 - loss_train: 0.7847334865227137 - loss_val: 0.9641750034859735\n",
      "Epoch: 5389 - time: 0.0031 - loss_train: 0.7847246358581383 - loss_val: 0.9641701757873974\n",
      "Epoch: 5390 - time: 0.0031 - loss_train: 0.7847157886886545 - loss_val: 0.9641653484441802\n",
      "Epoch: 5391 - time: 0.0031 - loss_train: 0.7847069450130852 - loss_val: 0.9641605214601948\n",
      "Epoch: 5392 - time: 0.0031 - loss_train: 0.7846981048302527 - loss_val: 0.9641556948393074\n",
      "Epoch: 5393 - time: 0.0031 - loss_train: 0.7846892681389757 - loss_val: 0.9641508685853779\n",
      "Epoch: 5394 - time: 0.0031 - loss_train: 0.7846804349380728 - loss_val: 0.9641460427022565\n",
      "Epoch: 5395 - time: 0.0031 - loss_train: 0.7846716052263607 - loss_val: 0.9641412171937882\n",
      "Epoch: 5396 - time: 0.0031 - loss_train: 0.7846627790026538 - loss_val: 0.9641363920638107\n",
      "Epoch: 5397 - time: 0.0031 - loss_train: 0.7846539562657653 - loss_val: 0.9641315673161543\n",
      "Epoch: 5398 - time: 0.0031 - loss_train: 0.7846451370145071 - loss_val: 0.9641267429546418\n",
      "Epoch: 5399 - time: 0.0031 - loss_train: 0.7846363212476892 - loss_val: 0.964121918983089\n",
      "Epoch: 5400 - time: 0.0031 - loss_train: 0.7846275089641193 - loss_val: 0.9641170954053049\n",
      "Epoch: 5401 - time: 0.0031 - loss_train: 0.784618700162604 - loss_val: 0.9641122722250898\n",
      "Epoch: 5402 - time: 0.0031 - loss_train: 0.7846098948419487 - loss_val: 0.9641074494462384\n",
      "Epoch: 5403 - time: 0.0031 - loss_train: 0.7846010930009557 - loss_val: 0.9641026270725379\n",
      "Epoch: 5404 - time: 0.0031 - loss_train: 0.7845922946384274 - loss_val: 0.9640978051077669\n",
      "Epoch: 5405 - time: 0.0031 - loss_train: 0.7845834997531635 - loss_val: 0.964092983555698\n",
      "Epoch: 5406 - time: 0.0031 - loss_train: 0.7845747083439615 - loss_val: 0.9640881624200961\n",
      "Epoch: 5407 - time: 0.0031 - loss_train: 0.7845659204096185 - loss_val: 0.9640833417047198\n",
      "Epoch: 5408 - time: 0.0032 - loss_train: 0.7845571359489291 - loss_val: 0.964078521413317\n",
      "Epoch: 5409 - time: 0.0031 - loss_train: 0.7845483549606859 - loss_val: 0.9640737015496322\n",
      "Epoch: 5410 - time: 0.0031 - loss_train: 0.7845395774436803 - loss_val: 0.9640688821174012\n",
      "Epoch: 5411 - time: 0.0031 - loss_train: 0.784530803396702 - loss_val: 0.9640640631203508\n",
      "Epoch: 5412 - time: 0.0031 - loss_train: 0.7845220328185388 - loss_val: 0.9640592445622023\n",
      "Epoch: 5413 - time: 0.0038 - loss_train: 0.7845132657079769 - loss_val: 0.9640544264466689\n",
      "Epoch: 5414 - time: 0.0033 - loss_train: 0.7845045020638008 - loss_val: 0.9640496087774566\n",
      "Epoch: 5415 - time: 0.0031 - loss_train: 0.7844957418847928 - loss_val: 0.9640447915582643\n",
      "Epoch: 5416 - time: 0.0031 - loss_train: 0.7844869851697338 - loss_val: 0.9640399747927817\n",
      "Epoch: 5417 - time: 0.0031 - loss_train: 0.7844782319174031 - loss_val: 0.9640351584846933\n",
      "Epoch: 5418 - time: 0.0031 - loss_train: 0.7844694821265777 - loss_val: 0.9640303426376741\n",
      "Epoch: 5419 - time: 0.0031 - loss_train: 0.7844607357960341 - loss_val: 0.9640255272553938\n",
      "Epoch: 5420 - time: 0.0031 - loss_train: 0.7844519929245453 - loss_val: 0.964020712341513\n",
      "Epoch: 5421 - time: 0.0031 - loss_train: 0.7844432535108833 - loss_val: 0.9640158978996856\n",
      "Epoch: 5422 - time: 0.0031 - loss_train: 0.7844345175538192 - loss_val: 0.9640110839335561\n",
      "Epoch: 5423 - time: 0.0031 - loss_train: 0.7844257850521209 - loss_val: 0.9640062704467638\n",
      "Epoch: 5424 - time: 0.0031 - loss_train: 0.7844170560045552 - loss_val: 0.96400145744294\n",
      "Epoch: 5425 - time: 0.0031 - loss_train: 0.7844083304098868 - loss_val: 0.9639966449257069\n",
      "Epoch: 5426 - time: 0.0031 - loss_train: 0.7843996082668792 - loss_val: 0.9639918328986814\n",
      "Epoch: 5427 - time: 0.0031 - loss_train: 0.7843908895742938 - loss_val: 0.9639870213654705\n",
      "Epoch: 5428 - time: 0.0031 - loss_train: 0.7843821743308901 - loss_val: 0.9639822103296756\n",
      "Epoch: 5429 - time: 0.0031 - loss_train: 0.7843734625354255 - loss_val: 0.9639773997948885\n",
      "Epoch: 5430 - time: 0.0031 - loss_train: 0.7843647541866564 - loss_val: 0.9639725897646945\n",
      "Epoch: 5431 - time: 0.0031 - loss_train: 0.7843560492833367 - loss_val: 0.9639677802426719\n",
      "Epoch: 5432 - time: 0.0031 - loss_train: 0.7843473478242186 - loss_val: 0.9639629712323907\n",
      "Epoch: 5433 - time: 0.0031 - loss_train: 0.7843386498080525 - loss_val: 0.9639581627374119\n",
      "Epoch: 5434 - time: 0.0031 - loss_train: 0.7843299552335868 - loss_val: 0.9639533547612908\n",
      "Epoch: 5435 - time: 0.0031 - loss_train: 0.7843212640995689 - loss_val: 0.9639485473075745\n",
      "Epoch: 5436 - time: 0.0031 - loss_train: 0.7843125764047435 - loss_val: 0.9639437403798016\n",
      "Epoch: 5437 - time: 0.0031 - loss_train: 0.784303892147853 - loss_val: 0.9639389339815035\n",
      "Epoch: 5438 - time: 0.0031 - loss_train: 0.7842952113276397 - loss_val: 0.9639341281162035\n",
      "Epoch: 5439 - time: 0.0031 - loss_train: 0.7842865339428422 - loss_val: 0.9639293227874183\n",
      "Epoch: 5440 - time: 0.0031 - loss_train: 0.7842778599921988 - loss_val: 0.963924517998655\n",
      "Epoch: 5441 - time: 0.0031 - loss_train: 0.7842691894744446 - loss_val: 0.9639197137534141\n",
      "Epoch: 5442 - time: 0.0031 - loss_train: 0.7842605223883133 - loss_val: 0.9639149100551899\n",
      "Epoch: 5443 - time: 0.0031 - loss_train: 0.7842518587325372 - loss_val: 0.9639101069074645\n",
      "Epoch: 5444 - time: 0.0031 - loss_train: 0.7842431985058462 - loss_val: 0.9639053043137153\n",
      "Epoch: 5445 - time: 0.0031 - loss_train: 0.7842345417069685 - loss_val: 0.9639005022774129\n",
      "Epoch: 5446 - time: 0.0031 - loss_train: 0.7842258883346301 - loss_val: 0.963895700802018\n",
      "Epoch: 5447 - time: 0.0031 - loss_train: 0.7842172383875557 - loss_val: 0.9638908998909832\n",
      "Epoch: 5448 - time: 0.0031 - loss_train: 0.7842085918644682 - loss_val: 0.9638860995477544\n",
      "Epoch: 5449 - time: 0.0031 - loss_train: 0.7841999487640874 - loss_val: 0.9638812997757689\n",
      "Epoch: 5450 - time: 0.0031 - loss_train: 0.7841913090851325 - loss_val: 0.9638765005784568\n",
      "Epoch: 5451 - time: 0.0031 - loss_train: 0.7841826728263204 - loss_val: 0.9638717019592402\n",
      "Epoch: 5452 - time: 0.0033 - loss_train: 0.7841740399863659 - loss_val: 0.9638669039215335\n",
      "Epoch: 5453 - time: 0.0031 - loss_train: 0.7841654105639815 - loss_val: 0.9638621064687409\n",
      "Epoch: 5454 - time: 0.0031 - loss_train: 0.7841567845578791 - loss_val: 0.9638573096042632\n",
      "Epoch: 5455 - time: 0.0031 - loss_train: 0.7841481619667673 - loss_val: 0.9638525133314878\n",
      "Epoch: 5456 - time: 0.0031 - loss_train: 0.7841395427893534 - loss_val: 0.9638477176537982\n",
      "Epoch: 5457 - time: 0.0031 - loss_train: 0.7841309270243431 - loss_val: 0.9638429225745685\n",
      "Epoch: 5458 - time: 0.0031 - loss_train: 0.7841223146704392 - loss_val: 0.9638381280971651\n",
      "Epoch: 5459 - time: 0.0031 - loss_train: 0.7841137057263439 - loss_val: 0.9638333342249453\n",
      "Epoch: 5460 - time: 0.0031 - loss_train: 0.7841051001907559 - loss_val: 0.9638285409612611\n",
      "Epoch: 5461 - time: 0.0031 - loss_train: 0.7840964980623725 - loss_val: 0.9638237483094535\n",
      "Epoch: 5462 - time: 0.0031 - loss_train: 0.7840878993398905 - loss_val: 0.9638189562728566\n",
      "Epoch: 5463 - time: 0.0031 - loss_train: 0.7840793040220029 - loss_val: 0.9638141648547979\n",
      "Epoch: 5464 - time: 0.0031 - loss_train: 0.7840707121074015 - loss_val: 0.9638093740585935\n",
      "Epoch: 5465 - time: 0.0031 - loss_train: 0.784062123594776 - loss_val: 0.9638045838875544\n",
      "Epoch: 5466 - time: 0.0031 - loss_train: 0.7840535384828142 - loss_val: 0.9637997943449828\n",
      "Epoch: 5467 - time: 0.0031 - loss_train: 0.784044956770202 - loss_val: 0.9637950054341727\n",
      "Epoch: 5468 - time: 0.0031 - loss_train: 0.7840363784556232 - loss_val: 0.9637902171584093\n",
      "Epoch: 5469 - time: 0.0031 - loss_train: 0.7840278035377596 - loss_val: 0.9637854295209716\n",
      "Epoch: 5470 - time: 0.0031 - loss_train: 0.7840192320152913 - loss_val: 0.9637806425251267\n",
      "Epoch: 5471 - time: 0.0045 - loss_train: 0.7840106638868961 - loss_val: 0.9637758561741385\n",
      "Epoch: 5472 - time: 0.0044 - loss_train: 0.78400209915125 - loss_val: 0.96377107047126\n",
      "Epoch: 5473 - time: 0.0044 - loss_train: 0.783993537807027 - loss_val: 0.9637662854197347\n",
      "Epoch: 5474 - time: 0.0044 - loss_train: 0.7839849798528989 - loss_val: 0.9637615010228023\n",
      "Epoch: 5475 - time: 0.0044 - loss_train: 0.783976425287536 - loss_val: 0.9637567172836897\n",
      "Epoch: 5476 - time: 0.0045 - loss_train: 0.7839678741096063 - loss_val: 0.9637519342056174\n",
      "Epoch: 5477 - time: 0.0045 - loss_train: 0.7839593263177751 - loss_val: 0.963747151791799\n",
      "Epoch: 5478 - time: 0.0045 - loss_train: 0.7839507819107073 - loss_val: 0.9637423700454386\n",
      "Epoch: 5479 - time: 0.0043 - loss_train: 0.783942240887064 - loss_val: 0.9637375889697314\n",
      "Epoch: 5480 - time: 0.0044 - loss_train: 0.7839337032455062 - loss_val: 0.9637328085678671\n",
      "Epoch: 5481 - time: 0.0043 - loss_train: 0.7839251689846913 - loss_val: 0.9637280288430236\n",
      "Epoch: 5482 - time: 0.0043 - loss_train: 0.7839166381032752 - loss_val: 0.9637232497983732\n",
      "Epoch: 5483 - time: 0.0045 - loss_train: 0.7839081105999116 - loss_val: 0.9637184714370794\n",
      "Epoch: 5484 - time: 0.0048 - loss_train: 0.7838995864732533 - loss_val: 0.9637136937622964\n",
      "Epoch: 5485 - time: 0.0045 - loss_train: 0.7838910657219494 - loss_val: 0.9637089167771702\n",
      "Epoch: 5486 - time: 0.0044 - loss_train: 0.7838825483446482 - loss_val: 0.9637041404848404\n",
      "Epoch: 5487 - time: 0.0043 - loss_train: 0.783874034339995 - loss_val: 0.9636993648884375\n",
      "Epoch: 5488 - time: 0.0043 - loss_train: 0.783865523706634 - loss_val: 0.9636945899910818\n",
      "Epoch: 5489 - time: 0.0045 - loss_train: 0.7838570164432069 - loss_val: 0.9636898157958876\n",
      "Epoch: 5490 - time: 0.0045 - loss_train: 0.7838485125483537 - loss_val: 0.9636850423059607\n",
      "Epoch: 5491 - time: 0.0045 - loss_train: 0.7838400120207116 - loss_val: 0.9636802695243964\n",
      "Epoch: 5492 - time: 0.0045 - loss_train: 0.7838315148589163 - loss_val: 0.9636754974542846\n",
      "Epoch: 5493 - time: 0.0038 - loss_train: 0.7838230210616021 - loss_val: 0.9636707260987047\n",
      "Epoch: 5494 - time: 0.0038 - loss_train: 0.7838145306273996 - loss_val: 0.9636659554607291\n",
      "Epoch: 5495 - time: 0.0038 - loss_train: 0.7838060435549387 - loss_val: 0.9636611855434207\n",
      "Epoch: 5496 - time: 0.0038 - loss_train: 0.7837975598428466 - loss_val: 0.9636564163498345\n",
      "Epoch: 5497 - time: 0.0038 - loss_train: 0.7837890794897493 - loss_val: 0.963651647883018\n",
      "Epoch: 5498 - time: 0.0039 - loss_train: 0.7837806024942695 - loss_val: 0.9636468801460091\n",
      "Epoch: 5499 - time: 0.0038 - loss_train: 0.7837721288550288 - loss_val: 0.9636421131418377\n",
      "Epoch: 5500 - time: 0.0041 - loss_train: 0.7837636585706461 - loss_val: 0.9636373468735249\n",
      "Epoch: 5501 - time: 0.0045 - loss_train: 0.7837551916397392 - loss_val: 0.963632581344084\n",
      "Epoch: 5502 - time: 0.0045 - loss_train: 0.7837467280609222 - loss_val: 0.9636278165565205\n",
      "Epoch: 5503 - time: 0.0046 - loss_train: 0.7837382678328083 - loss_val: 0.9636230525138302\n",
      "Epoch: 5504 - time: 0.0043 - loss_train: 0.7837298109540091 - loss_val: 0.9636182892190003\n",
      "Epoch: 5505 - time: 0.0045 - loss_train: 0.7837213574231328 - loss_val: 0.9636135266750103\n",
      "Epoch: 5506 - time: 0.0044 - loss_train: 0.7837129072387857 - loss_val: 0.9636087648848308\n",
      "Epoch: 5507 - time: 0.0044 - loss_train: 0.7837044603995734 - loss_val: 0.9636040038514265\n",
      "Epoch: 5508 - time: 0.0044 - loss_train: 0.7836960169040984 - loss_val: 0.963599243577749\n",
      "Epoch: 5509 - time: 0.0044 - loss_train: 0.7836875767509606 - loss_val: 0.9635944840667434\n",
      "Epoch: 5510 - time: 0.0043 - loss_train: 0.7836791399387587 - loss_val: 0.9635897253213491\n",
      "Epoch: 5511 - time: 0.0031 - loss_train: 0.7836707064660888 - loss_val: 0.963584967344492\n",
      "Epoch: 5512 - time: 0.0031 - loss_train: 0.7836622763315452 - loss_val: 0.9635802101390937\n",
      "Epoch: 5513 - time: 0.0037 - loss_train: 0.78365384953372 - loss_val: 0.963575453708065\n",
      "Epoch: 5514 - time: 0.0031 - loss_train: 0.7836454260712032 - loss_val: 0.9635706980543088\n",
      "Epoch: 5515 - time: 0.0031 - loss_train: 0.7836370059425831 - loss_val: 0.9635659431807198\n",
      "Epoch: 5516 - time: 0.0031 - loss_train: 0.7836285891464447 - loss_val: 0.9635611890901836\n",
      "Epoch: 5517 - time: 0.0031 - loss_train: 0.7836201756813722 - loss_val: 0.9635564357855773\n",
      "Epoch: 5518 - time: 0.0031 - loss_train: 0.783611765545947 - loss_val: 0.9635516832697707\n",
      "Epoch: 5519 - time: 0.0031 - loss_train: 0.783603358738749 - loss_val: 0.9635469315456225\n",
      "Epoch: 5520 - time: 0.0031 - loss_train: 0.783594955258355 - loss_val: 0.9635421806159862\n",
      "Epoch: 5521 - time: 0.0031 - loss_train: 0.7835865551033403 - loss_val: 0.9635374304837021\n",
      "Epoch: 5522 - time: 0.0031 - loss_train: 0.7835781582722782 - loss_val: 0.9635326811516074\n",
      "Epoch: 5523 - time: 0.0031 - loss_train: 0.78356976476374 - loss_val: 0.9635279326225253\n",
      "Epoch: 5524 - time: 0.0031 - loss_train: 0.7835613745762939 - loss_val: 0.9635231848992754\n",
      "Epoch: 5525 - time: 0.0031 - loss_train: 0.7835529877085069 - loss_val: 0.9635184379846663\n",
      "Epoch: 5526 - time: 0.0031 - loss_train: 0.7835446041589439 - loss_val: 0.9635136918814958\n",
      "Epoch: 5527 - time: 0.0031 - loss_train: 0.7835362239261674 - loss_val: 0.9635089465925573\n",
      "Epoch: 5528 - time: 0.0031 - loss_train: 0.7835278470087375 - loss_val: 0.9635042021206326\n",
      "Epoch: 5529 - time: 0.0031 - loss_train: 0.7835194734052124 - loss_val: 0.963499458468497\n",
      "Epoch: 5530 - time: 0.0031 - loss_train: 0.7835111031141487 - loss_val: 0.9634947156389143\n",
      "Epoch: 5531 - time: 0.0031 - loss_train: 0.7835027361341 - loss_val: 0.9634899736346415\n",
      "Epoch: 5532 - time: 0.0031 - loss_train: 0.7834943724636183 - loss_val: 0.9634852324584285\n",
      "Epoch: 5533 - time: 0.0031 - loss_train: 0.7834860121012528 - loss_val: 0.9634804921130143\n",
      "Epoch: 5534 - time: 0.0031 - loss_train: 0.7834776550455519 - loss_val: 0.9634757526011276\n",
      "Epoch: 5535 - time: 0.0031 - loss_train: 0.7834693012950604 - loss_val: 0.9634710139254937\n",
      "Epoch: 5536 - time: 0.0031 - loss_train: 0.783460950848322 - loss_val: 0.9634662760888241\n",
      "Epoch: 5537 - time: 0.0031 - loss_train: 0.7834526037038777 - loss_val: 0.9634615390938245\n",
      "Epoch: 5538 - time: 0.0031 - loss_train: 0.7834442598602659 - loss_val: 0.9634568029431899\n",
      "Epoch: 5539 - time: 0.0031 - loss_train: 0.7834359193160244 - loss_val: 0.9634520676396084\n",
      "Epoch: 5540 - time: 0.0031 - loss_train: 0.7834275820696873 - loss_val: 0.9634473331857588\n",
      "Epoch: 5541 - time: 0.0031 - loss_train: 0.7834192481197878 - loss_val: 0.9634425995843113\n",
      "Epoch: 5542 - time: 0.0031 - loss_train: 0.7834109174648558 - loss_val: 0.9634378668379268\n",
      "Epoch: 5543 - time: 0.0031 - loss_train: 0.7834025901034193 - loss_val: 0.9634331349492574\n",
      "Epoch: 5544 - time: 0.0031 - loss_train: 0.7833942660340049 - loss_val: 0.9634284039209473\n",
      "Epoch: 5545 - time: 0.0031 - loss_train: 0.7833859452551365 - loss_val: 0.9634236737556325\n",
      "Epoch: 5546 - time: 0.0031 - loss_train: 0.783377627765335 - loss_val: 0.9634189444559377\n",
      "Epoch: 5547 - time: 0.0031 - loss_train: 0.7833693135631217 - loss_val: 0.9634142160244803\n",
      "Epoch: 5548 - time: 0.0031 - loss_train: 0.7833610026470128 - loss_val: 0.9634094884638705\n",
      "Epoch: 5549 - time: 0.0044 - loss_train: 0.7833526950155237 - loss_val: 0.9634047617767079\n",
      "Epoch: 5550 - time: 0.0046 - loss_train: 0.7833443906671678 - loss_val: 0.9634000359655838\n",
      "Epoch: 5551 - time: 0.0045 - loss_train: 0.7833360896004558 - loss_val: 0.9633953110330796\n",
      "Epoch: 5552 - time: 0.0042 - loss_train: 0.7833277918138974 - loss_val: 0.9633905869817707\n",
      "Epoch: 5553 - time: 0.0044 - loss_train: 0.783319497305998 - loss_val: 0.963385863814221\n",
      "Epoch: 5554 - time: 0.0044 - loss_train: 0.7833112060752628 - loss_val: 0.9633811415329873\n",
      "Epoch: 5555 - time: 0.0044 - loss_train: 0.7833029181201944 - loss_val: 0.9633764201406159\n",
      "Epoch: 5556 - time: 0.0042 - loss_train: 0.7832946334392921 - loss_val: 0.9633716996396463\n",
      "Epoch: 5557 - time: 0.0044 - loss_train: 0.7832863520310543 - loss_val: 0.9633669800326077\n",
      "Epoch: 5558 - time: 0.0042 - loss_train: 0.7832780738939769 - loss_val: 0.9633622613220212\n",
      "Epoch: 5559 - time: 0.0044 - loss_train: 0.7832697990265532 - loss_val: 0.9633575435103983\n",
      "Epoch: 5560 - time: 0.0042 - loss_train: 0.7832615274272752 - loss_val: 0.9633528266002436\n",
      "Epoch: 5561 - time: 0.0044 - loss_train: 0.7832532590946321 - loss_val: 0.9633481105940498\n",
      "Epoch: 5562 - time: 0.0042 - loss_train: 0.7832449940271103 - loss_val: 0.9633433954943047\n",
      "Epoch: 5563 - time: 0.0044 - loss_train: 0.7832367322231953 - loss_val: 0.9633386813034842\n",
      "Epoch: 5564 - time: 0.0043 - loss_train: 0.7832284736813702 - loss_val: 0.9633339680240551\n",
      "Epoch: 5565 - time: 0.0044 - loss_train: 0.7832202184001149 - loss_val: 0.9633292556584774\n",
      "Epoch: 5566 - time: 0.0037 - loss_train: 0.783211966377908 - loss_val: 0.963324544209202\n",
      "Epoch: 5567 - time: 0.0035 - loss_train: 0.7832037176132257 - loss_val: 0.9633198336786697\n",
      "Epoch: 5568 - time: 0.0035 - loss_train: 0.7831954721045422 - loss_val: 0.9633151240693123\n",
      "Epoch: 5569 - time: 0.0036 - loss_train: 0.7831872298503295 - loss_val: 0.9633104153835547\n",
      "Epoch: 5570 - time: 0.0035 - loss_train: 0.7831789908490564 - loss_val: 0.9633057076238122\n",
      "Epoch: 5571 - time: 0.0036 - loss_train: 0.7831707550991918 - loss_val: 0.9633010007924888\n",
      "Epoch: 5572 - time: 0.0036 - loss_train: 0.7831625225991999 - loss_val: 0.9632962948919817\n",
      "Epoch: 5573 - time: 0.0036 - loss_train: 0.7831542933475444 - loss_val: 0.9632915899246816\n",
      "Epoch: 5574 - time: 0.0036 - loss_train: 0.7831460673426861 - loss_val: 0.9632868858929662\n",
      "Epoch: 5575 - time: 0.0036 - loss_train: 0.7831378445830836 - loss_val: 0.9632821827992044\n",
      "Epoch: 5576 - time: 0.0035 - loss_train: 0.7831296250671936 - loss_val: 0.963277480645761\n",
      "Epoch: 5577 - time: 0.0035 - loss_train: 0.7831214087934705 - loss_val: 0.9632727794349857\n",
      "Epoch: 5578 - time: 0.0035 - loss_train: 0.7831131957603663 - loss_val: 0.9632680791692244\n",
      "Epoch: 5579 - time: 0.0035 - loss_train: 0.7831049859663315 - loss_val: 0.9632633798508107\n",
      "Epoch: 5580 - time: 0.0038 - loss_train: 0.7830967794098137 - loss_val: 0.9632586814820709\n",
      "Epoch: 5581 - time: 0.0032 - loss_train: 0.7830885760892584 - loss_val: 0.9632539840653225\n",
      "Epoch: 5582 - time: 0.0031 - loss_train: 0.7830803760031092 - loss_val: 0.9632492876028729\n",
      "Epoch: 5583 - time: 0.0031 - loss_train: 0.7830721791498072 - loss_val: 0.9632445920970217\n",
      "Epoch: 5584 - time: 0.0031 - loss_train: 0.7830639855277921 - loss_val: 0.9632398975500589\n",
      "Epoch: 5585 - time: 0.0031 - loss_train: 0.7830557951354999 - loss_val: 0.9632352039642663\n",
      "Epoch: 5586 - time: 0.0031 - loss_train: 0.7830476079713655 - loss_val: 0.9632305113419156\n",
      "Epoch: 5587 - time: 0.0031 - loss_train: 0.7830394240338221 - loss_val: 0.963225819685272\n",
      "Epoch: 5588 - time: 0.0031 - loss_train: 0.7830312433212996 - loss_val: 0.9632211289965881\n",
      "Epoch: 5589 - time: 0.0031 - loss_train: 0.7830230658322256 - loss_val: 0.9632164392781105\n",
      "Epoch: 5590 - time: 0.0031 - loss_train: 0.7830148915650271 - loss_val: 0.9632117505320763\n",
      "Epoch: 5591 - time: 0.0032 - loss_train: 0.7830067205181275 - loss_val: 0.9632070627607128\n",
      "Epoch: 5592 - time: 0.0031 - loss_train: 0.7829985526899478 - loss_val: 0.9632023759662389\n",
      "Epoch: 5593 - time: 0.0031 - loss_train: 0.782990388078908 - loss_val: 0.9631976901508643\n",
      "Epoch: 5594 - time: 0.0031 - loss_train: 0.7829822266834247 - loss_val: 0.9631930053167905\n",
      "Epoch: 5595 - time: 0.0031 - loss_train: 0.7829740685019135 - loss_val: 0.9631883214662091\n",
      "Epoch: 5596 - time: 0.0031 - loss_train: 0.782965913532787 - loss_val: 0.9631836386013028\n",
      "Epoch: 5597 - time: 0.0031 - loss_train: 0.7829577617744559 - loss_val: 0.9631789567242479\n",
      "Epoch: 5598 - time: 0.0031 - loss_train: 0.7829496132253285 - loss_val: 0.9631742758372054\n",
      "Epoch: 5599 - time: 0.0031 - loss_train: 0.7829414678838107 - loss_val: 0.9631695959423358\n",
      "Epoch: 5600 - time: 0.0031 - loss_train: 0.7829333257483071 - loss_val: 0.963164917041784\n",
      "Epoch: 5601 - time: 0.0031 - loss_train: 0.7829251868172193 - loss_val: 0.9631602391376884\n",
      "Epoch: 5602 - time: 0.0031 - loss_train: 0.7829170510889474 - loss_val: 0.9631555622321785\n",
      "Epoch: 5603 - time: 0.0031 - loss_train: 0.7829089185618883 - loss_val: 0.9631508863273757\n",
      "Epoch: 5604 - time: 0.0031 - loss_train: 0.7829007892344375 - loss_val: 0.9631462114253904\n",
      "Epoch: 5605 - time: 0.0031 - loss_train: 0.7828926631049883 - loss_val: 0.9631415375283251\n",
      "Epoch: 5606 - time: 0.0031 - loss_train: 0.7828845401719308 - loss_val: 0.9631368646382727\n",
      "Epoch: 5607 - time: 0.0031 - loss_train: 0.7828764204336549 - loss_val: 0.963132192757319\n",
      "Epoch: 5608 - time: 0.0031 - loss_train: 0.7828683038885459 - loss_val: 0.9631275218875376\n",
      "Epoch: 5609 - time: 0.0031 - loss_train: 0.7828601905349895 - loss_val: 0.963122852030997\n",
      "Epoch: 5610 - time: 0.0031 - loss_train: 0.7828520803713666 - loss_val: 0.963118183189754\n",
      "Epoch: 5611 - time: 0.0031 - loss_train: 0.7828439733960582 - loss_val: 0.9631135153658568\n",
      "Epoch: 5612 - time: 0.0031 - loss_train: 0.7828358696074413 - loss_val: 0.9631088485613454\n",
      "Epoch: 5613 - time: 0.0031 - loss_train: 0.7828277690038921 - loss_val: 0.9631041827782498\n",
      "Epoch: 5614 - time: 0.0031 - loss_train: 0.7828196715837833 - loss_val: 0.9630995180185928\n",
      "Epoch: 5615 - time: 0.0031 - loss_train: 0.7828115773454866 - loss_val: 0.9630948542843858\n",
      "Epoch: 5616 - time: 0.0031 - loss_train: 0.782803486287371 - loss_val: 0.9630901915776329\n",
      "Epoch: 5617 - time: 0.0032 - loss_train: 0.7827953984078033 - loss_val: 0.9630855299003285\n",
      "Epoch: 5618 - time: 0.0031 - loss_train: 0.7827873137051483 - loss_val: 0.9630808692544593\n",
      "Epoch: 5619 - time: 0.0033 - loss_train: 0.7827792321777683 - loss_val: 0.9630762096420012\n",
      "Epoch: 5620 - time: 0.0031 - loss_train: 0.7827711538240233 - loss_val: 0.963071551064922\n",
      "Epoch: 5621 - time: 0.0031 - loss_train: 0.7827630786422722 - loss_val: 0.9630668935251797\n",
      "Epoch: 5622 - time: 0.0031 - loss_train: 0.7827550066308702 - loss_val: 0.9630622370247252\n",
      "Epoch: 5623 - time: 0.0031 - loss_train: 0.7827469377881715 - loss_val: 0.9630575815654987\n",
      "Epoch: 5624 - time: 0.0031 - loss_train: 0.7827388721125274 - loss_val: 0.9630529271494322\n",
      "Epoch: 5625 - time: 0.0031 - loss_train: 0.7827308096022874 - loss_val: 0.9630482737784487\n",
      "Epoch: 5626 - time: 0.0031 - loss_train: 0.7827227502557987 - loss_val: 0.9630436214544609\n",
      "Epoch: 5627 - time: 0.0031 - loss_train: 0.7827146940714065 - loss_val: 0.9630389701793749\n",
      "Epoch: 5628 - time: 0.0031 - loss_train: 0.7827066410474534 - loss_val: 0.9630343199550855\n",
      "Epoch: 5629 - time: 0.0031 - loss_train: 0.7826985911822798 - loss_val: 0.96302967078348\n",
      "Epoch: 5630 - time: 0.0031 - loss_train: 0.7826905444742248 - loss_val: 0.9630250226664357\n",
      "Epoch: 5631 - time: 0.0031 - loss_train: 0.7826825009216246 - loss_val: 0.963020375605822\n",
      "Epoch: 5632 - time: 0.0031 - loss_train: 0.7826744605228128 - loss_val: 0.963015729603499\n",
      "Epoch: 5633 - time: 0.0031 - loss_train: 0.782666423276122 - loss_val: 0.9630110846613167\n",
      "Epoch: 5634 - time: 0.0031 - loss_train: 0.7826583891798817 - loss_val: 0.9630064407811177\n",
      "Epoch: 5635 - time: 0.0031 - loss_train: 0.7826503582324199 - loss_val: 0.9630017979647338\n",
      "Epoch: 5636 - time: 0.0031 - loss_train: 0.7826423304320611 - loss_val: 0.9629971562139901\n",
      "Epoch: 5637 - time: 0.0031 - loss_train: 0.7826343057771299 - loss_val: 0.962992515530701\n",
      "Epoch: 5638 - time: 0.0031 - loss_train: 0.7826262842659466 - loss_val: 0.962987875916672\n",
      "Epoch: 5639 - time: 0.0031 - loss_train: 0.7826182658968301 - loss_val: 0.962983237373701\n",
      "Epoch: 5640 - time: 0.0031 - loss_train: 0.7826102506680976 - loss_val: 0.9629785999035737\n",
      "Epoch: 5641 - time: 0.0031 - loss_train: 0.7826022385780634 - loss_val: 0.9629739635080725\n",
      "Epoch: 5642 - time: 0.0031 - loss_train: 0.78259422962504 - loss_val: 0.9629693281889652\n",
      "Epoch: 5643 - time: 0.0031 - loss_train: 0.7825862238073377 - loss_val: 0.9629646939480119\n",
      "Epoch: 5644 - time: 0.0031 - loss_train: 0.7825782211232646 - loss_val: 0.9629600607869666\n",
      "Epoch: 5645 - time: 0.0031 - loss_train: 0.7825702215711269 - loss_val: 0.9629554287075709\n",
      "Epoch: 5646 - time: 0.0031 - loss_train: 0.7825622251492278 - loss_val: 0.9629507977115604\n",
      "Epoch: 5647 - time: 0.0031 - loss_train: 0.7825542318558697 - loss_val: 0.962946167800658\n",
      "Epoch: 5648 - time: 0.0031 - loss_train: 0.7825462416893516 - loss_val: 0.9629415389765817\n",
      "Epoch: 5649 - time: 0.0031 - loss_train: 0.7825382546479709 - loss_val: 0.9629369112410376\n",
      "Epoch: 5650 - time: 0.0031 - loss_train: 0.7825302707300222 - loss_val: 0.9629322845957239\n",
      "Epoch: 5651 - time: 0.0031 - loss_train: 0.7825222899338005 - loss_val: 0.962927659042329\n",
      "Epoch: 5652 - time: 0.0031 - loss_train: 0.7825143122575937 - loss_val: 0.9629230345825349\n",
      "Epoch: 5653 - time: 0.0031 - loss_train: 0.7825063376996927 - loss_val: 0.9629184112180111\n",
      "Epoch: 5654 - time: 0.0031 - loss_train: 0.7824983662583834 - loss_val: 0.9629137889504207\n",
      "Epoch: 5655 - time: 0.0031 - loss_train: 0.7824903979319502 - loss_val: 0.9629091677814172\n",
      "Epoch: 5656 - time: 0.0031 - loss_train: 0.7824824327186755 - loss_val: 0.9629045477126436\n",
      "Epoch: 5657 - time: 0.0033 - loss_train: 0.7824744706168394 - loss_val: 0.9628999287457365\n",
      "Epoch: 5658 - time: 0.0031 - loss_train: 0.7824665116247195 - loss_val: 0.9628953108823219\n",
      "Epoch: 5659 - time: 0.0031 - loss_train: 0.7824585557405916 - loss_val: 0.9628906941240174\n",
      "Epoch: 5660 - time: 0.0031 - loss_train: 0.7824506029627303 - loss_val: 0.9628860784724309\n",
      "Epoch: 5661 - time: 0.0031 - loss_train: 0.782442653289406 - loss_val: 0.9628814639291615\n",
      "Epoch: 5662 - time: 0.0031 - loss_train: 0.7824347067188885 - loss_val: 0.9628768504958011\n",
      "Epoch: 5663 - time: 0.0031 - loss_train: 0.7824267632494457 - loss_val: 0.96287223817393\n",
      "Epoch: 5664 - time: 0.0031 - loss_train: 0.7824188228793416 - loss_val: 0.9628676269651216\n",
      "Epoch: 5665 - time: 0.0031 - loss_train: 0.7824108856068399 - loss_val: 0.9628630168709404\n",
      "Epoch: 5666 - time: 0.0031 - loss_train: 0.7824029514302017 - loss_val: 0.9628584078929394\n",
      "Epoch: 5667 - time: 0.0031 - loss_train: 0.7823950203476849 - loss_val: 0.962853800032665\n",
      "Epoch: 5668 - time: 0.0031 - loss_train: 0.7823870923575469 - loss_val: 0.9628491932916544\n",
      "Epoch: 5669 - time: 0.0034 - loss_train: 0.7823791674580414 - loss_val: 0.962844587671435\n",
      "Epoch: 5670 - time: 0.0031 - loss_train: 0.7823712456474213 - loss_val: 0.9628399831735274\n",
      "Epoch: 5671 - time: 0.0031 - loss_train: 0.782363326923937 - loss_val: 0.9628353797994387\n",
      "Epoch: 5672 - time: 0.0031 - loss_train: 0.7823554112858357 - loss_val: 0.9628307775506725\n",
      "Epoch: 5673 - time: 0.0031 - loss_train: 0.7823474987313643 - loss_val: 0.9628261764287206\n",
      "Epoch: 5674 - time: 0.0031 - loss_train: 0.7823395892587665 - loss_val: 0.9628215764350657\n",
      "Epoch: 5675 - time: 0.0031 - loss_train: 0.7823316828662835 - loss_val: 0.9628169775711827\n",
      "Epoch: 5676 - time: 0.0031 - loss_train: 0.7823237795521554 - loss_val: 0.9628123798385362\n",
      "Epoch: 5677 - time: 0.0031 - loss_train: 0.7823158793146197 - loss_val: 0.9628077832385835\n",
      "Epoch: 5678 - time: 0.0031 - loss_train: 0.7823079821519116 - loss_val: 0.9628031877727725\n",
      "Epoch: 5679 - time: 0.0031 - loss_train: 0.7823000880622645 - loss_val: 0.9627985934425408\n",
      "Epoch: 5680 - time: 0.0031 - loss_train: 0.7822921970439093 - loss_val: 0.9627940002493195\n",
      "Epoch: 5681 - time: 0.0031 - loss_train: 0.7822843090950756 - loss_val: 0.9627894081945287\n",
      "Epoch: 5682 - time: 0.0031 - loss_train: 0.7822764242139899 - loss_val: 0.9627848172795812\n",
      "Epoch: 5683 - time: 0.0031 - loss_train: 0.7822685423988772 - loss_val: 0.9627802275058794\n",
      "Epoch: 5684 - time: 0.0031 - loss_train: 0.7822606636479605 - loss_val: 0.9627756388748178\n",
      "Epoch: 5685 - time: 0.0031 - loss_train: 0.7822527879594604 - loss_val: 0.9627710513877821\n",
      "Epoch: 5686 - time: 0.0031 - loss_train: 0.7822449153315953 - loss_val: 0.9627664650461484\n",
      "Epoch: 5687 - time: 0.0031 - loss_train: 0.7822370457625816 - loss_val: 0.9627618798512848\n",
      "Epoch: 5688 - time: 0.0031 - loss_train: 0.7822291792506342 - loss_val: 0.9627572958045494\n",
      "Epoch: 5689 - time: 0.0031 - loss_train: 0.7822213157939648 - loss_val: 0.9627527129072924\n",
      "Epoch: 5690 - time: 0.0031 - loss_train: 0.7822134553907839 - loss_val: 0.9627481311608551\n",
      "Epoch: 5691 - time: 0.0031 - loss_train: 0.7822055980392992 - loss_val: 0.962743550566569\n",
      "Epoch: 5692 - time: 0.0031 - loss_train: 0.7821977437377173 - loss_val: 0.9627389711257586\n",
      "Epoch: 5693 - time: 0.0031 - loss_train: 0.7821898924842421 - loss_val: 0.9627343928397372\n",
      "Epoch: 5694 - time: 0.0031 - loss_train: 0.7821820442770755 - loss_val: 0.9627298157098114\n",
      "Epoch: 5695 - time: 0.0032 - loss_train: 0.7821741991144172 - loss_val: 0.9627252397372759\n",
      "Epoch: 5696 - time: 0.0031 - loss_train: 0.7821663569944646 - loss_val: 0.962720664923422\n",
      "Epoch: 5697 - time: 0.0031 - loss_train: 0.7821585179154136 - loss_val: 0.9627160912695257\n",
      "Epoch: 5698 - time: 0.0031 - loss_train: 0.7821506818754581 - loss_val: 0.9627115187768589\n",
      "Epoch: 5699 - time: 0.0031 - loss_train: 0.782142848872789 - loss_val: 0.9627069474466832\n",
      "Epoch: 5700 - time: 0.0031 - loss_train: 0.7821350189055963 - loss_val: 0.9627023772802503\n",
      "Epoch: 5701 - time: 0.0031 - loss_train: 0.7821271919720673 - loss_val: 0.9626978082788044\n",
      "Epoch: 5702 - time: 0.0031 - loss_train: 0.7821193680703872 - loss_val: 0.9626932404435814\n",
      "Epoch: 5703 - time: 0.0031 - loss_train: 0.7821115471987389 - loss_val: 0.9626886737758064\n",
      "Epoch: 5704 - time: 0.0031 - loss_train: 0.7821037293553044 - loss_val: 0.9626841082766976\n",
      "Epoch: 5705 - time: 0.0031 - loss_train: 0.7820959145382627 - loss_val: 0.9626795439474629\n",
      "Epoch: 5706 - time: 0.0031 - loss_train: 0.7820881027457899 - loss_val: 0.962674980789302\n",
      "Epoch: 5707 - time: 0.0031 - loss_train: 0.7820802939760626 - loss_val: 0.9626704188034071\n",
      "Epoch: 5708 - time: 0.0031 - loss_train: 0.7820724882272527 - loss_val: 0.9626658579909603\n",
      "Epoch: 5709 - time: 0.0031 - loss_train: 0.7820646854975314 - loss_val: 0.9626612983531341\n",
      "Epoch: 5710 - time: 0.0031 - loss_train: 0.7820568857850678 - loss_val: 0.9626567398910947\n",
      "Epoch: 5711 - time: 0.0031 - loss_train: 0.7820490890880292 - loss_val: 0.962652182605996\n",
      "Epoch: 5712 - time: 0.0031 - loss_train: 0.7820412954045793 - loss_val: 0.9626476264989878\n",
      "Epoch: 5713 - time: 0.0031 - loss_train: 0.7820335047328824 - loss_val: 0.962643071571207\n",
      "Epoch: 5714 - time: 0.0031 - loss_train: 0.7820257170710982 - loss_val: 0.9626385178237834\n",
      "Epoch: 5715 - time: 0.0031 - loss_train: 0.7820179324173857 - loss_val: 0.9626339652578387\n",
      "Epoch: 5716 - time: 0.0031 - loss_train: 0.7820101507699019 - loss_val: 0.9626294138744842\n",
      "Epoch: 5717 - time: 0.0031 - loss_train: 0.7820023721268012 - loss_val: 0.9626248636748254\n",
      "Epoch: 5718 - time: 0.0031 - loss_train: 0.7819945964862365 - loss_val: 0.962620314659955\n",
      "Epoch: 5719 - time: 0.0031 - loss_train: 0.7819868238463582 - loss_val: 0.9626157668309604\n",
      "Epoch: 5720 - time: 0.0031 - loss_train: 0.7819790542053154 - loss_val: 0.9626112201889192\n",
      "Epoch: 5721 - time: 0.0031 - loss_train: 0.7819712875612544 - loss_val: 0.9626066747348994\n",
      "Epoch: 5722 - time: 0.0031 - loss_train: 0.7819635239123204 - loss_val: 0.9626021304699607\n",
      "Epoch: 5723 - time: 0.0031 - loss_train: 0.7819557632566553 - loss_val: 0.9625975873951556\n",
      "Epoch: 5724 - time: 0.0031 - loss_train: 0.7819480055924003 - loss_val: 0.9625930455115261\n",
      "Epoch: 5725 - time: 0.0031 - loss_train: 0.7819402509176939 - loss_val: 0.9625885048201069\n",
      "Epoch: 5726 - time: 0.0031 - loss_train: 0.7819324992306722 - loss_val: 0.9625839653219223\n",
      "Epoch: 5727 - time: 0.0031 - loss_train: 0.7819247505294703 - loss_val: 0.9625794270179893\n",
      "Epoch: 5728 - time: 0.0031 - loss_train: 0.7819170048122212 - loss_val: 0.9625748899093167\n",
      "Epoch: 5729 - time: 0.0031 - loss_train: 0.781909262077055 - loss_val: 0.9625703539969034\n",
      "Epoch: 5730 - time: 0.0031 - loss_train: 0.7819015223221005 - loss_val: 0.9625658192817402\n",
      "Epoch: 5731 - time: 0.0031 - loss_train: 0.7818937855454845 - loss_val: 0.9625612857648096\n",
      "Epoch: 5732 - time: 0.0031 - loss_train: 0.7818860517453318 - loss_val: 0.9625567534470832\n",
      "Epoch: 5733 - time: 0.0033 - loss_train: 0.781878320919765 - loss_val: 0.9625522223295291\n",
      "Epoch: 5734 - time: 0.0031 - loss_train: 0.7818705930669048 - loss_val: 0.962547692413101\n",
      "Epoch: 5735 - time: 0.0031 - loss_train: 0.7818628681848699 - loss_val: 0.962543163698747\n",
      "Epoch: 5736 - time: 0.0031 - loss_train: 0.7818551462717772 - loss_val: 0.9625386361874078\n",
      "Epoch: 5737 - time: 0.0031 - loss_train: 0.7818474273257421 - loss_val: 0.9625341098800116\n",
      "Epoch: 5738 - time: 0.0031 - loss_train: 0.7818397113448766 - loss_val: 0.9625295847774821\n",
      "Epoch: 5739 - time: 0.0031 - loss_train: 0.7818319983272921 - loss_val: 0.9625250608807315\n",
      "Epoch: 5740 - time: 0.0031 - loss_train: 0.7818242882710974 - loss_val: 0.9625205381906654\n",
      "Epoch: 5741 - time: 0.0031 - loss_train: 0.7818165811744001 - loss_val: 0.9625160167081802\n",
      "Epoch: 5742 - time: 0.0031 - loss_train: 0.7818088770353047 - loss_val: 0.9625114964341625\n",
      "Epoch: 5743 - time: 0.0031 - loss_train: 0.7818011758519142 - loss_val: 0.9625069773694913\n",
      "Epoch: 5744 - time: 0.0031 - loss_train: 0.7817934776223301 - loss_val: 0.9625024595150379\n",
      "Epoch: 5745 - time: 0.0031 - loss_train: 0.781785782344652 - loss_val: 0.9624979428716649\n",
      "Epoch: 5746 - time: 0.0031 - loss_train: 0.7817780900169766 - loss_val: 0.9624934274402257\n",
      "Epoch: 5747 - time: 0.0031 - loss_train: 0.7817704006373992 - loss_val: 0.9624889132215639\n",
      "Epoch: 5748 - time: 0.0030 - loss_train: 0.7817627142040142 - loss_val: 0.9624844002165175\n",
      "Epoch: 5749 - time: 0.0031 - loss_train: 0.781755030714912 - loss_val: 0.9624798884259141\n",
      "Epoch: 5750 - time: 0.0031 - loss_train: 0.7817473501681823 - loss_val: 0.962475377850573\n",
      "Epoch: 5751 - time: 0.0031 - loss_train: 0.7817396725619139 - loss_val: 0.9624708684913059\n",
      "Epoch: 5752 - time: 0.0031 - loss_train: 0.7817319978941915 - loss_val: 0.9624663603489148\n",
      "Epoch: 5753 - time: 0.0031 - loss_train: 0.7817243261630993 - loss_val: 0.962461853424194\n",
      "Epoch: 5754 - time: 0.0031 - loss_train: 0.7817166573667189 - loss_val: 0.962457347717929\n",
      "Epoch: 5755 - time: 0.0031 - loss_train: 0.7817089915031313 - loss_val: 0.9624528432308981\n",
      "Epoch: 5756 - time: 0.0031 - loss_train: 0.7817013285704136 - loss_val: 0.9624483399638691\n",
      "Epoch: 5757 - time: 0.0031 - loss_train: 0.7816936685666424 - loss_val: 0.9624438379176031\n",
      "Epoch: 5758 - time: 0.0031 - loss_train: 0.7816860114898921 - loss_val: 0.9624393370928513\n",
      "Epoch: 5759 - time: 0.0031 - loss_train: 0.781678357338235 - loss_val: 0.9624348374903577\n",
      "Epoch: 5760 - time: 0.0031 - loss_train: 0.7816707061097418 - loss_val: 0.9624303391108568\n",
      "Epoch: 5761 - time: 0.0031 - loss_train: 0.781663057802481 - loss_val: 0.9624258419550772\n",
      "Epoch: 5762 - time: 0.0031 - loss_train: 0.7816554124145197 - loss_val: 0.9624213460237352\n",
      "Epoch: 5763 - time: 0.0031 - loss_train: 0.7816477699439225 - loss_val: 0.9624168513175423\n",
      "Epoch: 5764 - time: 0.0031 - loss_train: 0.7816401303887526 - loss_val: 0.9624123578372006\n",
      "Epoch: 5765 - time: 0.0031 - loss_train: 0.7816324937470712 - loss_val: 0.9624078655834016\n",
      "Epoch: 5766 - time: 0.0031 - loss_train: 0.7816248600169373 - loss_val: 0.9624033745568318\n",
      "Epoch: 5767 - time: 0.0031 - loss_train: 0.7816172291964087 - loss_val: 0.9623988847581665\n",
      "Epoch: 5768 - time: 0.0031 - loss_train: 0.781609601283541 - loss_val: 0.9623943961880755\n",
      "Epoch: 5769 - time: 0.0031 - loss_train: 0.7816019762763876 - loss_val: 0.9623899088472178\n",
      "Epoch: 5770 - time: 0.0031 - loss_train: 0.7815943541730005 - loss_val: 0.9623854227362454\n",
      "Epoch: 5771 - time: 0.0033 - loss_train: 0.7815867349714296 - loss_val: 0.9623809378558023\n",
      "Epoch: 5772 - time: 0.0031 - loss_train: 0.7815791186697236 - loss_val: 0.9623764542065228\n",
      "Epoch: 5773 - time: 0.0031 - loss_train: 0.7815715052659284 - loss_val: 0.962371971789034\n",
      "Epoch: 5774 - time: 0.0031 - loss_train: 0.7815638947580881 - loss_val: 0.9623674906039555\n",
      "Epoch: 5775 - time: 0.0031 - loss_train: 0.7815562871442464 - loss_val: 0.9623630106518951\n",
      "Epoch: 5776 - time: 0.0031 - loss_train: 0.7815486824224431 - loss_val: 0.9623585319334577\n",
      "Epoch: 5777 - time: 0.0031 - loss_train: 0.781541080590718 - loss_val: 0.9623540544492363\n",
      "Epoch: 5778 - time: 0.0031 - loss_train: 0.7815334816471079 - loss_val: 0.9623495781998165\n",
      "Epoch: 5779 - time: 0.0031 - loss_train: 0.781525885589648 - loss_val: 0.9623451031857748\n",
      "Epoch: 5780 - time: 0.0031 - loss_train: 0.7815182924163723 - loss_val: 0.9623406294076815\n",
      "Epoch: 5781 - time: 0.0031 - loss_train: 0.7815107021253125 - loss_val: 0.962336156866097\n",
      "Epoch: 5782 - time: 0.0031 - loss_train: 0.7815031147144982 - loss_val: 0.9623316855615747\n",
      "Epoch: 5783 - time: 0.0031 - loss_train: 0.7814955301819577 - loss_val: 0.9623272154946594\n",
      "Epoch: 5784 - time: 0.0031 - loss_train: 0.7814879485257172 - loss_val: 0.9623227466658869\n",
      "Epoch: 5785 - time: 0.0031 - loss_train: 0.7814803697438016 - loss_val: 0.9623182790757859\n",
      "Epoch: 5786 - time: 0.0031 - loss_train: 0.781472793834234 - loss_val: 0.9623138127248771\n",
      "Epoch: 5787 - time: 0.0031 - loss_train: 0.781465220795034 - loss_val: 0.9623093476136722\n",
      "Epoch: 5788 - time: 0.0031 - loss_train: 0.7814576506242222 - loss_val: 0.9623048837426743\n",
      "Epoch: 5789 - time: 0.0031 - loss_train: 0.7814500833198151 - loss_val: 0.9623004211123809\n",
      "Epoch: 5790 - time: 0.0031 - loss_train: 0.7814425188798291 - loss_val: 0.9622959597232791\n",
      "Epoch: 5791 - time: 0.0031 - loss_train: 0.7814349573022776 - loss_val: 0.9622914995758481\n",
      "Epoch: 5792 - time: 0.0031 - loss_train: 0.7814273985851728 - loss_val: 0.9622870406705604\n",
      "Epoch: 5793 - time: 0.0031 - loss_train: 0.7814198427265248 - loss_val: 0.9622825830078798\n",
      "Epoch: 5794 - time: 0.0031 - loss_train: 0.781412289724343 - loss_val: 0.9622781265882598\n",
      "Epoch: 5795 - time: 0.0031 - loss_train: 0.7814047395766331 - loss_val: 0.9622736714121497\n",
      "Epoch: 5796 - time: 0.0031 - loss_train: 0.7813971922814015 - loss_val: 0.9622692174799892\n",
      "Epoch: 5797 - time: 0.0031 - loss_train: 0.7813896478366503 - loss_val: 0.962264764792209\n",
      "Epoch: 5798 - time: 0.0031 - loss_train: 0.781382106240382 - loss_val: 0.9622603133492326\n",
      "Epoch: 5799 - time: 0.0031 - loss_train: 0.7813745674905961 - loss_val: 0.9622558631514753\n",
      "Epoch: 5800 - time: 0.0031 - loss_train: 0.7813670315852905 - loss_val: 0.9622514141993445\n",
      "Epoch: 5801 - time: 0.0031 - loss_train: 0.7813594985224621 - loss_val: 0.9622469664932398\n",
      "Epoch: 5802 - time: 0.0031 - loss_train: 0.7813519683001059 - loss_val: 0.962242520033553\n",
      "Epoch: 5803 - time: 0.0031 - loss_train: 0.7813444409162139 - loss_val: 0.9622380748206681\n",
      "Epoch: 5804 - time: 0.0031 - loss_train: 0.7813369163687778 - loss_val: 0.9622336308549597\n",
      "Epoch: 5805 - time: 0.0031 - loss_train: 0.7813293946557879 - loss_val: 0.962229188136796\n",
      "Epoch: 5806 - time: 0.0031 - loss_train: 0.7813218757752309 - loss_val: 0.9622247466665377\n",
      "Epoch: 5807 - time: 0.0031 - loss_train: 0.7813143597250939 - loss_val: 0.9622203064445344\n",
      "Epoch: 5808 - time: 0.0031 - loss_train: 0.7813068465033606 - loss_val: 0.9622158674711332\n",
      "Epoch: 5809 - time: 0.0033 - loss_train: 0.7812993361080146 - loss_val: 0.9622114297466685\n",
      "Epoch: 5810 - time: 0.0031 - loss_train: 0.7812918285370363 - loss_val: 0.962206993271468\n",
      "Epoch: 5811 - time: 0.0031 - loss_train: 0.7812843237884056 - loss_val: 0.9622025580458535\n",
      "Epoch: 5812 - time: 0.0031 - loss_train: 0.7812768218600997 - loss_val: 0.9621981240701373\n",
      "Epoch: 5813 - time: 0.0031 - loss_train: 0.7812693227500952 - loss_val: 0.9621936913446245\n",
      "Epoch: 5814 - time: 0.0031 - loss_train: 0.7812618264563663 - loss_val: 0.9621892598696113\n",
      "Epoch: 5815 - time: 0.0031 - loss_train: 0.7812543329768855 - loss_val: 0.9621848296453878\n",
      "Epoch: 5816 - time: 0.0031 - loss_train: 0.7812468423096246 - loss_val: 0.9621804006722345\n",
      "Epoch: 5817 - time: 0.0031 - loss_train: 0.7812393544525527 - loss_val: 0.9621759729504259\n",
      "Epoch: 5818 - time: 0.0031 - loss_train: 0.7812318694036366 - loss_val: 0.9621715464802274\n",
      "Epoch: 5819 - time: 0.0031 - loss_train: 0.7812243871608441 - loss_val: 0.9621671212618974\n",
      "Epoch: 5820 - time: 0.0031 - loss_train: 0.7812169077221388 - loss_val: 0.9621626972956864\n",
      "Epoch: 5821 - time: 0.0031 - loss_train: 0.7812094310854836 - loss_val: 0.9621582745818376\n",
      "Epoch: 5822 - time: 0.0031 - loss_train: 0.7812019572488398 - loss_val: 0.9621538531205844\n",
      "Epoch: 5823 - time: 0.0031 - loss_train: 0.7811944862101674 - loss_val: 0.9621494329121553\n",
      "Epoch: 5824 - time: 0.0031 - loss_train: 0.7811870179674237 - loss_val: 0.9621450139567705\n",
      "Epoch: 5825 - time: 0.0031 - loss_train: 0.7811795525185655 - loss_val: 0.9621405962546408\n",
      "Epoch: 5826 - time: 0.0031 - loss_train: 0.7811720898615478 - loss_val: 0.9621361798059714\n",
      "Epoch: 5827 - time: 0.0031 - loss_train: 0.7811646299943233 - loss_val: 0.9621317646109584\n",
      "Epoch: 5828 - time: 0.0031 - loss_train: 0.7811571729148442 - loss_val: 0.9621273506697914\n",
      "Epoch: 5829 - time: 0.0031 - loss_train: 0.7811497186210598 - loss_val: 0.9621229379826517\n",
      "Epoch: 5830 - time: 0.0031 - loss_train: 0.7811422671109189 - loss_val: 0.9621185265497132\n",
      "Epoch: 5831 - time: 0.0031 - loss_train: 0.7811348183823686 - loss_val: 0.9621141163711422\n",
      "Epoch: 5832 - time: 0.0031 - loss_train: 0.7811273724333535 - loss_val: 0.9621097074470976\n",
      "Epoch: 5833 - time: 0.0031 - loss_train: 0.7811199292618178 - loss_val: 0.9621052997777296\n",
      "Epoch: 5834 - time: 0.0031 - loss_train: 0.7811124888657032 - loss_val: 0.9621008933631832\n",
      "Epoch: 5835 - time: 0.0031 - loss_train: 0.7811050512429506 - loss_val: 0.962096488203594\n",
      "Epoch: 5836 - time: 0.0031 - loss_train: 0.7810976163914986 - loss_val: 0.96209208429909\n",
      "Epoch: 5837 - time: 0.0031 - loss_train: 0.7810901843092849 - loss_val: 0.9620876816497932\n",
      "Epoch: 5838 - time: 0.0031 - loss_train: 0.7810827549942456 - loss_val: 0.9620832802558172\n",
      "Epoch: 5839 - time: 0.0031 - loss_train: 0.7810753284443145 - loss_val: 0.962078880117268\n",
      "Epoch: 5840 - time: 0.0031 - loss_train: 0.7810679046574253 - loss_val: 0.9620744812342434\n",
      "Epoch: 5841 - time: 0.0031 - loss_train: 0.7810604836315079 - loss_val: 0.9620700836068362\n",
      "Epoch: 5842 - time: 0.0031 - loss_train: 0.7810530653644934 - loss_val: 0.9620656872351295\n",
      "Epoch: 5843 - time: 0.0031 - loss_train: 0.7810456498543095 - loss_val: 0.9620612921191996\n",
      "Epoch: 5844 - time: 0.0031 - loss_train: 0.7810382370988825 - loss_val: 0.9620568982591169\n",
      "Epoch: 5845 - time: 0.0031 - loss_train: 0.7810308270961385 - loss_val: 0.9620525056549409\n",
      "Epoch: 5846 - time: 0.0031 - loss_train: 0.7810234198440005 - loss_val: 0.962048114306728\n",
      "Epoch: 5847 - time: 0.0033 - loss_train: 0.7810160153403912 - loss_val: 0.9620437242145241\n",
      "Epoch: 5848 - time: 0.0031 - loss_train: 0.7810086135832309 - loss_val: 0.9620393353783685\n",
      "Epoch: 5849 - time: 0.0031 - loss_train: 0.7810012145704393 - loss_val: 0.9620349477982947\n",
      "Epoch: 5850 - time: 0.0031 - loss_train: 0.7809938182999336 - loss_val: 0.9620305614743263\n",
      "Epoch: 5851 - time: 0.0031 - loss_train: 0.7809864247696305 - loss_val: 0.9620261764064821\n",
      "Epoch: 5852 - time: 0.0031 - loss_train: 0.7809790339774445 - loss_val: 0.9620217925947732\n",
      "Epoch: 5853 - time: 0.0031 - loss_train: 0.7809716459212893 - loss_val: 0.9620174100392009\n",
      "Epoch: 5854 - time: 0.0031 - loss_train: 0.7809642605990769 - loss_val: 0.9620130287397631\n",
      "Epoch: 5855 - time: 0.0031 - loss_train: 0.7809568780087176 - loss_val: 0.9620086486964479\n",
      "Epoch: 5856 - time: 0.0031 - loss_train: 0.7809494981481195 - loss_val: 0.962004269909236\n",
      "Epoch: 5857 - time: 0.0031 - loss_train: 0.7809421210151913 - loss_val: 0.9619998923781036\n",
      "Epoch: 5858 - time: 0.0031 - loss_train: 0.7809347466078389 - loss_val: 0.9619955161030155\n",
      "Epoch: 5859 - time: 0.0031 - loss_train: 0.7809273749239667 - loss_val: 0.9619911410839344\n",
      "Epoch: 5860 - time: 0.0031 - loss_train: 0.7809200059614778 - loss_val: 0.9619867673208112\n",
      "Epoch: 5861 - time: 0.0031 - loss_train: 0.7809126397182745 - loss_val: 0.9619823948135925\n",
      "Epoch: 5862 - time: 0.0034 - loss_train: 0.7809052761922576 - loss_val: 0.9619780235622171\n",
      "Epoch: 5863 - time: 0.0035 - loss_train: 0.780897915381325 - loss_val: 0.9619736535666159\n",
      "Epoch: 5864 - time: 0.0031 - loss_train: 0.7808905572833749 - loss_val: 0.9619692848267135\n",
      "Epoch: 5865 - time: 0.0031 - loss_train: 0.7808832018963037 - loss_val: 0.9619649173424281\n",
      "Epoch: 5866 - time: 0.0032 - loss_train: 0.7808758492180061 - loss_val: 0.9619605511136696\n",
      "Epoch: 5867 - time: 0.0036 - loss_train: 0.780868499246376 - loss_val: 0.9619561861403416\n",
      "Epoch: 5868 - time: 0.0035 - loss_train: 0.7808611519793045 - loss_val: 0.9619518224223401\n",
      "Epoch: 5869 - time: 0.0036 - loss_train: 0.7808538074146828 - loss_val: 0.9619474599595547\n",
      "Epoch: 5870 - time: 0.0036 - loss_train: 0.7808464655504008 - loss_val: 0.9619430987518675\n",
      "Epoch: 5871 - time: 0.0035 - loss_train: 0.7808391263843455 - loss_val: 0.9619387387991534\n",
      "Epoch: 5872 - time: 0.0035 - loss_train: 0.7808317899144045 - loss_val: 0.9619343801012833\n",
      "Epoch: 5873 - time: 0.0035 - loss_train: 0.7808244561384625 - loss_val: 0.9619300226581163\n",
      "Epoch: 5874 - time: 0.0035 - loss_train: 0.7808171250544037 - loss_val: 0.9619256664695065\n",
      "Epoch: 5875 - time: 0.0035 - loss_train: 0.7808097966601109 - loss_val: 0.9619213115353044\n",
      "Epoch: 5876 - time: 0.0035 - loss_train: 0.7808024709534648 - loss_val: 0.9619169578553494\n",
      "Epoch: 5877 - time: 0.0035 - loss_train: 0.7807951479323463 - loss_val: 0.961912605429475\n",
      "Epoch: 5878 - time: 0.0035 - loss_train: 0.7807878275946332 - loss_val: 0.9619082542575093\n",
      "Epoch: 5879 - time: 0.0035 - loss_train: 0.7807805099382035 - loss_val: 0.9619039043392726\n",
      "Epoch: 5880 - time: 0.0036 - loss_train: 0.7807731949609327 - loss_val: 0.9618995556745779\n",
      "Epoch: 5881 - time: 0.0036 - loss_train: 0.7807658826606964 - loss_val: 0.9618952082632317\n",
      "Epoch: 5882 - time: 0.0043 - loss_train: 0.7807585730353673 - loss_val: 0.9618908621050349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-95d8bc7f4cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             verbose=1) \n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/IsaNetNN/isanet/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, trainingSetX, trainingSetY, epochs, batch_size, validation_data, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                 \u001b[0mtrainingSetX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingSetX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                 \u001b[0mtrainingSetY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingSetY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                 validation_data=validation_data)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/IsaNetNN/isanet/optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, model, epochs, trainingSetX, trainingSetY, validation_data, batch_size, verbose)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mold_nabla_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mnabla_w\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__backpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/IsaNetNN/isanet/optimizer.py\u001b[0m in \u001b[0;36m__backpropagation\u001b[0;34m(self, model, batchs, currentBatch)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumLayer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaNodeToProp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mderivatesH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mdeltaNodesH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mderivatesH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mnabla_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumLayer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltaNodesH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/IsaNetNN/isanet/activation.py\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/IsaNetNN/isanet/activation.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         return np.where(x >= 10**-18, \n\u001b[0;32m---> 16\u001b[0;31m                         \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                         np.exp(self.a*x) / (1 + np.exp(self.a*x)))\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = TS[:1000,:-2]\n",
    "Y_train = TS[:1000,-2:]\n",
    "    \n",
    "X_val = TS[1000:1250,:-2]\n",
    "Y_val = TS[1000:1250,-2:]\n",
    "\n",
    "model = Mlp()\n",
    "units = 56\n",
    "model.add(units, activation=\"sigmoid\", input= 20, kernel_initializer = np.sqrt(6)/np.sqrt(20+units), kernel_regularizer = 0.0007108)\n",
    "model.add(2, activation=\"linear\", kernel_initializer = np.sqrt(6)/np.sqrt(units+2), kernel_regularizer = 0.000108)\n",
    "\n",
    "model.set_optimizer(\n",
    "    SGD(\n",
    "        lr = 0.018200000000000004,\n",
    "        momentum = 0.8800000000000002,\n",
    "        nesterov = True\n",
    "    ))\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train,\n",
    "            Y_train, \n",
    "            epochs=18000, \n",
    "            validation_data = [X_val, Y_val],\n",
    "            verbose=1) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "outputNet = model.predict(X_val)\n",
    "\n",
    "plt.plot(outputNet[:,-2], outputNet[:,-1], 'ro', markersize=0.3)\n",
    "plt.ylabel('y2')\n",
    "plt.xlabel('y1')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "printMSE(outputNet, Y_val, type = \"test\")\n",
    "plt.plot(model.history[\"loss_mse\"][500:])\n",
    "plt.plot(model.history[\"val_loss_mse\"][500:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train_index_fold, val_index_fold in zip(kfold[\"train\"], kfold[\"val\"]):\n",
    "    X_train = TS[train_index_fold,:-2]\n",
    "    Y_train = TS[train_index_fold,-2:]\n",
    "    \n",
    "    X_val = TS[val_index_fold,:-2]\n",
    "    Y_val = TS[val_index_fold,-2:]\n",
    "\n",
    "    model = Mlp()\n",
    "    model.add(38, activation=\"relu\", input= 20, kernel_initializer = np.sqrt(6)/np.sqrt(20+62), kernel_regularizer = 0)\n",
    "    model.add(2, activation=\"linear\", kernel_initializer = np.sqrt(6)/np.sqrt(62+2), kernel_regularizer = 0)\n",
    "\n",
    "    model.set_optimizer(\n",
    "        SGD(\n",
    "            lr = 0.00018200000000000004,\n",
    "            momentum = 0.8800000000000002,\n",
    "            nesterov = True\n",
    "        ))\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train,\n",
    "                Y_train, \n",
    "                epochs=6000, \n",
    "                validation_data = [X_val, Y_val],\n",
    "                verbose=1) \n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(model.history[\"loss_mse\"][-1])\n",
    "    print(model.history[\"val_loss_mse\"][-1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test with ealry stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - time: 0.0623 - loss_train: 134.09876838306036 - loss_val: 145.97654379762196\n",
      "Epoch: 2 - time: 0.0042 - loss_train: 36.033331667180214 - loss_val: 36.97240748090518\n",
      "Epoch: 3 - time: 0.0070 - loss_train: 50.23105476569823 - loss_val: 49.33762717678182\n",
      "Epoch: 4 - time: 0.0044 - loss_train: 97.6142077423665 - loss_val: 106.10891571103033\n",
      "Epoch: 5 - time: 0.0040 - loss_train: 45.623602132894895 - loss_val: 48.63455549724785\n",
      "Epoch: 6 - time: 0.0043 - loss_train: 11.630462267039297 - loss_val: 11.281772449134184\n",
      "Epoch: 7 - time: 0.0039 - loss_train: 26.112191369783336 - loss_val: 28.393422986355247\n",
      "Epoch: 8 - time: 0.0045 - loss_train: 39.27209240495549 - loss_val: 42.882683224697494\n",
      "Epoch: 9 - time: 0.0039 - loss_train: 35.67434818479178 - loss_val: 38.40378859813673\n",
      "Epoch: 10 - time: 0.0047 - loss_train: 21.21889947159912 - loss_val: 22.363315854851592\n",
      "Epoch: 11 - time: 0.0038 - loss_train: 11.512395377667277 - loss_val: 12.039895031732385\n",
      "Epoch: 12 - time: 0.0038 - loss_train: 14.424710078145482 - loss_val: 15.550241027849967\n",
      "Epoch: 13 - time: 0.0045 - loss_train: 21.76896801748087 - loss_val: 23.563474505631252\n",
      "Epoch: 14 - time: 0.0047 - loss_train: 21.89072822242981 - loss_val: 23.532574463149977\n",
      "Epoch: 15 - time: 0.0037 - loss_train: 14.591658769935707 - loss_val: 15.547640437918174\n",
      "Epoch: 16 - time: 0.0041 - loss_train: 8.623904135917877 - loss_val: 9.200644449182068\n",
      "Epoch: 17 - time: 0.0037 - loss_train: 9.068667219838662 - loss_val: 9.916646430300604\n",
      "Epoch: 18 - time: 0.0044 - loss_train: 12.782340463267314 - loss_val: 14.153210509677198\n",
      "Epoch: 19 - time: 0.0034 - loss_train: 14.111345289672707 - loss_val: 15.653997887747943\n",
      "Epoch: 20 - time: 0.0041 - loss_train: 11.448100148984977 - loss_val: 12.61052670002381\n",
      "Epoch: 21 - time: 0.0037 - loss_train: 7.815148160452855 - loss_val: 8.365406308195418\n",
      "Epoch: 22 - time: 0.0036 - loss_train: 6.518432811614515 - loss_val: 6.694256522069784\n",
      "Epoch: 23 - time: 0.0041 - loss_train: 7.636842237643827 - loss_val: 7.869101806430067\n",
      "Epoch: 24 - time: 0.0036 - loss_train: 8.791496266655356 - loss_val: 9.327004422464368\n",
      "Epoch: 25 - time: 0.0043 - loss_train: 8.257728612072263 - loss_val: 9.023561698993712\n",
      "Epoch: 26 - time: 0.0053 - loss_train: 6.556442089997436 - loss_val: 7.327574358995382\n",
      "Epoch: 27 - time: 0.0042 - loss_train: 5.328002859458851 - loss_val: 5.980918986961434\n",
      "Epoch: 28 - time: 0.0037 - loss_train: 5.350419465476824 - loss_val: 5.945871919870525\n",
      "Epoch: 29 - time: 0.0064 - loss_train: 5.848368769586298 - loss_val: 6.4479597773767505\n",
      "Epoch: 30 - time: 0.0050 - loss_train: 5.738556190633331 - loss_val: 6.264998041011087\n",
      "Epoch: 31 - time: 0.0063 - loss_train: 4.975749338306599 - loss_val: 5.297754832103007\n",
      "Epoch: 32 - time: 0.0094 - loss_train: 4.295506982108515 - loss_val: 4.376265309376535\n",
      "Epoch: 33 - time: 0.0050 - loss_train: 4.139304367009928 - loss_val: 4.0877195099144235\n",
      "Epoch: 34 - time: 0.0039 - loss_train: 4.2254136852503255 - loss_val: 4.2112371242492825\n",
      "Epoch: 35 - time: 0.0062 - loss_train: 4.092793022082517 - loss_val: 4.219127852558077\n",
      "Epoch: 36 - time: 0.0035 - loss_train: 3.7048018415439374 - loss_val: 3.965409284727692\n",
      "Epoch: 37 - time: 0.0038 - loss_train: 3.37618674812926 - loss_val: 3.708567559332578\n",
      "Epoch: 38 - time: 0.0043 - loss_train: 3.2983107076949083 - loss_val: 3.6478389664334476\n",
      "Epoch: 39 - time: 0.0039 - loss_train: 3.331780503806841 - loss_val: 3.664782881871425\n",
      "Epoch: 40 - time: 0.0037 - loss_train: 3.247159306931319 - loss_val: 3.528804960753028\n",
      "Epoch: 41 - time: 0.0045 - loss_train: 3.0242382536300356 - loss_val: 3.2106878666058547\n",
      "Epoch: 42 - time: 0.0033 - loss_train: 2.837511228415314 - loss_val: 2.900017279000935\n",
      "Epoch: 43 - time: 0.0042 - loss_train: 2.805921546489841 - loss_val: 2.7603983651422777\n",
      "Epoch: 44 - time: 0.0039 - loss_train: 2.8525731653002038 - loss_val: 2.7597756157565545\n",
      "Epoch: 45 - time: 0.0037 - loss_train: 2.827134921019588 - loss_val: 2.7598539842072567\n",
      "Epoch: 46 - time: 0.0034 - loss_train: 2.6987294916924056 - loss_val: 2.704760384772699\n",
      "Epoch: 47 - time: 0.0051 - loss_train: 2.5730821331373273 - loss_val: 2.6615953257657794\n",
      "Epoch: 48 - time: 0.0039 - loss_train: 2.543480587606249 - loss_val: 2.695600658499403\n",
      "Epoch: 49 - time: 0.0033 - loss_train: 2.5825737196985763 - loss_val: 2.7680452712826398\n",
      "Epoch: 50 - time: 0.0039 - loss_train: 2.5941648922974445 - loss_val: 2.7808839345635623\n",
      "Epoch: 51 - time: 0.0056 - loss_train: 2.5346033079174233 - loss_val: 2.6926125861840036\n",
      "Epoch: 52 - time: 0.0075 - loss_train: 2.4513573975869853 - loss_val: 2.5585683294454156\n",
      "Epoch: 53 - time: 0.0068 - loss_train: 2.410950992889328 - loss_val: 2.461380053134149\n",
      "Epoch: 54 - time: 0.0049 - loss_train: 2.4196980454526993 - loss_val: 2.4274486635539487\n",
      "Epoch: 55 - time: 0.0602 - loss_train: 2.42875729594734 - loss_val: 2.422167300983135\n",
      "Epoch: 56 - time: 0.0061 - loss_train: 2.4007935349598157 - loss_val: 2.4093615073713046\n",
      "Epoch: 57 - time: 0.0054 - loss_train: 2.3493299534075285 - loss_val: 2.3918698602027226\n",
      "Epoch: 58 - time: 0.0097 - loss_train: 2.3116701855622277 - loss_val: 2.392007704294011\n",
      "Epoch: 59 - time: 0.0040 - loss_train: 2.3012106440745774 - loss_val: 2.411076453800845\n",
      "Epoch: 60 - time: 0.0111 - loss_train: 2.2983010414223792 - loss_val: 2.4229636086316546\n",
      "Epoch: 61 - time: 0.0054 - loss_train: 2.2808196173455553 - loss_val: 2.4040237743783974\n",
      "Epoch: 62 - time: 0.0090 - loss_train: 2.249958056135807 - loss_val: 2.3577536144828684\n",
      "Epoch: 63 - time: 0.0056 - loss_train: 2.2229323215240213 - loss_val: 2.3070931599644493\n",
      "Epoch: 64 - time: 0.0060 - loss_train: 2.2090744508951365 - loss_val: 2.269571252404535\n",
      "Epoch: 65 - time: 0.0067 - loss_train: 2.2009875924847613 - loss_val: 2.245850254800058\n",
      "Epoch: 66 - time: 0.0091 - loss_train: 2.187445270567028 - loss_val: 2.2292897049689953\n",
      "Epoch: 67 - time: 0.0047 - loss_train: 2.1676524116248896 - loss_val: 2.218410597806125\n",
      "Epoch: 68 - time: 0.0048 - loss_train: 2.1496002482083187 - loss_val: 2.216252965983887\n",
      "Epoch: 69 - time: 0.0051 - loss_train: 2.138192496133527 - loss_val: 2.221373782947061\n",
      "Epoch: 70 - time: 0.0074 - loss_train: 2.129811770035015 - loss_val: 2.2251134571560165\n",
      "Epoch: 71 - time: 0.0071 - loss_train: 2.1184959964373706 - loss_val: 2.219021005853164\n",
      "Epoch: 72 - time: 0.0065 - loss_train: 2.103716896585296 - loss_val: 2.2025801232561375\n",
      "Epoch: 73 - time: 0.0078 - loss_train: 2.0899433657427906 - loss_val: 2.1821901521209113\n",
      "Epoch: 74 - time: 0.0079 - loss_train: 2.080164086906143 - loss_val: 2.1639728399118034\n",
      "Epoch: 75 - time: 0.0067 - loss_train: 2.072438124737686 - loss_val: 2.149390225731986\n",
      "Epoch: 76 - time: 0.0046 - loss_train: 2.063104471954684 - loss_val: 2.1373147546403963\n",
      "Epoch: 77 - time: 0.0055 - loss_train: 2.0515157800287387 - loss_val: 2.1278545882362017\n",
      "Epoch: 78 - time: 0.0045 - loss_train: 2.040276038306853 - loss_val: 2.122450598680405\n",
      "Epoch: 79 - time: 0.0045 - loss_train: 2.0315113822942257 - loss_val: 2.1208686887730703\n",
      "Epoch: 80 - time: 0.0064 - loss_train: 2.024378981508377 - loss_val: 2.119833940757433\n",
      "Epoch: 81 - time: 0.0067 - loss_train: 2.0165632528312103 - loss_val: 2.115440414078393\n",
      "Epoch: 82 - time: 0.0047 - loss_train: 2.007241452326711 - loss_val: 2.1064860848819635\n",
      "Epoch: 83 - time: 0.0074 - loss_train: 1.997745040100422 - loss_val: 2.0950006734971907\n",
      "Epoch: 84 - time: 0.0049 - loss_train: 1.9895913084970285 - loss_val: 2.0838523512427534\n",
      "Epoch: 85 - time: 0.0106 - loss_train: 1.9827019620431965 - loss_val: 2.074436172882058\n",
      "Epoch: 86 - time: 0.0040 - loss_train: 1.975831998056005 - loss_val: 2.0666019661203188\n",
      "Epoch: 87 - time: 0.0042 - loss_train: 1.9682419793291532 - loss_val: 2.0599882724294054\n",
      "Epoch: 88 - time: 0.0081 - loss_train: 1.9604145445983958 - loss_val: 2.054680457187987\n",
      "Epoch: 89 - time: 0.0066 - loss_train: 1.9532058408326711 - loss_val: 2.0506023778390228\n",
      "Epoch: 90 - time: 0.0117 - loss_train: 1.9467675460529068 - loss_val: 2.0468581321454935\n",
      "Epoch: 91 - time: 0.0112 - loss_train: 1.9405319475090268 - loss_val: 2.04212315051232\n",
      "Epoch: 92 - time: 0.0051 - loss_train: 1.9340230470003328 - loss_val: 2.0356904953235193\n",
      "Epoch: 93 - time: 0.0052 - loss_train: 1.9273622410652924 - loss_val: 2.0279850373069257\n",
      "Epoch: 94 - time: 0.0082 - loss_train: 1.92096633217962 - loss_val: 2.0200811357755932\n",
      "Epoch: 95 - time: 0.0037 - loss_train: 1.9149917085131454 - loss_val: 2.0128674349444493\n",
      "Epoch: 96 - time: 0.0039 - loss_train: 1.9092291851250025 - loss_val: 2.0066685910938364\n",
      "Epoch: 97 - time: 0.0041 - loss_train: 1.9034476943044878 - loss_val: 2.0014160765035154\n",
      "Epoch: 98 - time: 0.0037 - loss_train: 1.897662931423161 - loss_val: 1.9968985907434789\n",
      "Epoch: 99 - time: 0.0036 - loss_train: 1.8920362624354465 - loss_val: 1.9927899104146678\n",
      "Epoch: 100 - time: 0.0043 - loss_train: 1.8866270270862837 - loss_val: 1.9886116199258959\n",
      "Epoch: 101 - time: 0.0042 - loss_train: 1.8813376273763405 - loss_val: 1.9838799863829004\n",
      "Epoch: 102 - time: 0.0060 - loss_train: 1.876068223240285 - loss_val: 1.9783813254323603\n",
      "Epoch: 103 - time: 0.0057 - loss_train: 1.870836771680082 - loss_val: 1.972301392684282\n",
      "Epoch: 104 - time: 0.0047 - loss_train: 1.865723331011197 - loss_val: 1.9660801872173475\n",
      "Epoch: 105 - time: 0.0050 - loss_train: 1.860750171431986 - loss_val: 1.9601456213634807\n",
      "Epoch: 106 - time: 0.0035 - loss_train: 1.8558637677132428 - loss_val: 1.9547474477611686\n",
      "Epoch: 107 - time: 0.0055 - loss_train: 1.8510187231270587 - loss_val: 1.9499434924193588\n",
      "Epoch: 108 - time: 0.0037 - loss_train: 1.8462338704561023 - loss_val: 1.9456397914979666\n",
      "Epoch: 109 - time: 0.0035 - loss_train: 1.8415527984018878 - loss_val: 1.9416155322505206\n",
      "Epoch: 110 - time: 0.0048 - loss_train: 1.8369770165742385 - loss_val: 1.9375685599056474\n",
      "Epoch: 111 - time: 0.0037 - loss_train: 1.8324632111159553 - loss_val: 1.9332255106885528\n",
      "Epoch: 112 - time: 0.0040 - loss_train: 1.8279787185810514 - loss_val: 1.9284697000574724\n",
      "Epoch: 113 - time: 0.0040 - loss_train: 1.823536510203373 - loss_val: 1.9233881584829722\n",
      "Epoch: 114 - time: 0.0037 - loss_train: 1.8191695018642804 - loss_val: 1.9182018204048064\n",
      "Epoch: 115 - time: 0.0058 - loss_train: 1.814885729600981 - loss_val: 1.9131426916541572\n",
      "Epoch: 116 - time: 0.0045 - loss_train: 1.8106618973507829 - loss_val: 1.9083660326358094\n",
      "Epoch: 117 - time: 0.0035 - loss_train: 1.806475566725564 - loss_val: 1.9039261822538\n",
      "Epoch: 118 - time: 0.0047 - loss_train: 1.8023295594150628 - loss_val: 1.8997866819470588\n",
      "Epoch: 119 - time: 0.0037 - loss_train: 1.7982407264672833 - loss_val: 1.8958373897447498\n",
      "Epoch: 120 - time: 0.0038 - loss_train: 1.794213754351439 - loss_val: 1.8919242228801332\n",
      "Epoch: 121 - time: 0.0049 - loss_train: 1.7902345665982033 - loss_val: 1.8879026700994108\n",
      "Epoch: 122 - time: 0.0036 - loss_train: 1.7862874741761803 - loss_val: 1.8836972983765\n",
      "Epoch: 123 - time: 0.0044 - loss_train: 1.782371123825791 - loss_val: 1.879329746439415\n",
      "Epoch: 124 - time: 0.0044 - loss_train: 1.778494937258826 - loss_val: 1.874896741272295\n",
      "Epoch: 125 - time: 0.0034 - loss_train: 1.7746645127245584 - loss_val: 1.8705170081402007\n",
      "Epoch: 126 - time: 0.0050 - loss_train: 1.770875244372432 - loss_val: 1.8662822869317917\n",
      "Epoch: 127 - time: 0.0046 - loss_train: 1.7671191738386265 - loss_val: 1.8622329013309007\n",
      "Epoch: 128 - time: 0.0105 - loss_train: 1.7633935050986533 - loss_val: 1.8583559495033355\n",
      "Epoch: 129 - time: 0.0073 - loss_train: 1.7597003853569426 - loss_val: 1.8545967482742025\n",
      "Epoch: 130 - time: 0.0051 - loss_train: 1.7560406830578192 - loss_val: 1.8508792499157019\n",
      "Epoch: 131 - time: 0.0090 - loss_train: 1.7524109778769599 - loss_val: 1.8471331348019955\n",
      "Epoch: 132 - time: 0.0066 - loss_train: 1.7488067395695475 - loss_val: 1.8433193601844982\n",
      "Epoch: 133 - time: 0.0078 - loss_train: 1.7452263988707126 - loss_val: 1.8394419936861968\n",
      "Epoch: 134 - time: 0.0104 - loss_train: 1.7416711963273441 - loss_val: 1.8355404786502862\n",
      "Epoch: 135 - time: 0.0047 - loss_train: 1.7381420119598965 - loss_val: 1.831668307682949\n",
      "Epoch: 136 - time: 0.0049 - loss_train: 1.734637650285623 - loss_val: 1.8278704492828346\n",
      "Epoch: 137 - time: 0.0056 - loss_train: 1.7311560849307583 - loss_val: 1.8241688512209944\n",
      "Epoch: 138 - time: 0.0069 - loss_train: 1.7276961729708502 - loss_val: 1.8205585350807783\n",
      "Epoch: 139 - time: 0.0096 - loss_train: 1.7242575042491117 - loss_val: 1.817012665070678\n",
      "Epoch: 140 - time: 0.0038 - loss_train: 1.7208391103878824 - loss_val: 1.8134939940826642\n",
      "Epoch: 141 - time: 0.0107 - loss_train: 1.7174391422336288 - loss_val: 1.809969153018565\n",
      "Epoch: 142 - time: 0.0038 - loss_train: 1.7140559332134435 - loss_val: 1.8064206128570832\n",
      "Epoch: 143 - time: 0.0042 - loss_train: 1.7106889273722827 - loss_val: 1.802851308848664\n",
      "Epoch: 144 - time: 0.0280 - loss_train: 1.7073383198935592 - loss_val: 1.7992803768978949\n",
      "Epoch: 145 - time: 0.0070 - loss_train: 1.7040040339399556 - loss_val: 1.7957330528871887\n",
      "Epoch: 146 - time: 0.0070 - loss_train: 1.7006853322067728 - loss_val: 1.7922300352055525\n",
      "Epoch: 147 - time: 0.0073 - loss_train: 1.697381308536857 - loss_val: 1.788780476947545\n",
      "Epoch: 148 - time: 0.0049 - loss_train: 1.694091386339246 - loss_val: 1.785380153996081\n",
      "Epoch: 149 - time: 0.0066 - loss_train: 1.6908151693592612 - loss_val: 1.7820143711663214\n",
      "Epoch: 150 - time: 0.0060 - loss_train: 1.687551989119068 - loss_val: 1.7786641555632743\n",
      "Epoch: 151 - time: 0.0053 - loss_train: 1.6843008512304969 - loss_val: 1.7753135391117612\n",
      "Epoch: 152 - time: 0.0053 - loss_train: 1.6810608667690699 - loss_val: 1.7719552116821016\n",
      "Epoch: 153 - time: 0.0055 - loss_train: 1.6778316187050035 - loss_val: 1.7685923042860063\n",
      "Epoch: 154 - time: 0.0092 - loss_train: 1.674613055614932 - loss_val: 1.76523580859842\n",
      "Epoch: 155 - time: 0.0067 - loss_train: 1.6714051112340644 - loss_val: 1.7618991973241\n",
      "Epoch: 156 - time: 0.0078 - loss_train: 1.6682075016546436 - loss_val: 1.7585928460543723\n",
      "Epoch: 157 - time: 0.0070 - loss_train: 1.6650198316262237 - loss_val: 1.755320433802228\n",
      "Epoch: 158 - time: 0.0090 - loss_train: 1.6618417607133955 - loss_val: 1.752078264982306\n",
      "Epoch: 159 - time: 0.0241 - loss_train: 1.6586730016813012 - loss_val: 1.7488572769315187\n",
      "Epoch: 160 - time: 0.0039 - loss_train: 1.6555132138721733 - loss_val: 1.7456467300720349\n",
      "Epoch: 161 - time: 0.0113 - loss_train: 1.652361987655852 - loss_val: 1.7424381723903704\n",
      "Epoch: 162 - time: 0.0049 - loss_train: 1.6492189627129759 - loss_val: 1.7392282308556386\n",
      "Epoch: 163 - time: 0.0038 - loss_train: 1.6460839386294221 - loss_val: 1.7360192439329127\n",
      "Epoch: 164 - time: 0.0055 - loss_train: 1.6429568583243073 - loss_val: 1.7328176525057941\n",
      "Epoch: 165 - time: 0.0118 - loss_train: 1.6398377046715813 - loss_val: 1.7296309986044758\n",
      "Epoch: 166 - time: 0.0058 - loss_train: 1.6367264281134661 - loss_val: 1.7264648538745853\n",
      "Epoch: 167 - time: 0.0034 - loss_train: 1.6336229495871197 - loss_val: 1.7233208378745006\n",
      "Epoch: 168 - time: 0.0069 - loss_train: 1.6305271872845417 - loss_val: 1.7201962993700985\n",
      "Epoch: 169 - time: 0.0059 - loss_train: 1.6274390569603048 - loss_val: 1.7170855645341885\n",
      "Epoch: 170 - time: 0.0063 - loss_train: 1.6243584604468349 - loss_val: 1.7139821398944506\n",
      "Epoch: 171 - time: 0.0061 - loss_train: 1.6212853014291833 - loss_val: 1.7108809966135414\n",
      "Epoch: 172 - time: 0.0065 - loss_train: 1.6182195262956165 - loss_val: 1.7077801023798809\n",
      "Epoch: 173 - time: 0.0056 - loss_train: 1.6151611491765052 - loss_val: 1.704680703192379\n",
      "Epoch: 174 - time: 0.0078 - loss_train: 1.6121102369914229 - loss_val: 1.7015863722066416\n",
      "Epoch: 175 - time: 0.0082 - loss_train: 1.6090668742909129 - loss_val: 1.6985013147270323\n",
      "Epoch: 176 - time: 0.0053 - loss_train: 1.6060311412242199 - loss_val: 1.6954286434600683\n",
      "Epoch: 177 - time: 0.0067 - loss_train: 1.6030031123494224 - loss_val: 1.6923692544385642\n",
      "Epoch: 178 - time: 0.0046 - loss_train: 1.5999828598179655 - loss_val: 1.6893216316238318\n",
      "Epoch: 179 - time: 0.0059 - loss_train: 1.5969704500597308 - loss_val: 1.6862825401466643\n",
      "Epoch: 180 - time: 0.0055 - loss_train: 1.5939659420055983 - loss_val: 1.6832482650730154\n",
      "Epoch: 181 - time: 0.0049 - loss_train: 1.5909693971790735 - loss_val: 1.6802158968498193\n",
      "Epoch: 182 - time: 0.0055 - loss_train: 1.5879808961357205 - loss_val: 1.6771841938412853\n",
      "Epoch: 183 - time: 0.0050 - loss_train: 1.5850005454313736 - loss_val: 1.6741537503346913\n",
      "Epoch: 184 - time: 0.0081 - loss_train: 1.5820284682921142 - loss_val: 1.6711264842193176\n",
      "Epoch: 185 - time: 0.0114 - loss_train: 1.5790647880134543 - loss_val: 1.66810471176578\n",
      "Epoch: 186 - time: 0.0049 - loss_train: 1.5761096169539481 - loss_val: 1.6650901975666526\n",
      "Epoch: 187 - time: 0.0055 - loss_train: 1.5731630545103308 - loss_val: 1.6620835259912696\n",
      "Epoch: 188 - time: 0.0099 - loss_train: 1.570225188697208 - loss_val: 1.6590839789982672\n",
      "Epoch: 189 - time: 0.0072 - loss_train: 1.567296097038551 - loss_val: 1.656089902068525\n",
      "Epoch: 190 - time: 0.0054 - loss_train: 1.5643758481370067 - loss_val: 1.653099370277375\n",
      "Epoch: 191 - time: 0.0091 - loss_train: 1.5614645061928896 - loss_val: 1.6501108813693854\n",
      "Epoch: 192 - time: 0.0112 - loss_train: 1.5585621363446922 - loss_val: 1.6471238224088247\n",
      "Epoch: 193 - time: 0.0051 - loss_train: 1.555668806010136 - loss_val: 1.6441385662658894\n",
      "Epoch: 194 - time: 0.0090 - loss_train: 1.552784580405727 - loss_val: 1.641156206444843\n",
      "Epoch: 195 - time: 0.0063 - loss_train: 1.549909515401042 - loss_val: 1.6381780712869944\n",
      "Epoch: 196 - time: 0.0040 - loss_train: 1.547043652257932 - loss_val: 1.6352052221557383\n",
      "Epoch: 197 - time: 0.0089 - loss_train: 1.544187016113623 - loss_val: 1.6322381195383546\n",
      "Epoch: 198 - time: 0.0076 - loss_train: 1.5413396171843956 - loss_val: 1.6292765560455604\n",
      "Epoch: 199 - time: 0.0072 - loss_train: 1.538501453251433 - loss_val: 1.6263198462851882\n",
      "Epoch: 200 - time: 0.0070 - loss_train: 1.5356725128990663 - loss_val: 1.6233671722672602\n",
      "Epoch: 201 - time: 0.0145 - loss_train: 1.5328527790249673 - loss_val: 1.6204179389786486\n",
      "Epoch: 202 - time: 0.0071 - loss_train: 1.530042231326367 - loss_val: 1.6174720083203151\n",
      "Epoch: 203 - time: 0.0160 - loss_train: 1.5272408464316545 - loss_val: 1.6145297399324416\n",
      "Epoch: 204 - time: 0.0071 - loss_train: 1.524448595705145 - loss_val: 1.6115918473645794\n",
      "Epoch: 205 - time: 0.0164 - loss_train: 1.521665442235053 - loss_val: 1.6086591452726084\n",
      "Epoch: 206 - time: 0.0091 - loss_train: 1.5188913387277194 - loss_val: 1.6057322939257028\n",
      "Epoch: 207 - time: 0.0164 - loss_train: 1.5161262270939786 - loss_val: 1.6028116345887315\n",
      "Epoch: 208 - time: 0.0060 - loss_train: 1.513370039567562 - loss_val: 1.5998971639464235\n",
      "Epoch: 209 - time: 0.0074 - loss_train: 1.5106227008734776 - loss_val: 1.5969886386703356\n",
      "Epoch: 210 - time: 0.0108 - loss_train: 1.5078841309331799 - loss_val: 1.5940857546295888\n",
      "Epoch: 211 - time: 0.0065 - loss_train: 1.505154247421036 - loss_val: 1.5911883246606513\n",
      "Epoch: 212 - time: 0.0050 - loss_train: 1.502432967352137 - loss_val: 1.588296388753903\n",
      "Epoch: 213 - time: 0.0069 - loss_train: 1.4997202072102491 - loss_val: 1.5854102238934036\n",
      "Epoch: 214 - time: 0.0117 - loss_train: 1.4970158818608206 - loss_val: 1.5825302624182254\n",
      "Epoch: 215 - time: 0.0058 - loss_train: 1.494319903078555 - loss_val: 1.5796569609232147\n",
      "Epoch: 216 - time: 0.0038 - loss_train: 1.4916321785342905 - loss_val: 1.5767906748795746\n",
      "Epoch: 217 - time: 0.0114 - loss_train: 1.488952611667567 - loss_val: 1.5739315849681734\n",
      "Epoch: 218 - time: 0.0042 - loss_train: 1.4862811024365923 - loss_val: 1.5710796959731819\n",
      "Epoch: 219 - time: 0.0072 - loss_train: 1.4836175486998864 - loss_val: 1.5682348993943018\n",
      "Epoch: 220 - time: 0.0069 - loss_train: 1.480961847866195 - loss_val: 1.5653970682402947\n",
      "Epoch: 221 - time: 0.0060 - loss_train: 1.4783138983644217 - loss_val: 1.5625661443090453\n",
      "Epoch: 222 - time: 0.0199 - loss_train: 1.4756736005108215 - loss_val: 1.5597421859769056\n",
      "Epoch: 223 - time: 0.0064 - loss_train: 1.4730408565824085 - loss_val: 1.5569253633860627\n",
      "Epoch: 224 - time: 0.0076 - loss_train: 1.4704155702586135 - loss_val: 1.5541159094881327\n",
      "Epoch: 225 - time: 0.0092 - loss_train: 1.4677976458456705 - loss_val: 1.5513140511297066\n",
      "Epoch: 226 - time: 0.0065 - loss_train: 1.465186987709677 - loss_val: 1.5485199489575658\n",
      "Epoch: 227 - time: 0.0060 - loss_train: 1.4625835001679137 - loss_val: 1.545733668014804\n",
      "Epoch: 228 - time: 0.0072 - loss_train: 1.4599870878712875 - loss_val: 1.5429551865559665\n",
      "Epoch: 229 - time: 0.0075 - loss_train: 1.4573976565471103 - loss_val: 1.540184435173952\n",
      "Epoch: 230 - time: 0.0053 - loss_train: 1.4548151138729717 - loss_val: 1.5374213477590324\n",
      "Epoch: 231 - time: 0.0085 - loss_train: 1.452239370219927 - loss_val: 1.5346659035174526\n",
      "Epoch: 232 - time: 0.0067 - loss_train: 1.4496703390579695 - loss_val: 1.531918145171873\n",
      "Epoch: 233 - time: 0.0047 - loss_train: 1.4471079369578714 - loss_val: 1.5291781693607696\n",
      "Epoch: 234 - time: 0.0070 - loss_train: 1.4445520832895076 - loss_val: 1.5264460963992255\n",
      "Epoch: 235 - time: 0.0047 - loss_train: 1.4420026998214774 - loss_val: 1.5237220336452026\n",
      "Epoch: 236 - time: 0.0093 - loss_train: 1.4394597104275189 - loss_val: 1.5210060474842921\n",
      "Epoch: 237 - time: 0.0044 - loss_train: 1.4369230410259128 - loss_val: 1.5182981538520122\n",
      "Epoch: 238 - time: 0.0141 - loss_train: 1.4343926197725978 - loss_val: 1.5155983289035424\n",
      "Epoch: 239 - time: 0.0045 - loss_train: 1.4318683774375196 - loss_val: 1.5129065334777372\n",
      "Epoch: 240 - time: 0.0067 - loss_train: 1.4293502478365334 - loss_val: 1.5102227403972575\n",
      "Epoch: 241 - time: 0.0071 - loss_train: 1.4268381681803544 - loss_val: 1.5075469537869166\n",
      "Epoch: 242 - time: 0.0066 - loss_train: 1.424332079243221 - loss_val: 1.5048792138943827\n",
      "Epoch: 243 - time: 0.0054 - loss_train: 1.4218319253323344 - loss_val: 1.5022195872406605\n",
      "Epoch: 244 - time: 0.0055 - loss_train: 1.4193376541185805 - loss_val: 1.4995681476326568\n",
      "Epoch: 245 - time: 0.0053 - loss_train: 1.416849216432792 - loss_val: 1.4969249564964893\n",
      "Epoch: 246 - time: 0.0044 - loss_train: 1.4143665661264295 - loss_val: 1.494290050312552\n",
      "Epoch: 247 - time: 0.0043 - loss_train: 1.4118896600539292 - loss_val: 1.491663439314961\n",
      "Epoch: 248 - time: 0.0032 - loss_train: 1.4094184581799913 - loss_val: 1.4890451167852417\n",
      "Epoch: 249 - time: 0.0095 - loss_train: 1.4069529237687406 - loss_val: 1.4864350742249604\n",
      "Epoch: 250 - time: 0.0035 - loss_train: 1.404493023585638 - loss_val: 1.4838333159125419\n",
      "Epoch: 251 - time: 0.0038 - loss_train: 1.4020387280437876 - loss_val: 1.481239867280296\n",
      "Epoch: 252 - time: 0.0056 - loss_train: 1.399590011252884 - loss_val: 1.4786547745394234\n",
      "Epoch: 253 - time: 0.0070 - loss_train: 1.3971468509700706 - loss_val: 1.476078096654493\n",
      "Epoch: 254 - time: 0.0079 - loss_train: 1.3947092284888805 - loss_val: 1.4735098936257143\n",
      "Epoch: 255 - time: 0.0048 - loss_train: 1.3922771285199629 - loss_val: 1.4709502160532493\n",
      "Epoch: 256 - time: 0.0092 - loss_train: 1.3898505391109357 - loss_val: 1.4683990999326741\n",
      "Epoch: 257 - time: 0.0047 - loss_train: 1.3874294516294867 - loss_val: 1.4658565681786135\n",
      "Epoch: 258 - time: 0.0043 - loss_train: 1.385013860805333 - loss_val: 1.4633226375966895\n",
      "Epoch: 259 - time: 0.0078 - loss_train: 1.3826037648037364 - loss_val: 1.4607973280334559\n",
      "Epoch: 260 - time: 0.0049 - loss_train: 1.3801991652929333 - loss_val: 1.458280669919709\n",
      "Epoch: 261 - time: 0.0055 - loss_train: 1.3778000674724613 - loss_val: 1.4557727074304825\n",
      "Epoch: 262 - time: 0.0043 - loss_train: 1.3754064800461132 - loss_val: 1.453273496467014\n",
      "Epoch: 263 - time: 0.0063 - loss_train: 1.3730184151445408 - loss_val: 1.4507830987523498\n",
      "Epoch: 264 - time: 0.0077 - loss_train: 1.3706358882193634 - loss_val: 1.4483015747027417\n",
      "Epoch: 265 - time: 0.0063 - loss_train: 1.3682589179367446 - loss_val: 1.4458289779336997\n",
      "Epoch: 266 - time: 0.0155 - loss_train: 1.3658875260929075 - loss_val: 1.4433653533279498\n",
      "Epoch: 267 - time: 0.0061 - loss_train: 1.3635217375609268 - loss_val: 1.4409107390108518\n",
      "Epoch: 268 - time: 0.0061 - loss_train: 1.3611615802633235 - loss_val: 1.438465171027616\n",
      "Epoch: 269 - time: 0.0050 - loss_train: 1.3588070851541005 - loss_val: 1.4360286885935165\n",
      "Epoch: 270 - time: 0.0056 - loss_train: 1.3564582861904007 - loss_val: 1.4336013377854286\n",
      "Epoch: 271 - time: 0.0101 - loss_train: 1.3541152202783988 - loss_val: 1.4311831723657256\n",
      "Epoch: 272 - time: 0.0097 - loss_train: 1.3517779271879464 - loss_val: 1.4287742516730286\n",
      "Epoch: 273 - time: 0.0056 - loss_train: 1.3494464494413956 - loss_val: 1.4263746366528185\n",
      "Epoch: 274 - time: 0.0069 - loss_train: 1.3471208321895496 - loss_val: 1.4239843857042809\n",
      "Epoch: 275 - time: 0.0058 - loss_train: 1.3448011230893389 - loss_val: 1.4216035519105616\n",
      "Epoch: 276 - time: 0.0072 - loss_train: 1.3424873721938044 - loss_val: 1.419232182515559\n",
      "Epoch: 277 - time: 0.0042 - loss_train: 1.3401796318576817 - loss_val: 1.4168703205475157\n",
      "Epoch: 278 - time: 0.0037 - loss_train: 1.3378779566544425 - loss_val: 1.4145180076687298\n",
      "Epoch: 279 - time: 0.0076 - loss_train: 1.335582403295848 - loss_val: 1.4121752869547017\n",
      "Epoch: 280 - time: 0.0077 - loss_train: 1.3332930305443653 - loss_val: 1.409842204473172\n",
      "Epoch: 281 - time: 0.0041 - loss_train: 1.3310098991119839 - loss_val: 1.407518809120399\n",
      "Epoch: 282 - time: 0.0147 - loss_train: 1.3287330715443846 - loss_val: 1.405205150905779\n",
      "Epoch: 283 - time: 0.0068 - loss_train: 1.3264626120946712 - loss_val: 1.4029012784554986\n",
      "Epoch: 284 - time: 0.0050 - loss_train: 1.3241985865939816 - loss_val: 1.40060723672308\n",
      "Epoch: 285 - time: 0.0109 - loss_train: 1.3219410623263035 - loss_val: 1.3983230657046735\n",
      "Epoch: 286 - time: 0.0081 - loss_train: 1.3196901079122145 - loss_val: 1.396048800478528\n",
      "Epoch: 287 - time: 0.0078 - loss_train: 1.3174457932023778 - loss_val: 1.393784472339421\n",
      "Epoch: 288 - time: 0.0056 - loss_train: 1.3152081891781209 - loss_val: 1.3915301104015476\n",
      "Epoch: 289 - time: 0.0081 - loss_train: 1.312977367854526 - loss_val: 1.3892857429355545\n",
      "Epoch: 290 - time: 0.0036 - loss_train: 1.3107534021817355 - loss_val: 1.387051397896763\n",
      "Epoch: 291 - time: 0.0092 - loss_train: 1.308536365942144 - loss_val: 1.3848271024837717\n",
      "Epoch: 292 - time: 0.0054 - loss_train: 1.3063263336438964 - loss_val: 1.38261288196852\n",
      "Epoch: 293 - time: 0.0063 - loss_train: 1.3041233804133976 - loss_val: 1.3804087583006153\n",
      "Epoch: 294 - time: 0.0061 - loss_train: 1.301927581890552 - loss_val: 1.3782147490234709\n",
      "Epoch: 295 - time: 0.0080 - loss_train: 1.2997390141299505 - loss_val: 1.3760308668595258\n",
      "Epoch: 296 - time: 0.0055 - loss_train: 1.297557753509629 - loss_val: 1.3738571200219216\n",
      "Epoch: 297 - time: 0.0067 - loss_train: 1.2953838766470702 - loss_val: 1.3716935130223145\n",
      "Epoch: 298 - time: 0.0054 - loss_train: 1.2932174603206277 - loss_val: 1.369540047581159\n",
      "Epoch: 299 - time: 0.0068 - loss_train: 1.2910585813940065 - loss_val: 1.3673967232582949\n",
      "Epoch: 300 - time: 0.0055 - loss_train: 1.2889073167419038 - loss_val: 1.365263537583421\n",
      "Epoch: 301 - time: 0.0068 - loss_train: 1.2867637431760937 - loss_val: 1.3631404856968377\n",
      "Epoch: 302 - time: 0.0221 - loss_train: 1.284627937372513 - loss_val: 1.3610275597109476\n",
      "Epoch: 303 - time: 0.0054 - loss_train: 1.2824999758007745 - loss_val: 1.3589247480963018\n",
      "Epoch: 304 - time: 0.0094 - loss_train: 1.2803799346576792 - loss_val: 1.3568320353572272\n",
      "Epoch: 305 - time: 0.0037 - loss_train: 1.2782678898057733 - loss_val: 1.3547494021218205\n",
      "Epoch: 306 - time: 0.0053 - loss_train: 1.2761639167170713 - loss_val: 1.3526768255966863\n",
      "Epoch: 307 - time: 0.0050 - loss_train: 1.2740680904211725 - loss_val: 1.3506142802021164\n",
      "Epoch: 308 - time: 0.0074 - loss_train: 1.2719804854564756 - loss_val: 1.3485617381577826\n",
      "Epoch: 309 - time: 0.0047 - loss_train: 1.269901175823196 - loss_val: 1.3465191698408743\n",
      "Epoch: 310 - time: 0.0034 - loss_train: 1.2678302349373414 - loss_val: 1.34448654385604\n",
      "Epoch: 311 - time: 0.0077 - loss_train: 1.265767735585455 - loss_val: 1.3424638268848417\n",
      "Epoch: 312 - time: 0.0074 - loss_train: 1.2637137498805198 - loss_val: 1.3404509834686604\n",
      "Epoch: 313 - time: 0.0047 - loss_train: 1.2616683492196612 - loss_val: 1.3384479758928618\n",
      "Epoch: 314 - time: 0.0064 - loss_train: 1.2596316042441928 - loss_val: 1.3364547642839526\n",
      "Epoch: 315 - time: 0.0099 - loss_train: 1.2576035848021472 - loss_val: 1.3344713069357237\n",
      "Epoch: 316 - time: 0.0051 - loss_train: 1.2555843599129526 - loss_val: 1.3324975607882303\n",
      "Epoch: 317 - time: 0.0056 - loss_train: 1.2535739977335578 - loss_val: 1.3305334819317445\n",
      "Epoch: 318 - time: 0.0072 - loss_train: 1.2515725655252048 - loss_val: 1.328579026013248\n",
      "Epoch: 319 - time: 0.0047 - loss_train: 1.2495801296201874 - loss_val: 1.326634148477073\n",
      "Epoch: 320 - time: 0.0076 - loss_train: 1.2475967553882776 - loss_val: 1.324698804646775\n",
      "Epoch: 321 - time: 0.0108 - loss_train: 1.2456225072028473 - loss_val: 1.3227729497191731\n",
      "Epoch: 322 - time: 0.0078 - loss_train: 1.2436574484069514 - loss_val: 1.3208565387690279\n",
      "Epoch: 323 - time: 0.0059 - loss_train: 1.2417016412796744 - loss_val: 1.3189495268467204\n",
      "Epoch: 324 - time: 0.0051 - loss_train: 1.239755147002922 - loss_val: 1.317051869202908\n",
      "Epoch: 325 - time: 0.0055 - loss_train: 1.237818025628584 - loss_val: 1.3151635216166142\n",
      "Epoch: 326 - time: 0.0071 - loss_train: 1.2358903360457862 - loss_val: 1.3132844407611128\n",
      "Epoch: 327 - time: 0.0046 - loss_train: 1.233972135947833 - loss_val: 1.3114145845307514\n",
      "Epoch: 328 - time: 0.0046 - loss_train: 1.2320634817984542 - loss_val: 1.309553912272826\n",
      "Epoch: 329 - time: 0.0048 - loss_train: 1.2301644287971172 - loss_val: 1.307702384909737\n",
      "Epoch: 330 - time: 0.0041 - loss_train: 1.2282750308433719 - loss_val: 1.3058599649788964\n",
      "Epoch: 331 - time: 0.0038 - loss_train: 1.226395340500348 - loss_val: 1.3040266166439567\n",
      "Epoch: 332 - time: 0.0043 - loss_train: 1.2245254089576096 - loss_val: 1.3022023057318708\n",
      "Epoch: 333 - time: 0.0091 - loss_train: 1.2226652859935703 - loss_val: 1.3003869998285822\n",
      "Epoch: 334 - time: 0.0042 - loss_train: 1.2208150199375565 - loss_val: 1.2985806684331436\n",
      "Epoch: 335 - time: 0.0055 - loss_train: 1.218974657631519 - loss_val: 1.296783283140607\n",
      "Epoch: 336 - time: 0.0039 - loss_train: 1.217144244391286 - loss_val: 1.2949948178098845\n",
      "Epoch: 337 - time: 0.0129 - loss_train: 1.2153238239672537 - loss_val: 1.293215248678073\n",
      "Epoch: 338 - time: 0.0088 - loss_train: 1.2135134385044426 - loss_val: 1.2914445544032245\n",
      "Epoch: 339 - time: 0.0054 - loss_train: 1.2117131285019436 - loss_val: 1.2896827160430926\n",
      "Epoch: 340 - time: 0.0100 - loss_train: 1.20992293277187 - loss_val: 1.2879297169969635\n",
      "Epoch: 341 - time: 0.0073 - loss_train: 1.2081428883980063 - loss_val: 1.2861855429438869\n",
      "Epoch: 342 - time: 0.0051 - loss_train: 1.2063730306943534 - loss_val: 1.284450181802424\n",
      "Epoch: 343 - time: 0.0054 - loss_train: 1.2046133931637646 - loss_val: 1.2827236237194535\n",
      "Epoch: 344 - time: 0.0096 - loss_train: 1.2028640074568124 - loss_val: 1.2810058610770172\n",
      "Epoch: 345 - time: 0.0049 - loss_train: 1.201124903331004 - loss_val: 1.2792968884944558\n",
      "Epoch: 346 - time: 0.0039 - loss_train: 1.1993961086104221 - loss_val: 1.2775967028023658\n",
      "Epoch: 347 - time: 0.0065 - loss_train: 1.1976776491459016 - loss_val: 1.2759053029742642\n",
      "Epoch: 348 - time: 0.0093 - loss_train: 1.195969548775878 - loss_val: 1.2742226900162992\n",
      "Epoch: 349 - time: 0.0044 - loss_train: 1.1942718292880685 - loss_val: 1.2725488668282796\n",
      "Epoch: 350 - time: 0.0042 - loss_train: 1.1925845103822035 - loss_val: 1.2708838380555099\n",
      "Epoch: 351 - time: 0.0070 - loss_train: 1.1909076096340159 - loss_val: 1.269227609948564\n",
      "Epoch: 352 - time: 0.0053 - loss_train: 1.1892411424607172 - loss_val: 1.2675801902391413\n",
      "Epoch: 353 - time: 0.0082 - loss_train: 1.1875851220881415 - loss_val: 1.2659415880290912\n",
      "Epoch: 354 - time: 0.0079 - loss_train: 1.1859395595197644 - loss_val: 1.2643118136813978\n",
      "Epoch: 355 - time: 0.0070 - loss_train: 1.1843044635077495 - loss_val: 1.2626908786996562\n",
      "Epoch: 356 - time: 0.0104 - loss_train: 1.1826798405262067 - loss_val: 1.2610787955865894\n",
      "Epoch: 357 - time: 0.0229 - loss_train: 1.1810656947468292 - loss_val: 1.2594755776800983\n",
      "Epoch: 358 - time: 0.0047 - loss_train: 1.1794620280170904 - loss_val: 1.2578812389734457\n",
      "Epoch: 359 - time: 0.0072 - loss_train: 1.177868839841181 - loss_val: 1.2562957939309676\n",
      "Epoch: 360 - time: 0.0140 - loss_train: 1.1762861273638432 - loss_val: 1.2547192573105246\n",
      "Epoch: 361 - time: 0.0052 - loss_train: 1.1747138853572696 - loss_val: 1.253151643999382\n",
      "Epoch: 362 - time: 0.0080 - loss_train: 1.173152106211186 - loss_val: 1.2515929688636556\n",
      "Epoch: 363 - time: 0.0137 - loss_train: 1.1716007799262411 - loss_val: 1.2500432466059541\n",
      "Epoch: 364 - time: 0.0052 - loss_train: 1.1700598941107996 - loss_val: 1.2485024916235015\n",
      "Epoch: 365 - time: 0.0062 - loss_train: 1.1685294339812284 - loss_val: 1.2469707178605407\n",
      "Epoch: 366 - time: 0.0128 - loss_train: 1.167009382365764 - loss_val: 1.2454479386531214\n",
      "Epoch: 367 - time: 0.0050 - loss_train: 1.165499719712007 - loss_val: 1.2439341665693056\n",
      "Epoch: 368 - time: 0.0067 - loss_train: 1.1640004240981185 - loss_val: 1.2424294132512006\n",
      "Epoch: 369 - time: 0.0416 - loss_train: 1.1625114712477207 - loss_val: 1.2409336892658307\n",
      "Epoch: 370 - time: 0.0188 - loss_train: 1.161032834548507 - loss_val: 1.2394470039696104\n",
      "Epoch: 371 - time: 0.0088 - loss_train: 1.1595644850745328 - loss_val: 1.237969365387451\n",
      "Epoch: 372 - time: 0.0044 - loss_train: 1.158106391612141 - loss_val: 1.2365007801039247\n",
      "Epoch: 373 - time: 0.0123 - loss_train: 1.1566585206894395 - loss_val: 1.2350412531620014\n",
      "Epoch: 374 - time: 0.0053 - loss_train: 1.1552208366092693 - loss_val: 1.2335907879652313\n",
      "Epoch: 375 - time: 0.0074 - loss_train: 1.1537933014855644 - loss_val: 1.2321493861814414\n",
      "Epoch: 376 - time: 0.0058 - loss_train: 1.152375875282998 - loss_val: 1.2307170476488938\n",
      "Epoch: 377 - time: 0.0047 - loss_train: 1.1509685158598062 - loss_val: 1.2292937702880913\n",
      "Epoch: 378 - time: 0.0094 - loss_train: 1.1495711790136436 - loss_val: 1.227879550023135\n",
      "Epoch: 379 - time: 0.0094 - loss_train: 1.1481838185303204 - loss_val: 1.2264743807155334\n",
      "Epoch: 380 - time: 0.0087 - loss_train: 1.1468063862352382 - loss_val: 1.225078254111321\n",
      "Epoch: 381 - time: 0.0079 - loss_train: 1.1454388320473334 - loss_val: 1.2236911598001508\n",
      "Epoch: 382 - time: 0.0044 - loss_train: 1.1440811040353296 - loss_val: 1.2223130851836939\n",
      "Epoch: 383 - time: 0.0154 - loss_train: 1.1427331484760976 - loss_val: 1.2209440154505902\n",
      "Epoch: 384 - time: 0.0053 - loss_train: 1.1413949099149088 - loss_val: 1.2195839335562537\n",
      "Epoch: 385 - time: 0.0068 - loss_train: 1.1400663312273964 - loss_val: 1.2182328202074413\n",
      "Epoch: 386 - time: 0.0090 - loss_train: 1.1387473536830026 - loss_val: 1.2168906538528348\n",
      "Epoch: 387 - time: 0.0062 - loss_train: 1.1374379170097184 - loss_val: 1.2155574106814286\n",
      "Epoch: 388 - time: 0.0057 - loss_train: 1.1361379594598946 - loss_val: 1.2142330646301382\n",
      "Epoch: 389 - time: 0.0098 - loss_train: 1.1348474178769161 - loss_val: 1.2129175874009308\n",
      "Epoch: 390 - time: 0.0083 - loss_train: 1.1335662277625174 - loss_val: 1.2116109484865902\n",
      "Epoch: 391 - time: 0.0044 - loss_train: 1.1322943233445244 - loss_val: 1.2103131152034112\n",
      "Epoch: 392 - time: 0.0082 - loss_train: 1.1310316376448286 - loss_val: 1.2090240527290108\n",
      "Epoch: 393 - time: 0.0045 - loss_train: 1.1297781025473868 - loss_val: 1.207743724143977\n",
      "Epoch: 394 - time: 0.0075 - loss_train: 1.12853364886607 - loss_val: 1.2064720904769628\n",
      "Epoch: 395 - time: 0.0094 - loss_train: 1.127298206412196 - loss_val: 1.2052091107535854\n",
      "Epoch: 396 - time: 0.0044 - loss_train: 1.1260717040615726 - loss_val: 1.2039547420498484\n",
      "Epoch: 397 - time: 0.0098 - loss_train: 1.124854069820909 - loss_val: 1.202708939550605\n",
      "Epoch: 398 - time: 0.0084 - loss_train: 1.1236452308934404 - loss_val: 1.201471656613002\n",
      "Epoch: 399 - time: 0.0050 - loss_train: 1.1224451137436322 - loss_val: 1.2002428448342102\n",
      "Epoch: 400 - time: 0.0036 - loss_train: 1.1212536441608318 - loss_val: 1.1990224541222945\n",
      "Epoch: 401 - time: 0.0065 - loss_train: 1.1200707473217508 - loss_val: 1.1978104327690513\n",
      "Epoch: 402 - time: 0.0106 - loss_train: 1.1188963478516765 - loss_val: 1.196606727523978\n",
      "Epoch: 403 - time: 0.0044 - loss_train: 1.117730369884321 - loss_val: 1.1954112836690265\n",
      "Epoch: 404 - time: 0.0041 - loss_train: 1.1165727371202308 - loss_val: 1.194224045094264\n",
      "Epoch: 405 - time: 0.0297 - loss_train: 1.1154233728836944 - loss_val: 1.1930449543747363\n",
      "Epoch: 406 - time: 0.2249 - loss_train: 1.1142822001780917 - loss_val: 1.1918739528487268\n",
      "Epoch: 407 - time: 0.0327 - loss_train: 1.1131491417396373 - loss_val: 1.190710980697274\n",
      "Epoch: 408 - time: 0.0097 - loss_train: 1.112024120089479 - loss_val: 1.1895559770244364\n",
      "Epoch: 409 - time: 0.0158 - loss_train: 1.110907057584116 - loss_val: 1.1884088799375856\n",
      "Epoch: 410 - time: 0.0140 - loss_train: 1.1097978764641252 - loss_val: 1.1872696266270055\n",
      "Epoch: 411 - time: 0.0281 - loss_train: 1.1086964989011627 - loss_val: 1.1861381534442983\n",
      "Epoch: 412 - time: 0.0287 - loss_train: 1.1076028470432528 - loss_val: 1.185014395979419\n",
      "Epoch: 413 - time: 0.0384 - loss_train: 1.1065168430583572 - loss_val: 1.1838982891364334\n",
      "Epoch: 414 - time: 0.0252 - loss_train: 1.105438409176236 - loss_val: 1.182789767208183\n",
      "Epoch: 415 - time: 0.0224 - loss_train: 1.104367467728613 - loss_val: 1.1816887639500069\n",
      "Epoch: 416 - time: 0.0323 - loss_train: 1.1033039411876735 - loss_val: 1.1805952126524235\n",
      "Epoch: 417 - time: 0.0895 - loss_train: 1.1022477522028988 - loss_val: 1.179509046212509\n",
      "Epoch: 418 - time: 0.0214 - loss_train: 1.1011988236362786 - loss_val: 1.1784301972035494\n",
      "Epoch: 419 - time: 0.0089 - loss_train: 1.100157078595922 - loss_val: 1.1773585979425807\n",
      "Epoch: 420 - time: 0.0186 - loss_train: 1.099122440468097 - loss_val: 1.1762941805555653\n",
      "Epoch: 421 - time: 0.0065 - loss_train: 1.0980948329477347 - loss_val: 1.1752368770401493\n",
      "Epoch: 422 - time: 0.0047 - loss_train: 1.0970741800674324 - loss_val: 1.1741866193261046\n",
      "Epoch: 423 - time: 0.0086 - loss_train: 1.0960604062249946 - loss_val: 1.173143339333621\n",
      "Epoch: 424 - time: 0.0039 - loss_train: 1.095053436209549 - loss_val: 1.172106969029575\n",
      "Epoch: 425 - time: 0.0039 - loss_train: 1.094053195226283 - loss_val: 1.1710774404817648\n",
      "Epoch: 426 - time: 0.0052 - loss_train: 1.0930596089198268 - loss_val: 1.1700546859110086\n",
      "Epoch: 427 - time: 0.0083 - loss_train: 1.0920726033963355 - loss_val: 1.1690386377408895\n",
      "Epoch: 428 - time: 0.0072 - loss_train: 1.0910921052443014 - loss_val: 1.1680292286450076\n",
      "Epoch: 429 - time: 0.0079 - loss_train: 1.090118041554136 - loss_val: 1.167026391591617\n",
      "Epoch: 430 - time: 0.0073 - loss_train: 1.0891503399365585 - loss_val: 1.1660300598856994\n",
      "Epoch: 431 - time: 0.0053 - loss_train: 1.0881889285398334 - loss_val: 1.1650401672085686\n",
      "Epoch: 432 - time: 0.0037 - loss_train: 1.0872337360658852 - loss_val: 1.1640566476551744\n",
      "Epoch: 433 - time: 0.0057 - loss_train: 1.086284691785343 - loss_val: 1.1630794357691947\n",
      "Epoch: 434 - time: 0.0223 - loss_train: 1.0853417255515259 - loss_val: 1.1621084665759736\n",
      "Epoch: 435 - time: 0.0059 - loss_train: 1.0844047678134319 - loss_val: 1.161143675613277\n",
      "Epoch: 436 - time: 0.0066 - loss_train: 1.0834737496277407 - loss_val: 1.1601849989598008\n",
      "Epoch: 437 - time: 0.0050 - loss_train: 1.0825486026698765 - loss_val: 1.1592323732613907\n",
      "Epoch: 438 - time: 0.0110 - loss_train: 1.081629259244155 - loss_val: 1.1582857357549792\n",
      "Epoch: 439 - time: 0.0059 - loss_train: 1.0807156522930517 - loss_val: 1.1573450242903136\n",
      "Epoch: 440 - time: 0.0062 - loss_train: 1.0798077154056154 - loss_val: 1.1564101773495932\n",
      "Epoch: 441 - time: 0.0074 - loss_train: 1.0789053828250625 - loss_val: 1.1554811340651432\n",
      "Epoch: 442 - time: 0.0102 - loss_train: 1.0780085894555747 - loss_val: 1.154557834235234\n",
      "Epoch: 443 - time: 0.0053 - loss_train: 1.077117270868333 - loss_val: 1.1536402183381083\n",
      "Epoch: 444 - time: 0.0060 - loss_train: 1.0762313633068135 - loss_val: 1.1527282275442234\n",
      "Epoch: 445 - time: 0.0087 - loss_train: 1.0753508036913675 - loss_val: 1.1518218037267416\n",
      "Epoch: 446 - time: 0.0046 - loss_train: 1.0744755296231232 - loss_val: 1.1509208894702616\n",
      "Epoch: 447 - time: 0.0072 - loss_train: 1.073605479387218 - loss_val: 1.1500254280778641\n",
      "Epoch: 448 - time: 0.0097 - loss_train: 1.0727405919553994 - loss_val: 1.1491353635765482\n",
      "Epoch: 449 - time: 0.0100 - loss_train: 1.0718808069880146 - loss_val: 1.1482506407211837\n",
      "Epoch: 450 - time: 0.0045 - loss_train: 1.0710260648354097 - loss_val: 1.1473712049970737\n",
      "Epoch: 451 - time: 0.0062 - loss_train: 1.0701763065387682 - loss_val: 1.146497002621246\n",
      "Epoch: 452 - time: 0.0072 - loss_train: 1.0693314738304074 - loss_val: 1.1456279805425156\n",
      "Epoch: 453 - time: 0.0114 - loss_train: 1.0684915091335543 - loss_val: 1.1447640864403734\n",
      "Epoch: 454 - time: 0.0055 - loss_train: 1.0676563555616299 - loss_val: 1.143905268722735\n",
      "Epoch: 455 - time: 0.0057 - loss_train: 1.0668259569170564 - loss_val: 1.143051476522592\n",
      "Epoch: 456 - time: 0.0098 - loss_train: 1.0660002576896146 - loss_val: 1.1422026596936303\n",
      "Epoch: 457 - time: 0.0057 - loss_train: 1.0651792030543665 - loss_val: 1.1413587688048925\n",
      "Epoch: 458 - time: 0.0101 - loss_train: 1.0643627388691768 - loss_val: 1.1405197551345925\n",
      "Epoch: 459 - time: 0.0176 - loss_train: 1.0635508116718326 - loss_val: 1.1396855706631512\n",
      "Epoch: 460 - time: 0.0086 - loss_train: 1.0627433686768086 - loss_val: 1.1388561680655438\n",
      "Epoch: 461 - time: 0.0216 - loss_train: 1.0619403577716717 - loss_val: 1.1380315007030082\n",
      "Epoch: 462 - time: 0.0056 - loss_train: 1.0611417275131658 - loss_val: 1.137211522614161\n",
      "Epoch: 463 - time: 0.0081 - loss_train: 1.0603474271229802 - loss_val: 1.1363961885055553\n",
      "Epoch: 464 - time: 0.0092 - loss_train: 1.0595574064832323 - loss_val: 1.135585453741727\n",
      "Epoch: 465 - time: 0.0110 - loss_train: 1.0587716161316738 - loss_val: 1.134779274334794\n",
      "Epoch: 466 - time: 0.0204 - loss_train: 1.057990007256649 - loss_val: 1.1339776069336427\n",
      "Epoch: 467 - time: 0.0052 - loss_train: 1.0572125316918068 - loss_val: 1.1331804088128057\n",
      "Epoch: 468 - time: 0.0067 - loss_train: 1.0564391419106074 - loss_val: 1.132387637861059\n",
      "Epoch: 469 - time: 0.0173 - loss_train: 1.0556697910206134 - loss_val: 1.131599252569809\n",
      "Epoch: 470 - time: 0.0065 - loss_train: 1.0549044327576067 - loss_val: 1.1308152120213\n",
      "Epoch: 471 - time: 0.0137 - loss_train: 1.0541430214795269 - loss_val: 1.130035475876674\n",
      "Epoch: 472 - time: 0.0058 - loss_train: 1.053385512160263 - loss_val: 1.129260004363919\n",
      "Epoch: 473 - time: 0.0051 - loss_train: 1.0526318603832998 - loss_val: 1.128488758265729\n",
      "Epoch: 474 - time: 0.0175 - loss_train: 1.0518820223352432 - loss_val: 1.12772169890732\n",
      "Epoch: 475 - time: 0.0075 - loss_train: 1.0511359547992365 - loss_val: 1.1269587881442367\n",
      "Epoch: 476 - time: 0.0119 - loss_train: 1.0503936151482745 - loss_val: 1.1261999883501927\n",
      "Epoch: 477 - time: 0.0065 - loss_train: 1.0496549613384383 - loss_val: 1.1254452624049824\n",
      "Epoch: 478 - time: 0.0045 - loss_train: 1.048919951902058 - loss_val: 1.1246945736824805\n",
      "Epoch: 479 - time: 0.0186 - loss_train: 1.0481885459408158 - loss_val: 1.1239478860387646\n",
      "Epoch: 480 - time: 0.0074 - loss_train: 1.0474607031187984 - loss_val: 1.1232051638003653\n",
      "Epoch: 481 - time: 0.0039 - loss_train: 1.0467363836555177 - loss_val: 1.1224663717526706\n",
      "Epoch: 482 - time: 0.0165 - loss_train: 1.0460155483188995 - loss_val: 1.1217314751284908\n",
      "Epoch: 483 - time: 0.0058 - loss_train: 1.0452981584182612 - loss_val: 1.1210004395968165\n",
      "Epoch: 484 - time: 0.0056 - loss_train: 1.044584175797278 - loss_val: 1.12027323125178\n",
      "Epoch: 485 - time: 0.0053 - loss_train: 1.043873562826952 - loss_val: 1.1195498166018423\n",
      "Epoch: 486 - time: 0.0064 - loss_train: 1.043166282398593 - loss_val: 1.1188301625592205\n",
      "Epoch: 487 - time: 0.0055 - loss_train: 1.042462297916819 - loss_val: 1.1181142364295729\n",
      "Epoch: 488 - time: 0.0225 - loss_train: 1.0417615732925758 - loss_val: 1.1174020059019294\n",
      "Epoch: 489 - time: 0.0186 - loss_train: 1.0410640729361982 - loss_val: 1.1166934390388985\n",
      "Epoch: 490 - time: 0.0069 - loss_train: 1.0403697617505052 - loss_val: 1.1159885042671271\n",
      "Epoch: 491 - time: 0.0050 - loss_train: 1.0396786051239386 - loss_val: 1.1152871703680423\n",
      "Epoch: 492 - time: 0.0134 - loss_train: 1.038990568923762 - loss_val: 1.1145894064688682\n",
      "Epoch: 493 - time: 0.0068 - loss_train: 1.0383056194893052 - loss_val: 1.1138951820339271\n",
      "Epoch: 494 - time: 0.0038 - loss_train: 1.0376237236252783 - loss_val: 1.113204466856231\n",
      "Epoch: 495 - time: 0.0044 - loss_train: 1.0369448485951458 - loss_val: 1.1125172310493654\n",
      "Epoch: 496 - time: 0.0067 - loss_train: 1.0362689621145762 - loss_val: 1.1118334450396623\n",
      "Epoch: 497 - time: 0.0057 - loss_train: 1.0355960323449596 - loss_val: 1.1111530795586628\n",
      "Epoch: 498 - time: 0.0056 - loss_train: 1.0349260278870076 - loss_val: 1.1104761056358634\n",
      "Epoch: 499 - time: 0.0057 - loss_train: 1.0342589177744301 - loss_val: 1.1098024945917482\n",
      "Epoch: 500 - time: 0.0103 - loss_train: 1.033594671467693 - loss_val: 1.1091322180311\n",
      "Epoch: 501 - time: 0.0441 - loss_train: 1.032933258847868 - loss_val: 1.1084652478365837\n",
      "Epoch: 502 - time: 0.0140 - loss_train: 1.032274650210562 - loss_val: 1.1078015561626167\n",
      "Epoch: 503 - time: 0.0074 - loss_train: 1.0316188162599433 - loss_val: 1.1071411154295019\n",
      "Epoch: 504 - time: 0.0243 - loss_train: 1.0309657281028488 - loss_val: 1.1064838983178371\n",
      "Epoch: 505 - time: 0.0199 - loss_train: 1.0303153572429928 - loss_val: 1.1058298777631794\n",
      "Epoch: 506 - time: 0.0069 - loss_train: 1.029667675575267 - loss_val: 1.1051790269509727\n",
      "Epoch: 507 - time: 0.0110 - loss_train: 1.0290226553801258 - loss_val: 1.1045313193117179\n",
      "Epoch: 508 - time: 0.0050 - loss_train: 1.0283802693180812 - loss_val: 1.103886728516391\n",
      "Epoch: 509 - time: 0.0060 - loss_train: 1.027740490424279 - loss_val: 1.103245228472093\n",
      "Epoch: 510 - time: 0.0074 - loss_train: 1.0271032921031789 - loss_val: 1.1026067933179393\n",
      "Epoch: 511 - time: 0.0055 - loss_train: 1.0264686481233252 - loss_val: 1.1019713974211656\n",
      "Epoch: 512 - time: 0.0074 - loss_train: 1.0258365326122165 - loss_val: 1.1013390153734641\n",
      "Epoch: 513 - time: 0.0138 - loss_train: 1.0252069200512681 - loss_val: 1.100709621987526\n",
      "Epoch: 514 - time: 0.0050 - loss_train: 1.024579785270869 - loss_val: 1.1000831922937915\n",
      "Epoch: 515 - time: 0.0045 - loss_train: 1.0239551034455339 - loss_val: 1.0994597015373995\n",
      "Epoch: 516 - time: 0.0058 - loss_train: 1.0233328500891494 - loss_val: 1.0988391251753298\n",
      "Epoch: 517 - time: 0.0059 - loss_train: 1.0227130010503098 - loss_val: 1.098221438873728\n",
      "Epoch: 518 - time: 0.0058 - loss_train: 1.0220955325077479 - loss_val: 1.0976066185054105\n",
      "Epoch: 519 - time: 0.0042 - loss_train: 1.021480420965855 - loss_val: 1.0969946401475446\n",
      "Epoch: 520 - time: 0.0042 - loss_train: 1.02086764325029 - loss_val: 1.096385480079493\n",
      "Epoch: 521 - time: 0.0058 - loss_train: 1.020257176503678 - loss_val: 1.0957791147808202\n",
      "Epoch: 522 - time: 0.0059 - loss_train: 1.0196489981813968 - loss_val: 1.0951755209294571\n",
      "Epoch: 523 - time: 0.0046 - loss_train: 1.0190430860474462 - loss_val: 1.094574675400012\n",
      "Epoch: 524 - time: 0.0049 - loss_train: 1.0184394181704044 - loss_val: 1.0939765552622185\n",
      "Epoch: 525 - time: 0.0057 - loss_train: 1.0178379729194682 - loss_val: 1.0933811377795306\n",
      "Epoch: 526 - time: 0.0079 - loss_train: 1.0172387289605707 - loss_val: 1.0927884004078392\n",
      "Epoch: 527 - time: 0.0065 - loss_train: 1.0166416652525818 - loss_val: 1.0921983207943213\n",
      "Epoch: 528 - time: 0.0106 - loss_train: 1.0160467610435875 - loss_val: 1.0916108767764032\n",
      "Epoch: 529 - time: 0.0148 - loss_train: 1.015453995867245 - loss_val: 1.0910260463808474\n",
      "Epoch: 530 - time: 0.0073 - loss_train: 1.014863349539211 - loss_val: 1.0904438078229461\n",
      "Epoch: 531 - time: 0.0219 - loss_train: 1.0142748021536447 - loss_val: 1.0898641395058217\n",
      "Epoch: 532 - time: 0.0057 - loss_train: 1.0136883340797849 - loss_val: 1.0892870200198266\n",
      "Epoch: 533 - time: 0.0099 - loss_train: 1.01310392595859 - loss_val: 1.0887124281420457\n",
      "Epoch: 534 - time: 0.0069 - loss_train: 1.0125215586994538 - loss_val: 1.0881403428358818\n",
      "Epoch: 535 - time: 0.0044 - loss_train: 1.0119412134769803 - loss_val: 1.087570743250739\n",
      "Epoch: 536 - time: 0.0041 - loss_train: 1.0113628717278296 - loss_val: 1.0870036087217796\n",
      "Epoch: 537 - time: 0.0044 - loss_train: 1.010786515147619 - loss_val: 1.0864389187697705\n",
      "Epoch: 538 - time: 0.0045 - loss_train: 1.0102121256878913 - loss_val: 1.0858766531009991\n",
      "Epoch: 539 - time: 0.0046 - loss_train: 1.0096396855531355 - loss_val: 1.085316791607267\n",
      "Epoch: 540 - time: 0.0051 - loss_train: 1.0090691771978704 - loss_val: 1.0847593143659457\n",
      "Epoch: 541 - time: 0.0052 - loss_train: 1.008500583323779 - loss_val: 1.0842042016401046\n",
      "Epoch: 542 - time: 0.0054 - loss_train: 1.007933886876897 - loss_val: 1.0836514338786938\n",
      "Epoch: 543 - time: 0.0037 - loss_train: 1.007369071044854 - loss_val: 1.083100991716788\n",
      "Epoch: 544 - time: 0.0033 - loss_train: 1.006806119254159 - loss_val: 1.0825528559758837\n",
      "Epoch: 545 - time: 0.0040 - loss_train: 1.0062450151675442 - loss_val: 1.0820070076642467\n",
      "Epoch: 546 - time: 0.0033 - loss_train: 1.00568574268134 - loss_val: 1.081463427977311\n",
      "Epoch: 547 - time: 0.0074 - loss_train: 1.0051282859229043 - loss_val: 1.0809220982981151\n",
      "Epoch: 548 - time: 0.0060 - loss_train: 1.0045726292480919 - loss_val: 1.0803830001977888\n",
      "Epoch: 549 - time: 0.0045 - loss_train: 1.00401875723876 - loss_val: 1.0798461154360683\n",
      "Epoch: 550 - time: 0.0043 - loss_train: 1.0034666547003162 - loss_val: 1.0793114259618546\n",
      "Epoch: 551 - time: 0.0064 - loss_train: 1.0029163066593005 - loss_val: 1.078778913913798\n",
      "Epoch: 552 - time: 0.0082 - loss_train: 1.0023676983610037 - loss_val: 1.0782485616209119\n",
      "Epoch: 553 - time: 0.0046 - loss_train: 1.0018208152671169 - loss_val: 1.0777203516032143\n",
      "Epoch: 554 - time: 0.0052 - loss_train: 1.0012756430534138 - loss_val: 1.0771942665723855\n",
      "Epoch: 555 - time: 0.0048 - loss_train: 1.0007321676074619 - loss_val: 1.076670289432454\n",
      "Epoch: 556 - time: 0.0085 - loss_train: 1.00019037502636 - loss_val: 1.076148403280487\n",
      "Epoch: 557 - time: 0.0066 - loss_train: 0.9996502516145054 - loss_val: 1.0756285914073083\n",
      "Epoch: 558 - time: 0.0078 - loss_train: 0.999111783881379 - loss_val: 1.0751108372982043\n",
      "Epoch: 559 - time: 0.0168 - loss_train: 0.9985749585393612 - loss_val: 1.0745951246336598\n",
      "Epoch: 560 - time: 0.0046 - loss_train: 0.9980397625015626 - loss_val: 1.0740814372900769\n",
      "Epoch: 561 - time: 0.0117 - loss_train: 0.9975061828796754 - loss_val: 1.0735697593405047\n",
      "Epoch: 562 - time: 0.0049 - loss_train: 0.9969742069818467 - loss_val: 1.0730600750553605\n",
      "Epoch: 563 - time: 0.0045 - loss_train: 0.9964438223105613 - loss_val: 1.0725523689031484\n",
      "Epoch: 564 - time: 0.0169 - loss_train: 0.995915016560546 - loss_val: 1.0720466255511591\n",
      "Epoch: 565 - time: 0.0102 - loss_train: 0.9953877776166833 - loss_val: 1.0715428298661664\n",
      "Epoch: 566 - time: 0.0238 - loss_train: 0.994862093551937 - loss_val: 1.071040966915097\n",
      "Epoch: 567 - time: 0.0080 - loss_train: 0.9943379526252929 - loss_val: 1.070541021965685\n",
      "Epoch: 568 - time: 0.0095 - loss_train: 0.9938153432797014 - loss_val: 1.0700429804871034\n",
      "Epoch: 569 - time: 0.0114 - loss_train: 0.9932942541400346 - loss_val: 1.0695468281505611\n",
      "Epoch: 570 - time: 0.0079 - loss_train: 0.9927746740110466 - loss_val: 1.069052550829877\n",
      "Epoch: 571 - time: 0.0122 - loss_train: 0.9922565918753403 - loss_val: 1.0685601346020135\n",
      "Epoch: 572 - time: 0.0053 - loss_train: 0.9917399968913369 - loss_val: 1.0680695657475778\n",
      "Epoch: 573 - time: 0.0057 - loss_train: 0.9912248783912511 - loss_val: 1.0675808307512746\n",
      "Epoch: 574 - time: 0.0100 - loss_train: 0.990711225879065 - loss_val: 1.0670939163023199\n",
      "Epoch: 575 - time: 0.0061 - loss_train: 0.9901990290285074 - loss_val: 1.0666088092948047\n",
      "Epoch: 576 - time: 0.0041 - loss_train: 0.9896882776810262 - loss_val: 1.066125496828007\n",
      "Epoch: 577 - time: 0.0073 - loss_train: 0.9891789618437677 - loss_val: 1.0656439662066464\n",
      "Epoch: 578 - time: 0.0094 - loss_train: 0.9886710716875484 - loss_val: 1.0651642049410825\n",
      "Epoch: 579 - time: 0.0044 - loss_train: 0.9881645975448238 - loss_val: 1.0646862007474542\n",
      "Epoch: 580 - time: 0.0135 - loss_train: 0.9876595299076594 - loss_val: 1.0642099415477446\n",
      "Epoch: 581 - time: 0.0071 - loss_train: 0.9871558594256902 - loss_val: 1.0637354154697913\n",
      "Epoch: 582 - time: 0.0038 - loss_train: 0.9866535769040811 - loss_val: 1.0632626108472092\n",
      "Epoch: 583 - time: 0.0077 - loss_train: 0.9861526733014759 - loss_val: 1.0627915162192538\n",
      "Epoch: 584 - time: 0.0068 - loss_train: 0.9856531397279482 - loss_val: 1.0623221203305973\n",
      "Epoch: 585 - time: 0.0070 - loss_train: 0.9851549674429362 - loss_val: 1.0618544121310265\n",
      "Epoch: 586 - time: 0.0078 - loss_train: 0.9846581478531793 - loss_val: 1.0613883807750573\n",
      "Epoch: 587 - time: 0.0096 - loss_train: 0.9841626725106414 - loss_val: 1.0609240156214659\n",
      "Epoch: 588 - time: 0.0042 - loss_train: 0.9836685331104288 - loss_val: 1.0604613062327275\n",
      "Epoch: 589 - time: 0.0099 - loss_train: 0.9831757214887006 - loss_val: 1.0600002423743642\n",
      "Epoch: 590 - time: 0.0056 - loss_train: 0.9826842296205698 - loss_val: 1.059540814014201\n",
      "Epoch: 591 - time: 0.0070 - loss_train: 0.9821940496179977 - loss_val: 1.059083011321527\n",
      "Epoch: 592 - time: 0.0065 - loss_train: 0.9817051737276806 - loss_val: 1.0586268246661557\n",
      "Epoch: 593 - time: 0.0066 - loss_train: 0.9812175943289231 - loss_val: 1.0581722446173867\n",
      "Epoch: 594 - time: 0.0076 - loss_train: 0.9807313039315118 - loss_val: 1.0577192619428666\n",
      "Epoch: 595 - time: 0.0047 - loss_train: 0.9802462951735756 - loss_val: 1.0572678676073464\n",
      "Epoch: 596 - time: 0.0077 - loss_train: 0.9797625608194376 - loss_val: 1.0568180527713353\n",
      "Epoch: 597 - time: 0.0096 - loss_train: 0.9792800937574652 - loss_val: 1.0563698087896463\n",
      "Epoch: 598 - time: 0.0070 - loss_train: 0.9787988869979063 - loss_val: 1.0559231272098373\n",
      "Epoch: 599 - time: 0.0066 - loss_train: 0.9783189336707242 - loss_val: 1.055477999770544\n",
      "Epoch: 600 - time: 0.0089 - loss_train: 0.9778402270234242 - loss_val: 1.0550344183997054\n",
      "Epoch: 601 - time: 0.0038 - loss_train: 0.9773627604188748 - loss_val: 1.0545923752126778\n",
      "Epoch: 602 - time: 0.0157 - loss_train: 0.976886527333123 - loss_val: 1.0541518625102437\n",
      "Epoch: 603 - time: 0.0042 - loss_train: 0.9764115213532091 - loss_val: 1.0537128727765097\n",
      "Epoch: 604 - time: 0.0195 - loss_train: 0.9759377361749711 - loss_val: 1.0532753986766947\n",
      "Epoch: 605 - time: 0.0086 - loss_train: 0.9754651656008532 - loss_val: 1.0528394330548143\n",
      "Epoch: 606 - time: 0.0091 - loss_train: 0.9749938035377094 - loss_val: 1.0524049689312505\n",
      "Epoch: 607 - time: 0.0139 - loss_train: 0.9745236439946027 - loss_val: 1.0519719995002228\n",
      "Epoch: 608 - time: 0.0054 - loss_train: 0.9740546810806092 - loss_val: 1.051540518127148\n",
      "Epoch: 609 - time: 0.0064 - loss_train: 0.9735869090026208 - loss_val: 1.0511105183458982\n",
      "Epoch: 610 - time: 0.0062 - loss_train: 0.973120322063148 - loss_val: 1.0506819938559544\n",
      "Epoch: 611 - time: 0.0052 - loss_train: 0.972654914658126 - loss_val: 1.0502549385194624\n",
      "Epoch: 612 - time: 0.0084 - loss_train: 0.9721906812747265 - loss_val: 1.0498293463581865\n",
      "Epoch: 613 - time: 0.0117 - loss_train: 0.9717276164891714 - loss_val: 1.0494052115503691\n",
      "Epoch: 614 - time: 0.0083 - loss_train: 0.9712657149645538 - loss_val: 1.0489825284274925\n",
      "Epoch: 615 - time: 0.0056 - loss_train: 0.9708049714486651 - loss_val: 1.0485612914709563\n",
      "Epoch: 616 - time: 0.0111 - loss_train: 0.9703453807718312 - loss_val: 1.048141495308657\n",
      "Epoch: 617 - time: 0.0097 - loss_train: 0.9698869378447568 - loss_val: 1.0477231347114884\n",
      "Epoch: 618 - time: 0.0108 - loss_train: 0.9694296376563811 - loss_val: 1.0473062045897588\n",
      "Epoch: 619 - time: 0.0114 - loss_train: 0.9689734752717445 - loss_val: 1.0468906999895262\n",
      "Epoch: 620 - time: 0.0051 - loss_train: 0.9685184458298679 - loss_val: 1.0464766160888639\n",
      "Epoch: 621 - time: 0.0040 - loss_train: 0.9680645445416466 - loss_val: 1.046063948194046\n",
      "Epoch: 622 - time: 0.0050 - loss_train: 0.9676117666877583 - loss_val: 1.0456526917356745\n",
      "Epoch: 623 - time: 0.0097 - loss_train: 0.967160107616591 - loss_val: 1.0452428422647395\n",
      "Epoch: 624 - time: 0.0058 - loss_train: 0.9667095627421809 - loss_val: 1.0448343954486177\n",
      "Epoch: 625 - time: 0.0057 - loss_train: 0.9662601275421789 - loss_val: 1.04442734706702\n",
      "Epoch: 626 - time: 0.0051 - loss_train: 0.9658117975558291 - loss_val: 1.0440216930078858\n",
      "Epoch: 627 - time: 0.0039 - loss_train: 0.9653645683819715 - loss_val: 1.0436174292632387\n",
      "Epoch: 628 - time: 0.0045 - loss_train: 0.9649184356770675 - loss_val: 1.0432145519249902\n",
      "Epoch: 629 - time: 0.0039 - loss_train: 0.9644733951532477 - loss_val: 1.0428130571807168\n",
      "Epoch: 630 - time: 0.0037 - loss_train: 0.9640294425763836 - loss_val: 1.0424129413094048\n",
      "Epoch: 631 - time: 0.0065 - loss_train: 0.9635865737641854 - loss_val: 1.0420142006771644\n",
      "Epoch: 632 - time: 0.0050 - loss_train: 0.9631447845843281 - loss_val: 1.0416168317329297\n",
      "Epoch: 633 - time: 0.0043 - loss_train: 0.9627040709526005 - loss_val: 1.041220831004138\n",
      "Epoch: 634 - time: 0.0044 - loss_train: 0.962264428831086 - loss_val: 1.0408261950923994\n",
      "Epoch: 635 - time: 0.0053 - loss_train: 0.961825854226374 - loss_val: 1.040432920669164\n",
      "Epoch: 636 - time: 0.0063 - loss_train: 0.9613883431877969 - loss_val: 1.040041004471385\n",
      "Epoch: 637 - time: 0.0050 - loss_train: 0.9609518918057013 - loss_val: 1.0396504432971905\n",
      "Epoch: 638 - time: 0.0046 - loss_train: 0.9605164962097515 - loss_val: 1.0392612340015612\n",
      "Epoch: 639 - time: 0.0055 - loss_train: 0.9600821525672638 - loss_val: 1.0388733734920275\n",
      "Epoch: 640 - time: 0.0065 - loss_train: 0.9596488570815731 - loss_val: 1.0384868587243836\n",
      "Epoch: 641 - time: 0.0045 - loss_train: 0.9592166059904373 - loss_val: 1.0381016866984312\n",
      "Epoch: 642 - time: 0.0041 - loss_train: 0.9587853955644718 - loss_val: 1.0377178544537482\n",
      "Epoch: 643 - time: 0.0051 - loss_train: 0.9583552221056232 - loss_val: 1.0373353590654966\n",
      "Epoch: 644 - time: 0.0073 - loss_train: 0.9579260819456727 - loss_val: 1.036954197640269\n",
      "Epoch: 645 - time: 0.0093 - loss_train: 0.9574979714447824 - loss_val: 1.0365743673119805\n",
      "Epoch: 646 - time: 0.0106 - loss_train: 0.9570708869900727 - loss_val: 1.036195865237809\n",
      "Epoch: 647 - time: 0.0241 - loss_train: 0.9566448249942382 - loss_val: 1.0358186885941907\n",
      "Epoch: 648 - time: 0.0054 - loss_train: 0.9562197818942011 - loss_val: 1.0354428345728737\n",
      "Epoch: 649 - time: 0.0177 - loss_train: 0.9557957541498008 - loss_val: 1.0350683003770318\n",
      "Epoch: 650 - time: 0.0076 - loss_train: 0.9553727382425204 - loss_val: 1.0346950832174495\n",
      "Epoch: 651 - time: 0.0195 - loss_train: 0.9549507306742531 - loss_val: 1.0343231803087718\n",
      "Epoch: 652 - time: 0.0084 - loss_train: 0.9545297279661028 - loss_val: 1.0339525888658327\n",
      "Epoch: 653 - time: 0.0185 - loss_train: 0.954109726657224 - loss_val: 1.0335833061000617\n",
      "Epoch: 654 - time: 0.0064 - loss_train: 0.9536907233037001 - loss_val: 1.0332153292159674\n",
      "Epoch: 655 - time: 0.0147 - loss_train: 0.9532727144774579 - loss_val: 1.0328486554077105\n",
      "Epoch: 656 - time: 0.0116 - loss_train: 0.9528556967652189 - loss_val: 1.0324832818557628\n",
      "Epoch: 657 - time: 0.0191 - loss_train: 0.9524396667674896 - loss_val: 1.0321192057236557\n",
      "Epoch: 658 - time: 0.0103 - loss_train: 0.952024621097587 - loss_val: 1.0317564241548243\n",
      "Epoch: 659 - time: 0.0050 - loss_train: 0.9516105563807016 - loss_val: 1.0313949342695468\n",
      "Epoch: 660 - time: 0.0043 - loss_train: 0.9511974692529973 - loss_val: 1.031034733161981\n",
      "Epoch: 661 - time: 0.0039 - loss_train: 0.950785356360747 - loss_val: 1.0306758178973001\n",
      "Epoch: 662 - time: 0.0064 - loss_train: 0.9503742143595006 - loss_val: 1.0303181855089385\n",
      "Epoch: 663 - time: 0.0044 - loss_train: 0.9499640399132964 - loss_val: 1.029961832995932\n",
      "Epoch: 664 - time: 0.0037 - loss_train: 0.9495548296938993 - loss_val: 1.0296067573203669\n",
      "Epoch: 665 - time: 0.0046 - loss_train: 0.9491465803800758 - loss_val: 1.0292529554049434\n",
      "Epoch: 666 - time: 0.0041 - loss_train: 0.9487392886569053 - loss_val: 1.0289004241306337\n",
      "Epoch: 667 - time: 0.0049 - loss_train: 0.9483329512151208 - loss_val: 1.0285491603344619\n",
      "Epoch: 668 - time: 0.0043 - loss_train: 0.9479275647504873 - loss_val: 1.0281991608073877\n",
      "Epoch: 669 - time: 0.0038 - loss_train: 0.9475231259632058 - loss_val: 1.027850422292301\n",
      "Epoch: 670 - time: 0.0041 - loss_train: 0.9471196315573552 - loss_val: 1.0275029414821302\n",
      "Epoch: 671 - time: 0.0038 - loss_train: 0.946717078240361 - loss_val: 1.0271567150180587\n",
      "Epoch: 672 - time: 0.0040 - loss_train: 0.9463154627224964 - loss_val: 1.0268117394878542\n",
      "Epoch: 673 - time: 0.0041 - loss_train: 0.9459147817164123 - loss_val: 1.02646801142431\n",
      "Epoch: 674 - time: 0.0041 - loss_train: 0.9455150319366938 - loss_val: 1.0261255273037964\n",
      "Epoch: 675 - time: 0.0035 - loss_train: 0.9451162100994516 - loss_val: 1.0257842835449205\n",
      "Epoch: 676 - time: 0.0046 - loss_train: 0.9447183129219322 - loss_val: 1.0254442765073022\n",
      "Epoch: 677 - time: 0.0086 - loss_train: 0.944321337122162 - loss_val: 1.0251055024904494\n",
      "Epoch: 678 - time: 0.0068 - loss_train: 0.9439252794186133 - loss_val: 1.0247679577327504\n",
      "Epoch: 679 - time: 0.0042 - loss_train: 0.9435301365298983 - loss_val: 1.024431638410568\n",
      "Epoch: 680 - time: 0.0090 - loss_train: 0.9431359051744838 - loss_val: 1.0240965406374432\n",
      "Epoch: 681 - time: 0.0048 - loss_train: 0.9427425820704362 - loss_val: 1.023762660463399\n",
      "Epoch: 682 - time: 0.0054 - loss_train: 0.9423501639351815 - loss_val: 1.0234299938743499\n",
      "Epoch: 683 - time: 0.0059 - loss_train: 0.9419586474852953 - loss_val: 1.0230985367916126\n",
      "Epoch: 684 - time: 0.0062 - loss_train: 0.9415680294363099 - loss_val: 1.022768285071517\n",
      "Epoch: 685 - time: 0.0097 - loss_train: 0.9411783065025419 - loss_val: 1.0224392345051136\n",
      "Epoch: 686 - time: 0.0051 - loss_train: 0.9407894753969438 - loss_val: 1.0221113808179787\n",
      "Epoch: 687 - time: 0.0061 - loss_train: 0.9404015328309717 - loss_val: 1.0217847196701086\n",
      "Epoch: 688 - time: 0.0044 - loss_train: 0.940014475514472 - loss_val: 1.0214592466559145\n",
      "Epoch: 689 - time: 0.0039 - loss_train: 0.9396283001555888 - loss_val: 1.0211349573042996\n",
      "Epoch: 690 - time: 0.0040 - loss_train: 0.9392430034606832 - loss_val: 1.0208118470788272\n",
      "Epoch: 691 - time: 0.0047 - loss_train: 0.9388585821342773 - loss_val: 1.0204899113779717\n",
      "Epoch: 692 - time: 0.0043 - loss_train: 0.9384750328790051 - loss_val: 1.0201691455354558\n",
      "Epoch: 693 - time: 0.0047 - loss_train: 0.9380923523955855 - loss_val: 1.0198495448206653\n",
      "Epoch: 694 - time: 0.0033 - loss_train: 0.9377105373828064 - loss_val: 1.0195311044391417\n",
      "Epoch: 695 - time: 0.0040 - loss_train: 0.9373295845375241 - loss_val: 1.0192138195331548\n",
      "Epoch: 696 - time: 0.0039 - loss_train: 0.936949490554676 - loss_val: 1.0188976851823406\n",
      "Epoch: 697 - time: 0.0071 - loss_train: 0.936570252127304 - loss_val: 1.018582696404415\n",
      "Epoch: 698 - time: 0.0049 - loss_train: 0.9361918659465942 - loss_val: 1.0182688481559572\n",
      "Epoch: 699 - time: 0.0039 - loss_train: 0.9358143287019226 - loss_val: 1.0179561353332505\n",
      "Epoch: 700 - time: 0.0041 - loss_train: 0.9354376370809162 - loss_val: 1.017644552773191\n",
      "Epoch: 701 - time: 0.0033 - loss_train: 0.935061787769524 - loss_val: 1.0173340952542598\n",
      "Epoch: 702 - time: 0.0051 - loss_train: 0.9346867774520932 - loss_val: 1.0170247574975428\n",
      "Epoch: 703 - time: 0.0051 - loss_train: 0.9343126028114609 - loss_val: 1.0167165341678135\n",
      "Epoch: 704 - time: 0.0036 - loss_train: 0.9339392605290514 - loss_val: 1.0164094198746656\n",
      "Epoch: 705 - time: 0.0046 - loss_train: 0.9335667472849812 - loss_val: 1.0161034091736907\n",
      "Epoch: 706 - time: 0.0061 - loss_train: 0.9331950597581737 - loss_val: 1.01579849656771\n",
      "Epoch: 707 - time: 0.0055 - loss_train: 0.9328241946264786 - loss_val: 1.0154946765080475\n",
      "Epoch: 708 - time: 0.0047 - loss_train: 0.9324541485668016 - loss_val: 1.0151919433958407\n",
      "Epoch: 709 - time: 0.0044 - loss_train: 0.9320849182552375 - loss_val: 1.0148902915833982\n",
      "Epoch: 710 - time: 0.0060 - loss_train: 0.9317165003672113 - loss_val: 1.0145897153755894\n",
      "Epoch: 711 - time: 0.0538 - loss_train: 0.9313488915776218 - loss_val: 1.014290209031266\n",
      "Epoch: 712 - time: 0.0066 - loss_train: 0.9309820885609967 - loss_val: 1.0139917667647238\n",
      "Epoch: 713 - time: 0.0105 - loss_train: 0.9306160879916443 - loss_val: 1.0136943827471856\n",
      "Epoch: 714 - time: 0.0084 - loss_train: 0.9302508865438159 - loss_val: 1.0133980511083165\n",
      "Epoch: 715 - time: 0.0058 - loss_train: 0.9298864808918708 - loss_val: 1.0131027659377614\n",
      "Epoch: 716 - time: 0.0075 - loss_train: 0.929522867710443 - loss_val: 1.0128085212867077\n",
      "Epoch: 717 - time: 0.0120 - loss_train: 0.9291600436746132 - loss_val: 1.0125153111694671\n",
      "Epoch: 718 - time: 0.0064 - loss_train: 0.9287980054600853 - loss_val: 1.0122231295650719\n",
      "Epoch: 719 - time: 0.0064 - loss_train: 0.928436749743362 - loss_val: 1.0119319704188985\n",
      "Epoch: 720 - time: 0.0134 - loss_train: 0.9280762732019263 - loss_val: 1.011641827644293\n",
      "Epoch: 721 - time: 0.0062 - loss_train: 0.9277165725144242 - loss_val: 1.0113526951242136\n",
      "Epoch: 722 - time: 0.0066 - loss_train: 0.927357644360849 - loss_val: 1.01106456671289\n",
      "Epoch: 723 - time: 0.0092 - loss_train: 0.9269994854227296 - loss_val: 1.010777436237478\n",
      "Epoch: 724 - time: 0.0098 - loss_train: 0.9266420923833147 - loss_val: 1.0104912974997333\n",
      "Epoch: 725 - time: 0.0058 - loss_train: 0.9262854619277692 - loss_val: 1.0102061442776824\n",
      "Epoch: 726 - time: 0.0104 - loss_train: 0.9259295907433577 - loss_val: 1.0099219703273006\n",
      "Epoch: 727 - time: 0.0078 - loss_train: 0.9255744755196421 - loss_val: 1.0096387693841884\n",
      "Epoch: 728 - time: 0.0088 - loss_train: 0.9252201129486708 - loss_val: 1.009356535165252\n",
      "Epoch: 729 - time: 0.0167 - loss_train: 0.9248664997251749 - loss_val: 1.0090752613703773\n",
      "Epoch: 730 - time: 0.0188 - loss_train: 0.9245136325467596 - loss_val: 1.0087949416841053\n",
      "Epoch: 731 - time: 0.0041 - loss_train: 0.9241615081140999 - loss_val: 1.0085155697773\n",
      "Epoch: 732 - time: 0.0175 - loss_train: 0.9238101231311343 - loss_val: 1.0082371393088119\n",
      "Epoch: 733 - time: 0.0046 - loss_train: 0.9234594743052601 - loss_val: 1.0079596439271332\n",
      "Epoch: 734 - time: 0.0081 - loss_train: 0.9231095583475272 - loss_val: 1.007683077272047\n",
      "Epoch: 735 - time: 0.0063 - loss_train: 0.922760371972832 - loss_val: 1.0074074329762623\n",
      "Epoch: 736 - time: 0.0071 - loss_train: 0.9224119119001116 - loss_val: 1.007132704667044\n",
      "Epoch: 737 - time: 0.0059 - loss_train: 0.9220641748525379 - loss_val: 1.0068588859678256\n",
      "Epoch: 738 - time: 0.0039 - loss_train: 0.9217171575577097 - loss_val: 1.006585970499814\n",
      "Epoch: 739 - time: 0.0063 - loss_train: 0.9213708567478452 - loss_val: 1.0063139518835738\n",
      "Epoch: 740 - time: 0.0205 - loss_train: 0.9210252691599726 - loss_val: 1.0060428237406034\n",
      "Epoch: 741 - time: 0.0036 - loss_train: 0.9206803915361236 - loss_val: 1.0057725796948933\n",
      "Epoch: 742 - time: 0.0091 - loss_train: 0.92033622062352 - loss_val: 1.0055032133744648\n",
      "Epoch: 743 - time: 0.0108 - loss_train: 0.919992753174766 - loss_val: 1.0052347184128927\n",
      "Epoch: 744 - time: 0.0073 - loss_train: 0.9196499859480318 - loss_val: 1.0049670884508142\n",
      "Epoch: 745 - time: 0.0051 - loss_train: 0.9193079157072463 - loss_val: 1.0047003171374098\n",
      "Epoch: 746 - time: 0.0054 - loss_train: 0.9189665392222777 - loss_val: 1.004434398131876\n",
      "Epoch: 747 - time: 0.0036 - loss_train: 0.9186258532691202 - loss_val: 1.0041693251048656\n",
      "Epoch: 748 - time: 0.0039 - loss_train: 0.9182858546300773 - loss_val: 1.0039050917399166\n",
      "Epoch: 749 - time: 0.0038 - loss_train: 0.9179465400939448 - loss_val: 1.0036416917348565\n",
      "Epoch: 750 - time: 0.0103 - loss_train: 0.9176079064561878 - loss_val: 1.003379118803181\n",
      "Epoch: 751 - time: 0.0065 - loss_train: 0.9172699505191249 - loss_val: 1.0031173666754187\n",
      "Epoch: 752 - time: 0.0046 - loss_train: 0.9169326690921026 - loss_val: 1.0028564291004618\n",
      "Epoch: 753 - time: 0.0064 - loss_train: 0.9165960589916742 - loss_val: 1.002596299846885\n",
      "Epoch: 754 - time: 0.0105 - loss_train: 0.9162601170417711 - loss_val: 1.0023369727042315\n",
      "Epoch: 755 - time: 0.0076 - loss_train: 0.9159248400738813 - loss_val: 1.002078441484283\n",
      "Epoch: 756 - time: 0.0129 - loss_train: 0.915590224927216 - loss_val: 1.0018207000222952\n",
      "Epoch: 757 - time: 0.0051 - loss_train: 0.9152562684488849 - loss_val: 1.0015637421782206\n",
      "Epoch: 758 - time: 0.0040 - loss_train: 0.9149229674940611 - loss_val: 1.0013075618378968\n",
      "Epoch: 759 - time: 0.0088 - loss_train: 0.9145903189261494 - loss_val: 1.0010521529142145\n",
      "Epoch: 760 - time: 0.0063 - loss_train: 0.9142583196169529 - loss_val: 1.0007975093482597\n",
      "Epoch: 761 - time: 0.0070 - loss_train: 0.9139269664468352 - loss_val: 1.0005436251104287\n",
      "Epoch: 762 - time: 0.0066 - loss_train: 0.9135962563048837 - loss_val: 1.0002904942015198\n",
      "Epoch: 763 - time: 0.0061 - loss_train: 0.9132661860890683 - loss_val: 1.0000381106537959\n",
      "Epoch: 764 - time: 0.0065 - loss_train: 0.9129367527064031 - loss_val: 0.9997864685320267\n",
      "Epoch: 765 - time: 0.0052 - loss_train: 0.9126079530730985 - loss_val: 0.9995355619344974\n",
      "Epoch: 766 - time: 0.0056 - loss_train: 0.9122797841147221 - loss_val: 0.9992853849939992\n",
      "Epoch: 767 - time: 0.0046 - loss_train: 0.911952242766348 - loss_val: 0.9990359318787875\n",
      "Epoch: 768 - time: 0.0053 - loss_train: 0.911625325972709 - loss_val: 0.9987871967935185\n",
      "Epoch: 769 - time: 0.0051 - loss_train: 0.9112990306883478 - loss_val: 0.9985391739801558\n",
      "Epoch: 770 - time: 0.0073 - loss_train: 0.9109733538777641 - loss_val: 0.9982918577188543\n",
      "Epoch: 771 - time: 0.0043 - loss_train: 0.910648292515561 - loss_val: 0.9980452423288149\n",
      "Epoch: 772 - time: 0.0071 - loss_train: 0.9103238435865885 - loss_val: 0.9977993221691175\n",
      "Epoch: 773 - time: 0.0315 - loss_train: 0.9100000040860876 - loss_val: 0.9975540916395209\n",
      "Epoch: 774 - time: 0.0048 - loss_train: 0.9096767710198284 - loss_val: 0.9973095451812465\n",
      "Epoch: 775 - time: 0.0145 - loss_train: 0.9093541414042515 - loss_val: 0.9970656772777252\n",
      "Epoch: 776 - time: 0.0040 - loss_train: 0.9090321122666027 - loss_val: 0.9968224824553291\n",
      "Epoch: 777 - time: 0.0038 - loss_train: 0.9087106806450698 - loss_val: 0.99657995528407\n",
      "Epoch: 778 - time: 0.0048 - loss_train: 0.9083898435889127 - loss_val: 0.9963380903782745\n",
      "Epoch: 779 - time: 0.0117 - loss_train: 0.9080695981585984 - loss_val: 0.9960968823972359\n",
      "Epoch: 780 - time: 0.0037 - loss_train: 0.9077499414259259 - loss_val: 0.9958563260458378\n",
      "Epoch: 781 - time: 0.0056 - loss_train: 0.9074308704741572 - loss_val: 0.9956164160751554\n",
      "Epoch: 782 - time: 0.0060 - loss_train: 0.907112382398139 - loss_val: 0.9953771472830286\n",
      "Epoch: 783 - time: 0.0081 - loss_train: 0.9067944743044284 - loss_val: 0.9951385145146143\n",
      "Epoch: 784 - time: 0.0063 - loss_train: 0.9064771433114133 - loss_val: 0.9949005126629104\n",
      "Epoch: 785 - time: 0.0037 - loss_train: 0.906160386549431 - loss_val: 0.9946631366692574\n",
      "Epoch: 786 - time: 0.0046 - loss_train: 0.9058442011608864 - loss_val: 0.9944263815238168\n",
      "Epoch: 787 - time: 0.0117 - loss_train: 0.9055285843003659 - loss_val: 0.9941902422660215\n",
      "Epoch: 788 - time: 0.0056 - loss_train: 0.9052135331347522 - loss_val: 0.9939547139850097\n",
      "Epoch: 789 - time: 0.0087 - loss_train: 0.9048990448433331 - loss_val: 0.9937197918200248\n",
      "Epoch: 790 - time: 0.0143 - loss_train: 0.9045851166179134 - loss_val: 0.9934854709608036\n",
      "Epoch: 791 - time: 0.0049 - loss_train: 0.9042717456629183 - loss_val: 0.9932517466479319\n",
      "Epoch: 792 - time: 0.0050 - loss_train: 0.9039589291955012 - loss_val: 0.9930186141731845\n",
      "Epoch: 793 - time: 0.0089 - loss_train: 0.9036466644456455 - loss_val: 0.9927860688798341\n",
      "Epoch: 794 - time: 0.0044 - loss_train: 0.9033349486562635 - loss_val: 0.9925541061629506\n",
      "Epoch: 795 - time: 0.0060 - loss_train: 0.9030237790832977 - loss_val: 0.9923227214696646\n",
      "Epoch: 796 - time: 0.0060 - loss_train: 0.9027131529958143 - loss_val: 0.9920919102994185\n",
      "Epoch: 797 - time: 0.0036 - loss_train: 0.902403067676101 - loss_val: 0.9918616682041911\n",
      "Epoch: 798 - time: 0.0035 - loss_train: 0.9020935204197542 - loss_val: 0.9916319907887048\n",
      "Epoch: 799 - time: 0.0060 - loss_train: 0.9017845085357723 - loss_val: 0.9914028737106074\n",
      "Epoch: 800 - time: 0.0076 - loss_train: 0.9014760293466428 - loss_val: 0.9911743126806403\n",
      "Epoch: 801 - time: 0.0066 - loss_train: 0.901168080188427 - loss_val: 0.9909463034627749\n",
      "Epoch: 802 - time: 0.0038 - loss_train: 0.9008606584108428 - loss_val: 0.9907188418743431\n",
      "Epoch: 803 - time: 0.0087 - loss_train: 0.9005537613773477 - loss_val: 0.9904919237861333\n",
      "Epoch: 804 - time: 0.0072 - loss_train: 0.9002473864652141 - loss_val: 0.9902655451224824\n",
      "Epoch: 805 - time: 0.0080 - loss_train: 0.8999415310656104 - loss_val: 0.9900397018613328\n",
      "Epoch: 806 - time: 0.0206 - loss_train: 0.8996361925836712 - loss_val: 0.9898143900342823\n",
      "Epoch: 807 - time: 0.0046 - loss_train: 0.8993313684385703 - loss_val: 0.9895896057266107\n",
      "Epoch: 808 - time: 0.0055 - loss_train: 0.8990270560635922 - loss_val: 0.9893653450772897\n",
      "Epoch: 809 - time: 0.0151 - loss_train: 0.8987232529061977 - loss_val: 0.9891416042789702\n",
      "Epoch: 810 - time: 0.0045 - loss_train: 0.8984199564280887 - loss_val: 0.9889183795779618\n",
      "Epoch: 811 - time: 0.0046 - loss_train: 0.8981171641052726 - loss_val: 0.988695667274183\n",
      "Epoch: 812 - time: 0.0144 - loss_train: 0.8978148734281219 - loss_val: 0.988473463721104\n",
      "Epoch: 813 - time: 0.0050 - loss_train: 0.8975130819014325 - loss_val: 0.9882517653256676\n",
      "Epoch: 814 - time: 0.0067 - loss_train: 0.8972117870444789 - loss_val: 0.988030568548196\n",
      "Epoch: 815 - time: 0.0109 - loss_train: 0.8969109863910689 - loss_val: 0.9878098699022815\n",
      "Epoch: 816 - time: 0.0055 - loss_train: 0.8966106774895937 - loss_val: 0.9875896659546589\n",
      "Epoch: 817 - time: 0.0039 - loss_train: 0.8963108579030773 - loss_val: 0.9873699533250684\n",
      "Epoch: 818 - time: 0.0072 - loss_train: 0.8960115252092234 - loss_val: 0.987150728686096\n",
      "Epoch: 819 - time: 0.0083 - loss_train: 0.8957126770004576 - loss_val: 0.9869319887630051\n",
      "Epoch: 820 - time: 0.0076 - loss_train: 0.8954143108839722 - loss_val: 0.9867137303335519\n",
      "Epoch: 821 - time: 0.0069 - loss_train: 0.8951164244817625 - loss_val: 0.9864959502277862\n",
      "Epoch: 822 - time: 0.0099 - loss_train: 0.894819015430666 - loss_val: 0.9862786453278386\n",
      "Epoch: 823 - time: 0.0044 - loss_train: 0.8945220813823962 - loss_val: 0.9860618125676953\n",
      "Epoch: 824 - time: 0.0088 - loss_train: 0.8942256200035744 - loss_val: 0.9858454489329603\n",
      "Epoch: 825 - time: 0.0129 - loss_train: 0.8939296289757608 - loss_val: 0.9856295514606013\n",
      "Epoch: 826 - time: 0.0059 - loss_train: 0.8936341059954819 - loss_val: 0.9854141172386901\n",
      "Epoch: 827 - time: 0.0044 - loss_train: 0.8933390487742531 - loss_val: 0.9851991434061236\n",
      "Epoch: 828 - time: 0.0112 - loss_train: 0.8930444550386066 - loss_val: 0.9849846271523385\n",
      "Epoch: 829 - time: 0.0063 - loss_train: 0.892750322530108 - loss_val: 0.984770565717013\n",
      "Epoch: 830 - time: 0.0054 - loss_train: 0.8924566490053739 - loss_val: 0.9845569563897563\n",
      "Epoch: 831 - time: 0.0082 - loss_train: 0.8921634322360907 - loss_val: 0.9843437965097889\n",
      "Epoch: 832 - time: 0.0064 - loss_train: 0.8918706700090265 - loss_val: 0.9841310834656137\n",
      "Epoch: 833 - time: 0.0051 - loss_train: 0.8915783601260411 - loss_val: 0.9839188146946733\n",
      "Epoch: 834 - time: 0.0057 - loss_train: 0.8912865004040966 - loss_val: 0.9837069876830032\n",
      "Epoch: 835 - time: 0.0175 - loss_train: 0.8909950886752629 - loss_val: 0.9834955999648691\n",
      "Epoch: 836 - time: 0.0087 - loss_train: 0.8907041227867222 - loss_val: 0.9832846491224035\n",
      "Epoch: 837 - time: 0.0226 - loss_train: 0.8904136006007694 - loss_val: 0.983074132785224\n",
      "Epoch: 838 - time: 0.0037 - loss_train: 0.8901235199948142 - loss_val: 0.982864048630053\n",
      "Epoch: 839 - time: 0.0170 - loss_train: 0.8898338788613755 - loss_val: 0.9826543943803197\n",
      "Epoch: 840 - time: 0.0040 - loss_train: 0.8895446751080791 - loss_val: 0.9824451678057655\n",
      "Epoch: 841 - time: 0.0078 - loss_train: 0.8892559066576478 - loss_val: 0.9822363667220309\n",
      "Epoch: 842 - time: 0.0090 - loss_train: 0.8889675714478934 - loss_val: 0.9820279889902427\n",
      "Epoch: 843 - time: 0.0101 - loss_train: 0.8886796674317048 - loss_val: 0.981820032516593\n",
      "Epoch: 844 - time: 0.0127 - loss_train: 0.8883921925770332 - loss_val: 0.9816124952519091\n",
      "Epoch: 845 - time: 0.0086 - loss_train: 0.888105144866877 - loss_val: 0.9814053751912213\n",
      "Epoch: 846 - time: 0.0060 - loss_train: 0.887818522299262 - loss_val: 0.9811986703733211\n",
      "Epoch: 847 - time: 0.0165 - loss_train: 0.8875323228872227 - loss_val: 0.9809923788803189\n",
      "Epoch: 848 - time: 0.0120 - loss_train: 0.8872465446587774 - loss_val: 0.9807864988371885\n",
      "Epoch: 849 - time: 0.0163 - loss_train: 0.8869611856569062 - loss_val: 0.9805810284113159\n",
      "Epoch: 850 - time: 0.0037 - loss_train: 0.8866762439395206 - loss_val: 0.9803759658120363\n",
      "Epoch: 851 - time: 0.0066 - loss_train: 0.8863917175794379 - loss_val: 0.9801713092901714\n",
      "Epoch: 852 - time: 0.0150 - loss_train: 0.8861076046643475 - loss_val: 0.9799670571375597\n",
      "Epoch: 853 - time: 0.0066 - loss_train: 0.8858239032967797 - loss_val: 0.9797632076865843\n",
      "Epoch: 854 - time: 0.0053 - loss_train: 0.8855406115940692 - loss_val: 0.979559759309697\n",
      "Epoch: 855 - time: 0.0137 - loss_train: 0.8852577276883187 - loss_val: 0.9793567104189397\n",
      "Epoch: 856 - time: 0.0064 - loss_train: 0.88497524972636 - loss_val: 0.9791540594654619\n",
      "Epoch: 857 - time: 0.0053 - loss_train: 0.8846931758697129 - loss_val: 0.9789518049390356\n",
      "Epoch: 858 - time: 0.0072 - loss_train: 0.8844115042945416 - loss_val: 0.9787499453675691\n",
      "Epoch: 859 - time: 0.0052 - loss_train: 0.8841302331916107 - loss_val: 0.9785484793166156\n",
      "Epoch: 860 - time: 0.0069 - loss_train: 0.8838493607662388 - loss_val: 0.9783474053888843\n",
      "Epoch: 861 - time: 0.0130 - loss_train: 0.883568885238248 - loss_val: 0.9781467222237452\n",
      "Epoch: 862 - time: 0.0134 - loss_train: 0.8832888048419174 - loss_val: 0.9779464284967345\n",
      "Epoch: 863 - time: 0.0060 - loss_train: 0.8830091178259274 - loss_val: 0.9777465229190612\n",
      "Epoch: 864 - time: 0.0077 - loss_train: 0.8827298224533077 - loss_val: 0.977547004237105\n",
      "Epoch: 865 - time: 0.0070 - loss_train: 0.882450917001381 - loss_val: 0.9773478712319266\n",
      "Epoch: 866 - time: 0.0045 - loss_train: 0.8821723997617084 - loss_val: 0.9771491227187609\n",
      "Epoch: 867 - time: 0.0049 - loss_train: 0.8818942690400259 - loss_val: 0.9769507575465223\n",
      "Epoch: 868 - time: 0.0068 - loss_train: 0.8816165231561884 - loss_val: 0.9767527745973072\n",
      "Epoch: 869 - time: 0.0047 - loss_train: 0.8813391604441062 - loss_val: 0.976555172785892\n",
      "Epoch: 870 - time: 0.0046 - loss_train: 0.8810621792516804 - loss_val: 0.9763579510592364\n",
      "Epoch: 871 - time: 0.0069 - loss_train: 0.8807855779407394 - loss_val: 0.9761611083959837\n",
      "Epoch: 872 - time: 0.0254 - loss_train: 0.8805093548869724 - loss_val: 0.975964643805965\n",
      "Epoch: 873 - time: 0.0071 - loss_train: 0.8802335084798589 - loss_val: 0.9757685563297007\n",
      "Epoch: 874 - time: 0.0091 - loss_train: 0.8799580371226048 - loss_val: 0.9755728450379052\n",
      "Epoch: 875 - time: 0.0084 - loss_train: 0.8796829392320648 - loss_val: 0.9753775090309921\n",
      "Epoch: 876 - time: 0.0480 - loss_train: 0.8794082132386764 - loss_val: 0.9751825474385802\n",
      "Epoch: 877 - time: 0.0080 - loss_train: 0.8791338575863832 - loss_val: 0.9749879594190018\n",
      "Epoch: 878 - time: 0.0164 - loss_train: 0.8788598707325602 - loss_val: 0.9747937441588124\n",
      "Epoch: 879 - time: 0.0146 - loss_train: 0.878586251147941 - loss_val: 0.9745999008723009\n",
      "Epoch: 880 - time: 0.0066 - loss_train: 0.8783129973165379 - loss_val: 0.9744064288010044\n",
      "Epoch: 881 - time: 0.0128 - loss_train: 0.8780401077355638 - loss_val: 0.9742133272132214\n",
      "Epoch: 882 - time: 0.0065 - loss_train: 0.8777675809153557 - loss_val: 0.9740205954035308\n",
      "Epoch: 883 - time: 0.0055 - loss_train: 0.8774954153792904 - loss_val: 0.9738282326923097\n",
      "Epoch: 884 - time: 0.0073 - loss_train: 0.8772236096637064 - loss_val: 0.9736362384252575\n",
      "Epoch: 885 - time: 0.0051 - loss_train: 0.87695216231782 - loss_val: 0.9734446119729191\n",
      "Epoch: 886 - time: 0.0155 - loss_train: 0.8766810719036428 - loss_val: 0.9732533527302126\n",
      "Epoch: 887 - time: 0.0045 - loss_train: 0.8764103369958965 - loss_val: 0.973062460115959\n",
      "Epoch: 888 - time: 0.0053 - loss_train: 0.8761399561819281 - loss_val: 0.9728719335724133\n",
      "Epoch: 889 - time: 0.0064 - loss_train: 0.875869928061624 - loss_val: 0.9726817725648055\n",
      "Epoch: 890 - time: 0.0040 - loss_train: 0.8756002512473239 - loss_val: 0.972491976580874\n",
      "Epoch: 891 - time: 0.0037 - loss_train: 0.8753309243637308 - loss_val: 0.9723025451304099\n",
      "Epoch: 892 - time: 0.0043 - loss_train: 0.8750619460478266 - loss_val: 0.9721134777448021\n",
      "Epoch: 893 - time: 0.0037 - loss_train: 0.8747933149487788 - loss_val: 0.9719247739765868\n",
      "Epoch: 894 - time: 0.0041 - loss_train: 0.8745250297278535 - loss_val: 0.9717364333989983\n",
      "Epoch: 895 - time: 0.0037 - loss_train: 0.8742570890583244 - loss_val: 0.9715484556055253\n",
      "Epoch: 896 - time: 0.0040 - loss_train: 0.873989491625382 - loss_val: 0.9713608402094682\n",
      "Epoch: 897 - time: 0.0040 - loss_train: 0.8737222361260406 - loss_val: 0.9711735868435064\n",
      "Epoch: 898 - time: 0.0040 - loss_train: 0.8734553212690491 - loss_val: 0.9709866951592585\n",
      "Epoch: 899 - time: 0.0051 - loss_train: 0.8731887457747962 - loss_val: 0.9708001648268588\n",
      "Epoch: 900 - time: 0.0039 - loss_train: 0.8729225083752177 - loss_val: 0.9706139955345258\n",
      "Epoch: 901 - time: 0.0043 - loss_train: 0.8726566078137051 - loss_val: 0.9704281869881449\n",
      "Epoch: 902 - time: 0.0040 - loss_train: 0.8723910428450081 - loss_val: 0.9702427389108473\n",
      "Epoch: 903 - time: 0.0037 - loss_train: 0.8721258122351441 - loss_val: 0.970057651042595\n",
      "Epoch: 904 - time: 0.0035 - loss_train: 0.8718609147613028 - loss_val: 0.9698729231397767\n",
      "Epoch: 905 - time: 0.0042 - loss_train: 0.8715963492117494 - loss_val: 0.9696885549747936\n",
      "Epoch: 906 - time: 0.0035 - loss_train: 0.8713321143857331 - loss_val: 0.969504546335663\n",
      "Epoch: 907 - time: 0.0034 - loss_train: 0.8710682090933888 - loss_val: 0.9693208970256185\n",
      "Epoch: 908 - time: 0.0033 - loss_train: 0.870804632155644 - loss_val: 0.9691376068627171\n",
      "Epoch: 909 - time: 0.0064 - loss_train: 0.870541382404121 - loss_val: 0.9689546756794511\n",
      "Epoch: 910 - time: 0.0062 - loss_train: 0.8702784586810446 - loss_val: 0.9687721033223583\n",
      "Epoch: 911 - time: 0.0064 - loss_train: 0.8700158598391435 - loss_val: 0.968589889651647\n",
      "Epoch: 912 - time: 0.0042 - loss_train: 0.869753584741555 - loss_val: 0.9684080345408167\n",
      "Epoch: 913 - time: 0.0040 - loss_train: 0.8694916322617303 - loss_val: 0.9682265378762848\n",
      "Epoch: 914 - time: 0.0058 - loss_train: 0.8692300012833383 - loss_val: 0.9680453995570214\n",
      "Epoch: 915 - time: 0.0033 - loss_train: 0.8689686907001699 - loss_val: 0.9678646194941839\n",
      "Epoch: 916 - time: 0.0047 - loss_train: 0.8687076994160411 - loss_val: 0.9676841976107577\n",
      "Epoch: 917 - time: 0.0042 - loss_train: 0.8684470263446993 - loss_val: 0.9675041338412039\n",
      "Epoch: 918 - time: 0.0057 - loss_train: 0.8681866704097276 - loss_val: 0.9673244281311052\n",
      "Epoch: 919 - time: 0.0057 - loss_train: 0.8679266305444475 - loss_val: 0.9671450804368235\n",
      "Epoch: 920 - time: 0.0055 - loss_train: 0.867666905691826 - loss_val: 0.966966090725157\n",
      "Epoch: 921 - time: 0.0045 - loss_train: 0.8674074948043796 - loss_val: 0.9667874589730029\n",
      "Epoch: 922 - time: 0.0040 - loss_train: 0.8671483968440802 - loss_val: 0.9666091851670249\n",
      "Epoch: 923 - time: 0.0057 - loss_train: 0.86688961078226 - loss_val: 0.9664312693033249\n",
      "Epoch: 924 - time: 0.0066 - loss_train: 0.866631135599517 - loss_val: 0.96625371138712\n",
      "Epoch: 925 - time: 0.0046 - loss_train: 0.8663729702856227 - loss_val: 0.9660765114324231\n",
      "Epoch: 926 - time: 0.0049 - loss_train: 0.8661151138394271 - loss_val: 0.9658996694617277\n",
      "Epoch: 927 - time: 0.0046 - loss_train: 0.8658575652687661 - loss_val: 0.9657231855056971\n",
      "Epoch: 928 - time: 0.0041 - loss_train: 0.8656003235903684 - loss_val: 0.9655470596028596\n",
      "Epoch: 929 - time: 0.0047 - loss_train: 0.8653433878297635 - loss_val: 0.9653712917993068\n",
      "Epoch: 930 - time: 0.0037 - loss_train: 0.865086757021189 - loss_val: 0.9651958821483951\n",
      "Epoch: 931 - time: 0.0035 - loss_train: 0.8648304302074994 - loss_val: 0.9650208307104562\n",
      "Epoch: 932 - time: 0.0088 - loss_train: 0.8645744064400757 - loss_val: 0.9648461375525055\n",
      "Epoch: 933 - time: 0.0055 - loss_train: 0.8643186847787332 - loss_val: 0.9646718027479613\n",
      "Epoch: 934 - time: 0.0065 - loss_train: 0.8640632642916326 - loss_val: 0.9644978263763635\n",
      "Epoch: 935 - time: 0.0045 - loss_train: 0.86380814405519 - loss_val: 0.9643242085230985\n",
      "Epoch: 936 - time: 0.0039 - loss_train: 0.8635533231539878 - loss_val: 0.9641509492791325\n",
      "Epoch: 937 - time: 0.0058 - loss_train: 0.8632988006806861 - loss_val: 0.9639780487407397\n",
      "Epoch: 938 - time: 0.0045 - loss_train: 0.8630445757359344 - loss_val: 0.9638055070092455\n",
      "Epoch: 939 - time: 0.0033 - loss_train: 0.8627906474282849 - loss_val: 0.9636333241907671\n",
      "Epoch: 940 - time: 0.0036 - loss_train: 0.8625370148741052 - loss_val: 0.9634615003959599\n",
      "Epoch: 941 - time: 0.0037 - loss_train: 0.8622836771974925 - loss_val: 0.9632900357397697\n",
      "Epoch: 942 - time: 0.0037 - loss_train: 0.8620306335301875 - loss_val: 0.9631189303411909\n",
      "Epoch: 943 - time: 0.0042 - loss_train: 0.8617778830114907 - loss_val: 0.9629481843230212\n",
      "Epoch: 944 - time: 0.0042 - loss_train: 0.8615254247881757 - loss_val: 0.9627777978116319\n",
      "Epoch: 945 - time: 0.0039 - loss_train: 0.8612732580144088 - loss_val: 0.9626077709367313\n",
      "Epoch: 946 - time: 0.0051 - loss_train: 0.8610213818516643 - loss_val: 0.9624381038311424\n",
      "Epoch: 947 - time: 0.0056 - loss_train: 0.8607697954686415 - loss_val: 0.9622687966305766\n",
      "Epoch: 948 - time: 0.0060 - loss_train: 0.860518498041186 - loss_val: 0.9620998494734172\n",
      "Epoch: 949 - time: 0.0050 - loss_train: 0.8602674887522062 - loss_val: 0.9619312625005058\n",
      "Epoch: 950 - time: 0.0059 - loss_train: 0.8600167667915947 - loss_val: 0.9617630358549292\n",
      "Epoch: 951 - time: 0.0073 - loss_train: 0.8597663313561492 - loss_val: 0.9615951696818182\n",
      "Epoch: 952 - time: 0.0071 - loss_train: 0.8595161816494923 - loss_val: 0.9614276641281415\n",
      "Epoch: 953 - time: 0.0096 - loss_train: 0.8592663168819977 - loss_val: 0.9612605193425112\n",
      "Epoch: 954 - time: 0.0473 - loss_train: 0.8590167362707078 - loss_val: 0.9610937354749894\n",
      "Epoch: 955 - time: 0.0159 - loss_train: 0.8587674390392622 - loss_val: 0.9609273126768981\n",
      "Epoch: 956 - time: 0.0067 - loss_train: 0.8585184244178192 - loss_val: 0.960761251100635\n",
      "Epoch: 957 - time: 0.0151 - loss_train: 0.8582696916429835 - loss_val: 0.9605955508994928\n",
      "Epoch: 958 - time: 0.0043 - loss_train: 0.8580212399577312 - loss_val: 0.9604302122274807\n",
      "Epoch: 959 - time: 0.0079 - loss_train: 0.8577730686113373 - loss_val: 0.9602652352391551\n",
      "Epoch: 960 - time: 0.0168 - loss_train: 0.8575251768593031 - loss_val: 0.9601006200894485\n",
      "Epoch: 961 - time: 0.0066 - loss_train: 0.8572775639632854 - loss_val: 0.9599363669335061\n",
      "Epoch: 962 - time: 0.0077 - loss_train: 0.8570302291910257 - loss_val: 0.9597724759265246\n",
      "Epoch: 963 - time: 0.0115 - loss_train: 0.856783171816281 - loss_val: 0.9596089472235962\n",
      "Epoch: 964 - time: 0.0071 - loss_train: 0.8565363911187551 - loss_val: 0.9594457809795559\n",
      "Epoch: 965 - time: 0.0184 - loss_train: 0.85628988638403 - loss_val: 0.9592829773488338\n",
      "Epoch: 966 - time: 0.0051 - loss_train: 0.8560436569034996 - loss_val: 0.9591205364853079\n",
      "Epoch: 967 - time: 0.0080 - loss_train: 0.8557977019743027 - loss_val: 0.9589584585421677\n",
      "Epoch: 968 - time: 0.0058 - loss_train: 0.8555520208992591 - loss_val: 0.9587967436717729\n",
      "Epoch: 969 - time: 0.0071 - loss_train: 0.8553066129868033 - loss_val: 0.9586353920255241\n",
      "Epoch: 970 - time: 0.0055 - loss_train: 0.8550614775509225 - loss_val: 0.9584744037537318\n",
      "Epoch: 971 - time: 0.0081 - loss_train: 0.8548166139110933 - loss_val: 0.9583137790054914\n",
      "Epoch: 972 - time: 0.0056 - loss_train: 0.8545720213922197 - loss_val: 0.958153517928563\n",
      "Epoch: 973 - time: 0.0038 - loss_train: 0.8543276993245729 - loss_val: 0.9579936206692523\n",
      "Epoch: 974 - time: 0.0098 - loss_train: 0.8540836470437297 - loss_val: 0.957834087372298\n",
      "Epoch: 975 - time: 0.0054 - loss_train: 0.8538398638905151 - loss_val: 0.9576749181807612\n",
      "Epoch: 976 - time: 0.0059 - loss_train: 0.8535963492109442 - loss_val: 0.9575161132359189\n",
      "Epoch: 977 - time: 0.0052 - loss_train: 0.853353102356162 - loss_val: 0.9573576726771624\n",
      "Epoch: 978 - time: 0.0050 - loss_train: 0.8531101226823905 - loss_val: 0.9571995966418967\n",
      "Epoch: 979 - time: 0.0095 - loss_train: 0.8528674095508718 - loss_val: 0.9570418852654468\n",
      "Epoch: 980 - time: 0.0086 - loss_train: 0.8526249623278116 - loss_val: 0.9568845386809661\n",
      "Epoch: 981 - time: 0.0074 - loss_train: 0.852382780384328 - loss_val: 0.9567275570193461\n",
      "Epoch: 982 - time: 0.0054 - loss_train: 0.8521408630963977 - loss_val: 0.9565709404091352\n",
      "Epoch: 983 - time: 0.0073 - loss_train: 0.8518992098448038 - loss_val: 0.9564146889764552\n",
      "Epoch: 984 - time: 0.0109 - loss_train: 0.8516578200150848 - loss_val: 0.9562588028449264\n",
      "Epoch: 985 - time: 0.0083 - loss_train: 0.8514166929974842 - loss_val: 0.95610328213559\n",
      "Epoch: 986 - time: 0.0156 - loss_train: 0.8511758281869024 - loss_val: 0.9559481269668422\n",
      "Epoch: 987 - time: 0.0052 - loss_train: 0.8509352249828457 - loss_val: 0.9557933374543655\n",
      "Epoch: 988 - time: 0.0110 - loss_train: 0.8506948827893825 - loss_val: 0.9556389137110625\n",
      "Epoch: 989 - time: 0.0090 - loss_train: 0.8504548010150933 - loss_val: 0.9554848558470005\n",
      "Epoch: 990 - time: 0.0050 - loss_train: 0.8502149790730268 - loss_val: 0.9553311639693519\n",
      "Epoch: 991 - time: 0.0076 - loss_train: 0.8499754163806553 - loss_val: 0.9551778381823419\n",
      "Epoch: 992 - time: 0.0109 - loss_train: 0.8497361123598292 - loss_val: 0.9550248785871984\n",
      "Epoch: 993 - time: 0.0090 - loss_train: 0.8494970664367354 - loss_val: 0.9548722852821034\n",
      "Epoch: 994 - time: 0.0197 - loss_train: 0.8492582780418552 - loss_val: 0.9547200583621535\n",
      "Epoch: 995 - time: 0.0041 - loss_train: 0.849019746609922 - loss_val: 0.9545681979193152\n",
      "Epoch: 996 - time: 0.0052 - loss_train: 0.848781471579882 - loss_val: 0.9544167040423926\n",
      "Epoch: 997 - time: 0.0158 - loss_train: 0.8485434523948537 - loss_val: 0.9542655768169883\n",
      "Epoch: 998 - time: 0.0052 - loss_train: 0.8483056885020916 - loss_val: 0.9541148163254766\n",
      "Epoch: 999 - time: 0.0064 - loss_train: 0.8480681793529445 - loss_val: 0.9539644226469763\n",
      "Epoch: 1000 - time: 0.0051 - loss_train: 0.8478309244028236 - loss_val: 0.9538143958573223\n",
      "Epoch: 1001 - time: 0.0060 - loss_train: 0.8475939231111617 - loss_val: 0.9536647360290476\n",
      "Epoch: 1002 - time: 0.0065 - loss_train: 0.8473571749413815 - loss_val: 0.9535154432313628\n",
      "Epoch: 1003 - time: 0.0051 - loss_train: 0.8471206793608613 - loss_val: 0.953366517530143\n",
      "Epoch: 1004 - time: 0.0051 - loss_train: 0.8468844358409 - loss_val: 0.9532179589879138\n",
      "Epoch: 1005 - time: 0.0124 - loss_train: 0.8466484438566848 - loss_val: 0.9530697676638413\n",
      "Epoch: 1006 - time: 0.0041 - loss_train: 0.8464127028872618 - loss_val: 0.9529219436137267\n",
      "Epoch: 1007 - time: 0.0053 - loss_train: 0.8461772124155026 - loss_val: 0.9527744868900005\n",
      "Epoch: 1008 - time: 0.0049 - loss_train: 0.8459419719280766 - loss_val: 0.952627397541725\n",
      "Epoch: 1009 - time: 0.0064 - loss_train: 0.8457069809154204 - loss_val: 0.9524806756145924\n",
      "Epoch: 1010 - time: 0.0096 - loss_train: 0.845472238871711 - loss_val: 0.952334321150933\n",
      "Epoch: 1011 - time: 0.0101 - loss_train: 0.8452377452948374 - loss_val: 0.9521883341897176\n",
      "Epoch: 1012 - time: 0.0109 - loss_train: 0.8450034996863747 - loss_val: 0.9520427147665733\n",
      "Epoch: 1013 - time: 0.0094 - loss_train: 0.8447695015515585 - loss_val: 0.9518974629137917\n",
      "Epoch: 1014 - time: 0.0070 - loss_train: 0.8445357503992611 - loss_val: 0.9517525786603462\n",
      "Epoch: 1015 - time: 0.0111 - loss_train: 0.8443022457419652 - loss_val: 0.9516080620319097\n",
      "Epoch: 1016 - time: 0.0099 - loss_train: 0.8440689870957433 - loss_val: 0.9514639130508737\n",
      "Epoch: 1017 - time: 0.0149 - loss_train: 0.843835973980234 - loss_val: 0.9513201317363736\n",
      "Epoch: 1018 - time: 0.0089 - loss_train: 0.8436032059186211 - loss_val: 0.9511767181043113\n",
      "Epoch: 1019 - time: 0.0093 - loss_train: 0.8433706824376136 - loss_val: 0.9510336721673854\n",
      "Epoch: 1020 - time: 0.0046 - loss_train: 0.8431384030674242 - loss_val: 0.9508909939351197\n",
      "Epoch: 1021 - time: 0.0035 - loss_train: 0.8429063673417527 - loss_val: 0.9507486834138963\n",
      "Epoch: 1022 - time: 0.0042 - loss_train: 0.8426745747977654 - loss_val: 0.9506067406069911\n",
      "Epoch: 1023 - time: 0.0035 - loss_train: 0.8424430249760801 - loss_val: 0.950465165514609\n",
      "Epoch: 1024 - time: 0.0152 - loss_train: 0.8422117174207474 - loss_val: 0.9503239581339263\n",
      "Epoch: 1025 - time: 0.0065 - loss_train: 0.8419806516792376 - loss_val: 0.9501831184591301\n",
      "Epoch: 1026 - time: 0.0227 - loss_train: 0.8417498273024223 - loss_val: 0.9500426464814605\n",
      "Epoch: 1027 - time: 0.0064 - loss_train: 0.8415192438445631 - loss_val: 0.949902542189262\n",
      "Epoch: 1028 - time: 0.0059 - loss_train: 0.8412889008632983 - loss_val: 0.949762805568024\n",
      "Epoch: 1029 - time: 0.0142 - loss_train: 0.8410587979196276 - loss_val: 0.9496234366004368\n",
      "Epoch: 1030 - time: 0.0056 - loss_train: 0.8408289345779022 - loss_val: 0.9494844352664403\n",
      "Epoch: 1031 - time: 0.0055 - loss_train: 0.840599310405815 - loss_val: 0.9493458015432784\n",
      "Epoch: 1032 - time: 0.0080 - loss_train: 0.8403699249743878 - loss_val: 0.9492075354055566\n",
      "Epoch: 1033 - time: 0.0067 - loss_train: 0.8401407778579625 - loss_val: 0.9490696368252954\n",
      "Epoch: 1034 - time: 0.0114 - loss_train: 0.8399118686341939 - loss_val: 0.9489321057719952\n",
      "Epoch: 1035 - time: 0.0190 - loss_train: 0.8396831968840391 - loss_val: 0.9487949422126921\n",
      "Epoch: 1036 - time: 0.0073 - loss_train: 0.8394547621917531 - loss_val: 0.9486581461120249\n",
      "Epoch: 1037 - time: 0.0044 - loss_train: 0.8392265641448791 - loss_val: 0.9485217174322973\n",
      "Epoch: 1038 - time: 0.0069 - loss_train: 0.8389986023342453 - loss_val: 0.9483856561335445\n",
      "Epoch: 1039 - time: 0.0065 - loss_train: 0.8387708763539586 - loss_val: 0.9482499621736026\n",
      "Epoch: 1040 - time: 0.0072 - loss_train: 0.8385433858014003 - loss_val: 0.9481146355081747\n",
      "Epoch: 1041 - time: 0.0036 - loss_train: 0.8383161302772225 - loss_val: 0.947979676090905\n",
      "Epoch: 1042 - time: 0.0091 - loss_train: 0.8380891093853456 - loss_val: 0.9478450838734489\n",
      "Epoch: 1043 - time: 0.0054 - loss_train: 0.837862322732954 - loss_val: 0.9477108588055475\n",
      "Epoch: 1044 - time: 0.0043 - loss_train: 0.8376357699304988 - loss_val: 0.9475770008351027\n",
      "Epoch: 1045 - time: 0.0051 - loss_train: 0.8374094505916913 - loss_val: 0.9474435099082523\n",
      "Epoch: 1046 - time: 0.0109 - loss_train: 0.837183364333507 - loss_val: 0.947310385969449\n",
      "Epoch: 1047 - time: 0.0035 - loss_train: 0.8369575107761845 - loss_val: 0.9471776289615373\n",
      "Epoch: 1048 - time: 0.0077 - loss_train: 0.8367318895432262 - loss_val: 0.947045238825835\n",
      "Epoch: 1049 - time: 0.0091 - loss_train: 0.8365065002614008 - loss_val: 0.9469132155022136\n",
      "Epoch: 1050 - time: 0.0107 - loss_train: 0.8362813425607446 - loss_val: 0.9467815589291797\n",
      "Epoch: 1051 - time: 0.0062 - loss_train: 0.8360564160745659 - loss_val: 0.9466502690439578\n",
      "Epoch: 1052 - time: 0.0086 - loss_train: 0.8358317204394475 - loss_val: 0.9465193457825751\n",
      "Epoch: 1053 - time: 0.0050 - loss_train: 0.8356072552952515 - loss_val: 0.9463887890799456\n",
      "Epoch: 1054 - time: 0.0048 - loss_train: 0.8353830202851226 - loss_val: 0.9462585988699553\n",
      "Epoch: 1055 - time: 0.0206 - loss_train: 0.8351590150554962 - loss_val: 0.9461287750855502\n",
      "Epoch: 1056 - time: 0.0048 - loss_train: 0.8349352392561021 - loss_val: 0.9459993176588196\n",
      "Epoch: 1057 - time: 0.0076 - loss_train: 0.8347116925399719 - loss_val: 0.9458702265210879\n",
      "Epoch: 1058 - time: 0.0061 - loss_train: 0.8344883745634458 - loss_val: 0.9457415016030009\n",
      "Epoch: 1059 - time: 0.0069 - loss_train: 0.8342652849861797 - loss_val: 0.9456131428346148\n",
      "Epoch: 1060 - time: 0.0067 - loss_train: 0.8340424234711562 - loss_val: 0.9454851501454838\n",
      "Epoch: 1061 - time: 0.0104 - loss_train: 0.8338197896846887 - loss_val: 0.9453575234647551\n",
      "Epoch: 1062 - time: 0.0044 - loss_train: 0.8335973832964343 - loss_val: 0.9452302627212521\n",
      "Epoch: 1063 - time: 0.0059 - loss_train: 0.833375203979402 - loss_val: 0.945103367843569\n",
      "Epoch: 1064 - time: 0.0079 - loss_train: 0.8331532514099637 - loss_val: 0.9449768387601616\n",
      "Epoch: 1065 - time: 0.0064 - loss_train: 0.8329315252678625 - loss_val: 0.9448506753994355\n",
      "Epoch: 1066 - time: 0.0062 - loss_train: 0.8327100252362273 - loss_val: 0.94472487768984\n",
      "Epoch: 1067 - time: 0.0057 - loss_train: 0.832488751001582 - loss_val: 0.944599445559957\n",
      "Epoch: 1068 - time: 0.0123 - loss_train: 0.8322677022538585 - loss_val: 0.9444743789385937\n",
      "Epoch: 1069 - time: 0.0052 - loss_train: 0.8320468786864089 - loss_val: 0.9443496777548726\n",
      "Epoch: 1070 - time: 0.0152 - loss_train: 0.8318262799960171 - loss_val: 0.9442253419383225\n",
      "Epoch: 1071 - time: 0.0070 - loss_train: 0.8316059058829139 - loss_val: 0.9441013714189699\n",
      "Epoch: 1072 - time: 0.0042 - loss_train: 0.8313857560507893 - loss_val: 0.943977766127429\n",
      "Epoch: 1073 - time: 0.0042 - loss_train: 0.831165830206808 - loss_val: 0.9438545259949922\n",
      "Epoch: 1074 - time: 0.0160 - loss_train: 0.8309461280616215 - loss_val: 0.9437316509537178\n",
      "Epoch: 1075 - time: 0.1849 - loss_train: 0.8307266493293839 - loss_val: 0.9436091409365263\n",
      "Epoch: 1076 - time: 0.0045 - loss_train: 0.8305073937277674 - loss_val: 0.9434869958772799\n",
      "Epoch: 1077 - time: 0.0128 - loss_train: 0.8302883609779754 - loss_val: 0.9433652157108777\n",
      "Epoch: 1078 - time: 0.0036 - loss_train: 0.830069550804761 - loss_val: 0.9432438003733417\n",
      "Epoch: 1079 - time: 0.0042 - loss_train: 0.8298509629364398 - loss_val: 0.9431227498019047\n",
      "Epoch: 1080 - time: 0.0034 - loss_train: 0.829632597104908 - loss_val: 0.943002063935093\n",
      "Epoch: 1081 - time: 0.0059 - loss_train: 0.8294144530456572 - loss_val: 0.9428817427128181\n",
      "Epoch: 1082 - time: 0.0040 - loss_train: 0.8291965304977911 - loss_val: 0.9427617860764557\n",
      "Epoch: 1083 - time: 0.0049 - loss_train: 0.8289788292040436 - loss_val: 0.9426421939689352\n",
      "Epoch: 1084 - time: 0.0039 - loss_train: 0.8287613489107923 - loss_val: 0.9425229663348164\n",
      "Epoch: 1085 - time: 0.0039 - loss_train: 0.8285440893680791 - loss_val: 0.9424041031203765\n",
      "Epoch: 1086 - time: 0.0053 - loss_train: 0.8283270503296238 - loss_val: 0.9422856042736881\n",
      "Epoch: 1087 - time: 0.0037 - loss_train: 0.828110231552844 - loss_val: 0.9421674697446999\n",
      "Epoch: 1088 - time: 0.0042 - loss_train: 0.8278936327988704 - loss_val: 0.9420496994853139\n",
      "Epoch: 1089 - time: 0.0037 - loss_train: 0.8276772538325641 - loss_val: 0.9419322934494633\n",
      "Epoch: 1090 - time: 0.0035 - loss_train: 0.8274610944225355 - loss_val: 0.9418152515931875\n",
      "Epoch: 1091 - time: 0.0055 - loss_train: 0.82724515434116 - loss_val: 0.9416985738747068\n",
      "Epoch: 1092 - time: 0.0078 - loss_train: 0.8270294333645952 - loss_val: 0.9415822602544939\n",
      "Epoch: 1093 - time: 0.0056 - loss_train: 0.8268139312727988 - loss_val: 0.941466310695347\n",
      "Epoch: 1094 - time: 0.0070 - loss_train: 0.8265986478495457 - loss_val: 0.9413507251624563\n",
      "Epoch: 1095 - time: 0.0131 - loss_train: 0.8263835828824458 - loss_val: 0.9412355036234753\n",
      "Epoch: 1096 - time: 0.0038 - loss_train: 0.8261687361629584 - loss_val: 0.9411206460485837\n",
      "Epoch: 1097 - time: 0.0090 - loss_train: 0.8259541074864118 - loss_val: 0.9410061524105524\n",
      "Epoch: 1098 - time: 0.0082 - loss_train: 0.825739696652019 - loss_val: 0.9408920226848074\n",
      "Epoch: 1099 - time: 0.0041 - loss_train: 0.8255255034628942 - loss_val: 0.9407782568494876\n",
      "Epoch: 1100 - time: 0.0108 - loss_train: 0.8253115277260681 - loss_val: 0.9406648548855048\n",
      "Epoch: 1101 - time: 0.0036 - loss_train: 0.8250977692525064 - loss_val: 0.9405518167765986\n",
      "Epoch: 1102 - time: 0.0040 - loss_train: 0.8248842278571238 - loss_val: 0.940439142509393\n",
      "Epoch: 1103 - time: 0.0059 - loss_train: 0.8246709033587984 - loss_val: 0.9403268320734448\n",
      "Epoch: 1104 - time: 0.0100 - loss_train: 0.8244577955803909 - loss_val: 0.9402148854612968\n",
      "Epoch: 1105 - time: 0.0057 - loss_train: 0.8242449043487556 - loss_val: 0.9401033026685223\n",
      "Epoch: 1106 - time: 0.0064 - loss_train: 0.8240322294947566 - loss_val: 0.939992083693772\n",
      "Epoch: 1107 - time: 0.0122 - loss_train: 0.8238197708532821 - loss_val: 0.9398812285388148\n",
      "Epoch: 1108 - time: 0.0052 - loss_train: 0.823607528263258 - loss_val: 0.93977073720858\n",
      "Epoch: 1109 - time: 0.0068 - loss_train: 0.8233955015676603 - loss_val: 0.9396606097111939\n",
      "Epoch: 1110 - time: 0.0063 - loss_train: 0.823183690613529 - loss_val: 0.9395508460580138\n",
      "Epoch: 1111 - time: 0.0054 - loss_train: 0.8229720952519806 - loss_val: 0.9394414462636608\n",
      "Epoch: 1112 - time: 0.0091 - loss_train: 0.8227607153382185 - loss_val: 0.9393324103460516\n",
      "Epoch: 1113 - time: 0.0101 - loss_train: 0.8225495507315459 - loss_val: 0.9392237383264227\n",
      "Epoch: 1114 - time: 0.0071 - loss_train: 0.8223386012953758 - loss_val: 0.9391154302293558\n",
      "Epoch: 1115 - time: 0.0060 - loss_train: 0.8221278668972406 - loss_val: 0.9390074860827983\n",
      "Epoch: 1116 - time: 0.0042 - loss_train: 0.8219173474088013 - loss_val: 0.9388999059180824\n",
      "Epoch: 1117 - time: 0.0061 - loss_train: 0.8217070427058587 - loss_val: 0.9387926897699411\n",
      "Epoch: 1118 - time: 0.0063 - loss_train: 0.8214969526683586 - loss_val: 0.9386858376765183\n",
      "Epoch: 1119 - time: 0.0075 - loss_train: 0.8212870771804 - loss_val: 0.9385793496793823\n",
      "Epoch: 1120 - time: 0.0077 - loss_train: 0.8210774161302421 - loss_val: 0.9384732258235273\n",
      "Epoch: 1121 - time: 0.0038 - loss_train: 0.8208679694103109 - loss_val: 0.9383674661573809\n",
      "Epoch: 1122 - time: 0.0079 - loss_train: 0.8206587369172024 - loss_val: 0.9382620707328033\n",
      "Epoch: 1123 - time: 0.0118 - loss_train: 0.8204497185516878 - loss_val: 0.9381570396050816\n",
      "Epoch: 1124 - time: 0.0065 - loss_train: 0.8202409142187175 - loss_val: 0.9380523728329274\n",
      "Epoch: 1125 - time: 0.0045 - loss_train: 0.8200323238274215 - loss_val: 0.937948070478466\n",
      "Epoch: 1126 - time: 0.0113 - loss_train: 0.8198239472911139 - loss_val: 0.937844132607223\n",
      "Epoch: 1127 - time: 0.0068 - loss_train: 0.8196157845272912 - loss_val: 0.9377405592881076\n",
      "Epoch: 1128 - time: 0.0041 - loss_train: 0.8194078354576314 - loss_val: 0.9376373505933967\n",
      "Epoch: 1129 - time: 0.0056 - loss_train: 0.8192001000079957 - loss_val: 0.9375345065987097\n",
      "Epoch: 1130 - time: 0.0075 - loss_train: 0.8189925781084234 - loss_val: 0.937432027382982\n",
      "Epoch: 1131 - time: 0.0054 - loss_train: 0.8187852696931289 - loss_val: 0.9373299130284378\n",
      "Epoch: 1132 - time: 0.0091 - loss_train: 0.8185781747004989 - loss_val: 0.9372281636205553\n",
      "Epoch: 1133 - time: 0.0042 - loss_train: 0.8183712930730845 - loss_val: 0.937126779248033\n",
      "Epoch: 1134 - time: 0.0075 - loss_train: 0.8181646247575954 - loss_val: 0.9370257600027473\n",
      "Epoch: 1135 - time: 0.0067 - loss_train: 0.8179581697048932 - loss_val: 0.936925105979711\n",
      "Epoch: 1136 - time: 0.0124 - loss_train: 0.8177519278699801 - loss_val: 0.936824817277027\n",
      "Epoch: 1137 - time: 0.0038 - loss_train: 0.8175458992119912 - loss_val: 0.9367248939958386\n",
      "Epoch: 1138 - time: 0.0045 - loss_train: 0.8173400836941812 - loss_val: 0.9366253362402744\n",
      "Epoch: 1139 - time: 0.0083 - loss_train: 0.817134481283912 - loss_val: 0.936526144117393\n",
      "Epoch: 1140 - time: 0.0051 - loss_train: 0.8169290919526397 - loss_val: 0.936427317737124\n",
      "Epoch: 1141 - time: 0.0078 - loss_train: 0.8167239156758989 - loss_val: 0.9363288572122013\n",
      "Epoch: 1142 - time: 0.0103 - loss_train: 0.8165189524332853 - loss_val: 0.9362307626580982\n",
      "Epoch: 1143 - time: 0.0124 - loss_train: 0.8163142022084399 - loss_val: 0.9361330341929562\n",
      "Epoch: 1144 - time: 0.0041 - loss_train: 0.8161096649890276 - loss_val: 0.9360356719375118\n",
      "Epoch: 1145 - time: 0.0118 - loss_train: 0.8159053407667186 - loss_val: 0.9359386760150172\n",
      "Epoch: 1146 - time: 0.0058 - loss_train: 0.8157012295371651 - loss_val: 0.9358420465511618\n",
      "Epoch: 1147 - time: 0.0068 - loss_train: 0.8154973312999793 - loss_val: 0.9357457836739873\n",
      "Epoch: 1148 - time: 0.0143 - loss_train: 0.8152936460587075 - loss_val: 0.9356498875138016\n",
      "Epoch: 1149 - time: 0.0061 - loss_train: 0.8150901738208047 - loss_val: 0.9355543582030841\n",
      "Epoch: 1150 - time: 0.0058 - loss_train: 0.8148869145976074 - loss_val: 0.935459195876398\n",
      "Epoch: 1151 - time: 0.0074 - loss_train: 0.814683868404304 - loss_val: 0.9353644006702889\n",
      "Epoch: 1152 - time: 0.0051 - loss_train: 0.8144810352599052 - loss_val: 0.9352699727231852\n",
      "Epoch: 1153 - time: 0.0052 - loss_train: 0.8142784151872101 - loss_val: 0.9351759121752953\n",
      "Epoch: 1154 - time: 0.0058 - loss_train: 0.8140760082127766 - loss_val: 0.9350822191685009\n",
      "Epoch: 1155 - time: 0.0159 - loss_train: 0.8138738143668828 - loss_val: 0.9349888938462482\n",
      "Epoch: 1156 - time: 0.0100 - loss_train: 0.8136718336834926 - loss_val: 0.9348959363534336\n",
      "Epoch: 1157 - time: 0.0089 - loss_train: 0.8134700662002181 - loss_val: 0.9348033468362896\n",
      "Epoch: 1158 - time: 0.0038 - loss_train: 0.8132685119582789 - loss_val: 0.9347111254422664\n",
      "Epoch: 1159 - time: 0.0041 - loss_train: 0.8130671710024632 - loss_val: 0.9346192723199089\n",
      "Epoch: 1160 - time: 0.0036 - loss_train: 0.8128660433810839 - loss_val: 0.9345277876187364\n",
      "Epoch: 1161 - time: 0.0092 - loss_train: 0.8126651291459354 - loss_val: 0.9344366714891106\n",
      "Epoch: 1162 - time: 0.0129 - loss_train: 0.8124644283522477 - loss_val: 0.9343459240821104\n",
      "Epoch: 1163 - time: 0.0064 - loss_train: 0.8122639410586416 - loss_val: 0.9342555455493987\n",
      "Epoch: 1164 - time: 0.0161 - loss_train: 0.8120636673270775 - loss_val: 0.9341655360430879\n",
      "Epoch: 1165 - time: 0.0045 - loss_train: 0.8118636072228073 - loss_val: 0.9340758957156029\n",
      "Epoch: 1166 - time: 0.0038 - loss_train: 0.8116637608143226 - loss_val: 0.9339866247195407\n",
      "Epoch: 1167 - time: 0.0065 - loss_train: 0.8114641281733023 - loss_val: 0.9338977232075323\n",
      "Epoch: 1168 - time: 0.0047 - loss_train: 0.811264709374558 - loss_val: 0.9338091913320943\n",
      "Epoch: 1169 - time: 0.0047 - loss_train: 0.8110655044959774 - loss_val: 0.9337210292454876\n",
      "Epoch: 1170 - time: 0.0045 - loss_train: 0.810866513618469 - loss_val: 0.933633237099566\n",
      "Epoch: 1171 - time: 0.0051 - loss_train: 0.810667736825901 - loss_val: 0.93354581504563\n",
      "Epoch: 1172 - time: 0.0080 - loss_train: 0.8104691742050428 - loss_val: 0.933458763234271\n",
      "Epoch: 1173 - time: 0.0055 - loss_train: 0.810270825845504 - loss_val: 0.9333720818152219\n",
      "Epoch: 1174 - time: 0.0056 - loss_train: 0.8100726918396683 - loss_val: 0.9332857709372\n",
      "Epoch: 1175 - time: 0.0080 - loss_train: 0.8098747722826336 - loss_val: 0.9331998307477511\n",
      "Epoch: 1176 - time: 0.0104 - loss_train: 0.8096770672721418 - loss_val: 0.9331142613930917\n",
      "Epoch: 1177 - time: 0.0048 - loss_train: 0.8094795769085154 - loss_val: 0.9330290630179507\n",
      "Epoch: 1178 - time: 0.0052 - loss_train: 0.8092823012945854 - loss_val: 0.9329442357654052\n",
      "Epoch: 1179 - time: 0.0212 - loss_train: 0.8090852405356259 - loss_val: 0.9328597797767241\n",
      "Epoch: 1180 - time: 0.0075 - loss_train: 0.8088883947392793 - loss_val: 0.9327756951912023\n",
      "Epoch: 1181 - time: 0.0132 - loss_train: 0.8086917640154854 - loss_val: 0.9326919821459972\n",
      "Epoch: 1182 - time: 0.0073 - loss_train: 0.8084953484764084 - loss_val: 0.9326086407759668\n",
      "Epoch: 1183 - time: 0.0039 - loss_train: 0.8082991482363604 - loss_val: 0.9325256712135019\n",
      "Epoch: 1184 - time: 0.0147 - loss_train: 0.8081031634117282 - loss_val: 0.9324430735883621\n",
      "Epoch: 1185 - time: 0.0050 - loss_train: 0.8079073941208929 - loss_val: 0.9323608480275098\n",
      "Epoch: 1186 - time: 0.0069 - loss_train: 0.8077118404841546 - loss_val: 0.9322789946549426\n",
      "Epoch: 1187 - time: 0.0068 - loss_train: 0.8075165026236509 - loss_val: 0.9321975135915285\n",
      "Epoch: 1188 - time: 0.0091 - loss_train: 0.8073213806632779 - loss_val: 0.9321164049548397\n",
      "Epoch: 1189 - time: 0.0047 - loss_train: 0.8071264747286084 - loss_val: 0.9320356688589818\n",
      "Epoch: 1190 - time: 0.0040 - loss_train: 0.8069317849468084 - loss_val: 0.9319553054144334\n",
      "Epoch: 1191 - time: 0.0104 - loss_train: 0.8067373114465558 - loss_val: 0.9318753147278758\n",
      "Epoch: 1192 - time: 0.0048 - loss_train: 0.8065430543579548 - loss_val: 0.9317956969020277\n",
      "Epoch: 1193 - time: 0.0037 - loss_train: 0.8063490138124513 - loss_val: 0.93171645203548\n",
      "Epoch: 1194 - time: 0.0070 - loss_train: 0.8061551899427462 - loss_val: 0.9316375802225342\n",
      "Epoch: 1195 - time: 0.0071 - loss_train: 0.8059615828827094 - loss_val: 0.9315590815530316\n",
      "Epoch: 1196 - time: 0.0076 - loss_train: 0.8057681927672913 - loss_val: 0.9314809561121972\n",
      "Epoch: 1197 - time: 0.0156 - loss_train: 0.8055750197324371 - loss_val: 0.9314032039804722\n",
      "Epoch: 1198 - time: 0.0083 - loss_train: 0.8053820639149946 - loss_val: 0.9313258252333576\n",
      "Epoch: 1199 - time: 0.0098 - loss_train: 0.8051893254526266 - loss_val: 0.9312488199412499\n",
      "Epoch: 1200 - time: 0.0107 - loss_train: 0.8049968044837207 - loss_val: 0.9311721881692844\n",
      "Epoch: 1201 - time: 0.0041 - loss_train: 0.8048045011472986 - loss_val: 0.931095929977179\n",
      "Epoch: 1202 - time: 0.0077 - loss_train: 0.8046124155829247 - loss_val: 0.931020045419077\n",
      "Epoch: 1203 - time: 0.0092 - loss_train: 0.8044205479306151 - loss_val: 0.9309445345433933\n",
      "Epoch: 1204 - time: 0.0039 - loss_train: 0.8042288983307448 - loss_val: 0.9308693973926627\n",
      "Epoch: 1205 - time: 0.0041 - loss_train: 0.8040374669239566 - loss_val: 0.9307946340033898\n",
      "Epoch: 1206 - time: 0.0053 - loss_train: 0.8038462538510678 - loss_val: 0.9307202444058998\n",
      "Epoch: 1207 - time: 0.0065 - loss_train: 0.8036552592529783 - loss_val: 0.9306462286241923\n",
      "Epoch: 1208 - time: 0.0071 - loss_train: 0.8034644832705763 - loss_val: 0.9305725866757982\n",
      "Epoch: 1209 - time: 0.0070 - loss_train: 0.8032739260446465 - loss_val: 0.930499318571635\n",
      "Epoch: 1210 - time: 0.0060 - loss_train: 0.8030835877157763 - loss_val: 0.9304264243158727\n",
      "Epoch: 1211 - time: 0.0067 - loss_train: 0.802893468424263 - loss_val: 0.9303539039057904\n",
      "Epoch: 1212 - time: 0.0044 - loss_train: 0.8027035683100194 - loss_val: 0.9302817573316463\n",
      "Epoch: 1213 - time: 0.0056 - loss_train: 0.8025138875124831 - loss_val: 0.9302099845765456\n",
      "Epoch: 1214 - time: 0.0097 - loss_train: 0.8023244261705206 - loss_val: 0.9301385856163088\n",
      "Epoch: 1215 - time: 0.0048 - loss_train: 0.8021351844223362 - loss_val: 0.9300675604193479\n",
      "Epoch: 1216 - time: 0.0096 - loss_train: 0.8019461624053797 - loss_val: 0.9299969089465432\n",
      "Epoch: 1217 - time: 0.0065 - loss_train: 0.8017573602562531 - loss_val: 0.9299266311511224\n",
      "Epoch: 1218 - time: 0.0039 - loss_train: 0.8015687781106182 - loss_val: 0.9298567269785418\n",
      "Epoch: 1219 - time: 0.0045 - loss_train: 0.8013804161031064 - loss_val: 0.9297871963663764\n",
      "Epoch: 1220 - time: 0.0049 - loss_train: 0.8011922743672256 - loss_val: 0.9297180392442058\n",
      "Epoch: 1221 - time: 0.0092 - loss_train: 0.8010043530352718 - loss_val: 0.9296492555335075\n",
      "Epoch: 1222 - time: 0.0079 - loss_train: 0.8008166522382361 - loss_val: 0.929580845147553\n",
      "Epoch: 1223 - time: 0.0066 - loss_train: 0.8006291721057173 - loss_val: 0.9295128079913069\n",
      "Epoch: 1224 - time: 0.0052 - loss_train: 0.8004419127658321 - loss_val: 0.9294451439613306\n",
      "Epoch: 1225 - time: 0.0048 - loss_train: 0.8002548743451253 - loss_val: 0.9293778529456866\n",
      "Epoch: 1226 - time: 0.0051 - loss_train: 0.8000680569684842 - loss_val: 0.9293109348238513\n",
      "Epoch: 1227 - time: 0.0053 - loss_train: 0.7998814607590514 - loss_val: 0.9292443894666248\n",
      "Epoch: 1228 - time: 0.0060 - loss_train: 0.7996950858381368 - loss_val: 0.9291782167360516\n",
      "Epoch: 1229 - time: 0.0057 - loss_train: 0.7995089323251341 - loss_val: 0.9291124164853392\n",
      "Epoch: 1230 - time: 0.0040 - loss_train: 0.7993230003374353 - loss_val: 0.9290469885587846\n",
      "Epoch: 1231 - time: 0.0042 - loss_train: 0.7991372899903497 - loss_val: 0.9289819327916997\n",
      "Epoch: 1232 - time: 0.0047 - loss_train: 0.798951801397018 - loss_val: 0.928917249010347\n",
      "Epoch: 1233 - time: 0.0036 - loss_train: 0.798766534668332 - loss_val: 0.9288529370318722\n",
      "Epoch: 1234 - time: 0.0082 - loss_train: 0.7985814899128566 - loss_val: 0.928788996664249\n",
      "Epoch: 1235 - time: 0.0097 - loss_train: 0.7983966672367472 - loss_val: 0.9287254277062164\n",
      "Epoch: 1236 - time: 0.0083 - loss_train: 0.7982120667436731 - loss_val: 0.9286622299472312\n",
      "Epoch: 1237 - time: 0.0079 - loss_train: 0.798027688534741 - loss_val: 0.9285994031674175\n",
      "Epoch: 1238 - time: 0.0048 - loss_train: 0.7978435327084185 - loss_val: 0.9285369471375234\n",
      "Epoch: 1239 - time: 0.0036 - loss_train: 0.7976595993604603 - loss_val: 0.9284748616188776\n",
      "Epoch: 1240 - time: 0.0040 - loss_train: 0.797475888583833 - loss_val: 0.9284131463633553\n",
      "Epoch: 1241 - time: 0.0091 - loss_train: 0.797292400468648 - loss_val: 0.9283518011133456\n",
      "Epoch: 1242 - time: 0.0080 - loss_train: 0.7971091351020846 - loss_val: 0.9282908256017194\n",
      "Epoch: 1243 - time: 0.0039 - loss_train: 0.7969260925683259 - loss_val: 0.9282302195518055\n",
      "Epoch: 1244 - time: 0.0054 - loss_train: 0.7967432729484892 - loss_val: 0.9281699826773717\n",
      "Epoch: 1245 - time: 0.0084 - loss_train: 0.79656067632056 - loss_val: 0.9281101146826046\n",
      "Epoch: 1246 - time: 0.0100 - loss_train: 0.7963783027593268 - loss_val: 0.9280506152620958\n",
      "Epoch: 1247 - time: 0.0088 - loss_train: 0.7961961523363179 - loss_val: 0.9279914841008329\n",
      "Epoch: 1248 - time: 0.0097 - loss_train: 0.7960142251197407 - loss_val: 0.9279327208741933\n",
      "Epoch: 1249 - time: 0.0162 - loss_train: 0.7958325211744198 - loss_val: 0.9278743252479427\n",
      "Epoch: 1250 - time: 0.0094 - loss_train: 0.7956510405617403 - loss_val: 0.927816296878234\n",
      "Epoch: 1251 - time: 0.0090 - loss_train: 0.7954697833395887 - loss_val: 0.9277586354116141\n",
      "Epoch: 1252 - time: 0.0108 - loss_train: 0.795288749562298 - loss_val: 0.9277013404850311\n",
      "Epoch: 1253 - time: 0.0043 - loss_train: 0.7951079392805959 - loss_val: 0.9276444117258474\n",
      "Epoch: 1254 - time: 0.0056 - loss_train: 0.794927352541549 - loss_val: 0.9275878487518546\n",
      "Epoch: 1255 - time: 0.0098 - loss_train: 0.7947469893885154 - loss_val: 0.9275316511712931\n",
      "Epoch: 1256 - time: 0.0096 - loss_train: 0.7945668498610938 - loss_val: 0.9274758185828735\n",
      "Epoch: 1257 - time: 0.0072 - loss_train: 0.7943869339950768 - loss_val: 0.9274203505758036\n",
      "Epoch: 1258 - time: 0.0081 - loss_train: 0.7942072418224061 - loss_val: 0.9273652467298169\n",
      "Epoch: 1259 - time: 0.0042 - loss_train: 0.7940277733711286 - loss_val: 0.9273105066152043\n",
      "Epoch: 1260 - time: 0.0068 - loss_train: 0.7938485286653517 - loss_val: 0.9272561297928513\n",
      "Epoch: 1261 - time: 0.0128 - loss_train: 0.7936695077252073 - loss_val: 0.9272021158142748\n",
      "Epoch: 1262 - time: 0.0084 - loss_train: 0.7934907105668081 - loss_val: 0.927148464221666\n",
      "Epoch: 1263 - time: 0.0088 - loss_train: 0.7933121372022158 - loss_val: 0.9270951745479331\n",
      "Epoch: 1264 - time: 0.0177 - loss_train: 0.7931337876394009 - loss_val: 0.9270422463167529\n",
      "Epoch: 1265 - time: 0.0267 - loss_train: 0.7929556618822123 - loss_val: 0.9269896790426176\n",
      "Epoch: 1266 - time: 0.0048 - loss_train: 0.792777759930344 - loss_val: 0.9269374722308887\n",
      "Epoch: 1267 - time: 0.0060 - loss_train: 0.7926000817793059 - loss_val: 0.9268856253778549\n",
      "Epoch: 1268 - time: 0.0074 - loss_train: 0.792422627420394 - loss_val: 0.9268341379707866\n",
      "Epoch: 1269 - time: 0.0038 - loss_train: 0.7922453968406649 - loss_val: 0.9267830094880007\n",
      "Epoch: 1270 - time: 0.0037 - loss_train: 0.792068390022911 - loss_val: 0.9267322393989242\n",
      "Epoch: 1271 - time: 0.0072 - loss_train: 0.7918916069456352 - loss_val: 0.926681827164158\n",
      "Epoch: 1272 - time: 0.0049 - loss_train: 0.791715047583031 - loss_val: 0.9266317722355445\n",
      "Epoch: 1273 - time: 0.0103 - loss_train: 0.7915387119049623 - loss_val: 0.9265820740562426\n",
      "Epoch: 1274 - time: 0.0046 - loss_train: 0.7913625998769444 - loss_val: 0.926532732060796\n",
      "Epoch: 1275 - time: 0.0084 - loss_train: 0.7911867114601275 - loss_val: 0.9264837456752095\n",
      "Epoch: 1276 - time: 0.0062 - loss_train: 0.7910110466112829 - loss_val: 0.9264351143170269\n",
      "Epoch: 1277 - time: 0.0064 - loss_train: 0.7908356052827867 - loss_val: 0.9263868373954077\n",
      "Epoch: 1278 - time: 0.0090 - loss_train: 0.7906603874226126 - loss_val: 0.9263389143112088\n",
      "Epoch: 1279 - time: 0.0110 - loss_train: 0.7904853929743156 - loss_val: 0.9262913444570675\n",
      "Epoch: 1280 - time: 0.0049 - loss_train: 0.7903106218770298 - loss_val: 0.9262441272174834\n",
      "Epoch: 1281 - time: 0.0109 - loss_train: 0.7901360740654562 - loss_val: 0.9261972619689073\n",
      "Epoch: 1282 - time: 0.0092 - loss_train: 0.7899617494698604 - loss_val: 0.926150748079825\n",
      "Epoch: 1283 - time: 0.0080 - loss_train: 0.7897876480160674 - loss_val: 0.926104584910848\n",
      "Epoch: 1284 - time: 0.0053 - loss_train: 0.7896137696254588 - loss_val: 0.9260587718148034\n",
      "Epoch: 1285 - time: 0.0050 - loss_train: 0.7894401142149732 - loss_val: 0.9260133081368228\n",
      "Epoch: 1286 - time: 0.0067 - loss_train: 0.7892666816971046 - loss_val: 0.9259681932144395\n",
      "Epoch: 1287 - time: 0.0075 - loss_train: 0.7890934719799065 - loss_val: 0.9259234263776771\n",
      "Epoch: 1288 - time: 0.0052 - loss_train: 0.7889204849669936 - loss_val: 0.9258790069491476\n",
      "Epoch: 1289 - time: 0.0070 - loss_train: 0.7887477205575475 - loss_val: 0.9258349342441456\n",
      "Epoch: 1290 - time: 0.0055 - loss_train: 0.7885751786463222 - loss_val: 0.9257912075707448\n",
      "Epoch: 1291 - time: 0.0062 - loss_train: 0.7884028591236525 - loss_val: 0.9257478262298964\n",
      "Epoch: 1292 - time: 0.0057 - loss_train: 0.7882307618754613 - loss_val: 0.9257047895155271\n",
      "Epoch: 1293 - time: 0.0060 - loss_train: 0.7880588867832714 - loss_val: 0.9256620967146375\n",
      "Epoch: 1294 - time: 0.0044 - loss_train: 0.7878872337242155 - loss_val: 0.9256197471074017\n",
      "Epoch: 1295 - time: 0.0053 - loss_train: 0.7877158025710492 - loss_val: 0.9255777399672671\n",
      "Epoch: 1296 - time: 0.0061 - loss_train: 0.7875445931921661 - loss_val: 0.9255360745610558\n",
      "Epoch: 1297 - time: 0.0061 - loss_train: 0.7873736054516098 - loss_val: 0.925494750149066\n",
      "Epoch: 1298 - time: 0.0052 - loss_train: 0.7872028392090941 - loss_val: 0.9254537659851713\n",
      "Epoch: 1299 - time: 0.0086 - loss_train: 0.7870322943200168 - loss_val: 0.9254131213169257\n",
      "Epoch: 1300 - time: 0.0220 - loss_train: 0.7868619706354796 - loss_val: 0.9253728153856601\n",
      "Epoch: 1301 - time: 0.0092 - loss_train: 0.7866918680023093 - loss_val: 0.9253328474265909\n",
      "Epoch: 1302 - time: 0.0037 - loss_train: 0.7865219862630745 - loss_val: 0.9252932166689184\n",
      "Epoch: 1303 - time: 0.0035 - loss_train: 0.7863523252561103 - loss_val: 0.9252539223359281\n",
      "Epoch: 1304 - time: 0.0046 - loss_train: 0.7861828848155411 - loss_val: 0.9252149636450968\n",
      "Epoch: 1305 - time: 0.0039 - loss_train: 0.7860136647713021 - loss_val: 0.9251763398081907\n",
      "Epoch: 1306 - time: 0.0063 - loss_train: 0.7858446649491646 - loss_val: 0.9251380500313703\n",
      "Epoch: 1307 - time: 0.0042 - loss_train: 0.785675885170763 - loss_val: 0.9251000935152904\n",
      "Epoch: 1308 - time: 0.0036 - loss_train: 0.7855073252536189 - loss_val: 0.9250624694552037\n",
      "Epoch: 1309 - time: 0.0047 - loss_train: 0.7853389850111696 - loss_val: 0.9250251770410621\n",
      "Epoch: 1310 - time: 0.0037 - loss_train: 0.7851708642527965 - loss_val: 0.9249882154576148\n",
      "Epoch: 1311 - time: 0.0038 - loss_train: 0.7850029627838522 - loss_val: 0.9249515838845138\n",
      "Epoch: 1312 - time: 0.0059 - loss_train: 0.7848352804056917 - loss_val: 0.9249152814964102\n",
      "Epoch: 1313 - time: 0.0037 - loss_train: 0.7846678169157033 - loss_val: 0.9248793074630571\n",
      "Epoch: 1314 - time: 0.0041 - loss_train: 0.7845005721073369 - loss_val: 0.9248436609494067\n",
      "Epoch: 1315 - time: 0.0039 - loss_train: 0.7843335457701389 - loss_val: 0.9248083411157131\n",
      "Epoch: 1316 - time: 0.0036 - loss_train: 0.7841667376897822 - loss_val: 0.9247733471176262\n",
      "Epoch: 1317 - time: 0.0057 - loss_train: 0.7840001476481019 - loss_val: 0.9247386781062924\n",
      "Epoch: 1318 - time: 0.0046 - loss_train: 0.783833775423126 - loss_val: 0.9247043332284508\n",
      "Epoch: 1319 - time: 0.0041 - loss_train: 0.7836676207891123 - loss_val: 0.9246703116265308\n",
      "Epoch: 1320 - time: 0.0097 - loss_train: 0.7835016835165816 - loss_val: 0.9246366124387475\n",
      "Epoch: 1321 - time: 0.0051 - loss_train: 0.7833359633723531 - loss_val: 0.924603234799198\n",
      "Epoch: 1322 - time: 0.0111 - loss_train: 0.7831704601195818 - loss_val: 0.9245701778379528\n",
      "Epoch: 1323 - time: 0.0112 - loss_train: 0.7830051735177932 - loss_val: 0.9245374406811525\n",
      "Epoch: 1324 - time: 0.0084 - loss_train: 0.7828401033229212 - loss_val: 0.924505022451101\n",
      "Epoch: 1325 - time: 0.0097 - loss_train: 0.7826752492873436 - loss_val: 0.9244729222663565\n",
      "Epoch: 1326 - time: 0.0090 - loss_train: 0.7825106111599237 - loss_val: 0.9244411392418218\n",
      "Epoch: 1327 - time: 0.0079 - loss_train: 0.7823461886860426 - loss_val: 0.9244096724888381\n",
      "Epoch: 1328 - time: 0.0152 - loss_train: 0.782181981607643 - loss_val: 0.9243785211152717\n",
      "Epoch: 1329 - time: 0.0085 - loss_train: 0.782017989663265 - loss_val: 0.9243476842256024\n",
      "Epoch: 1330 - time: 0.0063 - loss_train: 0.7818542125880854 - loss_val: 0.9243171609210155\n",
      "Epoch: 1331 - time: 0.0122 - loss_train: 0.7816906501139583 - loss_val: 0.9242869502994838\n",
      "Epoch: 1332 - time: 0.0050 - loss_train: 0.7815273019694527 - loss_val: 0.9242570514558575\n",
      "Epoch: 1333 - time: 0.0075 - loss_train: 0.7813641678798952 - loss_val: 0.9242274634819462\n",
      "Epoch: 1334 - time: 0.0209 - loss_train: 0.7812012475674068 - loss_val: 0.9241981854666065\n",
      "Epoch: 1335 - time: 0.0077 - loss_train: 0.7810385407509468 - loss_val: 0.9241692164958211\n",
      "Epoch: 1336 - time: 0.0055 - loss_train: 0.7808760471463496 - loss_val: 0.9241405556527844\n",
      "Epoch: 1337 - time: 0.0037 - loss_train: 0.7807137664663678 - loss_val: 0.9241122020179828\n",
      "Epoch: 1338 - time: 0.0040 - loss_train: 0.7805516984207126 - loss_val: 0.9240841546692741\n",
      "Epoch: 1339 - time: 0.0071 - loss_train: 0.7803898427160945 - loss_val: 0.9240564126819681\n",
      "Epoch: 1340 - time: 0.0083 - loss_train: 0.7802281990562637 - loss_val: 0.924028975128904\n",
      "Epoch: 1341 - time: 0.0062 - loss_train: 0.7800667671420521 - loss_val: 0.924001841080527\n",
      "Epoch: 1342 - time: 0.0050 - loss_train: 0.7799055466714153 - loss_val: 0.9239750096049675\n",
      "Epoch: 1343 - time: 0.0088 - loss_train: 0.7797445373394716 - loss_val: 0.9239484797681128\n",
      "Epoch: 1344 - time: 0.0057 - loss_train: 0.7795837388385446 - loss_val: 0.9239222506336843\n",
      "Epoch: 1345 - time: 0.0041 - loss_train: 0.779423150858206 - loss_val: 0.9238963212633087\n",
      "Epoch: 1346 - time: 0.0082 - loss_train: 0.779262773085313 - loss_val: 0.9238706907165919\n",
      "Epoch: 1347 - time: 0.0152 - loss_train: 0.7791026052040545 - loss_val: 0.9238453580511892\n",
      "Epoch: 1348 - time: 0.0073 - loss_train: 0.7789426468959885 - loss_val: 0.9238203223228769\n",
      "Epoch: 1349 - time: 0.0044 - loss_train: 0.7787828978400853 - loss_val: 0.9237955825856191\n",
      "Epoch: 1350 - time: 0.0215 - loss_train: 0.7786233577127681 - loss_val: 0.9237711378916394\n",
      "Epoch: 1351 - time: 0.0082 - loss_train: 0.7784640261879553 - loss_val: 0.9237469872914855\n",
      "Epoch: 1352 - time: 0.0056 - loss_train: 0.7783049029370988 - loss_val: 0.9237231298340971\n",
      "Epoch: 1353 - time: 0.0066 - loss_train: 0.7781459876292289 - loss_val: 0.9236995645668701\n",
      "Epoch: 1354 - time: 0.0082 - loss_train: 0.7779872799309918 - loss_val: 0.9236762905357225\n",
      "Epoch: 1355 - time: 0.0042 - loss_train: 0.7778287795066922 - loss_val: 0.9236533067851563\n",
      "Epoch: 1356 - time: 0.0101 - loss_train: 0.7776704860183333 - loss_val: 0.9236306123583216\n",
      "Epoch: 1357 - time: 0.0129 - loss_train: 0.7775123991256576 - loss_val: 0.9236082062970763\n",
      "Epoch: 1358 - time: 0.0046 - loss_train: 0.7773545184861873 - loss_val: 0.9235860876420476\n",
      "Epoch: 1359 - time: 0.0137 - loss_train: 0.7771968437552634 - loss_val: 0.9235642554326913\n",
      "Epoch: 1360 - time: 0.0092 - loss_train: 0.7770393745860884 - loss_val: 0.9235427087073524\n",
      "Epoch: 1361 - time: 0.0041 - loss_train: 0.776882110629763 - loss_val: 0.923521446503319\n",
      "Epoch: 1362 - time: 0.0112 - loss_train: 0.776725051535328 - loss_val: 0.9235004678568841\n",
      "Epoch: 1363 - time: 0.0076 - loss_train: 0.7765681969498021 - loss_val: 0.9234797718033964\n",
      "Epoch: 1364 - time: 0.0067 - loss_train: 0.7764115465182235 - loss_val: 0.9234593573773198\n",
      "Epoch: 1365 - time: 0.0178 - loss_train: 0.7762550998836864 - loss_val: 0.9234392236122846\n",
      "Epoch: 1366 - time: 0.0069 - loss_train: 0.7760988566873809 - loss_val: 0.9234193695411425\n",
      "Epoch: 1367 - time: 0.0061 - loss_train: 0.7759428165686327 - loss_val: 0.9233997941960183\n",
      "Epoch: 1368 - time: 0.0114 - loss_train: 0.7757869791649395 - loss_val: 0.9233804966083614\n",
      "Epoch: 1369 - time: 0.0044 - loss_train: 0.7756313441120108 - loss_val: 0.9233614758089973\n",
      "Epoch: 1370 - time: 0.0062 - loss_train: 0.7754759110438045 - loss_val: 0.9233427308281767\n",
      "Epoch: 1371 - time: 0.0145 - loss_train: 0.775320679592565 - loss_val: 0.9233242606956256\n",
      "Epoch: 1372 - time: 0.0040 - loss_train: 0.7751656493888616 - loss_val: 0.9233060644405919\n",
      "Epoch: 1373 - time: 0.0041 - loss_train: 0.7750108200616238 - loss_val: 0.9232881410918945\n",
      "Epoch: 1374 - time: 0.0055 - loss_train: 0.774856191238179 - loss_val: 0.9232704896779697\n",
      "Epoch: 1375 - time: 0.0042 - loss_train: 0.7747017625442898 - loss_val: 0.9232531092269162\n",
      "Epoch: 1376 - time: 0.0041 - loss_train: 0.7745475336041887 - loss_val: 0.9232359987665418\n",
      "Epoch: 1377 - time: 0.0040 - loss_train: 0.7743935040406157 - loss_val: 0.9232191573244057\n",
      "Epoch: 1378 - time: 0.0046 - loss_train: 0.7742396734748525 - loss_val: 0.9232025839278637\n",
      "Epoch: 1379 - time: 0.0062 - loss_train: 0.7740860415267589 - loss_val: 0.9231862776041112\n",
      "Epoch: 1380 - time: 0.0050 - loss_train: 0.7739326078148083 - loss_val: 0.9231702373802239\n",
      "Epoch: 1381 - time: 0.0055 - loss_train: 0.77377937195612 - loss_val: 0.9231544622832021\n",
      "Epoch: 1382 - time: 0.0061 - loss_train: 0.7736263335664976 - loss_val: 0.923138951340007\n",
      "Epoch: 1383 - time: 0.0078 - loss_train: 0.7734734922604605 - loss_val: 0.9231237035776053\n",
      "Epoch: 1384 - time: 0.0089 - loss_train: 0.7733208476512773 - loss_val: 0.9231087180230059\n",
      "Epoch: 1385 - time: 0.0083 - loss_train: 0.7731683993510021 - loss_val: 0.9230939937032999\n",
      "Epoch: 1386 - time: 0.0074 - loss_train: 0.7730161469705048 - loss_val: 0.9230795296456982\n",
      "Epoch: 1387 - time: 0.0052 - loss_train: 0.7728640901195067 - loss_val: 0.9230653248775675\n",
      "Epoch: 1388 - time: 0.0066 - loss_train: 0.7727122284066108 - loss_val: 0.9230513784264704\n",
      "Epoch: 1389 - time: 0.0116 - loss_train: 0.7725605614393356 - loss_val: 0.9230376893201983\n",
      "Epoch: 1390 - time: 0.0076 - loss_train: 0.7724090888241465 - loss_val: 0.9230242565868086\n",
      "Epoch: 1391 - time: 0.0067 - loss_train: 0.7722578101664872 - loss_val: 0.9230110792546591\n",
      "Epoch: 1392 - time: 0.0116 - loss_train: 0.7721067250708119 - loss_val: 0.9229981563524426\n",
      "Epoch: 1393 - time: 0.0047 - loss_train: 0.7719558331406156 - loss_val: 0.9229854869092208\n",
      "Epoch: 1394 - time: 0.0066 - loss_train: 0.7718051339784651 - loss_val: 0.922973069954457\n",
      "Epoch: 1395 - time: 0.0113 - loss_train: 0.7716546271860294 - loss_val: 0.9229609045180491\n",
      "Epoch: 1396 - time: 0.0059 - loss_train: 0.771504312364109 - loss_val: 0.9229489896303612\n",
      "Epoch: 1397 - time: 0.0039 - loss_train: 0.771354189112667 - loss_val: 0.9229373243222551\n",
      "Epoch: 1398 - time: 0.0060 - loss_train: 0.7712042570308565 - loss_val: 0.922925907625123\n",
      "Epoch: 1399 - time: 0.0056 - loss_train: 0.7710545157170521 - loss_val: 0.9229147385709143\n",
      "Epoch: 1400 - time: 0.0096 - loss_train: 0.7709049647688764 - loss_val: 0.9229038161921692\n",
      "Epoch: 1401 - time: 0.0052 - loss_train: 0.7707556037832303 - loss_val: 0.9228931395220459\n",
      "Epoch: 1402 - time: 0.0064 - loss_train: 0.7706064323563189 - loss_val: 0.9228827075943509\n",
      "Epoch: 1403 - time: 0.0058 - loss_train: 0.7704574500836815 - loss_val: 0.9228725194435667\n",
      "Epoch: 1404 - time: 0.0102 - loss_train: 0.7703086565602166 - loss_val: 0.9228625741048792\n",
      "Epoch: 1405 - time: 0.0052 - loss_train: 0.7701600513802122 - loss_val: 0.9228528706142061\n",
      "Epoch: 1406 - time: 0.0090 - loss_train: 0.7700116341373688 - loss_val: 0.9228434080082237\n",
      "Epoch: 1407 - time: 0.0079 - loss_train: 0.7698634044248294 - loss_val: 0.922834185324394\n",
      "Epoch: 1408 - time: 0.0035 - loss_train: 0.7697153618352026 - loss_val: 0.9228252016009882\n",
      "Epoch: 1409 - time: 0.0064 - loss_train: 0.7695675059605903 - loss_val: 0.9228164558771159\n",
      "Epoch: 1410 - time: 0.0080 - loss_train: 0.7694198363926127 - loss_val: 0.9228079471927497\n",
      "Epoch: 1411 - time: 0.0050 - loss_train: 0.7692723527224334 - loss_val: 0.922799674588745\n",
      "Epoch: 1412 - time: 0.0034 - loss_train: 0.7691250545407833 - loss_val: 0.9227916371068732\n",
      "Epoch: 1413 - time: 0.0098 - loss_train: 0.7689779414379876 - loss_val: 0.9227838337898376\n",
      "Epoch: 1414 - time: 0.0079 - loss_train: 0.7688310130039869 - loss_val: 0.9227762636813036\n",
      "Epoch: 1415 - time: 0.0052 - loss_train: 0.7686842688283636 - loss_val: 0.9227689258259146\n",
      "Epoch: 1416 - time: 0.0066 - loss_train: 0.7685377085003636 - loss_val: 0.9227618192693207\n",
      "Epoch: 1417 - time: 0.0069 - loss_train: 0.7683913316089211 - loss_val: 0.9227549430581994\n",
      "Epoch: 1418 - time: 0.0067 - loss_train: 0.7682451377426807 - loss_val: 0.922748296240278\n",
      "Epoch: 1419 - time: 0.0064 - loss_train: 0.7680991264900198 - loss_val: 0.9227418778643537\n",
      "Epoch: 1420 - time: 0.0036 - loss_train: 0.7679532974390718 - loss_val: 0.9227356869803147\n",
      "Epoch: 1421 - time: 0.0034 - loss_train: 0.7678076501777473 - loss_val: 0.9227297226391654\n",
      "Epoch: 1422 - time: 0.0158 - loss_train: 0.7676621842937564 - loss_val: 0.9227239838930416\n",
      "Epoch: 1423 - time: 0.0053 - loss_train: 0.76751689937463 - loss_val: 0.9227184697952341\n",
      "Epoch: 1424 - time: 0.0046 - loss_train: 0.7673717950077406 - loss_val: 0.9227131794002077\n",
      "Epoch: 1425 - time: 0.0063 - loss_train: 0.7672268707803231 - loss_val: 0.9227081117636201\n",
      "Epoch: 1426 - time: 0.0041 - loss_train: 0.7670821262794961 - loss_val: 0.9227032659423426\n",
      "Epoch: 1427 - time: 0.0045 - loss_train: 0.766937561092282 - loss_val: 0.9226986409944776\n",
      "Epoch: 1428 - time: 0.0040 - loss_train: 0.7667931748056256 - loss_val: 0.9226942359793796\n",
      "Epoch: 1429 - time: 0.0107 - loss_train: 0.7666489670064147 - loss_val: 0.9226900499576702\n",
      "Epoch: 1430 - time: 0.0064 - loss_train: 0.7665049372815008 - loss_val: 0.9226860819912585\n",
      "Epoch: 1431 - time: 0.0082 - loss_train: 0.7663610852177153 - loss_val: 0.9226823311433583\n",
      "Epoch: 1432 - time: 0.0167 - loss_train: 0.7662174104018916 - loss_val: 0.9226787964785049\n",
      "Epoch: 1433 - time: 0.0136 - loss_train: 0.76607391242088 - loss_val: 0.9226754770625737\n",
      "Epoch: 1434 - time: 0.0047 - loss_train: 0.7659305908615694 - loss_val: 0.9226723719627951\n",
      "Epoch: 1435 - time: 0.0053 - loss_train: 0.765787445310903 - loss_val: 0.9226694802477726\n",
      "Epoch: 1436 - time: 0.0061 - loss_train: 0.7656444753558971 - loss_val: 0.9226668009874998\n",
      "Epoch: 1437 - time: 0.0049 - loss_train: 0.765501680583658 - loss_val: 0.9226643332533732\n",
      "Epoch: 1438 - time: 0.0043 - loss_train: 0.7653590605813994 - loss_val: 0.9226620761182116\n",
      "Epoch: 1439 - time: 0.0045 - loss_train: 0.7652166149364589 - loss_val: 0.9226600286562701\n",
      "Epoch: 1440 - time: 0.0051 - loss_train: 0.7650743432363152 - loss_val: 0.9226581899432549\n",
      "Epoch: 1441 - time: 0.0055 - loss_train: 0.7649322450686042 - loss_val: 0.922656559056339\n",
      "Epoch: 1442 - time: 0.0083 - loss_train: 0.7647903200211353 - loss_val: 0.922655135074177\n",
      "Epoch: 1443 - time: 0.0091 - loss_train: 0.7646485676819064 - loss_val: 0.9226539170769196\n",
      "Epoch: 1444 - time: 0.0040 - loss_train: 0.7645069876391205 - loss_val: 0.9226529041462269\n",
      "Epoch: 1445 - time: 0.0056 - loss_train: 0.7643655794812014 - loss_val: 0.9226520953652839\n",
      "Epoch: 1446 - time: 0.0142 - loss_train: 0.7642243427968065 - loss_val: 0.9226514898188143\n",
      "Epoch: 1447 - time: 0.0060 - loss_train: 0.7640832771748441 - loss_val: 0.9226510865930914\n",
      "Epoch: 1448 - time: 0.0066 - loss_train: 0.7639423822044873 - loss_val: 0.922650884775956\n",
      "Epoch: 1449 - time: 0.0196 - loss_train: 0.7638016574751878 - loss_val: 0.9226508834568254\n",
      "Epoch: 1450 - time: 0.0057 - loss_train: 0.7636611025766903 - loss_val: 0.9226510817267087\n",
      "Epoch: 1451 - time: 0.0057 - loss_train: 0.7635207170990461 - loss_val: 0.9226514786782182\n",
      "Epoch: 1452 - time: 0.0071 - loss_train: 0.7633805006326274 - loss_val: 0.922652073405583\n",
      "Epoch: 1453 - time: 0.0098 - loss_train: 0.7632404527681405 - loss_val: 0.9226528650046603\n",
      "Epoch: 1454 - time: 0.0056 - loss_train: 0.7631005730966387 - loss_val: 0.9226538525729484\n",
      "Epoch: 1455 - time: 0.0061 - loss_train: 0.7629608612095348 - loss_val: 0.9226550352095966\n",
      "Epoch: 1456 - time: 0.0053 - loss_train: 0.7628213166986145 - loss_val: 0.9226564120154203\n",
      "Epoch: 1457 - time: 0.0057 - loss_train: 0.7626819391560491 - loss_val: 0.9226579820929095\n",
      "Epoch: 1458 - time: 0.0039 - loss_train: 0.762542728174407 - loss_val: 0.9226597445462403\n",
      "Epoch: 1459 - time: 0.0050 - loss_train: 0.7624036833466662 - loss_val: 0.9226616984812872\n",
      "Epoch: 1460 - time: 0.0080 - loss_train: 0.7622648042662266 - loss_val: 0.9226638430056348\n",
      "stop for early stopping\n",
      "--- 19.830846071243286 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 0.9226661772285841 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = TS[:1000,:-2]\n",
    "Y_train = TS[:1000,-2:]\n",
    "    \n",
    "X_val = TS[1000:1250,:-2]\n",
    "Y_val = TS[1000:1250,-2:]\n",
    "\n",
    "model = Mlp()\n",
    "model.add(52, activation=\"sigmoid\", input= 20, kernel_initializer = 1/np.sqrt(20), kernel_regularizer = 0.0001)\n",
    "model.add(2, activation=\"linear\", kernel_initializer = 1/np.sqrt(100), kernel_regularizer = 0.0001)\n",
    "\n",
    "model.set_optimizer(\n",
    "    SGD(\n",
    "        lr = 0.018200000000000004,\n",
    "        momentum = 0.8800000000000002,\n",
    "        nesterov = True\n",
    "    ))\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train,\n",
    "            Y_train, \n",
    "            epochs=10000, \n",
    "            validation_data = [X_val, Y_val],\n",
    "            es = 0.0001,\n",
    "            verbose=1) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "outputNet = model.predict(X_val)\n",
    "\n",
    "plt.plot(outputNet[:,-2], outputNet[:,-1], 'ro', markersize=0.3)\n",
    "plt.ylabel('y2')\n",
    "plt.xlabel('y1')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "printMSE(outputNet, Y_val, type = \"test\")\n",
    "plt.plot(model.history[\"loss_mse\"][500:])\n",
    "plt.plot(model.history[\"val_loss_mse\"][500:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
